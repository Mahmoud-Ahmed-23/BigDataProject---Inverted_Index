Identification of which sense of a word is being used
 Disambiguation  redirects here  For information on Wikipedia disambiguation pages  see Wikipedia Disambiguation  For other uses  see Disambiguation  disambiguation  
Word sense disambiguation is the process of identifying which sense of a word is meant in a sentence or other segment of context  In human language processing and cognition  it is usually subconscious 
Given that natural language requires reflection of neurological reality  as shaped by the abilities provided by the brain s neural networks  computer science has had a long term challenge in developing the ability in computers to do natural language processing and machine learning 
Many techniques have been researched  including dictionary based methods that use the knowledge encoded in lexical resources  supervised machine learning methods in which a classifier is trained for each distinct word on a corpus of manually sense annotated examples  and completely unsupervised methods that cluster occurrences of words  thereby inducing word senses  Among these  supervised learning approaches have been the most successful algorithms to date 
Accuracy of current algorithms is difficult to state without a host of caveats  In English  accuracy at the coarse grained  homograph  level is routinely above      as of        with some methods on particular homographs achieving over      On finer grained sense distinctions  top accuracies from       to       have been reported in evaluation exercises  SemEval       Senseval     where the baseline accuracy of the simplest possible algorithm of always choosing the most frequent sense was       and      respectively 


Variants edit 
Disambiguation requires two strict inputs  a dictionary to specify the senses which are to be disambiguated and a corpus of language data to be disambiguated  in some methods  a training corpus of language examples is also required   WSD task has two variants   lexical sample   disambiguating the occurrences of a small sample of target words which were previously selected  and  all words  task  disambiguation of all the words in a running text    All words  task is generally considered a more realistic form of evaluation  but the corpus is more expensive to produce because human annotators have to read the definitions for each word in the sequence every time they need to make a tagging judgement  rather than once for a block of instances for the same target word 

History edit 
WSD was first formulated as a distinct computational task during the early days of machine translation in the     s  making it one of the oldest problems in computational linguistics  Warren Weaver first introduced the problem in a computational context in his      memorandum on translation             Later  Bar Hillel        argued            that WSD could not be solved by  electronic computer  because of the need in general to model all world knowledge 
In the     s  WSD was a subtask of semantic interpretation systems developed within the field of artificial intelligence  starting with Wilks  preference semantics  However  since WSD systems were at the time largely rule based and hand coded they were prone to a knowledge acquisition bottleneck 
By the     s large scale lexical resources  such as the Oxford Advanced Learner s Dictionary of Current English  OALD   became available  hand coding was replaced with knowledge automatically extracted from these resources  but disambiguation was still knowledge based or dictionary based 
In the     s  the statistical revolution advanced computational linguistics  and WSD became a paradigm problem on which to apply supervised machine learning techniques 
The     s saw supervised techniques reach a plateau in accuracy  and so attention has shifted to coarser grained senses  domain adaptation  semi supervised and unsupervised corpus based systems  combinations of different methods  and the return of knowledge based systems via graph based methods  Still  supervised systems continue to perform best 

Difficulties edit 
Differences between dictionaries edit 
One problem with word sense disambiguation is deciding what the senses are  as different dictionaries and thesauruses will provide different divisions of words into senses  Some researchers have suggested choosing a particular dictionary  and using its set of senses to deal with this issue  Generally  however  research results using broad distinctions in senses have been much better than those using narrow ones                        Most researchers continue to work on fine grained WSD 
Most research in the field of WSD is performed by using WordNet as a reference sense inventory for English  WordNet is a computational lexicon that encodes concepts as synonym sets  e g  the concept of car is encoded as   car  auto  automobile  machine  motorcar     Other resources used for disambiguation purposes include Roget s Thesaurus            and Wikipedia             More recently  BabelNet  a multilingual encyclopedic dictionary  has been used for multilingual WSD            

Part of speech tagging edit 
In any real test  part of speech tagging and sense tagging have proven to be very closely related  with each potentially imposing constraints upon the other  The question whether these tasks should be kept together or decoupled is still not unanimously resolved  but recently scientists incline to test these things separately  e g  in the Senseval SemEval competitions parts of speech are provided as input for the text to disambiguate  
Both WSD and part of speech tagging involve disambiguating or tagging with words  However  algorithms used for one do not tend to work well for the other  mainly because the part of speech of a word is primarily determined by the immediately adjacent one to three words  whereas the sense of a word may be determined by words further away  The success rate for part of speech tagging algorithms is at present much higher than that for WSD  state of the art being around                accuracy or better  as compared to less than         citation needed      accuracy in word sense disambiguation with supervised learning  These figures are typical for English  and may be very different from those for other languages 

Inter judge variance edit 
Another problem is inter judge variance  WSD systems are normally tested by having their results on a task compared against those of a human  However  while it is relatively easy to assign parts of speech to text  training people to tag senses has been proven to be far more difficult             While users can memorize all of the possible parts of speech a word can take  it is often impossible for individuals to memorize all of the senses a word can take  Moreover  humans do not agree on the task at hand   give a list of senses and sentences  and humans will not always agree on which word belongs in which sense             
As human performance serves as the standard  it is an upper bound for computer performance  Human performance  however  is much better on coarse grained than fine grained distinctions  so this again is why research on coarse grained distinctions                         has been put to test in recent WSD evaluation exercises                       

Sense inventory and algorithms  task dependency edit 
A task independent sense inventory is not a coherent concept              each task requires its own division of word meaning into senses relevant to the task  Additionally  completely different algorithms might be required by different applications  In machine translation  the problem takes the form of target word selection  The  senses  are words in the target language  which often correspond to significant meaning distinctions in the source language   bank  could translate to the French banque   that is   financial bank  or rive   that is   edge of river    In information retrieval  a sense inventory is not necessarily required  because it is enough to know that a word is used in the same sense in the query and a retrieved document  what sense that is  is unimportant 

Discreteness of senses edit 
Finally  the very notion of  word sense  is slippery and controversial  Most people can agree in distinctions at the coarse grained homograph level  e g   pen as writing instrument or enclosure   but go down one level to fine grained polysemy  and disagreements arise  For example  in Senseval    which used fine grained sense distinctions  human annotators agreed in only     of word occurrences              Word meaning is in principle infinitely variable and context sensitive  It does not divide up easily into distinct or discrete sub meanings              Lexicographers frequently discover in corpora loose and overlapping word meanings  and standard or conventional meanings extended  modulated  and exploited in a bewildering variety of ways  The art of lexicography is to generalize from the corpus to definitions that evoke and explain the full range of meaning of a word  making it seem like words are well behaved semantically  However  it is not at all clear if these same meaning distinctions are applicable in computational applications  as the decisions of lexicographers are usually driven by other considerations  In       a task   named lexical substitution   was proposed as a possible solution to the sense discreteness problem              The task consists of providing a substitute for a word in context that preserves the meaning of the original word  potentially  substitutes can be chosen from the full lexicon of the target language  thus overcoming discreteness  

Approaches and methods edit 
There are two main approaches to WSD   deep approaches and shallow approaches 
Deep approaches presume access to a comprehensive body of world knowledge  These approaches are generally not considered to be very successful in practice  mainly because such a body of knowledge does not exist in a computer readable format  outside very limited domains              Additionally due to the long tradition in computational linguistics  of trying such approaches in terms of coded knowledge and in some cases  it can be hard to distinguish between knowledge involved in linguistic or world knowledge  The first attempt was that by Margaret Masterman and her colleagues  at the Cambridge Language Research Unit in England  in the     s  This attempt used as data a punched card version of Roget s Thesaurus and its numbered  heads   as an indicator of topics and looked for repetitions in text  using a set intersection algorithm  It was not very successful              but had strong relationships to later work  especially Yarowsky s machine learning optimisation of a thesaurus method in the     s 
Shallow approaches do not try to understand the text  but instead consider the surrounding words  These rules can be automatically derived by the computer  using a training corpus of words tagged with their word senses  This approach  while theoretically not as powerful as deep approaches  gives superior results in practice  due to the computer s limited world knowledge 
There are four conventional approaches to WSD 

Dictionary  and knowledge based methods  These rely primarily on dictionaries  thesauri  and lexical knowledge bases  without using any corpus evidence 
Semi supervised or minimally supervised methods  These make use of a secondary source of knowledge such as a small annotated corpus as seed data in a bootstrapping process  or a word aligned bilingual corpus 
Supervised methods  These make use of sense annotated corpora to train from 
Unsupervised methods  These eschew  almost  completely external information and work directly from raw unannotated corpora  These methods are also known under the name of word sense discrimination 
Almost all these approaches work by defining a window of n content words around each word to be disambiguated in the corpus  and statistically analyzing those n surrounding words  Two shallow approaches used to train and then disambiguate are Na ve Bayes classifiers and decision trees  In recent research  kernel based methods such as support vector machines have shown superior performance in supervised learning  Graph based approaches have also gained much attention from the research community  and currently achieve performance close to the state of the art 

Dictionary  and knowledge based methods edit 
The Lesk algorithm             is the seminal dictionary based method  It is based on the hypothesis that words used together in text are related to each other and that the relation can be observed in the definitions of the words and their senses  Two  or more  words are disambiguated by finding the pair of dictionary senses with the greatest word overlap in their dictionary definitions  For example  when disambiguating the words in  pine cone   the definitions of the appropriate senses both include the words evergreen and tree  at least in one dictionary   A similar approach             searches for the shortest path between two words  the second word is iteratively searched among the definitions of every semantic variant of the first word  then among the definitions of every semantic variant of each word in the previous definitions and so on  Finally  the first word is disambiguated by selecting the semantic variant which minimizes the distance from the first to the second word 
An alternative to the use of the definitions is to consider general word sense relatedness and to compute the semantic similarity of each pair of word senses based on a given lexical knowledge base such as WordNet  Graph based methods reminiscent of spreading activation research of the early days of AI research have been applied with some success  More complex graph based approaches have been shown to perform almost as well as supervised methods             or even outperforming them on specific domains                         Recently  it has been reported that simple graph connectivity measures  such as degree  perform state of the art WSD in the presence of a sufficiently rich lexical knowledge base              Also  automatically transferring knowledge in the form of semantic relations from Wikipedia to WordNet has been shown to boost simple knowledge based methods  enabling them to rival the best supervised systems and even outperform them in a domain specific setting             
The use of selectional preferences  or selectional restrictions  is also useful  for example  knowing that one typically cooks food  one can disambiguate the word bass in  I am cooking basses   i e   it s not a musical instrument  

Supervised methods edit 
Supervised methods are based on the assumption that the context can provide enough evidence on its own to disambiguate words  hence  common sense and reasoning are deemed unnecessary   Probably every machine learning algorithm going has been applied to WSD  including associated techniques such as feature selection  parameter optimization  and ensemble learning  Support Vector Machines and memory based learning have been shown to be the most successful approaches  to date  probably because they can cope with the high dimensionality of the feature space  However  these supervised methods are subject to a new knowledge acquisition bottleneck since they rely on substantial amounts of manually sense tagged corpora for training  which are laborious and expensive to create 

Semi supervised methods edit 
Because of the lack of training data  many word sense disambiguation algorithms use semi supervised learning  which allows both labeled and unlabeled data  The Yarowsky algorithm was an early example of such an algorithm              It uses the  One sense per collocation  and the  One sense per discourse  properties of human languages for word sense disambiguation  From observation  words tend to exhibit only one sense in most given discourse and in a given collocation             
The bootstrapping approach starts from a small amount of seed data for each word  either manually tagged training examples or a small number of surefire decision rules  e g    play  in the context of  bass  almost always indicates the musical instrument   The seeds are used to train an initial classifier  using any supervised method  This classifier is then used on the untagged portion of the corpus to extract a larger training set  in which only the most confident classifications are included  The process repeats  each new classifier being trained on a successively larger training corpus  until the whole corpus is consumed  or until a given maximum number of iterations is reached 
Other semi supervised techniques use large quantities of untagged corpora to provide co occurrence information that supplements the tagged corpora  These techniques have the potential to help in the adaptation of supervised models to different domains 
Also  an ambiguous word in one language is often translated into different words in a second language depending on the sense of the word  Word aligned bilingual corpora have been used to infer cross lingual sense distinctions  a kind of semi supervised system      citation needed     

Unsupervised methods edit 
Main article  Word sense induction
Unsupervised learning is the greatest challenge for WSD researchers  The underlying assumption is that similar senses occur in similar contexts  and thus senses can be induced from text by clustering word occurrences using some measure of similarity of context              a task referred to as word sense induction or discrimination  Then  new occurrences of the word can be classified into the closest induced clusters senses  Performance has been lower than for the other methods described above  but comparisons are difficult since senses induced must be mapped to a known dictionary of word senses  If a mapping to a set of dictionary senses is not desired  cluster based evaluations  including measures of entropy and purity  can be performed  Alternatively  word sense induction methods can be tested and compared within an application  For instance  it has been shown that word sense induction improves Web search result clustering by increasing the quality of result clusters and the degree diversification of result lists                          It is hoped that unsupervised learning will overcome the knowledge acquisition bottleneck because they are not dependent on manual effort 
Representing words considering their context through fixed size dense vectors  word embeddings  has become one of the most fundamental blocks in several NLP systems                                      Even though most of traditional word embedding techniques conflate words with multiple meanings into a single vector representation  they still can be used to improve WSD              A simple approach to employ pre computed word embeddings to represent word senses is to compute the centroids of sense clusters                          In addition to word embedding techniques  lexical databases  e g   WordNet  ConceptNet  BabelNet  can also assist unsupervised systems in mapping words and their senses as dictionaries  Some techniques that combine lexical databases and word embeddings are presented in AutoExtend                         and Most Suitable Sense Annotation  MSSA               In AutoExtend              they present a method that decouples an object input representation into its properties  such as words and their word senses  AutoExtend uses a graph structure to map words  e g  text  and non word  e g  synsets in WordNet  objects as nodes and the relationship between nodes as edges  The relations  edges  in AutoExtend can either express the addition or similarity between its nodes  The former captures the intuition behind the offset calculus              while the latter defines the similarity between two nodes  In MSSA              an unsupervised disambiguation system uses the similarity between word senses in a fixed context window to select the most suitable word sense using a pre trained word embedding model and WordNet  For each context window  MSSA calculates the centroid of each word sense definition by averaging the word vectors of its words in WordNet s glosses  i e   short defining gloss and one or more usage example  using a pre trained word embedding model  These centroids are later used to select the word sense with the highest similarity of a target word to its immediately adjacent neighbors  i e   predecessor and successor words   After all words are annotated and disambiguated  they can be used as a training corpus in any standard word embedding technique  In its improved version  MSSA can make use of word sense embeddings to repeat its disambiguation process iteratively 

Other approaches edit 
Other approaches may vary differently in their methods 

Domain driven disambiguation                         
Identification of dominant word senses                                     
WSD using Cross Lingual Evidence                         
WSD solution in John Ball s language independent NLU combining Patom Theory and RRG  Role and Reference Grammar 
Type inference in constraint based grammars            
Other languages edit 
Hindi  Lack of lexical resources in Hindi have hindered the performance of supervised models of WSD  while the unsupervised models suffer due to extensive morphology  A possible solution to this problem is the design of a WSD model by means of parallel corpora                          The creation of the Hindi WordNet has paved way for several Supervised methods which have been proven to produce a higher accuracy in disambiguating nouns             
Local impediments and summary edit 
The knowledge acquisition bottleneck is perhaps the major impediment to solving the WSD problem  Unsupervised methods rely on knowledge about word senses  which is only sparsely formulated in dictionaries and lexical databases  Supervised methods depend crucially on the existence of manually annotated examples for every word sense  a requisite that can so far     when       be met only for a handful of words for testing purposes  as it is done in the Senseval exercises 
One of the most promising trends in WSD research is using the largest corpus ever accessible  the World Wide Web  to acquire lexical information automatically              WSD has been traditionally understood as an intermediate language engineering technology which could improve applications such as information retrieval  IR   In this case  however  the reverse is also true  web search engines implement simple and robust IR techniques that can successfully mine the Web for information to use in WSD  The historic lack of training data has provoked the appearance of some new algorithms and techniques  as described in Automatic acquisition of sense tagged corpora 

External knowledge sources edit 
Knowledge is a fundamental component of WSD  Knowledge sources provide data which are essential to associate senses with words  They can vary from corpora of texts  either unlabeled or annotated with word senses  to machine readable dictionaries  thesauri  glossaries  ontologies  etc  They can be                         classified as follows 
Structured 

Machine readable dictionaries  MRDs 
Ontologies
Thesauri
Unstructured 

Collocation resources
Other resources  such as word frequency lists  stoplists  domain labels              etc  
Corpora  raw corpora and sense annotated corpora
Evaluation edit 
Comparing and evaluating different WSD systems is extremely difficult  because of the different test sets  sense inventories  and knowledge resources adopted  Before the organization of specific evaluation campaigns most systems were assessed on in house  often small scale  data sets  In order to test one s algorithm  developers should spend their time to annotate all word occurrences  And comparing methods even on the same corpus is not eligible if there is different sense inventories 
In order to define common evaluation datasets and procedures  public evaluation campaigns have been organized  Senseval  now renamed SemEval  is an international word sense disambiguation competition  held every three years since       Senseval           Senseval           Senseval       usurped              and its successor  SemEval         The objective of the competition is to organize different lectures  preparing and hand annotating corpus for testing systems  perform a comparative evaluation of WSD systems in several kinds of tasks  including all words and lexical sample WSD for different languages  and  more recently  new tasks such as semantic role labeling  gloss WSD  lexical substitution  etc  The systems submitted for evaluation to these competitions usually integrate different techniques and often combine supervised and knowledge based methods  especially for avoiding bad performance in lack of training examples  
In recent years            the WSD evaluation task choices had grown and the criterion for evaluating WSD has changed drastically depending on the variant of the WSD evaluation task  Below enumerates the variety of WSD tasks 

Task design choices edit 
As technology evolves  the Word Sense Disambiguation  WSD  tasks grows in different flavors towards various research directions and for more languages 

Classic monolingual WSD evaluation tasks use WordNet as the sense inventory and are largely based on supervised semi supervised classification with the manually sense annotated corpora             
Classic English WSD uses the Princeton WordNet as it sense inventory and the primary classification input is normally based on the SemCor corpus 
Classical WSD for other languages uses their respective WordNet as sense inventories and sense annotated corpora tagged in their respective languages  Often researchers will also tapped on the SemCor corpus and aligned bitexts with English as its source language
Cross lingual WSD evaluation task is also focused on WSD across   or more languages simultaneously  Unlike the Multilingual WSD tasks  instead of providing manually sense annotated examples for each sense of a polysemous noun  the sense inventory is built up on the basis of parallel corpora  e g  Europarl corpus             
Multilingual WSD evaluation tasks focused on WSD across   or more languages simultaneously  using their respective WordNets as its sense inventories or BabelNet as multilingual sense inventory              It evolved from the Translation WSD evaluation tasks that took place in Senseval    A popular approach is to carry out monolingual WSD and then map the source language senses into the corresponding target word translations             
Word Sense Induction and Disambiguation task is a combined task evaluation where the sense inventory is first induced from a fixed training set data  consisting of polysemous words and the sentence that they occurred in  then WSD is performed on a different testing data set             
Software edit 
Babelfy              a unified state of the art system for multilingual Word Sense Disambiguation and Entity Linking
BabelNet API              a Java API for knowledge based multilingual Word Sense Disambiguation in   different languages using the BabelNet semantic network
WordNet  SenseRelate              a project that includes free  open source systems for word sense disambiguation and lexical sample sense disambiguation
UKB  Graph Base WSD              a collection of programs for performing graph based Word Sense Disambiguation and lexical similarity relatedness using a pre existing Lexical Knowledge Base            
pyWSD              python implementations of Word Sense Disambiguation  WSD  technologies
See also edit 



Wikimedia Commons has media related to Word sense disambiguation 


Linguistics portal
Controlled natural language
Entity linking
Judicial interpretation
Semantic unification
Sentence boundary disambiguation
Syntactic ambiguity
References edit 


  Weaver      

  Bar Hillel       pp               

  a b c Navigli  Litkowski  amp  Hargraves       pp             

  a b Pradhan et al        pp             

  Yarowsky       pp               

  Mihalcea      

  A  Moro  A  Raganato  R  Navigli  Entity Linking meets Word Sense Disambiguation  a Unified Approach  Archived            at the Wayback Machine  Transactions of the Association for Computational Linguistics  TACL      pp                

  Martinez  Angel R   January         Part of speech tagging  Part of speech tagging   Wiley Interdisciplinary Reviews  Computational Statistics                  doi         wics      S CID                Archived from the original on             Retrieved            

  Fellbaum      

  Snyder  amp  Palmer       pp             

  Navigli       pp               

  Snow et al        pp                 

  Palmer  Babko Malaya  amp  Dang       pp             

  Edmonds      

  Kilgarrif       pp               sfn error  no target  CITEREFKilgarrif      help 

  McCarthy  amp  Navigli       pp               

  Lenat  amp  Guha      

  Wilks  Slator  amp  Guthrie      

  Lesk       pp             

  Diamantini  C   Mircoli  A   Potena  D   Storti  E                 Semantic disambiguation in a social information discovery system        International Conference on Collaboration Technologies and Systems  CTS   pp                doi         CTS               ISBN                         S CID               

  Navigli  amp  Velardi       pp                 

  Agirre  Lopez de Lacalle  amp  Soroa       pp                 

  Navigli  amp  Lapata       pp               

  Ponzetto  amp  Navigli       pp                 

  Yarowsky       pp               

  Mitkov  Ruslan                 Two claims about senses   The Oxford Handbook of Computational Linguistics  OUP  p            ISBN                         Archived from the original on             Retrieved            

  Sch tze       pp              

  Navigli  amp  Crisafulli      

  Di Marco  amp  Navigli      

  a b Mikolov  Tomas  Chen  Kai  Corrado  Greg  Dean  Jeffrey                Efficient Estimation of Word Representations in Vector Space   arXiv            cs CL  

  Pennington  Jeffrey  Socher  Richard  Manning  Christopher          Glove  Global Vectors for Word Representation   Proceedings of the      Conference on Empirical Methods in Natural Language Processing  EMNLP   Stroudsburg  PA  USA  Association for Computational Linguistics  pp                  doi         v  d         S CID              

  Bojanowski  Piotr  Grave  Edouard  Joulin  Armand  Mikolov  Tomas  December         Enriching Word Vectors with Subword Information   Transactions of the Association for Computational Linguistics              arXiv             doi         tacl a        ISSN              X 

  Iacobacci  Ignacio  Pilehvar  Mohammad Taher  Navigli  Roberto          Embeddings for Word Sense Disambiguation  An Evaluation Study   Proceedings of the   th Annual Meeting of the Association for Computational Linguistics  Volume    Long Papers   Berlin  Germany  Association for Computational Linguistics           doi          v  P         hdl               Archived from the original on             Retrieved            

  Bhingardive  Sudha  Singh  Dhirendra  V  Rudramurthy  Redkar  Hanumant  Bhattacharyya  Pushpak          Unsupervised Most Frequent Sense Detection using Word Embeddings   Proceedings of the      Conference of the North American Chapter of the Association for Computational Linguistics  Human Language Technologies  Denver  Colorado  Association for Computational Linguistics  pp                  doi         v  N         S CID                Archived from the original on             Retrieved            

  Butnaru  Andrei  Ionescu  Radu Tudor  Hristea  Florentina          ShotgunWSD  An unsupervised algorithm for global word sense disambiguation inspired by DNA sequencing   Proceedings of the   th Conference of the European Chapter of the Association for Computational Linguistics           arXiv             Archived from the original on             Retrieved            

  Rothe  Sascha  Sch tze  Hinrich          AutoExtend  Extending Word Embeddings to Embeddings for Synsets and Lexemes   Volume    Long Papers  Association for Computational Linguistics and the International Joint Conference on Natural Language Processing  Proceedings of the   rd Annual Meeting of the Association for Computational Linguistics and the  th International Joint Conference on Natural Language Processing  Stroudsburg  Pennsylvania  USA  Association for Computational Linguistics  pp                  arXiv             Bibcode     arXiv         R  doi         v  p         S CID               

  a b Rothe  Sascha  Sch tze  Hinrich  September         AutoExtend  Combining Word Embeddings with Semantic Resources   Computational Linguistics                   doi         coli a        ISSN                

  a b Ruas  Terry  Grosky  William  Aizawa  Akiko  December         Multi sense embeddings through a word sense disambiguation process   Expert Systems with Applications                arXiv             doi         j eswa              hdl                 S CID               

  Gliozzo  Magnini  amp  Strapparava       pp               

  Buitelaar et al        pp               

  McCarthy et al        pp               

  Mohammad  amp  Hirst       pp               

  Lapata  amp  Keller       pp               

  Ide  Erjavec  amp  Tufis       pp             

  Chan  amp  Ng       pp                 

  Shieber  Stuart M          Constraint based Grammar Formalisms  Parsing and Type Inference for Natural and Computer Languages  Massachusetts  MIT Press  ISBN                         Archived from the original on             Retrieved            

  Bhattacharya  Indrajit  Lise Getoor  and Yoshua Bengio  Unsupervised sense disambiguation using bilingual probabilistic models Archived            at the Wayback Machine  Proceedings of the   nd Annual Meeting on Association for Computational Linguistics  Association for Computational Linguistics       

  Diab  Mona  and Philip Resnik  An unsupervised method for word sense tagging using parallel corpora Archived            at the Wayback Machine  Proceedings of the   th Annual Meeting on Association for Computational Linguistics  Association for Computational Linguistics       

  Manish Sinha  Mahesh Kumar  Prabhakar Pande  Laxmi Kashyap  and Pushpak Bhattacharyya  Hindi word sense disambiguation Archived            at the Wayback Machine  In International Symposium on Machine Translation  Natural Language Processing and Translation Support Systems  Delhi  India       

  Kilgarrif  amp  Grefenstette       pp                sfn error  no target  CITEREFKilgarrifGrefenstette      help 

  Litkowski       pp               

  Agirre  amp  Stevenson       pp               

  Magnini  amp  Cavagli        pp                 

  Lucia Specia  Maria das Gracas Volpe Nunes  Gabriela Castelo Branco Ribeiro  and Mark Stevenson  Multilingual versus monolingual WSD Archived            at the Wayback Machine  In EACL      Workshop on Making Sense of Sense  Bringing Psycholinguistics and Computational Linguistics Together  pages        Trento  Italy  April      

  Els Lefever and Veronique Hoste  SemEval      task    cross lingual word sense disambiguation Archived            at the Wayback Machine  Proceedings of the Workshop on Semantic Evaluations  Recent Achievements and Future Directions  June              Boulder  Colorado 

  R  Navigli  D  A  Jurgens  D  Vannella  SemEval      Task     Multilingual Word Sense Disambiguation Archived            at the Wayback Machine  Proc  of seventh International Workshop on Semantic Evaluation  SemEval   in the Second Joint Conference on Lexical and Computational Semantics   SEM        Atlanta  USA  June      th        pp          

  Lucia Specia  Maria das Gracas Volpe Nunes  Gabriela Castelo Branco Ribeiro  and Mark Stevenson  Multilingual versus monolingual WSD Archived            at the Wayback Machine  In EACL      Workshop on Making Sense of Sense  Bringing Psycholinguistics and Computational Linguistics Together  pages        Trento  Italy  April      

  Eneko Agirre and Aitor Soroa  Semeval      task     evaluating word sense induction and discrimination systems Archived            at the Wayback Machine  Proceedings of the  th International Workshop on Semantic Evaluations  pp        June              Prague  Czech Republic 

   Babelfy   Babelfy  Archived from the original on             Retrieved            

   BabelNet API   Babelnet org  Archived from the original on             Retrieved            

   WordNet  SenseRelate   Senserelate sourceforge net  Archived from the original on             Retrieved            

   UKB  Graph Base WSD   Ixa  si ehu es  Archived from the original on             Retrieved            

   Lexical Knowledge Base  LKB    Moin delph in net              Archived from the original on             Retrieved            

  alvations   pyWSD   Github com  Archived from the original on             Retrieved            


Works cited edit 

Agirre  E   Lopez de Lacalle  A   Soroa  A           Knowledge based WSD on Specific Domains  Performing better than Generic Supervised WSD   PDF   Proc  of IJCAI 
Agirre  E   Stevenson  M           Knowledge sources for WSD   In Agirre  E   Edmonds  P   eds    Word Sense Disambiguation  Algorithms and Applications  New York  Springer  ISBN                     
Bar Hillel  Y          Language and information  Reading  MA  Addison Wesley 
Buitelaar  P   Magnini  B   Strapparava  C   Vossen  P           Domain specific WSD   In Agirre  E   Edmonds  P   eds    Word Sense Disambiguation  Algorithms and Applications  New York  Springer 
Chan  Y  S   Ng  H  T          Scaling up word sense disambiguation via parallel texts  Proceedings of the   th National Conference on Artificial Intelligence  Pittsburgh  AAAI 
Di Marco  A   Navigli  R           Clustering and Diversifying Web Search Results with Graph Based Word Sense Induction   Computational Linguistics          MIT Press           doi         COLI a        S CID              
Edmonds  P           Designing a task for SENSEVAL     Tech  note   Brighton  UK  University of Brighton 
Fellbaum  Christiane          Analysis of a handwriting task   Proc  of ANLP    Workshop on Tagging Text with Lexical Semantics  Why  What  and How   Washington D C   cite book     CS  maint  location missing publisher  link 
Gliozzo  A   Magnini  B   Strapparava  C          Unsupervised domain relevance estimation for word sense disambiguation  PDF   Proceedings of the      Conference on Empirical Methods in Natural Language Processing  Barcelona  Spain  EMNLP 
Ide  N   Erjavec  T   Tufis  D          Sense discrimination with parallel corpora  PDF   Proceedings of ACL Workshop on Word Sense Disambiguation  Recent Successes and Future Directions  Philadelphia 
Lapata  M   Keller  F          An information retrieval approach to sense ranking  PDF   Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics  Rochester  New York  HLT NAACL 
Lenat  D   Guha  R  V          Building Large Knowledge Based Systems  Addison Wesley 
Lesk  M          Automatic sense disambiguation using machine readable dictionaries  How to tell a pine cone from an ice cream cone  PDF   Proc  of SIGDOC      th International Conference on Systems Documentation  Toronto  Canada 
Litkowski  K  C           Computational lexicons and dictionaries   In Brown  K  R   ed    Encyclopaedia of Language and Linguistics   nd      ed    Oxford  Elsevier Publishers 
Magnini  B   Cavagli   G          Integrating subject field codes into WordNet  Proceedings of the  nd Conference on Language Resources and Evaluation  Athens  Greece  LREC 
McCarthy  D   Koeling  R   Weeds  J   Carroll  J           Unsupervised acquisition of predominant word senses   PDF   Computational Linguistics                   doi         coli               
McCarthy  D   Navigli  R           The English Lexical Substitution Task   PDF   Language Resources and Evaluation          Springer           doi         s                  S CID               
Mihalcea  R   April        Using Wikipedia for Automatic Word Sense Disambiguation  PDF   Proc  of the North American Chapter of the Association for Computational Linguistics  Rochester  New York  NAACL  Archived from the original  PDF  on            
Mohammad  S   Hirst  G          Determining word sense dominance using a thesaurus  PDF   Proceedings of the   th Conference on European chapter of the Association for Computational Linguistics  Trento  Italy  EACL 
Navigli  R          Meaningful Clustering of Senses Helps Boost Word Sense Disambiguation Performance  PDF   Proc  of the   th Annual Meeting of the Association for Computational Linguistics joint with the   st International Conference on Computational Linguistics  Sydney  Australia  COLING ACL  Archived from the original  PDF  on            
Navigli  R   Crisafulli  G          Inducing Word Senses to Improve Web Search Result Clustering  PDF   Proc  of the      Conference on Empirical Methods in Natural Language Processing  MIT Stata Center  Massachusetts  US  EMNLP 
Navigli  R   Lapata  M           An Experimental Study of Graph Connectivity for Unsupervised Word Sense Disambiguation   PDF   IEEE Transactions on Pattern Analysis and Machine Intelligence          IEEE Press           doi         TPAMI          PMID                S CID              
Navigli  R   Litkowski  K   Hargraves  O          SemEval      Task     Coarse Grained English All Words Task  PDF   Proc  of Semeval      Workshop  SemEval   in the   th Annual Meeting of the Association for Computational Linguistics  Prague  Czech Republic  ACL 
Navigli  R   Velardi  P           Structural Semantic Interconnections  a Knowledge Based Approach to Word Sense Disambiguation   PDF   IEEE Transactions on Pattern Analysis and Machine Intelligence                     doi         TPAMI           PMID                S CID               
Palmer  M   Babko Malaya  O   Dang  H  T          Different sense granularities for different applications  PDF   Proceedings of the  nd Workshop on Scalable Natural Language Understanding Systems in HLT NAACL  Boston 
Ponzetto  S  P   Navigli  R          Knowledge rich Word Sense Disambiguation rivaling supervised systems  PDF   Proc  of the   th Annual Meeting of the Association for Computational Linguistics  ACL  Archived from the original  PDF  on            
Pradhan  S   Loper  E   Dligach  D   Palmer  M          SemEval      Task     English lexical sample  SRL and all words  PDF   Proc  of Semeval      Workshop  SEMEVAL   in the   th Annual Meeting of the Association for Computational Linguistics  Prague  Czech Republic  ACL 
Sch tze  H           Automatic word sense discrimination   PDF   Computational Linguistics                 
Snow  R   Prakash  S   Jurafsky  D   Ng  A  Y          Learning to Merge Word Senses  PDF   Proceedings of the      Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning  EMNLP CoNLL 
Snyder  B   Palmer  M          The English all words task  Proc  of the  rd International Workshop on the Evaluation of Systems for the Semantic Analysis of Text  Senseval     Barcelona  Spain  Archived from the original on            
Weaver  Warren          Translation   PDF   In Locke  W N   Booth  A D   eds    Machine Translation of Languages  Fourteen Essays  Cambridge  MA  MIT Press 
Wilks  Y   Slator  B   Guthrie  L          Electric Words  dictionaries  computers and meanings  Cambridge  Massachusetts  MIT Press 
Yarowsky  D          Word sense disambiguation using statistical models of Roget s categories trained on large corpora  Proc  of the   th conference on Computational linguistics  COLING 
Yarowsky  D          Unsupervised word sense disambiguation rivaling supervised methods  Proc  of the   rd Annual Meeting of the Association for Computational Linguistics 

Further reading edit 

Agirre  Eneko  Edmonds  Philip  eds          Word Sense Disambiguation  Algorithms and Applications  Springer  ISBN                     
Edmonds  Philip  Kilgarriff  Adam          Introduction to the special issue on evaluating word sense disambiguation systems   Journal of Natural Language Engineering                  doi         S                  S CID               
Ide  Nancy  V ronis  Jean          Word sense disambiguation  The state of the art   PDF   Computational Linguistics               
Jurafsky  Daniel  Martin  James H          Speech and Language Processing  New Jersey  US  Prentice Hall 
Kilgarriff  A           I don t believe in word senses   PDF   Comput  Human                  doi         A                S CID              
Kilgarriff  A   Grefenstette  G           Introduction to the special issue on the Web as corpus   PDF   Computational Linguistics                   doi                             S CID              
Manning  Christopher D   Sch tze  Hinrich         Foundations of Statistical Natural Language Processing  Cambridge  Massachusetts  MIT Press 
Navigli  Roberto          Word Sense Disambiguation  A Survey   PDF   ACM Computing Surveys                doi                          S CID             
Resnik  Philip  Yarowsky  David          Distinguishing systems and distinguishing senses  New evaluation methods for word sense disambiguation   Natural Language Engineering                  doi         S                  S CID               
Yarowsky  David          Word sense disambiguation   In Dale  et      al   eds    Handbook of Natural Language Processing  New York  Marcel Dekker  pp               

External links edit 



Look up disambiguation in Wiktionary  the free dictionary 

Computational Linguistics Special Issue on Word Sense Disambiguation       
Word Sense Disambiguation Tutorial by Rada Mihalcea and Ted Pedersen        
vteNatural language processingGeneral terms
AI complete
Bag of words
n gram
Bigram
Trigram
Computational linguistics
Natural language understanding
Stop words
Text processing
Text analysis
Argument mining
Collocation extraction
Concept mining
Coreference resolution
Deep linguistic processing
Distant reading
Information extraction
Named entity recognition
Ontology learning
Parsing
Semantic parsing
Syntactic parsing
Part of speech tagging
Semantic analysis
Semantic role labeling
Semantic decomposition
Semantic similarity
Sentiment analysis
Terminology extraction
Text mining
Textual entailment
Truecasing
Word sense disambiguation
Word sense induction
Text segmentation
Compound term processing
Lemmatisation
Lexical analysis
Text chunking
Stemming
Sentence segmentation
Word segmentation

Automatic summarization
Multi document summarization
Sentence extraction
Text simplification
Machine translation
Computer assisted
Example based
Rule based
Statistical
Transfer based
Neural
Distributional semantics models
BERT
Document term matrix
Explicit semantic analysis
fastText
GloVe
Language model  large 
Latent semantic analysis
Seq seq
Word embedding
Word vec
Language resources datasets and corporaTypes andstandards
Corpus linguistics
Lexical resource
Linguistic Linked Open Data
Machine readable dictionary
Parallel text
PropBank
Semantic network
Simple Knowledge Organization System
Speech corpus
Text corpus
Thesaurus  information retrieval 
Treebank
Universal Dependencies
Data
BabelNet
Bank of English
DBpedia
FrameNet
Google Ngram Viewer
UBY
WordNet
Wikidata
Automatic identificationand data capture
Speech recognition
Speech segmentation
Speech synthesis
Natural language generation
Optical character recognition
Topic model
Document classification
Latent Dirichlet allocation
Pachinko allocation
Computer assistedreviewing
Automated essay scoring
Concordancer
Grammar checker
Predictive text
Pronunciation assessment
Spell checker
Natural languageuser interface
Chatbot
Interactive fiction  cf  Syntax guessing 
Question answering
Virtual assistant
Voice user interface
Related
Formal semantics
Hallucination
Natural Language Toolkit
spaCy

Authority control databases  National GermanyUnited StatesIsrael





Retrieved from  https   en wikipedia org w index php title Word sense disambiguation amp oldid