Moral behaviours of man made machines
Machine ethics  or machine morality  computational morality  or computational ethics  is a part of the ethics of artificial intelligence concerned with adding or ensuring moral behaviors of man made machines that use artificial intelligence  otherwise known as artificial intelligent agents             Machine ethics differs from other ethical fields related to engineering and technology  It should not be confused with computer ethics  which focuses on human use of computers  It should also be distinguished from the philosophy of technology  which concerns itself with technology s grander social effects            


Definitions edit 
James H  Moor  one of the pioneering theoreticians in the field of computer ethics  defines four kinds of ethical robots  As an extensive researcher on the studies of philosophy of artificial intelligence  philosophy of mind  philosophy of science  and logic  Moor defines machines as ethical impact agents  implicit ethical agents  explicit ethical agents  or full ethical agents  A machine can be more than one type of agent            

Ethical impact agents  These are machine systems that carry an ethical impact whether intended or not  At the same time  they have the potential to act unethically  Moor gives a hypothetical example  the  Goodman agent   named after philosopher Nelson Goodman  The Goodman agent compares dates but has the millennium bug  This bug resulted from programmers who represented dates with only the last two digits of the year  so any dates after      would be misleadingly treated as earlier than those in the late   th century  The Goodman agent was thus an ethical impact agent before      and an unethical impact agent thereafter 
Implicit ethical agents  For the consideration of human safety  these agents are programmed to have a fail safe  or a built in virtue  They are not entirely ethical in nature  but rather programmed to avoid unethical outcomes 
Explicit ethical agents  These are machines capable of processing scenarios and acting on ethical decisions  machines that have algorithms to act ethically 
Full ethical agents  These are similar to explicit ethical agents in being able to make ethical decisions  But they also have human metaphysical features  i e   have free will  consciousness  and intentionality  
 See artificial systems and moral responsibility  

History edit 
Before the   st century the ethics of machines had largely been the subject of science fiction  mainly due to computing and artificial intelligence  AI  limitations  Although the definition of  machine ethics  has evolved since  the term was coined by Mitchell Waldrop in the      AI magazine article  A Question of Responsibility  One thing that is apparent from the above discussion is that intelligent machines will embody values  assumptions  and purposes  whether their programmers consciously intend them to or not  Thus  as computers and robots become more and more intelligent  it becomes imperative that we think carefully and explicitly about what those built in values are  Perhaps what we need is  in fact  a theory and practice of machine ethics  in the spirit of Asimov s three laws of robotics            
In       Towards Machine Ethics            was presented at the AAAI Workshop on Agent Organizations  Theory and Practice             Theoretical foundations for machine ethics were laid out 
At the AAAI Fall      Symposium on Machine Ethics  researchers met for the first time to consider implementation of an ethical dimension in autonomous systems             A variety of perspectives of this nascent field can be found in the collected edition Machine Ethics            that stems from that symposium 
In       AI magazine published  Machine Ethics  Creating an Ethical Intelligent Agent              an article that discussed the importance of machine ethics  the need for machines that represent ethical principles explicitly  and challenges facing those working on machine ethics  It also demonstrated that it is possible  at least in a limited domain  for a machine to abstract an ethical principle from examples of ethical judgments and use that principle to guide its behavior 
In       Oxford University Press published Moral Machines  Teaching Robots Right from Wrong              which it advertised as  the first book to examine the challenge of building artificial moral agents  probing deeply into the nature of human decision making and ethics   It cited     sources  about     of which addressed major questions of machine ethics 
In       Cambridge University Press published a collection of essays about machine ethics edited by Michael and Susan Leigh Anderson             who also edited a special issue of IEEE Intelligent Systems on the topic in                   The collection focuses on the challenges of adding ethical principles to machines             
In       the US Office of Naval Research announced that it would distribute      million in grants over five years to university researchers to study questions of machine ethics as applied to autonomous robots              and Nick Bostrom s Superintelligence  Paths  Dangers  Strategies  which raised machine ethics as the  most important   issue humanity has ever faced   reached     on The New York Times s list of best selling science books             
In      the European Parliament published a paper             to encourage the Commission to address robots  legal status              The paper includes sections about robots  legal liability  in which it is argued that their liability should be proportional to their level of autonomy  The paper also discusses how many jobs could be taken by AI robots             
In      the Proceedings of the IEEE published a special issue on Machine Ethics  The Design and Governance of Ethical AI and Autonomous Systems  edited by Alan Winfield  Katina Michael  Jeremy Pitt and Vanessa Evers               The issue includes papers describing implicit ethical agents  where machines are designed to avoid unethical outcomes  as well as explicit ethical agents  or machines that either encode or learn ethics and determine actions based on those ethics              

Areas of focus edit 
AI control problem edit 
Main articles  Existential risk from artificial general intelligence and AI control problem
Some scholars  such as Bostrom and AI researcher Stuart Russell  argue that  if AI surpasses humanity in general intelligence and becomes  superintelligent   this new superintelligence could become powerful and difficult to control  just as the mountain gorilla s fate depends on human goodwill  so might humanity s fate depend on a future superintelligence s actions              In their respective books Superintelligence and Human Compatible  Bostrom and Russell assert that while the future of AI is very uncertain  the risk to humanity is great enough to merit significant action in the present 
This presents the AI control problem  how to build an intelligent agent that will aid its creators without inadvertently building a superintelligence that will harm them  The danger of not designing control right  the first time  is that a superintelligence may be able to seize power over its environment and prevent us from shutting it down  Potential AI control strategies include  capability control   limiting an AI s ability to influence the world  and  motivational control   one way of building an AI whose goals are aligned with human or optimal values   A number of organizations are researching the AI control problem  including the Future of Humanity Institute  the Machine Intelligence Research Institute  the Center for Human Compatible Artificial Intelligence  and the Future of Life Institute 

Algorithms and training edit 
AI paradigms have been debated  especially their efficacy and bias  Bostrom and Eliezer Yudkowsky have argued for decision trees  such as ID   over neural networks and genetic algorithms on the grounds that decision trees obey modern social norms of transparency and predictability  e g  stare decisis               In contrast  Chris Santos Lang has argued in favor of neural networks and genetic algorithms on the grounds that the norms of any age must be allowed to change and that natural failure to fully satisfy these particular norms has been essential in making humans less vulnerable than machines to criminal hackers                         
In       in an experiment at the Ecole Polytechnique F d rale of Lausanne s Laboratory of Intelligent Systems  AI robots were programmed to cooperate with each other and tasked with searching for a beneficial resource while avoiding a poisonous one              During the experiment  the robots were grouped into clans  and the successful members  digital genetic code was used for the next generation  a type of algorithm known as a genetic algorithm  After    successive generations in the AI  one clan s members discovered how to distinguish the beneficial resource from the poisonous one  The robots then learned to lie to each other in an attempt to hoard the beneficial resource from other robots              In the same experiment  the same robots also learned to behave selflessly and signaled danger to other robots  and died to save other robots              Machine ethicists have questioned the experiment s implications  In the experiment  the robots  goals were programmed to be  terminal   but human motives typically require never ending learning 

Autonomous weapons systems edit 
Main article  Lethal autonomous weapon
See also  Slaughterbots
In       academics and technical experts attended a conference to discuss the potential impact of robots and computers and the impact of the possibility that they could become self sufficient and able to make their own decisions  They discussed the extent to which computers and robots might acquire autonomy  and to what degree they could use it to pose a threat or hazard  They noted that some machines have acquired various forms of semi autonomy  including the ability to find power sources on their own and to independently choose targets to attack with weapons  They also noted that some computer viruses can evade elimination and have achieved  cockroach intelligence   They noted that self awareness as depicted in science fiction is probably unlikely  but that there are other potential hazards and pitfalls             
Some experts and academics have questioned the use of robots in military combat  especially robots with a degree of autonomy              The U S  Navy funded a report that indicates that as military robots become more complex  we should pay greater attention to the implications of their ability to make autonomous decisions                          The president of the Association for the Advancement of Artificial Intelligence has commissioned a study of this issue             

Integration of artificial general intelligences with society edit 
A hospital delivery robot in front of elevator doors stating  Robot Has Priority   a situation that may be regarded as reverse discrimination in relation to humans
Preliminary work has been conducted on methods of integrating artificial general intelligences  full ethical agents as defined above  with existing legal and social frameworks  Approaches have focused on their legal position and rights             

Machine learning bias edit 
Further information  Algorithmic bias
Big data and machine learning algorithms have become popular in numerous industries  including online advertising  credit ratings  and criminal sentencing  with the promise of providing more objective  data driven results  but have been identified as a potential way to perpetuate social inequalities and discrimination                          A      study found that women were less likely than men to be shown high income job ads by Google s AdSense  Another study found that Amazon s same day delivery service was intentionally made unavailable in black neighborhoods  Both Google and Amazon were unable to isolate these outcomes to a single issue  and said the outcomes were the result of the black box algorithms they use             
The U S  judicial system has begun using quantitative risk assessment software when making decisions related to releasing people on bail and sentencing in an effort to be fairer and reduce the imprisonment rate  These tools analyze a defendant s criminal history  among other attributes  In a study of       people arrested in Broward County  Florida  only     of people predicted to commit a crime using the county s risk assessment scoring system proceeded to commit a crime              A      ProPublica report analyzed recidivism risk scores calculated by one of the most commonly used tools  the Northpointe COMPAS system  and looked at outcomes over two years  The report found that only     of those deemed high risk committed additional crimes during that period  The report also flagged that African American defendants were far more likely to be given high risk scores than their white counterparts              It has been argued that such pretrial risk assessments violate Equal Protection rights on the basis of race  due to factors including possible discriminatory intent by the algorithm itself  under a theory of partial legal capacity for artificial intelligences             
In       the Obama administration s Big Data Working Group an overseer of various big data regulatory frameworks released reports warning of  the potential of encoding discrimination in automated decisions  and calling for  equal opportunity by design  for applications such as credit scoring                          The reports encourage discourse among policy makers  citizens  and academics alike  but recognize that no solution yet exists for the encoding of bias and discrimination into algorithmic systems 

Ethical frameworks and practices edit 
Practices edit 
In March       in an effort to address rising concerns over machine learning s impact on human rights  the World Economic Forum and Global Future Council on Human Rights published a white paper with detailed recommendations on how best to prevent discriminatory outcomes in machine learning              The World Economic Forum developed four recommendations based on the UN Guiding Principles of Human Rights to help address and prevent discriminatory outcomes in machine learning             

Active inclusion  Development and design of machine learning applications must actively seek a diversity of input  especially of the norms and values of populations affected by the output of AI systems 
Fairness  People involved in conceptualizing  developing  and implementing machine learning systems should consider which definition of fairness best applies to their context and application  and prioritize it in the machine learning system s architecture and evaluation metrics 
Right to understanding  Involvement of machine learning systems in decision making that affects individual rights must be disclosed  and the systems must be able to explain their decision making in a way that is understandable to end users and reviewable by a competent human authority  Where this is impossible and rights are at stake  leaders in the design  deployment  and regulation of machine learning technology must question whether it should be used 
Access to redress  Leaders  designers  and developers of machine learning systems are responsible for identifying the potential negative human rights impacts of their systems  They must make visible avenues for redress for those affected by disparate impacts  and establish processes for the timely redress of any discriminatory outputs 
In January       Harvard University s Berkman Klein Center for Internet and Society published a meta study of    prominent sets of principles for AI  identifying eight key themes  privacy  accountability  safety and security  transparency and explainability  fairness and non discrimination  human control of technology  professional responsibility  and promotion of human values              Researchers at the Swiss Federal Institute of Technology in Zurich conducted a similar meta study in                  

Approaches edit 
There have been several attempts to make ethics computable  or at least formal  Isaac Asimov s Three Laws of Robotics are not usually considered suitable for an artificial moral agent              but whether Kant s categorical imperative can be used has been studied              It has been pointed out that human value is  in some aspects  very complex              A way to explicitly surmount this difficulty is to receive human values directly from people through some mechanism  for example by learning them                                      Another approach is to base current ethical considerations on previous similar situations  This is called casuistry  and could be implemented through research on the Internet  The consensus from a million past decisions would lead to a new decision that is democracy dependent             Bruce M  McLaren built an early  mid     s  computational model of casuistry  a program called SIROCCO built with AI and case base reasoning techniques that retrieves and analyzes ethical dilemmas              But this approach could lead to decisions that reflect society s biases and unethical behavior  The negative effects of this approach can be seen in Microsoft s Tay  a chatterbot that learned to repeat racist and sexually charged tweets              
One thought experiment focuses on a Genie Golem with unlimited powers presenting itself to the reader  This Genie declares that it will return in    years and demands that it be provided with a definite set of morals it will then immediately act upon  This experiment s purpose is to spark discourse over how best to handle defining sets of ethics that computers may understand             
Some recent work attempts to reconstruct AI morality and control more broadly as a problem of mutual contestation between AI as a Foucauldian subjectivity on the one hand and humans or institutions on the other hand  all within a disciplinary apparatus  Certain desiderata need to be fulfilled  embodied self care  embodied intentionality  imagination and reflexivity  which together would condition AI s emergence as an ethical subject capable of self conduct             

In fiction edit 
In science fiction  movies and novels have played with the idea of sentient robots and machines 
Neill Blomkamp s Chappie        enacts a scenario of being able to transfer one s consciousness into a computer              Alex Garland s      film Ex Machina follows an android with artificial intelligence undergoing a variation of the Turing Test  a test administered to a machine to see whether its behavior can be distinguished from that of a human  Films such as The Terminator        and The Matrix        incorporate the concept of machines turning on their human masters 
Asimov considered the issue in the     s in I  Robot  At the insistence of his editor John W  Campbell Jr   he proposed the Three Laws of Robotics to govern artificially intelligent systems  Much of his work was then spent testing his three laws  boundaries to see where they break down or create paradoxical or unanticipated behavior  His work suggests that no set of fixed laws can sufficiently anticipate all possible circumstances              Philip K  Dick s      novel Do Androids Dream of Electric Sheep  explores what it means to be human  In his post apocalyptic scenario  he questions whether empathy is an entirely human characteristic  The book is the basis for the      science fiction film Blade Runner 

Related fields edit 
Affective computing
Bioethics
Computational theory of mind
Computer ethics
Ethics of artificial intelligence
Formal ethics
Moral psychology
Philosophy of artificial intelligence
Philosophy of mind
See also edit 
Artificial intelligence
AI safety
AI takeover
Artificial intelligence in fiction
Friendly artificial intelligence
Automating medical decision support
Google car
Machine Intelligence Research Institute
Military robot
Robot ethics
Space law
Self replicating spacecraft
Watson project for automating medical decision support
Notes edit 


  Moor  J H           The Nature  Importance  and Difficulty of Machine Ethics   IEEE Intelligent Systems                 doi         MIS          S CID             

  Boyles  Robert James   A Case for Machine Ethics in Modeling Human Level Intelligent Agents   PDF   Kritike  Retrieved   November      

  Moor  James M           Four Kinds of Ethical Robots   Philosophy Now 

  Waldrop  Mitchell  Spring         A Question of Responsibility   AI Magazine                doi         aimag v i      

  Anderson  M   Anderson  S   and Armen  C          Towards Machine Ethics  in Proceedings of the AAAI Workshop on Agent Organization  Theory and Practice  AAAI Press    

  AAAI Workshop on Agent Organization  Theory and Practice  AAAI Press

   Papers from the      AAAI Fall Symposium   Archived from the original on            

  a b Anderson  Michael  Anderson  Susan Leigh  eds   July        Machine Ethics  Cambridge University Press  ISBN                        

  a b Anderson  M  and Anderson  S          Creating an Ethical Intelligent Agent  AI Magazine  Volume       

  Wallach  Wendell  Allen  Colin         Moral machines        teaching robots right from wrong  Oxford University Press  ISBN                    

  Anderson  Michael  Anderson  Susan Leigh  eds   July August         Special Issue on Machine Ethics   IEEE Intelligent Systems                 doi         mis          ISSN                 S CID               Archived from the original on            

  Siler  Cory          Review of Anderson and Anderson s Machine Ethics   Artificial Intelligence                doi         j artint              S CID              

  Tucker  Patrick     May         Now The Military Is Going To Build Robots That Have Morals   Defense One  Retrieved   July      

   Best Selling Science Books   New York Times  September          Retrieved   November      

   European Parliament  Committee on Legal Affairs  Draft Report with recommendations to the Commission on Civil Law Rules on Robotics   European Commission  Retrieved January          

  Wakefield  Jane                MEPs vote on robots  legal status   and if a kill switch is required   BBC News  Retrieved    January      

   European Parliament resolution of    February      with recommendations to the Commission on Civil Law Rules on Robotics   European Parliament  Retrieved   November      

  Alan Winfield  Katina Michael  Jeremy Pitt  Vanessa Evers  March         Machine Ethics  The Design and Governance of Ethical AI and Autonomous Systems   Proceedings of the IEEE                    doi         JPROC              

   Proceedings of the IEEE Addresses Machine Ethics   IEEE Standards Association     August       Archived from the original on December         

  Bostrom  Nick         Superintelligence  Paths  Dangers  Strategies  First      ed    Oxford University Press  ISBN                     

  Bostrom  Nick  Yudkowsky  Eliezer          The Ethics of Artificial Intelligence   PDF   Cambridge Handbook of Artificial Intelligence  Cambridge Press  Archived from the original  PDF  on             Retrieved            

  a b Santos Lang  Chris          Ethics for Artificial Intelligences   Archived from the original on            

  Santos Lang  Christopher          Moral Ecology Approaches to Machine Ethics   PDF   In van Rysewyk  Simon  Pontier  Matthijs  eds    Machine Medical Ethics  Intelligent Systems  Control and Automation  Science and Engineering  Vol           Switzerland  Springer  pp                doi                              ISBN                        

  a b Fox  Stuart  August             Evolving Robots Learn To Lie To Each Other   Popular Science 

  Markoff  John  July             Scientists Worry Machines May Outsmart Man   New York Times 

  Palmer  Jason    August         Call for debate on killer robots   BBC News 

  Science New Navy funded Report Warns of War Robots Going  Terminator  Archived            at the Wayback Machine  by Jason Mick  Blog   dailytech com  February          

  Flatley  Joseph L   February             Navy report warns of robot uprising  suggests a strong moral compass   Engadget 

  AAAI Presidential Panel on Long Term AI Futures           Study  Association for the Advancement of Artificial Intelligence  Accessed         

  Sotala  Kaj  Yampolskiy  Roman V                Responses to catastrophic AGI risk  a survey   Physica Scripta             doi                                ISSN                

  a b Crawford  Kate     June         Artificial Intelligence s White Guy Problem   The New York Times 

  a b c Julia Angwin  Surya Mattu  Jeff Larson  Lauren Kircher     May         Machine Bias  There s Software Used Across the Country to Predict Future Criminals  And it s Biased Against Blacks   ProPublica 

  Thomas  C   Nunez  A           Automating Judicial Discretion  How Algorithmic Risk Assessments in Pretrial Adjudications Violate Equal Protection Rights on the Basis of Race   Law  amp  Inequality                   doi                       

  Executive Office of the President  May         Big Data  A Report on Algorithmic Systems  Opportunity  and Civil Rights   PDF   Obama White House 

   Big Risks  Big Opportunities  the Intersection of Big Data and Civil Rights   Obama White House    May      

  a b  How to Prevent Discriminatory Outcomes in Machine Learning   World Economic Forum     March       Retrieved            

  Fjeld  Jessica  Achten  Nele  Hilligoss  Hannah  Nagy  Adam  Srikumar  Madhulika          Principled Artificial Intelligence  Mapping Consensus in Ethical and Rights Based Approaches to Principles for AI   SSRN Working Paper Series  doi         ssrn          ISSN                 S CID                

  Jobin  Anna  Ienca  Marcello  Vayena  Effy          The global landscape of AI ethics guidelines   Nature Machine Intelligence                  arXiv             doi         s                  ISSN                 S CID                

  Anderson  Susan Leigh         The Unacceptability of Asimov s Three Laws of Robotics as a Basis for Machine Ethics  In  Machine Ethics  ed  Michael Anderson  Susan Leigh Anderson  New York  Oxford University Press  pp          ISBN                   

  Powers  Thomas M          Prospects for a Kantian Machine  In  Machine Ethics  ed  Michael Anderson  Susan Leigh Anderson  New York  Oxford University Press  pp         

  Muehlhauser  Luke  Helm  Louie         Intelligence Explosion and Machine Ethics 

  Yudkowsky  Eliezer         Coherent Extrapolated Volition 

  Guarini  Marcello         Computational Neural Modeling and the Philosophy of Ethics  Reflections on the Particularism Generalism Debate  In  Machine Ethics  ed  Michael Anderson  Susan Leigh Anderson  New York  Oxford University Press  pp         

  Hibbard  Bill          Ethical Artificial Intelligence   arXiv            cs AI  

  McLaren  Bruce M           Extensionally defining principles and cases in ethics  An AI model   Artificial Intelligence                      doi         S                      S CID               

  Wakefield  Jane     March         Microsoft chatbot is taught to swear on Twitter   BBC News  Retrieved            

  Nazaretyan  A          A  H  Eden  J  H  Moor  J  H  S raker and E  Steinhart  eds   Singularity Hypotheses  A Scientific and Philosophical Assessment  Minds  amp  Machines         pp         

  D Amato  Kristian                ChatGPT  towards AI subjectivity   AI  amp  Society  doi         s                z  ISSN                

  Brundage  Miles  Winterton  Jamie     March         Chappie and the Future of Moral Machines   Slate  Retrieved    October      

  Asimov  Isaac         I  robot  New York  Bantam  ISBN                        


References edit 
Wallach  Wendell  Allen  Colin  November        Moral Machines  Teaching Robots Right from Wrong  US  Oxford University Press 
Anderson  Michael  Anderson  Susan Leigh  eds  July        Machine Ethics  Cambridge University Press 
Storrs Hall  J   May            Beyond AI  Creating the Conscience of the Machine Prometheus Books 
Moor  J          The Nature  Importance  and Difficulty of Machine Ethics  IEEE Intelligent Systems         pp             
Anderson  M  and Anderson  S          Creating an Ethical Intelligent Agent  AI Magazine  Volume       
Further reading edit 
Hagendorff  Thilo         Linking Human And Machine Behavior  A New Approach to Evaluate Training Data Quality for Beneficial Machine Learning  Minds and Machines  doi         s                  
Anderson  Michael  Anderson  Susan Leigh  eds  July August         Special Issue on Machine Ethics   IEEE Intelligent Systems               
Bendel  Oliver  December            Considerations about the Relationship between Animal and Machine Ethics  AI  amp  SOCIETY  doi         s                 
Dabringer  Gerhard  ed           Ethical and Legal Aspects of Unmanned Systems  Interviews   Austrian Ministry of Defence and Sports  Vienna       ISBN                        
Gardner  A          An Artificial Approach to Legal Reasoning  Cambridge  MA  MIT Press 
Georges  T  M          Digital Soul  Intelligent Machines and Human Values  Cambridge  MA  Westview Press 
Singer  P W   December            Wired for War  The Robotics Revolution and Conflict in the   st Century  Penguin 
Winfield  A   Michael  K   Pitt  J  and Evers  V   March        Special Issue on Machine Ethics  The Design and Governance of Ethical AI and Autonomous Systems  Proceedings of the IEEE                    doi         JPROC             
External links edit 
Machine Ethics  Interdisciplinary project on machine ethics 
The Machine Ethics Podcast  Podcast discussing Machine Ethics  AI and Tech ethics 
vteEthicsNormative
Consequentialism
Deontology
Care
Particularism
Pragmatic
Role
Suffering focused
Utilitarianism
Virtue
Applied
Animal
Artificial intelligence
Bio
Business
Computer
Discourse
Economic
Engineering
Environmental
Land
Legal
Machine
Marketing
Meat eating
Media
Medical
Nursing
Professional
Programming
Research
Sexual
Technology
Terraforming
Uncertain sentience
Work
Meta
Absolutism
Axiology
Cognitivism
Realism
Naturalism
Non naturalism
Subjectivism
Ideal observer theory
Divine command theory
Constructivism
Euthyphro dilemma
Intuitionism
Nihilism
Non cognitivism
Emotivism
Expressivism
Quasi realism
Universal prescriptivism
Rationalism
Relativism
Skepticism
Universalism
Value monism   Value pluralism
Schools
Buddhist
Christian
Protestant
Confucian
Epicurean
Existentialist
Feminist
Islamic
Jewish
Kantian
Rousseauian
Stoic
Tao
Concepts
Accountability
Authority
Autonomy
Blame
Common sense
Compassion
Conscience
Consent
Culture of life
Desert
Dignity
Double standard
Duty
Equality
Etiquette
Eudaimonia
Family values
Fidelity
Free will
Good and evil
Good
Evil
Problem of evil
Greed
Happiness
Honour
Ideal
Immorality
Importance
Justice
Liberty
Loyalty
Moral agency
Moral courage
Moral hierarchy
Moral imperative
Morality
Norm
Pacifism
Political freedom
Precept
Punishment
Rights
Self discipline
Suffering
Stewardship
Sympathy
Theodicy
Torture
Trust
Utility
Value
Instrumental
Intrinsic
Japan
Western
Vice
Virtue
Vow
Wrong
Ethicists
Laozi
Socrates
Plato
Aristotle
Diogenes
Valluvar
Cicero
Confucius
Augustine
Mencius
Mozi
Xunzi
Aquinas
Spinoza
Butler
Hume
Smith
Kant
Hegel
Schopenhauer
Bentham
Mill
Kierkegaard
Sidgwick
Nietzsche
Moore
Barth
Tillich
Bonhoeffer
Foot
Rawls
Dewey
Williams
Mackie
Anscombe
Frankena
MacIntyre
Hare
Singer
Parfit
Nagel
Adams
Taylor
Azurmendi
Korsgaard
Nussbaum
Works
Nicomachean Ethics  c      BC 
Ethics  Spinoza        
Fifteen Sermons Preached at the Rolls Chapel       
A Treatise of Human Nature       
The Theory of Moral Sentiments       
An Introduction to the Principles of Morals and Legislation       
Groundwork of the Metaphysics of Morals       
Critique of Practical Reason       
Elements of the Philosophy of Right       
Either Or       
Utilitarianism       
The Methods of Ethics       
On the Genealogy of Morality       
Principia Ethica       
A Theory of Justice       
Practical Ethics       
After Virtue       
Reasons and Persons       
Related
Axiology
Casuistry
Descriptive ethics
Ethics in religion
Evolutionary ethics
History of ethics
Human rights
Ideology
Moral psychology
Philosophy of law
Political philosophy
Population ethics
Rehabilitation
Secular ethics
Social philosophy
Index

 Category
 Outline
 Portal
 WikiProject

vteExistential risk from artificial intelligenceConcepts
AGI
AI alignment
AI capability control
AI safety
AI takeover
Consequentialism
Effective accelerationism
Ethics of artificial intelligence
Existential risk from artificial intelligence
Friendly artificial intelligence
Instrumental convergence
Vulnerable world hypothesis
Intelligence explosion
Longtermism
Machine ethics
Suffering risks
Superintelligence
Technological singularity
Organizations
Alignment Research Center
Center for AI Safety
Center for Applied Rationality
Center for Human Compatible Artificial Intelligence
Centre for the Study of Existential Risk
EleutherAI
Future of Humanity Institute
Future of Life Institute
Google DeepMind
Humanity 
Institute for Ethics and Emerging Technologies
Leverhulme Centre for the Future of Intelligence
Machine Intelligence Research Institute
OpenAI
People
Scott Alexander
Sam Altman
Yoshua Bengio
Nick Bostrom
Paul Christiano
Eric Drexler
Sam Harris
Stephen Hawking
Dan Hendrycks
Geoffrey Hinton
Bill Joy
Shane Legg
Elon Musk
Steve Omohundro
Huw Price
Martin Rees
Stuart J  Russell
Jaan Tallinn
Max Tegmark
Frank Wilczek
Roman Yampolskiy
Eliezer Yudkowsky
Other
Statement on AI risk of extinction
Human Compatible
Open letter on artificial intelligence       
Our Final Invention
The Precipice
Superintelligence  Paths  Dangers  Strategies
Do You Trust This Computer 
Artificial Intelligence Act
 Category





Retrieved from  https   en wikipedia org w index php title Machine ethics amp oldid