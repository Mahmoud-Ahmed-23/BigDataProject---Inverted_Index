Image generating machine learning model


Stable DiffusionAn image generated with Stable Diffusion     based on the text prompt a photograph of an astronaut riding a horseOriginal author s Runway  CompVis  and Stability AIDeveloper s Stability AIInitial releaseAugust         Stable releaseSD      model            
     October         
Repositorygithub com Stability AI generative models 
Written inPython           TypeText to image modelLicenseStability AI Community LicenseWebsitestability ai stable image
Stable Diffusion is a deep learning  text to image model released in      based on diffusion techniques  The generative artificial intelligence technology is the premier product of Stability AI and is considered to be a part of the ongoing artificial intelligence boom 
It is primarily used to generate detailed images conditioned on text descriptions  though it can also be applied to other tasks such as inpainting  outpainting  and generating image to image translations guided by a text prompt             Its development involved  researchers from the CompVis Group at Ludwig Maximilian University of Munich and Runway with a computational donation from Stability and training data from non profit organizations                                             
Stable Diffusion is a latent diffusion model  a kind of deep generative artificial neural network  Its code and model weights have been released publicly             and an optimized version can run on most consumer hardware equipped with a modest GPU with as little as          GB VRAM             This marked a departure from previous proprietary text to image models such as DALL E and Midjourney which were accessible only via cloud services                         


Development edit 
Stable Diffusion originated from a project called Latent Diffusion              developed in Germany by researchers at Ludwig Maximilian University in Munich and Heidelberg University  Four of the original   authors  Robin Rombach  Andreas Blattmann  Patrick Esser and Dominik Lorenz  later joined Stability AI and released subsequent versions of Stable Diffusion             
The technical license for the model was released by the CompVis group at Ludwig Maximilian University of Munich              Development was led by Patrick Esser of Runway and Robin Rombach of CompVis  who were among the researchers who had earlier invented the latent diffusion model architecture used by Stable Diffusion             Stability AI also credited EleutherAI and LAION  a German nonprofit which assembled the dataset on which Stable Diffusion was trained  as supporters of the project            

Technology edit 
Diagram of the latent diffusion architecture used by Stable Diffusion
The denoising process used by Stable Diffusion  The model generates images by iteratively denoising random noise until a configured number of steps have been reached  guided by the CLIP text encoder pretrained on concepts along with the attention mechanism  resulting in the desired image depicting a representation of the trained concept 
Architecture edit 
Main article  Latent diffusion model
Diffusion models  introduced in       are trained with the objective of removing successive applications of Gaussian noise on training images  which can be thought of as a sequence of denoising autoencoders  The name diffusion is from the thermodynamic diffusion  since they were first developed with inspiration from thermodynamics                         
Models in Stable Diffusion series before SD   all used a variant of diffusion models  called latent diffusion model  LDM   developed in      by the CompVis  Computer Vision  amp  Learning              group at LMU Munich                         
Stable Diffusion consists of   parts  the variational autoencoder  VAE   U Net  and an optional text encoder              The VAE encoder compresses the image from pixel space to a smaller dimensional latent space  capturing a more fundamental semantic meaning of the image              Gaussian noise is iteratively applied to the compressed latent representation during forward diffusion              The U Net block  composed of a ResNet backbone  denoises the output from forward diffusion backwards to obtain a latent representation  Finally  the VAE decoder generates the final image by converting the representation back into pixel space             
The denoising step can be flexibly conditioned on a string of text  an image  or another modality  The encoded conditioning data is exposed to denoising U Nets via a cross attention mechanism              For conditioning on text  the fixed  pretrained CLIP ViT L    text encoder is used to transform text prompts to an embedding space             Researchers point to increased computational efficiency for training and generation as an advantage of LDMs                        
With          million parameters in the U Net and          million in the text encoder  Stable Diffusion is considered relatively lightweight by      standards  and unlike other diffusion models  it can run on consumer GPUs              and even CPU only if using the OpenVINO version of Stable Diffusion             

SD XL edit 
The XL version uses the same LDM architecture as previous versions              except larger  larger UNet backbone  larger cross attention context  two text encoders instead of one  and trained on multiple aspect ratios  not just the square aspect ratio like previous versions  
The SD XL Refiner  released at the same time  has the same architecture as SD XL  but it was trained for adding fine details to preexisting images via text conditional img img 

SD     edit 
Main article  Diffusion model        Rectified flow
The     version             completely changes the backbone  Not a UNet  but a Rectified Flow Transformer  which implements the rectified flow method                         with a Transformer 
The Transformer architecture used for SD     has three  tracks   for original text encoding  transformed text encoding  and image encoding  in latent space   The transformed text encoding and image encoding are mixed during each transformer block 
The architecture is named  multimodal diffusion transformer  MMDiT   where the  multimodal  means that it mixes text and image encodings inside its operations  This differs from previous versions of DiT  where the text encoding affects the image encoding  but not vice versa 

Training data edit 
Stable Diffusion was trained on pairs of images and captions taken from LAION  B  a publicly available dataset derived from Common Crawl data scraped from the web  where   billion image text pairs were classified based on language and filtered into separate datasets by resolution  a predicted likelihood of containing a watermark  and predicted  aesthetic  score  e g  subjective visual quality               The dataset was created by LAION  a German non profit which receives funding from Stability AI                          The Stable Diffusion model was trained on three subsets of LAION  B  laion B en  laion high resolution  and laion aesthetics v                  A third party analysis of the model s training data identified that out of a smaller subset of         million images taken from the original wider dataset used  approximately     of the sample size of images came from     different domains  with Pinterest taking up      of the subset  followed by websites such as WordPress  Blogspot  Flickr  DeviantArt and Wikimedia Commons      citation needed       An investigation by Bayerischer Rundfunk showed that LAION s datasets  hosted on Hugging Face  contain large amounts of private and sensitive data             

Training procedures edit 
The model was initially trained on the laion B en and laion high resolution subsets  with the last few rounds of training done on LAION Aesthetics v      a subset of          million captioned images which the LAION Aesthetics Predictor V  predicted that humans would  on average  give a score of at least   out of    when asked to rate how much they liked them                                      The LAION Aesthetics v     subset also excluded low resolution images and images which LAION  B WatermarkDetection identified as carrying a watermark with greater than     probability              Final rounds of training additionally dropped     of text conditioning to improve Classifier Free Diffusion Guidance             
The model was trained using     Nvidia A    GPUs on Amazon Web Services for a total of         GPU hours  at a cost of                                              

Limitations edit 
Stable Diffusion has issues with degradation and inaccuracies in certain scenarios  Initial releases of the model were trained on a dataset that consists of         resolution images  meaning that the quality of generated images noticeably degrades when user specifications deviate from its  expected          resolution              the version     update of the Stable Diffusion model later introduced the ability to natively generate images at         resolution              Another challenge is in generating human limbs due to poor data quality of limbs in the LAION database              The model is insufficiently trained to replicate human limbs and faces due to the lack of representative features in the database  and prompting the model to generate images of such type can confound the model              Stable Diffusion XL  SDXL  version      released in July       introduced native     x     resolution and improved generation for limbs and text                         
Accessibility for individual developers can also be a problem  In order to customize the model for new use cases that are not included in the dataset  such as generating anime characters   waifu diffusion                new data and further training are required  Fine tuned adaptations of Stable Diffusion created through additional retraining have been used for a variety of different use cases  from medical imaging             to algorithmically generated music              However  this fine tuning process is sensitive to the quality of new data  low resolution images or different resolutions from the original data can not only fail to learn the new task but degrade the overall performance of the model  Even when the model is additionally trained on high quality images  it is difficult for individuals to run models in consumer electronics  For example  the training process for waifu diffusion requires a minimum         GB of VRAM              which exceeds the usual resource provided in such consumer GPUs as Nvidia s GeForce    series  which has only about         GB             
The creators of Stable Diffusion acknowledge the potential for algorithmic bias  as the model was primarily trained on images with English descriptions              As a result  generated images reinforce social biases and are from a western perspective  as the creators note that the model lacks data from other communities and cultures  The model gives more accurate results for prompts that are written in English in comparison to those written in other languages  with western or white cultures often being the default representation             

End user fine tuning edit 
To address the limitations of the model s initial training  end users may opt to implement additional training to fine tune generation outputs to match more specific use cases  a process also referred to as personalization  There are three methods in which user accessible fine tuning can be applied to a Stable Diffusion model checkpoint 

An  embedding  can be trained from a collection of user provided images  and allows the model to generate visually similar images whenever the name of the embedding is used within a generation prompt              Embeddings are based on the  textual inversion  concept developed by researchers from Tel Aviv University in      with support from Nvidia  where vector representations for specific tokens used by the model s text encoder are linked to new pseudo words  Embeddings can be used to reduce biases within the original model  or mimic visual styles             
A  hypernetwork  is a small pretrained neural network that is applied to various points within a larger neural network  and refers to the technique created by NovelAI developer Kurumuz in       originally intended for text generation transformer models  Hypernetworks steer results towards a particular direction  allowing Stable Diffusion based models to imitate the art style of specific artists  even if the artist is not recognised by the original model  they process the image by finding key areas of importance such as hair and eyes  and then patch these areas in secondary latent space             
DreamBooth is a deep learning generation model developed by researchers from Google Research and Boston University in      which can fine tune the model to generate precise  personalised outputs that depict a specific subject  following training via a set of images which depict the subject             
Capabilities edit 
The Stable Diffusion model supports the ability to generate new images from scratch through the use of a text prompt describing elements to be included or omitted from the output             Existing images can be re drawn by the model to incorporate new elements described by a text prompt  a process known as  guided image synthesis               through its diffusion denoising mechanism             In addition  the model also allows the use of prompts to partially alter existing images via inpainting and outpainting  when used with an appropriate user interface that supports such features  of which numerous different open source implementations exist             
Stable Diffusion is recommended to be run with         GB or more VRAM  however users with less VRAM may opt to load the weights in float   precision instead of the default float   to tradeoff model performance with lower VRAM usage             

Text to image generation edit 
Demonstration of the effect of negative prompts on image generation
Top  no negative prompt
Centre   green trees 
Bottom   round stones  round rocks 
The text to image sampling script within Stable Diffusion  known as  txt img   consumes a text prompt in addition to assorted option parameters covering sampling types  output image dimensions  and seed values  The script outputs an image file based on the model s interpretation of the prompt             Generated images are tagged with an invisible digital watermark to allow users to identify an image as generated by Stable Diffusion             although this watermark loses its efficacy if the image is resized or rotated             
Each txt img generation will involve a specific seed value which affects the output image  Users may opt to randomize the seed in order to explore different generated outputs  or use the same seed to obtain the same image output as a previously generated image              Users are also able to adjust the number of inference steps for the sampler  a higher value takes a longer duration of time  however a smaller value may result in visual defects              Another configurable option  the classifier free guidance scale value  allows the user to adjust how closely the output image adheres to the prompt              More experimentative use cases may opt for a lower scale value  while use cases aiming for more specific outputs may use a higher value             
Additional text img features are provided by front end implementations of Stable Diffusion  which allow users to modify the weight given to specific parts of the text prompt  Emphasis markers allow users to add or reduce emphasis to keywords by enclosing them with brackets              An alternative method of adjusting weight to parts of the prompt are  negative prompts   Negative prompts are a feature included in some front end implementations  including Stability AI s own DreamStudio cloud service  and allow the user to specify prompts which the model should avoid during image generation  The specified prompts may be undesirable image features that would otherwise be present within image outputs due to the positive prompts provided by the user  or due to how the model was originally trained  with mangled human hands being a common example                         

Image modification edit 
Demonstration of img img modification
Left  Original image created with Stable Diffusion    
Right  Modified image created with Stable Diffusion XL    
Stable Diffusion also includes another sampling script   img img   which consumes a text prompt  path to an existing image  and strength value between     and      The script outputs a new image based on the original image that also features elements provided within the text prompt  The strength value denotes the amount of noise added to the output image  A higher strength value produces more variation within the image but may produce an image that is not semantically consistent with the prompt provided            
There are different methods for performing img img  The main method is SDEdit              which first adds noise to an image  then denoises it as usual in text img 
The ability of img img to add noise to the original image makes it potentially useful for data anonymization and data augmentation  in which the visual features of image data are changed and anonymized              The same process may also be useful for image upscaling  in which the resolution of an image is increased  with more detail potentially being added to the image              Additionally  Stable Diffusion has been experimented with as a tool for image compression  Compared to JPEG and WebP  the recent methods used for image compression in Stable Diffusion face limitations in preserving small text and faces             
Additional use cases for image modification via img img are offered by numerous front end implementations of the Stable Diffusion model  Inpainting involves selectively modifying a portion of an existing image delineated by a user provided layer mask  which fills the masked space with newly generated content based on the provided prompt              A dedicated model specifically fine tuned for inpainting use cases was created by Stability AI alongside the release of Stable Diffusion                  Conversely  outpainting extends an image beyond its original dimensions  filling the previously empty space with content generated based on the provided prompt             
A depth guided model  named  depth img   was introduced with the release of Stable Diffusion     on November           this model infers the depth of the provided input image  and generates a new output image based on both the text prompt and the depth information  which allows the coherence and depth of the original input image to be maintained in the generated output             

ControlNet edit 
ControlNet             is a neural network architecture designed to manage diffusion models by incorporating additional conditions  It duplicates the weights of neural network blocks into a  locked  copy and a  trainable  copy  The  trainable  copy learns the desired condition  while the  locked  copy preserves the original model  This approach ensures that training with small datasets of image pairs does not compromise the integrity of production ready diffusion models  The  zero convolution  is a     convolution with both weight and bias initialized to zero  Before training  all zero convolutions produce zero output  preventing any distortion caused by ControlNet  No layer is trained from scratch  the process is still fine tuning  keeping the original model secure  This method enables training on small scale or even personal devices 

User interfaces edit 
Stability provides an online image generation service called DreamStudio                          The company also released an open source version of DreamStudio called StableStudio                          In addition to Stability s interfaces  many third party open source interfaces exist  such as AUTOMATIC     Stable Diffusion Web UI  which is the most popular and offers extra features              Fooocus  which aims to decrease the amount of prompting needed by the user              and ComfyUI  which has a node based user interface  essentially a visual programming language akin to many  D modeling applications                                     

Releases edit 




Version number

Release date

Parameters

Notes


                              

August     



All released by CompVis  There is no  version           gave rise to      and     gave rise to both     and                 


               

October     

   M

Initialized with the weights of      not      Released by RunwayML 


               

November     



Retrained from scratch on a filtered dataset             


               

December     



Initialized with the weights of     


XL                            

July     

   B

The XL     base model has     billion parameters  making it around    x larger than previous versions             


XL Turbo            

November     



Distilled from XL     to run in fewer diffusion steps             


                           

February       early preview 

   M to  B

A family of models 


               

October     

   B to  B

A family of models with Large    billion parameters   Large Turbo  distilled from SD     Large   and Medium      billion parameters  

Key papers

Learning Transferable Visual Models From Natural Language Supervision                     This paper describes the CLIP method for training text encoders  which convert text into floating point vectors  Such text encodings are used by the diffusion model to create images 
SDEdit  Guided Image Synthesis and Editing with Stochastic Differential Equations                     This paper describes SDEdit  aka  img img  
High Resolution Image Synthesis with Latent Diffusion Models        updated in                    This paper describes the latent diffusion model  LDM   This is the backbone of the Stable Diffusion architecture 
Classifier Free Diffusion Guidance                     This paper describes CFG  which allows the text encoding vector to steer the diffusion model towards creating the image described by the text 
SDXL  Improving Latent Diffusion Models for High Resolution Image Synthesis                     Describes SDXL 
Flow Straight and Fast  Learning to Generate and Transfer Data with Rectified Flow                                 Describes rectified flow  which is used for the backbone architecture of SD     
Scaling Rectified Flow Transformers for High resolution Image Synthesis                     Describes SD     
Training cost

SD          million hours on A       GB              
Stable Diffusion     Large was made available for enterprise usage on Amazon Bedrock of Amazon Web Services             

Usage and controversy edit 
Stable Diffusion claims no rights on generated images and freely gives users the rights of usage to any generated images from the model provided that the image content is not illegal or harmful to individuals             
The images Stable Diffusion was trained on have been filtered without human input  leading to some harmful images and large amounts of private and sensitive information appearing in the training data             
More traditional visual artists have expressed concern that widespread usage of image synthesis software such as Stable Diffusion may eventually lead to human artists  along with photographers  models  cinematographers  and actors  gradually losing commercial viability against AI based competitors             
Stable Diffusion is notably more permissive in the types of content users may generate  such as violent or sexually explicit imagery  in comparison to other commercial products based on generative AI              Addressing the concerns that the model may be used for abusive purposes  CEO of Stability AI  Emad Mostaque  argues that   it is  peoples  responsibility as to whether they are ethical  moral  and legal in how they operate this technology               and that putting the capabilities of Stable Diffusion into the hands of the public would result in the technology providing a net benefit  in spite of the potential negative consequences              In addition  Mostaque argues that the intention behind the open availability of Stable Diffusion is to end corporate control and dominance over such technologies  who have previously only developed closed AI systems for image synthesis                          This is reflected by the fact that any restrictions Stability AI places on the content that users may generate can easily be bypassed due to the availability of the source code             
Controversy around photorealistic sexualized depictions of underage characters have been brought up  due to such images generated by Stable Diffusion being shared on websites such as Pixiv             
In June of       a hack on an extension of ComfyUI  a user interface for Stable Diffusion  took place  with the hackers claiming they targeted users who committed  one of our sins   which included AI art generation  art theft  promoting cryptocurrency                  clarification needed     

Litigation edit 
Andersen  McKernan  and Ortiz v  Stability AI  Midjourney  and DeviantArt edit 
In January       three artists  Sarah Andersen  Kelly McKernan  and Karla Ortiz  filed a copyright infringement lawsuit against Stability AI  Midjourney  and DeviantArt  claiming that these companies have infringed the rights of millions of artists by training AI tools on five billion images scraped from the web without the consent of the original artists             
In July       U S  District Judge William Orrick inclined to dismiss most of the lawsuit filed by Andersen  McKernan  and Ortiz but allowed them to file a new complaint  providing them an opportunity to reframe their arguments             

Getty Images v  Stability AI edit 
In January       Getty Images initiated legal proceedings against Stability AI in the English High Court  alleging significant infringement of its intellectual property rights  Getty Images claims that Stability AI  scraped  millions of images from Getty s websites without consent and used these images to train and develop its deep learning Stable Diffusion model                         
Key points of the lawsuit include 

Getty Images asserting that the training and development of Stable Diffusion involved the unauthorized use of its images  which were downloaded on servers and computers that were potentially in the UK  However  Stability AI argues that all training and development took place outside the UK  specifically in U S  data centers operated by Amazon Web Services             
Stability AI applied for reverse summary judgment and or strike out of two claims  the training and development claim  and the secondary infringement of copyright claim  The High Court  however  refused to strike out these claims  allowing them to proceed to trial  The court is to determine whether the training and development of Stable Diffusion occurred in the UK  which is crucial for establishing jurisdiction under the UK s Copyright  Designs and Patents Act       CDPA              
The secondary infringement claim revolves around whether the pre trained Stable Diffusion software  made available in the UK through platforms like GitHub  HuggingFace  and DreamStudio  constitutes an  article  under sections    and    of the CDPA  The court will decide whether the term  article  can encompass intangible items such as software             
The trial is expected to take place in summer      and has significant implications for UK copyright law and the licensing of AI generated content 

License edit 
Unlike models like DALL E  Stable Diffusion makes its source code available                         along with the model  pretrained weights   Prior to Stable Diffusion    it applied the Creative ML OpenRAIL M license  a form of Responsible AI License  RAIL   to the model  M               The license prohibits certain use cases  including crime  libel  harassment  doxing   exploiting     minors   giving medical advice  automatically creating legal obligations  producing legal evidence  and  discriminating against or harming individuals or groups based on     social behavior or     personal or personality characteristics      or  legally protected characteristics or categories                           The user owns the rights to their generated output images  and is free to use them commercially             
Stable Diffusion     applies the permissive Stability AI Community License while commercial enterprises with revenue exceed    million need the Stability AI Enterprise License              As with the OpenRAIL M license  the user retains the rights to their generated output images and is free to use them commercially             

See also edit 
Artificial intelligence art
Runway
Midjourney
Craiyon
Hugging Face
Imagen
References edit 


   Stable Diffusion       Stability AI  Archived from the original on October           Retrieved October          

  Ryan O Connor  August             How to Run Stable Diffusion Locally to Generate Images   Archived from the original on October           Retrieved May         

   Diffuse The Rest   a Hugging Face Space by huggingface   huggingface co  Archived from the original on September          Retrieved September         

   Leaked deck raises questions over Stability AI s Series A pitch to investors   sifted eu  Archived from the original on June           Retrieved June          

   Revolutionizing image generation by AI  Turning text into images   www lmu de  Archived from the original on September           Retrieved June          

  Mostaque  Emad  November            Stable Diffusion came from the Machine Vision  amp  Learning research group  CompVis   LMU Muenchen   Twitter  Archived from the original on July           Retrieved June          

  a b c d  Stable Diffusion Launch Announcement   Stability Ai  Archived from the original on September          Retrieved September         

  a b c d e f g h i  Stable Diffusion Repository on GitHub   CompVis   Machine Vision and Learning Research Group  LMU Munich  September           Archived from the original on January           Retrieved September          

   basujindal stable diffusion   GitHub  November           Archived from the original on March           Retrieved March          

   The new killer app  Creating AI art will absolutely crush your PC   PCWorld  Archived from the original on August           Retrieved August          

  a b c d e Vincent  James  September             Anyone can use this AI art generator   that s the risk   The Verge  Archived from the original on January           Retrieved September          

   CompVis Latent diffusion   GitHub 

   Stable Diffusion    Research Paper  

  David  Foster      Diffusion Models   Generative Deep Learning         ed    O Reilly 

  Jascha Sohl Dickstein  Eric A  Weiss  Niru Maheswaranathan  Surya Ganguli  March             Deep Unsupervised Learning using Nonequilibrium Thermodynamics   arXiv             cs LG    cite arXiv     CS  maint  multiple names  authors list  link 

   Home   Computer Vision  amp  Learning Group  Retrieved September         

  a b c Rombach  Blattmann  Lorenz  Esser  Ommer  June        High Resolution Image Synthesis with Latent Diffusion Models  PDF   International Conference on Computer Vision and Pattern Recognition  CVPR   New Orleans  LA  pp                    arXiv             Archived  PDF  from the original on January           Retrieved September          

  a b c d Alammar  Jay   The Illustrated Stable Diffusion   jalammar github io  Archived from the original on November          Retrieved October          

   Stable diffusion pipelines   huggingface co  Archived from the original on June           Retrieved June          

   Text to Image Generation with Stable Diffusion and OpenVINO    openvino ai  Intel  Retrieved February          

  a b c Podell  Dustin  English  Zion  Lacey  Kyle  Blattmann  Andreas  Dockhorn  Tim  M ller  Jonas  Penna  Joe  Rombach  Robin  July            SDXL  Improving Latent Diffusion Models for High Resolution Image Synthesis   arXiv             cs CV  

  a b c Esser  Patrick  Kulal  Sumith  Blattmann  Andreas  Entezari  Rahim  M ller  Jonas  Saini  Harry  Levi  Yam  Lorenz  Dominik  Sauer  Axel  March           Scaling Rectified Flow Transformers for High Resolution Image Synthesis  arXiv           

  a b Liu  Xingchao  Gong  Chengyue  Liu  Qiang  September           Flow Straight and Fast  Learning to Generate and Transfer Data with Rectified Flow  arXiv           

  a b  Rectified Flow   Rectified Flow   www cs utexas edu  Retrieved March         

  a b c d e Baio  Andy  August             Exploring    Million of the     Billion Images Used to Train Stable Diffusion s Image Generator   Waxy org  Archived from the original on January           Retrieved November         

   This artist is dominating AI generated art  And he s not happy about it   MIT Technology Review  Archived from the original on January           Retrieved November         

  a b Brunner  Katharina  Harlan  Elisa  July            We Are All Raw Material for AI   Bayerischer Rundfunk  BR   Archived from the original on September           Retrieved September          

  Schuhmann  Christoph  November           CLIP MLP Aesthetic Score Predictor  archived from the original on June          retrieved November        

   LAION Aesthetics   LAION   laion ai  Archived from the original on August           Retrieved September         

  a b c Ho  Jonathan  Salimans  Tim  July             Classifier Free Diffusion Guidance   arXiv             cs LG  

  Mostaque  Emad  August             Cost of construction   Twitter  Archived from the original on September          Retrieved September         

  a b c  CompVis stable diffusion v      Hugging Face   huggingface co  Archived from the original on January           Retrieved November         

  Wiggers  Kyle  August             A startup wants to democratize the tech behind DALL E    consequences be damned   TechCrunch  Archived from the original on January           Retrieved November         

  a b c d e  Stable Diffusion with    Diffusers   huggingface co  Archived from the original on January           Retrieved October          

  a b c  Stable Diffusion     Release   stability ai  Archived from the original on December          

   LAION   laion ai  Archived from the original on October           Retrieved October          

   Generating images with Stable Diffusion   Paperspace Blog  August           Archived from the original on October           Retrieved October          

   Announcing SDXL       Stability AI  Archived from the original on July           Retrieved August          

  Edwards  Benj  July             Stability AI releases Stable Diffusion XL  its next gen image synthesis model   Ars Technica  Archived from the original on August           Retrieved August          

   hakurei waifu diffusion   Hugging Face   huggingface co  Archived from the original on October          Retrieved October          

  Chambon  Pierre  Bluethgen  Christian  Langlotz  Curtis P   Chaudhari  Akshay  October            Adapting Pretrained Vision Language Foundational Models to Medical Imaging Domains   arXiv             cs CV  

  Seth Forsgren  Hayk Martiros   Riffusion   Stable diffusion for real time music generation   Riffusion  Archived from the original on December          

  Mercurio  Anthony  October            Waifu Diffusion  archived from the original on October           retrieved October         

  Smith  Ryan   NVIDIA Quietly Launches GeForce RTX        GB  More VRAM  More Power  More Money   www anandtech com  Archived from the original on August           Retrieved October          

  Dave James  October             I thrashed the RTX      for   hours straight training Stable Diffusion to paint like my uncle Hermann   PC Gamer  Archived from the original on November         

  Gal  Rinon  Alaluf  Yuval  Atzmon  Yuval  Patashnik  Or  Bermano  Amit H   Chechik  Gal  Cohen Or  Daniel  August            An Image is Worth One Word  Personalizing Text to Image Generation using Textual Inversion   arXiv             cs CV  

   NovelAI Improvements on Stable Diffusion   NovelAI  October           Archived from the original on October          

  Yuki Yamashita  September                         AI                 Google      ITmedia Inc   in Japanese   Archived from the original on August          

  Meng  Chenlin  He  Yutong  Song  Yang  Song  Jiaming  Wu  Jiajun  Zhu  Jun Yan  Ermon  Stefano  August            SDEdit  Guided Image Synthesis and Editing with Stochastic Differential Equations   arXiv             cs CV  

  a b c d  Stable Diffusion web UI   GitHub  November           Archived from the original on January           Retrieved September          

  invisible watermark  Shield Mountain  November          archived from the original on October           retrieved November        

   stable diffusion tools emphasis at master   JohannesGaessler stable diffusion tools   GitHub  Archived from the original on October          Retrieved November         

   Stable Diffusion v    and DreamStudio Updates   Dec      stability ai  Archived from the original on December          

  a b Meng  Chenlin  He  Yutong  Song  Yang  Song  Jiaming  Wu  Jiajun  Zhu  Jun Yan  Ermon  Stefano  January            SDEdit  Guided Image Synthesis and Editing with Stochastic Differential Equations   arXiv             cs CV  

  a b Luzi  Lorenzo  Siahkoohi  Ali  Mayer  Paul M   Casco Rodriguez  Josue  Baraniuk  Richard  October             Boomerang  Local sampling on image manifolds using diffusion models   arXiv             cs CV  

  B hlmann  Matthias  September             Stable Diffusion Based Image Compression   Medium  Archived from the original on November          Retrieved November         

  Zhang  Lvmin  February             Adding Conditional Control to Text to Image Diffusion Models   arXiv             cs CV  

  Edwards  Benj  November             Stable Diffusion in your pocket   Draw Things  brings AI images to iPhone   Ars Technica  Retrieved July          

  Wendling  Mike  March            AI can be easily used to make fake election photos   report   bbc com  Retrieved July           The CCDH  a campaign group  tested four of the largest public facing AI platforms  Midjourney  OpenAI s ChatGPT Plus  Stability ai s DreamStudio and Microsoft s Image Creator 

  Wiggers  Kyle  May             Stability AI open sources its AI powered design studio   TechCrunch  Retrieved July          

  Weatherbed  Jess  May             Stability AI is open sourcing its DreamStudio web app   The Verge 

  Mann  Tobias  June             A friendly guide to local AI image gen with Stable Diffusion and Automatic       The Register 

  Hachman  Mak   Fooocus is the easiest way to create AI art on your PC   PCWorld 

   ComfyUI Workflows and what you need to know   thinkdiffusion com  December       Retrieved July          

   ComfyUI   github com  Retrieved July          

  Huang  Yenkai  May            Latent Auto recursive Composition Engine  M S  Computer Science thesis   Dartmouth College  Retrieved July          

   CompVis stable diffusion v      Hugging Face   huggingface co  Archived from the original on January           Retrieved August          

   CompVis  CompVis    huggingface co  August           Retrieved March         

   runwayml stable diffusion v      Hugging Face   huggingface co  Archived from the original on September           Retrieved August          

  a b  stabilityai stable diffusion     Hugging Face   huggingface co  Archived from the original on September           Retrieved August          

   stabilityai stable diffusion   base   Hugging Face   huggingface co  Retrieved January         

   stabilityai stable diffusion       Hugging Face   huggingface co  Archived from the original on September           Retrieved August          

   stabilityai stable diffusion xl base       Hugging Face   huggingface co  Archived from the original on October          Retrieved August          

   Announcing SDXL       Stability AI  Retrieved January         

   stabilityai sdxl turbo   Hugging Face   huggingface co  Retrieved January         

   Adversarial Diffusion Distillation   Stability AI  Retrieved January         

   Stable Diffusion     Stability AI  Retrieved March         

  a b  Stable Diffusion       Stability AI  Archived from the original on October           Retrieved October          

  Radford  Alec  Kim  Jong Wook  Hallacy  Chris  Ramesh  Aditya  Goh  Gabriel  Agarwal  Sandhini  Sastry  Girish  Askell  Amanda  Mishkin  Pamela  February             Learning Transferable Visual Models From Natural Language Supervision   arXiv             cs CV  

  Rombach  Robin  Blattmann  Andreas  Lorenz  Dominik  Esser  Patrick  Ommer  Bj rn          High Resolution Image Synthesis With Latent Diffusion Models   Proceedings of the IEEE CVF Conference on Computer Vision and Pattern Recognition  CVPR   pp                    arXiv            

  Kerner  Sean Michael  December             Stable Diffusion     hits Amazon Bedrock  What it means for enterprise AI workflows   VentureBeat  Retrieved December          

   LICENSE md   stabilityai stable diffusion xl base     at main   huggingface co  July           Retrieved January         

  Heikkil   Melissa  September             This artist is dominating AI generated art  And he s not happy about it   MIT Technology Review  Archived from the original on January           Retrieved September          

  a b Ryo Shimizu  August             Midjourney           AI   StableDiffusion    AI                  Business Insider Japan  in Japanese   Archived from the original on December           Retrieved October         

  Cai  Kenrick   Startup Behind AI Image Generator Stable Diffusion Is In Talks To Raise At A Valuation Up To    Billion   Forbes  Archived from the original on September           Retrieved October          

   Illegal trade in AI child sex abuse images exposed   BBC News  June           Archived from the original on September           Retrieved September          

  Maiberg  Emanuel  June             Hackers Target AI Users With Malicious Stable Diffusion Tool on GitHub to Protest  Art Theft        Media  Retrieved June          

  Vincent  James  January             AI art tools Stable Diffusion and Midjourney targeted with copyright lawsuit   The Verge  Archived from the original on March          Retrieved January          

  Brittain  Blake  July             US judge finds flaws in artists  lawsuit against AI companies   Reuters  Archived from the original on September          Retrieved August         

  Goosens  Sophia  February             Getty Images v Stability AI  the implications for UK copyright law and licensing  

  Gill  Dennis  December             Getty Images v Stability AI  copyright claims can proceed to trial  

  Goosens  Sophia  February             Getty v  Stability AI case goes to trial in the UK   what we learned  

  a b Hill  Charlotte  February             Generative AI in the courts  Getty Images v Stability AI  

   Stable Diffusion Public Release   Stability Ai  Archived from the original on August           Retrieved August          

   From RAIL to Open RAIL  Topologies of RAIL Licenses   Responsible AI Licenses  RAIL   August           Archived from the original on July           Retrieved February          

   Ready or not  mass video deepfakes are coming   The Washington Post  August           Archived from the original on August           Retrieved August          

   License   a Hugging Face Space by CompVis   huggingface co  Archived from the original on September          Retrieved September         

  Katsuo Ishida  August                         AI      Stable Diffusion                Impress Corporation  in Japanese   Archived from the original on November           Retrieved October         

   Community License   Stability AI  July          Retrieved October          


External links edit 



Wikimedia Commons has media related to Stable Diffusion 

Stable Diffusion Demo
 Step by Step visual introduction to Diffusion Models    Blog by Kemal Erdem   Retrieved August          
 U Net for Stable Diffusion   U Net for Stable Diffusion  Retrieved August          
Interactive Explanation of Stable Diffusion
 We Are All Raw Material for AI   Investigation on sensitive and private data in Stable Diffusions training data
 Negative Prompts in Stable Diffusion 
 Negative Prompts in Stable Diffusion 
vteGenerative AIConcepts
Autoencoder
Deep learning
Generative adversarial network
Generative pre trained transformer
Large language model
Neural network
Prompt engineering
Retrieval augmented generation
Reinforcement learning from human feedback
Self supervised learning
Transformer
Variational autoencoder
Vision transformer
Word embedding
ModelsText
Claude
DBRX
DeepSeek
ERNIE
Gemini
GPT
 
 
 
J
ChatGPT
 
 o
o 
o 
   
   
o 
Granite
Grok
Llama
Manus
Mistral Large
PanGu  
Qwen
Image
Aurora
DALL E
Firefly
Flux
GPT Image  
Ideogram
Imagen
Midjourney
Stable Diffusion
Speech
   ai
WaveNet
Video
Dream Machine
Gen  
Hailuo AI
Kling
Sora
Veo
VideoPoet
Music
Endel
Suno AI
Udio
Companies
   AI
Alibaba
Anthropic
Baichuan
Baidu
DeepSeek
ElevenLabs
Google DeepMind
Hugging Face
Kuaishou
Meta AI
MiniMax
Mistral AI
Moonshot AI
OpenAI
Runway
Stability AI
Synthesia
xAI
Zhipu AI

 Category
 Commons

vteArtificial intelligence  AI History  timeline Concepts
Parameter
Hyperparameter
Loss functions
Regression
Bias variance tradeoff
Double descent
Overfitting
Clustering
Gradient descent
SGD
Quasi Newton method
Conjugate gradient method
Backpropagation
Attention
Convolution
Normalization
Batchnorm
Activation
Softmax
Sigmoid
Rectifier
Gating
Weight initialization
Regularization
Datasets
Augmentation
Prompt engineering
Reinforcement learning
Q learning
SARSA
Imitation
Policy gradient
Diffusion
Latent diffusion model
Autoregression
Adversary
RAG
Uncanny valley
RLHF
Self supervised learning
Recursive self improvement
Word embedding
Hallucination
Applications
Machine learning
In context learning
Artificial neural network
Deep learning
Language model
Large language model
NMT
Artificial general intelligence  AGI 
ImplementationsAudio visual
AlexNet
WaveNet
Human image synthesis
HWR
OCR
Speech synthesis
   ai
ElevenLabs
Speech recognition
Whisper
Facial recognition
AlphaFold
Text to image models
Aurora
DALL E
Firefly
Flux
Ideogram
Imagen
Midjourney
Stable Diffusion
Text to video models
Dream Machine
Runway Gen
Hailuo AI
Kling
Sora
Veo
Music generation
Suno AI
Udio
Text
Word vec
Seq seq
GloVe
BERT
T 
Llama
Chinchilla AI
PaLM
GPT
 
 
 
J
ChatGPT
 
 o
o 
o 
   
   
o 
Claude
Gemini
chatbot
Grok
LaMDA
BLOOM
Project Debater
IBM Watson
IBM Watsonx
Granite
PanGu  
DeepSeek
Qwen
Decisional
AlphaGo
AlphaZero
OpenAI Five
Self driving car
MuZero
Action selection
AutoGPT
Robot control
People
Alan Turing
Warren Sturgis McCulloch
Walter Pitts
John von Neumann
Claude Shannon
Marvin Minsky
John McCarthy
Nathaniel Rochester
Allen Newell
Cliff Shaw
Herbert A  Simon
Oliver Selfridge
Frank Rosenblatt
Bernard Widrow
Joseph Weizenbaum
Seymour Papert
Seppo Linnainmaa
Paul Werbos
J rgen Schmidhuber
Yann LeCun
Geoffrey Hinton
John Hopfield
Yoshua Bengio
Lotfi A  Zadeh
Stephen Grossberg
Alex Graves
Andrew Ng
Fei Fei Li
Alex Krizhevsky
Ilya Sutskever
Demis Hassabis
David Silver
Ian Goodfellow
Andrej Karpathy
James Goodnight
Architectures
Neural Turing machine
Differentiable neural computer
Transformer
Vision transformer  ViT 
Recurrent neural network  RNN 
Long short term memory  LSTM 
Gated recurrent unit  GRU 
Echo state network
Multilayer perceptron  MLP 
Convolutional neural network  CNN 
Residual neural network  RNN 
Highway network
Mamba
Autoencoder
Variational autoencoder  VAE 
Generative adversarial network  GAN 
Graph neural network  GNN 

 Portals
Technology
 Category
Artificial neural networks
Machine learning
 List
Companies
Projects






Retrieved from  https   en wikipedia org w index php title Stable Diffusion amp oldid