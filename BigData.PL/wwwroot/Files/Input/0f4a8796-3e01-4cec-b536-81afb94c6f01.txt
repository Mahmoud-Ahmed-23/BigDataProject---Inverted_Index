Methods in artificial intelligence research
Part of a series onArtificial intelligence  AI 
Major goals
Artificial general intelligence
Intelligent agent
Recursive self improvement
Planning
Computer vision
General game playing
Knowledge reasoning
Natural language processing
Robotics
AI safety

Approaches
Machine learning
Symbolic
Deep learning
Bayesian networks
Evolutionary algorithms
Hybrid intelligent systems
Systems integration

Applications
Bioinformatics
Deepfake
Earth sciences
 Finance 
Generative AI
Art
Audio
Music
Government
Healthcare
Mental health
Industry
Translation
 Military 
Physics
Projects

Philosophy
Artificial consciousness
Chinese room
Friendly AI
Control problem Takeover
Ethics
Existential risk
Turing test
Uncanny valley

History
Timeline
Progress
AI winter
AI boom

Glossary
Glossary
vte
In artificial intelligence  symbolic artificial intelligence  also known as classical artificial intelligence  or logic based artificial intelligence                       
is the term for the collection of all methods in artificial intelligence research that are based on high level symbolic  human readable  representations of problems  logic and search             Symbolic AI used tools such as logic programming  production rules  semantic nets and frames  and it developed applications such as knowledge based systems  in particular  expert systems    symbolic mathematics  automated theorem provers  ontologies  the semantic web  and automated planning and scheduling systems  The Symbolic AI paradigm led to seminal ideas in search  symbolic programming languages  agents  multi agent systems  the semantic web  and the strengths and limitations of formal knowledge and reasoning systems 
Symbolic AI was the dominant paradigm of AI research from the mid     s until the mid     s             Researchers in the     s and the     s were convinced that symbolic approaches would eventually succeed in creating a machine with artificial general intelligence and considered this the ultimate goal of their field      citation needed      An early boom  with early successes such as the Logic Theorist and Samuel s Checkers Playing Program  led to unrealistic expectations and promises and was followed by the first AI Winter as funding dried up                        A second boom             occurred with the rise of expert systems  their promise of capturing corporate expertise  and an enthusiastic corporate embrace                        That boom  and some early successes  e g   with XCON at DEC  was followed again by later disappointment             Problems with difficulties in knowledge acquisition  maintaining large knowledge bases  and brittleness in handling out of domain problems arose  Another  second  AI Winter             followed             Subsequently  AI researchers focused on addressing underlying problems in handling uncertainty and in knowledge acquisition              Uncertainty was addressed with formal methods such as hidden Markov models  Bayesian reasoning  and statistical relational learning                          Symbolic machine learning addressed the knowledge acquisition problem with contributions including Version Space  Valiant s PAC learning  Quinlan s ID  decision tree learning  case based learning  and inductive logic programming to learn relations             
Neural networks  a subsymbolic approach  had been pursued from early days and reemerged strongly in        Early examples are Rosenblatt s perceptron learning work  the backpropagation work of Rumelhart  Hinton and Williams              and work in convolutional neural networks by LeCun et al  in                   However  neural networks were not viewed as successful until about        Until Big Data became commonplace  the general consensus in the Al community was that the so called neural network approach was hopeless  Systems just didn t work that well  compared to other methods      A revolution came in       when a number of people  including a team of researchers working with Hinton  worked out a way to use the power of GPUs to enormously increase the power of neural networks               Over the next several years  deep learning had spectacular success in handling vision  speech recognition  speech synthesis  image generation  and machine translation  However  since       as inherent difficulties with bias  explanation  comprehensibility  and robustness became more apparent with deep learning approaches  an increasing number of AI researchers have called for combining the best of both the symbolic and neural network approaches                         and addressing areas that both approaches have difficulty with  such as common sense reasoning             


History edit 
A short history of symbolic AI to the present day follows below  Time periods and titles are drawn from Henry Kautz s      AAAI Robert S  Engelmore Memorial Lecture             and the longer Wikipedia article on the History of AI  with dates and titles differing slightly for increased clarity 

The first AI summer  irrational exuberance            edit 
Success at early attempts in AI occurred in three main areas  artificial neural networks  knowledge representation  and heuristic search  contributing to high expectations  This section summarizes Kautz s reprise of early AI history 

Approaches inspired by human or animal cognition or behavior edit 
Cybernetic approaches attempted to replicate the feedback loops between animals and their environments  A robotic turtle  with sensors  motors for driving and steering  and seven vacuum tubes for control  based on a preprogrammed neural net  was built as early as       This work can be seen as an early precursor to later work in neural networks  reinforcement learning  and situated robotics             
An important early symbolic AI program was the Logic theorist  written by Allen Newell  Herbert Simon and Cliff Shaw in          as it was able to prove    elementary theorems from Whitehead and Russell s Principia Mathematica  Newell  Simon  and Shaw later generalized this work to create a domain independent problem solver  GPS  General Problem Solver   GPS solved problems represented with formal operators via state space search using means ends analysis             
During the     s  symbolic approaches achieved great success at simulating intelligent behavior in structured environments such as game playing  symbolic mathematics  and theorem proving  AI research was concentrated in four institutions in the     s  Carnegie Mellon University  Stanford  MIT and  later  University of Edinburgh  Each one developed its own style of research  Earlier approaches based on cybernetics or artificial neural networks were abandoned or pushed into the background 
Herbert Simon and Allen Newell studied human problem solving skills and attempted to formalize them  and their work laid the foundations of the field of artificial intelligence  as well as cognitive science  operations research and management science  Their research team used the results of psychological experiments to develop programs that simulated the techniques that people used to solve problems                          This tradition  centered at Carnegie Mellon University would eventually culminate in the development of the Soar architecture in the middle     s                         

Heuristic search edit 
In addition to the highly specialized domain specific kinds of knowledge that we will see later used in expert systems  early symbolic AI researchers discovered another more general application of knowledge  These were called heuristics  rules of thumb that guide a search in promising directions   How can non enumerative search be practical when the underlying problem is exponentially hard  The approach advocated by Simon and Newell is to employ heuristics  fast algorithms that may fail on some inputs or output suboptimal solutions               Another important advance was to find a way to apply these heuristics that guarantees a solution will be found  if there is one  not withstanding the occasional fallibility of heuristics   The A  algorithm provided a general frame for complete and optimal heuristically guided search  A  is used as a subroutine within practically every AI algorithm today but is still no magic bullet  its guarantee of completeness is bought at the cost of worst case exponential time             

Early work on knowledge representation and reasoning edit 
Early work covered both applications of formal reasoning emphasizing first order logic  along with attempts to handle common sense reasoning in a less formal manner 

Modeling formal reasoning with logic  the  neats  edit 
Main article  logic programming
Unlike Simon and Newell  John McCarthy felt that machines did not need to simulate the exact mechanisms of human thought  but could instead try to find the essence of abstract reasoning and problem solving with logic              regardless of whether people used the same algorithms      a     
His laboratory at Stanford  SAIL  focused on using formal logic to solve a wide variety of problems  including knowledge representation  planning and learning             
Logic was also the focus of the work at the University of Edinburgh and elsewhere in Europe which led to the development of the programming language Prolog and the science of logic programming                         

Modeling implicit common sense knowledge with frames and scripts  the  scruffies  edit 
Main article  neats vs  scruffies
Researchers at MIT  such as Marvin Minsky and Seymour Papert                                     found that solving difficult problems in vision and natural language processing required ad hoc solutions they argued that no simple and general principle  like logic  would capture all the aspects of intelligent behavior  Roger Schank described their  anti logic  approaches as  scruffy   as opposed to the  neat  paradigms at CMU and Stanford                          
Commonsense knowledge bases  such as Doug Lenat s Cyc  are an example of  scruffy  AI  since they must be built by hand  one complicated concept at a time                                     

The first AI winter  crushed dreams            edit 
The first AI winter was a shock 

During the first AI summer  many people thought that machine intelligence could be achieved in just a few years  The Defense Advance Research Projects Agency  DARPA  launched programs to support AI research to use AI to solve problems of national security  in particular  to automate the translation of Russian to English for intelligence operations and to create autonomous tanks for the battlefield  Researchers had begun to realize that achieving AI was going to be much harder than was supposed a decade earlier  but a combination of hubris and disingenuousness led many university and think tank researchers to accept funding with promises of deliverables that they should have known they could not fulfill  By the mid     s neither useful natural language translation systems nor autonomous tanks had been created  and a dramatic backlash set in  New DARPA leadership canceled existing AI funding programs 
   

Outside of the United States  the most fertile ground for AI research was the United Kingdom  The AI winter in the United Kingdom was spurred on not so much by disappointed military leaders as by rival academics who viewed AI researchers as charlatans and a drain on research funding  A professor of applied mathematics  Sir James Lighthill  was commissioned by Parliament to evaluate the state of AI research in the nation  The report stated that all of the problems being worked on in AI would be better handled by researchers from other disciplines such as applied mathematics  The report also claimed that AI successes on toy problems could never scale to real world applications due to combinatorial explosion             
The second AI summer  knowledge is power            edit 
Knowledge based systems edit 
As limitations with weak  domain independent methods became more and more apparent              researchers from all three traditions began to build knowledge into AI applications                         The knowledge revolution was driven by the realization that knowledge underlies high performance  domain specific AI applications 
Edward Feigenbaum said 

 In the knowledge lies the power              
to describe that high performance in a specific domain requires both general and highly domain specific knowledge  Ed Feigenbaum and Doug Lenat called this The Knowledge Principle  

    The Knowledge Principle  if a program is to perform a complex task well  it must know a great deal about the world in which it operates     A plausible extension of that principle  called the Breadth Hypothesis  there are two additional abilities necessary for intelligent behavior in unexpected situations  falling back on increasingly general knowledge  and analogizing to specific but far flung knowledge             
Success with expert systems edit 
Main article  Expert systems
This  knowledge revolution  led to the development and deployment of expert systems  introduced by Edward Feigenbaum   the first commercially successful form of AI software                                     
Key expert systems were 

DENDRAL  which found the structure of organic molecules from their chemical formula and mass spectrometer readings 
MYCIN  which diagnosed bacteremia   and suggested further lab tests  when necessary   by interpreting lab results  patient history  and doctor observations   With about     rules  MYCIN was able to perform as well as some experts  and considerably better than junior doctors              
INTERNIST and CADUCEUS which tackled internal medicine diagnosis  Internist attempted to capture the expertise of the chairman of internal medicine at the University of Pittsburgh School of Medicine while CADUCEUS could eventually diagnose up to      different diseases 
GUIDON  which showed how a knowledge base built for expert problem solving could be repurposed for teaching             
XCON  to configure VAX computers  a then laborious process that could take up to    days  XCON reduced the time to about    minutes            
DENDRAL is considered the first expert system that relied on knowledge intensive problem solving  It is described below  by Ed Feigenbaum  from a Communications of the ACM interview  Interview with Ed Feigenbaum 

One of the people at Stanford interested in computer based models of mind was Joshua Lederberg  the      Nobel Prize winner in genetics  When I told him I wanted an induction  sandbox   he said   I have just the one for you   His lab was doing mass spectrometry of amino acids  The question was  how do you go from looking at the spectrum of an amino acid to the chemical structure of the amino acid  That s how we started the DENDRAL Project  I was good at heuristic search methods  and he had an algorithm that was good at generating the chemical problem space 
We did not have a grandiose vision  We worked bottom up  Our chemist was Carl Djerassi  inventor of the chemical behind the birth control pill  and also one of the world s most respected mass spectrometrists  Carl and his postdocs were world class experts in mass spectrometry  We began to add to their knowledge  inventing knowledge of engineering as we went along  These experiments amounted to titrating DENDRAL more and more knowledge  The more you did that  the smarter the program became  We had very good results 

The generalization was  in the knowledge lies the power  That was the big idea  In my career that is the huge   Ah ha    and it wasn t the way AI was being done previously  Sounds simple  but it s probably AI s most powerful generalization             
The other expert systems mentioned above came after DENDRAL  MYCIN exemplifies the classic expert system architecture of a knowledge base of rules coupled to a symbolic reasoning mechanism  including the use of certainty factors to handle uncertainty  GUIDON shows how an explicit knowledge base can be repurposed for a second application  tutoring  and is an example of an intelligent tutoring system  a particular kind of knowledge based application  Clancey showed that it was not sufficient simply to use MYCIN s rules for instruction  but that he also needed to add rules for dialogue management and student modeling              XCON is significant because of the millions of dollars it saved DEC  which triggered the expert system boom where most all major corporations in the US had expert systems groups  to capture corporate expertise  preserve it  and automate it 

By       DEC s AI group had    expert systems deployed  with more on the way  DuPont had     in use and     in development  Nearly every major U S  corporation had its own Al group and was either using or investigating expert systems             
Chess expert knowledge was encoded in Deep Blue  In       this allowed IBM s Deep Blue  with the help of symbolic AI  to win in a game of chess against the world champion at that time  Garry Kasparov             

Architecture of knowledge based and expert systems edit 
A key component of the system architecture for all expert systems is the knowledge base  which stores facts and rules for problem solving             
The simplest approach for an expert system knowledge base is simply a collection or network of production rules  Production rules connect symbols in a relationship similar to an If Then statement  The expert system processes the rules to make deductions and to determine what additional information it needs  i e  what questions to ask  using human readable symbols  For example  OPS   CLIPS and their successors Jess and Drools operate in this fashion 
Expert systems can operate in either a forward chaining   from evidence to conclusions   or backward chaining   from goals to needed data and prerequisites   manner  More advanced knowledge based systems  such as Soar can also perform meta level reasoning  that is reasoning about their own reasoning in terms of deciding how to solve problems and monitoring the success of problem solving strategies 
Blackboard systems are a second kind of knowledge based or expert system architecture  They model a community of experts incrementally contributing  where they can  to solve a problem  The problem is represented in multiple levels of abstraction or alternate views  The experts  knowledge sources  volunteer their services whenever they recognize they can contribute  Potential problem solving actions are represented on an agenda that is updated as the problem situation changes  A controller decides how useful each contribution is  and who should make the next problem solving action  One example  the BB  blackboard architecture             was originally inspired by studies of how humans plan to perform multiple tasks in a trip              An innovation of BB  was to apply the same blackboard model to solving its control problem  i e   its controller performed meta level reasoning with knowledge sources that monitored how well a plan or the problem solving was proceeding and could switch from one strategy to another as conditions   such as goals or times   changed  BB  has been applied in multiple domains  construction site planning  intelligent tutoring systems  and real time patient monitoring 

The second AI winter            edit 
At the height of the AI boom  companies such as Symbolics  LMI  and Texas Instruments were selling LISP machines specifically targeted to accelerate the development of AI applications and research  In addition  several artificial intelligence companies  such as Teknowledge and Inference Corporation  were selling expert system shells  training  and consulting to corporations 
Unfortunately  the AI boom did not last and Kautz best describes the second AI winter that followed 

Many reasons can be offered for the arrival of the second AI winter  The hardware companies failed when much more cost effective general Unix workstations from Sun together with good compilers for LISP and Prolog came onto the market  Many commercial deployments of expert systems were discontinued when they proved too costly to maintain  Medical expert systems never caught on for several reasons  the difficulty in keeping them up to date  the challenge for medical professionals to learn how to use a bewildering variety of different expert systems for different medical conditions  and perhaps most crucially  the reluctance of doctors to trust a computer made diagnosis over their gut instinct  even for specific domains where the expert systems could outperform an average doctor  Venture capital money deserted AI practically overnight  The world AI conference IJCAI hosted an enormous and lavish trade show and thousands of nonacademic attendees in      in Vancouver  the main AI conference the following year  AAAI      in St  Paul  was a small and strictly academic affair 
           
Adding in more rigorous foundations            edit 
Uncertain reasoning edit 
Both statistical approaches and extensions to logic were tried 
One statistical approach  hidden Markov models  had already been popularized in the     s for speech recognition work              Subsequently  in       Judea Pearl popularized the use of Bayesian Networks as a sound but efficient way of handling uncertain reasoning with his publication of the book Probabilistic Reasoning in Intelligent Systems  Networks of Plausible Inference              and Bayesian approaches were applied successfully in expert systems              Even later  in the     s  statistical relational learning  an approach that combines probability with logical formulas  allowed probability to be combined with first order logic  e g   with either Markov Logic Networks or Probabilistic Soft Logic 
Other  non probabilistic extensions to first order logic to support were also tried  For example  non monotonic reasoning could be used with truth maintenance systems  A truth maintenance system tracked assumptions and justifications for all inferences  It allowed inferences to be withdrawn when assumptions were found out to be incorrect or a contradiction was derived  Explanations could be provided for an inference by explaining which rules were applied to create it and then continuing through underlying inferences and rules all the way back to root assumptions              Lotfi Zadeh had introduced a different kind of extension to handle the representation of vagueness  For example  in deciding how  heavy  or  tall  a man is  there is frequently no clear  yes  or  no  answer  and a predicate for heavy or tall would instead return values between   and    Those values represented to what degree the predicates were true  His fuzzy logic further provided a means for propagating combinations of these values through logical formulas             

Machine learning edit 
Symbolic machine learning approaches were investigated to address the knowledge acquisition bottleneck  One of the earliest is Meta DENDRAL  Meta DENDRAL used a generate and test technique to generate plausible rule hypotheses to test against spectra  Domain and task knowledge reduced the number of candidates tested to a manageable size  Feigenbaum described Meta DENDRAL as

   the culmination of my dream of the early to mid     s having to do with theory formation  The conception was that you had a problem solver like DENDRAL that took some inputs and produced an output  In doing so  it used layers of knowledge to steer and prune the search  That knowledge got in there because we interviewed people  But how did the people get the knowledge  By looking at thousands of spectra  So we wanted a program that would look at thousands of spectra and infer the knowledge of mass spectrometry that DENDRAL could use to solve individual hypothesis formation problems 
We did it  We were even able to publish new knowledge of mass spectrometry in the Journal of the American Chemical Society  giving credit only in a footnote that a program  Meta DENDRAL  actually did it  We were able to do something that had been a dream  to have a computer program come up with a new and publishable piece of science             
In contrast to the knowledge intensive approach of Meta DENDRAL  Ross Quinlan invented a domain independent approach to statistical classification  decision tree learning  starting first with ID              and then later extending its capabilities to C                 The decision trees created are glass box  interpretable classifiers  with human interpretable classification rules 
Advances were made in understanding machine learning theory  too  Tom Mitchell introduced version space learning which describes learning as a search through a space of hypotheses  with upper  more general  and lower  more specific  boundaries encompassing all viable hypotheses consistent with the examples seen so far              More formally  Valiant introduced Probably Approximately Correct Learning  PAC Learning   a framework for the mathematical analysis of machine learning             
Symbolic machine learning encompassed more than learning by example  E g   John Anderson provided a cognitive model of human learning where skill practice results in a compilation of rules from a declarative format to a procedural format with his ACT R cognitive architecture  For example  a student might learn to apply  Supplementary angles are two angles whose measures sum     degrees  as several different procedural rules  E g   one rule might say that if X and Y are supplementary and you know X  then Y will be       X  He called his approach  knowledge compilation   ACT R has been used successfully to model aspects of human cognition  such as learning and retention  ACT R is also used in intelligent tutoring systems  called cognitive tutors  to successfully teach geometry  computer programming  and algebra to school children             
Inductive logic programming was another approach to learning that allowed logic programs to be synthesized from input output examples  E g   Ehud Shapiro s MIS  Model Inference System  could synthesize Prolog programs from examples              John R  Koza applied genetic algorithms to program synthesis to create genetic programming  which he used to synthesize LISP programs  Finally  Zohar Manna and Richard Waldinger provided a more general approach to program synthesis that synthesizes a functional program in the course of proving its specifications to be correct             
As an alternative to logic  Roger Schank introduced case based reasoning  CBR   The CBR approach outlined in his book  Dynamic Memory              focuses first on remembering key problem solving cases for future use and generalizing them where appropriate  When faced with a new problem  CBR retrieves the most similar previous case and adapts it to the specifics of the current problem              Another alternative to logic  genetic algorithms and genetic programming are based on an evolutionary model of learning  where sets of rules are encoded into populations  the rules govern the behavior of individuals  and selection of the fittest prunes out sets of unsuitable rules over many generations             
Symbolic machine learning was applied to learning concepts  rules  heuristics  and problem solving  Approaches  other than those above  include 

Learning from instruction or advice i e   taking human instruction  posed as advice  and determining how to operationalize it in specific situations  For example  in a game of Hearts  learning exactly how to play a hand to  avoid taking points              
Learning from exemplars improving performance by accepting subject matter expert  SME  feedback during training  When problem solving fails  querying the expert to either learn a new exemplar for problem solving or to learn a new explanation as to exactly why one exemplar is more relevant than another  For example  the program Protos learned to diagnose tinnitus cases by interacting with an audiologist             
Learning by analogy constructing problem solutions based on similar problems seen in the past  and then modifying their solutions to fit a new situation or domain                         
Apprentice learning systems learning novel solutions to problems by observing human problem solving  Domain knowledge explains why novel solutions are correct and how the solution can be generalized  LEAP learned how to design VLSI circuits by observing human designers             
Learning by discovery i e   creating tasks to carry out experiments and then learning from the results  Doug Lenat s Eurisko  for example  learned heuristics to beat human players at the Traveller role playing game for two years in a row             
Learning macro operators i e   searching for useful macro operators to be learned from sequences of basic problem solving actions  Good macro operators simplify problem solving by allowing problems to be solved at a more abstract level             
Deep learning and neuro symbolic AI      now edit 
With the rise of deep learning  the symbolic AI approach has been compared to deep learning as complementary     with parallels having been drawn many times by AI researchers between Kahneman s research on human reasoning and decision making   reflected in his book Thinking  Fast and Slow   and the so called  AI systems   and     which would in principle be modelled by deep learning and symbolic reasoning  respectively   In this view  symbolic reasoning is more apt for deliberative reasoning  planning  and explanation while deep learning is more apt for fast pattern recognition in perceptual applications with noisy data                         

Neuro symbolic AI  integrating neural and symbolic approaches edit 
Neuro symbolic AI attempts to integrate neural and symbolic architectures in a manner that addresses strengths and weaknesses of each  in a complementary fashion  in order to support robust AI capable of reasoning  learning  and cognitive modeling  As argued by Valiant             and many others              the effective construction of rich computational cognitive models demands the combination of sound symbolic reasoning and efficient  machine  learning models  Gary Marcus  similarly  argues that   We cannot construct rich cognitive models in an adequate  automated way without the triumvirate of hybrid architecture  rich prior knowledge  and sophisticated techniques for reasoning                and in particular 
 To build a robust  knowledge driven approach to AI we must have the machinery of symbol manipulation in our toolkit  Too much of useful knowledge is abstract to make do without tools that represent and manipulate abstraction  and to date  the only machinery that we know of that can manipulate such abstract knowledge reliably is the apparatus of symbol manipulation              
Henry Kautz              Francesca Rossi              and Bart Selman             have also argued for a synthesis  Their arguments are based on a need to address the two kinds of thinking discussed in Daniel Kahneman s book  Thinking  Fast and Slow  Kahneman describes human thinking as having two components  System   and System    System   is fast  automatic  intuitive and unconscious  System   is slower  step by step  and explicit  System   is the kind used for pattern recognition while System   is far better suited for planning  deduction  and deliberative thinking  In this view  deep learning best models the first kind of thinking while symbolic reasoning best models the second kind and both are needed 
Garcez and Lamb describe research in this area as being ongoing for at least the past twenty years              dating from their      book on neurosymbolic learning systems              A series of workshops on neuro symbolic reasoning has been held every year since       see http   www neural symbolic org  for details 
In their      paper  Neural Symbolic Learning and Reasoning  Contributions and Challenges  Garcez et al  argue that 

The integration of the symbolic and connectionist paradigms of AI has been pursued by a relatively small research community over the last two decades and has yielded several significant results  Over the last decade  neural symbolic systems have been shown capable of overcoming the so called propositional fixation of neural networks  as McCarthy        put it in response to Smolensky         see also  Hinton         Neural networks were shown capable of representing modal and temporal logics  d Avila Garcez and Lamb        and fragments of first order logic  Bader  Hitzler  H lldobler        d Avila Garcez  Lamb  Gabbay         Further  neural symbolic systems have been applied to a number of problems in the areas of bioinformatics  control engineering  software verification and adaptation  visual intelligence  ontology learning  and computer games             
Approaches for integration are varied  Henry Kautz s taxonomy of neuro symbolic architectures  along with some examples  follows 

Symbolic Neural symbolic is the current approach of many neural models in natural language processing  where words or subword tokens are both the ultimate input and output of large language models  Examples include BERT  RoBERTa  and GPT   
Symbolic Neural  is exemplified by AlphaGo  where symbolic techniques are used to call neural techniques  In this case the symbolic approach is Monte Carlo tree search and the neural techniques learn how to evaluate game positions 
Neural Symbolic uses a neural architecture to interpret perceptual data as symbols and relationships that are then reasoned about symbolically 
Neural Symbolic   Neural relies on symbolic reasoning to generate or label training data that is subsequently learned by a deep learning model  e g   to train a neural model for symbolic computation by using a Macsyma like symbolic mathematics system to create or label examples 
Neural  Symbolic  uses a neural net that is generated from symbolic rules  An example is the Neural Theorem Prover              which constructs a neural network from an AND OR proof tree generated from knowledge base rules and terms  Logic Tensor Networks             also fall into this category 
Neural Symbolic  allows a neural model to directly call a symbolic reasoning engine  e g   to perform an action or evaluate a state 
Many key research questions remain  such as 

What is the best way to integrate neural and symbolic architectures             
How should symbolic structures be represented within neural networks and extracted from them 
How should common sense knowledge be learned and reasoned about 
How can abstract knowledge that is hard to encode logically be handled 
Techniques and contributions edit 
This section provides an overview of techniques and contributions in an overall context leading to many other  more detailed articles in Wikipedia  Sections on Machine Learning and Uncertain Reasoning are covered earlier in the history section 

AI programming languages edit 
The key AI programming language in the US during the last symbolic AI boom period was LISP  LISP is the second oldest programming language after FORTRAN and was created in      by John McCarthy  LISP provided the first read eval print loop to support rapid program development  Compiled functions could be freely mixed with interpreted functions  Program tracing  stepping  and breakpoints were also provided  along with the ability to change values or functions and continue from breakpoints or errors  It had the first self hosting compiler  meaning that the compiler itself was originally written in LISP and then ran interpretively to compile the compiler code 
Other key innovations pioneered by LISP that have spread to other programming languages include 

Garbage collection
Dynamic typing
Higher order functions
Recursion
Conditionals
Programs were themselves data structures that other programs could operate on  allowing the easy definition of higher level languages 
In contrast to the US  in Europe the key AI programming language during that same period was Prolog  Prolog provided a built in store of facts and clauses that could be queried by a read eval print loop  The store could act as a knowledge base and the clauses could act as rules or a restricted form of logic  As a subset of first order logic Prolog was based on Horn clauses with a closed world assumption any facts not known were considered false and a unique name assumption for primitive terms e g   the identifier barack obama was considered to refer to exactly one object  Backtracking and unification are built in to Prolog 
Alain Colmerauer and Philippe Roussel are credited as the inventors of Prolog  Prolog is a form of logic programming  which was invented by Robert Kowalski  Its history was also influenced by Carl Hewitt s PLANNER  an assertional database with pattern directed invocation of methods  For more detail see the section on the origins of Prolog in the PLANNER article 
Prolog is also a kind of declarative programming  The logic clauses that describe programs are directly interpreted to run the programs specified  No explicit series of actions is required  as is the case with imperative programming languages 
Japan championed Prolog for its Fifth Generation Project  intending to build special hardware for high performance  Similarly  LISP machines were built to run LISP  but as the second AI boom turned to bust these companies could not compete with new workstations that could now run LISP or Prolog natively at comparable speeds  See the history section for more detail 
Smalltalk was another influential AI programming language  For example  it introduced metaclasses and  along with Flavors and CommonLoops  influenced the Common Lisp Object System  or  CLOS   that is now part of Common Lisp  the current standard Lisp dialect  CLOS is a Lisp based object oriented system that allows multiple inheritance  in addition to incremental extensions to both classes and metaclasses  thus providing a run time meta object protocol             
For other AI programming languages see this list of programming languages for artificial intelligence  Currently  Python  a multi paradigm programming language  is the most popular programming language  partly due to its extensive package library that supports data science  natural language processing  and deep learning  Python includes a read eval print loop  functional elements such as higher order functions  and object oriented programming that includes metaclasses 

Search edit 
Main article  Combinatorial search
Search arises in many kinds of problem solving  including planning  constraint satisfaction  and playing games such as checkers  chess  and go  The best known AI search tree search algorithms are breadth first search  depth first search  A   and Monte Carlo Search  Key search algorithms for Boolean satisfiability are WalkSAT  conflict driven clause learning  and the DPLL algorithm  For adversarial search when playing games  alpha beta pruning  branch and bound  and minimax were early contributions 

Knowledge representation and reasoning edit 
Main article  Knowledge representation and reasoning
Multiple different approaches to represent knowledge and then reason with those representations have been investigated  Below is a quick overview of approaches to knowledge representation and automated reasoning 

Knowledge representation edit 
Main article  Knowledge Representation
Semantic networks  conceptual graphs  frames  and logic are all approaches to modeling knowledge such as domain knowledge  problem solving knowledge  and the semantic meaning of language  Ontologies model key concepts and their relationships in a domain  Example ontologies are YAGO  WordNet  and DOLCE  DOLCE is an example of an upper ontology that can be used for any domain while WordNet is a lexical resource that can also be viewed as an ontology  YAGO incorporates WordNet as part of its ontology  to align facts extracted from Wikipedia with WordNet synsets  The Disease Ontology is an example of a medical ontology currently being used 
Description logic is a logic for automated classification of ontologies and for detecting inconsistent classification data  OWL is a language used to represent ontologies with description logic  Prot g  is an ontology editor that can read in OWL ontologies and then check consistency with deductive classifiers such as such as HermiT             
First order logic is more general than description logic  The automated theorem provers discussed below can prove theorems in first order logic  Horn clause logic is more restricted than first order logic and is used in logic programming languages such as Prolog  Extensions to first order logic include temporal logic  to handle time  epistemic logic  to reason about agent knowledge  modal logic  to handle possibility and necessity  and probabilistic logics to handle logic and probability together 

Automatic theorem proving edit 
Main article  Automated theorem proving
Examples of automated theorem provers for first order logic are 

Prover 
ACL 
Vampire
Prover  can be used in conjunction with the Mace  model checker  ACL  is a theorem prover that can handle proofs by induction and is a descendant of the Boyer Moore Theorem Prover  also known as Nqthm 

Reasoning in knowledge based systems edit 
Main article  Reasoning system
Knowledge based systems have an explicit knowledge base  typically of rules  to enhance reusability across domains by separating procedural code and domain knowledge  A separate inference engine processes rules and adds  deletes  or modifies a knowledge store 
Forward chaining inference engines are the most common  and are seen in CLIPS and OPS   Backward chaining occurs in Prolog  where a more limited logical representation is used  Horn Clauses  Pattern matching  specifically unification  is used in Prolog 
A more flexible kind of problem solving occurs when reasoning about what to do next occurs  rather than simply choosing one of the available actions  This kind of meta level reasoning is used in Soar and in the BB  blackboard architecture 
Cognitive architectures such as ACT R may have additional capabilities  such as the ability to compile frequently used knowledge into higher level chunks 

Commonsense reasoning edit 
Main article  Commonsense reasoning
Marvin Minsky first proposed frames as a way of interpreting common visual situations  such as an office  and Roger Schank extended this idea to scripts for common routines  such as dining out  Cyc has attempted to capture useful common sense knowledge and has  micro theories  to handle particular kinds of domain specific reasoning 
Qualitative simulation  such as Benjamin Kuipers s QSIM              approximates human reasoning about naive physics  such as what happens when we heat a liquid in a pot on the stove  We expect it to heat and possibly boil over  even though we may not know its temperature  its boiling point  or other details  such as atmospheric pressure 
Similarly  Allen s temporal interval algebra is a simplification of reasoning about time and Region Connection Calculus is a simplification of reasoning about spatial relationships  Both can be solved with constraint solvers 

Constraints and constraint based reasoning edit 
Main articles  Constraint programming and Spatial temporal reasoning
Constraint solvers perform a more limited kind of inference than first order logic  They can simplify sets of spatiotemporal constraints  such as those for RCC or Temporal Algebra  along with solving other kinds of puzzle problems  such as Wordle  Sudoku  cryptarithmetic problems  and so on  Constraint logic programming can be used to solve scheduling problems  for example with constraint handling rules  CHR  

Automated planning edit 
Main article  Automated planning and scheduling
The General Problem Solver  GPS  cast planning as problem solving used means ends analysis to create plans  STRIPS took a different approach  viewing planning as theorem proving  Graphplan takes a least commitment approach to planning  rather than sequentially choosing actions from an initial state  working forwards  or a goal state if working backwards   Satplan is an approach to planning where a planning problem is reduced to a Boolean satisfiability problem 

Natural language processing edit 
Main article  Natural language processing
Natural language processing focuses on treating language as data to perform tasks such as identifying topics without necessarily understanding the intended meaning  Natural language understanding  in contrast  constructs a meaning representation and uses that for further processing  such as answering questions 
Parsing  tokenizing  spelling correction  part of speech tagging  noun and verb phrase chunking are all aspects of natural language processing long handled by symbolic AI  but since improved by deep learning approaches  In symbolic AI  discourse representation theory and first order logic have been used to represent sentence meanings  Latent semantic analysis  LSA  and explicit semantic analysis also provided vector representations of documents  In the latter case  vector components are interpretable as concepts named by Wikipedia articles 
New deep learning approaches based on Transformer models have now eclipsed these earlier symbolic AI approaches and attained state of the art performance in natural language processing  However  Transformer models are opaque and do not yet produce human interpretable semantic representations for sentences and documents  Instead  they produce task specific vectors where the meaning of the vector components is opaque 

Agents and multi agent systems edit 
Main articles  Agent architecture and Multi agent system
Agents are autonomous systems embedded in an environment they perceive and act upon in some sense  Russell and Norvig s standard textbook on artificial intelligence is organized to reflect agent architectures of increasing sophistication              The sophistication of agents varies from simple reactive agents  to those with a model of the world and automated planning capabilities  possibly a BDI agent  i e   one with beliefs  desires  and intentions   or alternatively a reinforcement learning model learned over time to choose actions   up to a combination of alternative architectures  such as a neuro symbolic architecture             that includes deep learning for perception             
In contrast  a multi agent system consists of multiple agents that communicate amongst themselves with some inter agent communication language such as Knowledge Query and Manipulation Language  KQML   The agents need not all have the same internal architecture  Advantages of multi agent systems include the ability to divide work among the agents and to increase fault tolerance when agents are lost  Research problems include how agents reach consensus  distributed problem solving  multi agent learning  multi agent planning  and distributed constraint optimization 

Controversies edit 
Controversies arose from early on in symbolic AI  both within the field e g   between logicists  the pro logic  neats   and non logicists  the anti logic  scruffies   and between those who embraced AI but rejected symbolic approaches primarily connectionists and those outside the field  Critiques from outside of the field were primarily from philosophers  on intellectual grounds  but also from funding agencies  especially during the two AI winters 

The Frame Problem  knowledge representation challenges for first order logic edit 
Main article  Philosophy of artificial intelligence
Limitations were discovered in using simple first order logic to reason about dynamic domains  Problems were discovered both with regards to enumerating the preconditions for an action to succeed and in providing axioms for what did not change after an action was performed 
McCarthy and Hayes introduced the Frame Problem in      in the paper   Some Philosophical Problems from the Standpoint of Artificial Intelligence               A simple example occurs in  proving that one person could get into conversation with another   as an axiom asserting  if a person has a telephone he still has it after looking up a number in the telephone book  would be required for the deduction to succeed  Similar axioms would be required for other domain actions to specify what did not change 
A similar problem  called the Qualification Problem  occurs in trying to enumerate the preconditions for an action to succeed  An infinite number of pathological conditions can be imagined  e g   a banana in a tailpipe could prevent a car from operating correctly 
McCarthy s approach to fix the frame problem was circumscription  a kind of non monotonic logic where deductions could be made from actions that need only specify what would change while not having to explicitly specify everything that would not change  Other non monotonic logics provided truth maintenance systems that revised beliefs leading to contradictions 
Other ways of handling more open ended domains included probabilistic reasoning systems and machine learning to learn new concepts and rules   McCarthy s Advice Taker can be viewed as an inspiration here  as it could incorporate new knowledge provided by a human in the form of assertions or rules  For example  experimental symbolic machine learning systems explored the ability to take high level natural language advice and to interpret it into domain specific actionable rules 
Similar to the problems in handling dynamic domains  common sense reasoning is also difficult to capture in formal reasoning  Examples of common sense reasoning include implicit reasoning about how people think or general knowledge of day to day events  objects  and living creatures   This kind of knowledge is taken for granted and not viewed as noteworthy  Common sense reasoning is an open area of research and challenging both for symbolic systems  e g   Cyc has attempted to capture key parts of this knowledge over more than a decade  and neural systems  e g   self driving cars that do not know not to drive into cones or not to hit pedestrians walking a bicycle  
McCarthy viewed his Advice Taker as having common sense  but his definition of common sense was different than the one above              He defined a program as having common sense  if it automatically deduces for itself a sufficiently wide class of immediate consequences of anything it is told and what it already knows  

Connectionist AI  philosophical challenges and sociological conflicts edit 
Connectionist approaches include earlier work on neural networks              such as perceptrons  work in the mid to late   s  such as Danny Hillis s Connection Machine and Yann LeCun s advances in convolutional neural networks  to today s more advanced approaches  such as Transformers  GANs  and other work in deep learning 
Three philosophical positions             have been outlined among connectionists 

Implementationism where connectionist architectures implement the capabilities for symbolic processing 
Radical connectionism where symbolic processing is rejected totally  and connectionist architectures underlie intelligence and are fully sufficient to explain it 
Moderate connectionism where symbolic processing and connectionist architectures are viewed as complementary and both are required for intelligence 
Olazaran  in his sociological history of the controversies within the neural network community  described the moderate connectionism view as essentially compatible with current research in neuro symbolic hybrids 
The third and last position I would like to examine here is what I call the moderate connectionist view  a more eclectic view of the current debate between connectionism and symbolic AI  One of the researchers who has elaborated this position most explicitly is Andy Clark  a philosopher from the School of Cognitive and Computing Sciences of the University of Sussex  Brighton  England   Clark defended hybrid  partly symbolic  partly connectionist  systems  He claimed that  at least  two kinds of theories are needed in order to study and model cognition  On the one hand  for some information processing tasks  such as pattern recognition  connectionism has advantages over symbolic models  But on the other hand  for other cognitive processes  such as serial  deductive reasoning  and generative symbol manipulation processes  the symbolic paradigm offers adequate models  and not only  approximations   contrary to what radical connectionists would claim              
Gary Marcus has claimed that the animus in the deep learning community against symbolic approaches now may be more sociological than philosophical To think that we can simply abandon symbol manipulation is to suspend disbelief 

And yet  for the most part  that s how most current AI proceeds  Hinton and many others have tried hard to banish symbols altogether  The deep learning hope seemingly grounded not so much in science  but in a sort of historical grudge is that intelligent behavior will emerge purely from the confluence of massive data and deep learning  Where classical computers and software solve tasks by defining sets of symbol manipulating rules dedicated to particular jobs  such as editing a line in a word processor or performing a calculation in a spreadsheet  neural networks typically try to solve tasks by statistical approximation and learning from examples According to Marcus  Geoffrey Hinton and his colleagues have been vehemently  anti symbolic  When deep learning reemerged in       it was with a kind of take no prisoners attitude that has characterized most of the last decade  By       his hostility toward all things symbols had fully crystallized  He gave a talk at an AI workshop at Stanford comparing symbols to aether  one of science s greatest mistakes 
   

Since then  his anti symbolic campaign has only increased in intensity  In       Yann LeCun  Bengio  and Hinton wrote a manifesto for deep learning in one of science s most important journals  Nature  It closed with a direct attack on symbol manipulation  calling not for reconciliation but for outright replacement  Later  Hinton told a gathering of European Union leaders that investing any further money in symbol manipulating approaches was  a huge mistake   likening it to investing in internal combustion engines in the era of electric cars             
Part of these disputes may be due to unclear terminology  

Turing award winner Judea Pearl offers a critique of machine learning which  unfortunately  conflates the terms machine learning and deep learning  Similarly  when Geoffrey Hinton refers to symbolic AI  the connotation of the term tends to be that of expert systems dispossessed of any ability to learn  The use of the terminology is in need of clarification  Machine learning is not confined to association rule mining  c f  the body of work on symbolic ML and relational learning  the differences to deep learning being the choice of representation  localist logical rather than distributed  and the non use of gradient based learning algorithms   Equally  symbolic AI is not just about production rules written by hand  A proper definition of AI concerns knowledge representation and reasoning  autonomous multi agent systems  planning and argumentation  as well as learning             It is worth noting that  from a theoretical perspective  the boundary of advantages between connectionist AI and symbolic AI may not be as clear cut as it appears  For instance  Heng Zhang and his colleagues have proved that mainstream knowledge representation formalisms are  recursively isomorphic  provided they are universal or have equivalent expressive power               This finding implies that there is no fundamental distinction between using symbolic or connectionist knowledge representation formalisms for the realization of artificial general intelligence  AGI   Moreover  the existence of recursive isomorphisms suggests that different technical approaches can draw insights from one another  From this perspective  it seems unnecessary to overemphasize the advantages of any single technical school  instead  mutual learning and integration may offer the most promising path toward the realization of AGI 
Situated robotics  the world as a model edit 
Another critique of symbolic AI is the embodied cognition approach 

The embodied cognition approach claims that it makes no sense to consider the brain separately  cognition takes place within a body  which is embedded in an environment  We need to study the system as a whole  the brain s functioning exploits regularities in its environment  including the rest of its body  Under the embodied cognition approach  robotics  vision  and other sensors become central  not peripheral              
Rodney Brooks invented behavior based robotics  one approach to embodied cognition  Nouvelle AI  another name for this approach  is viewed as an alternative to both symbolic AI and connectionist AI  His approach rejected representations  either symbolic or distributed  as not only unnecessary  but as detrimental  Instead  he created the subsumption architecture  a layered architecture for embodied agents  Each layer achieves a different purpose and must function in the real world  For example  the first robot he describes in Intelligence Without Representation  has three layers  The bottom layer interprets sonar sensors to avoid objects  The middle layer causes the robot to wander around when there are no obstacles  The top layer causes the robot to go to more distant places for further exploration  Each layer can temporarily inhibit or suppress a lower level layer  He criticized AI researchers for defining AI problems for their systems  when   There is no clean division between perception  abstraction  and reasoning in the real world                He called his robots  Creatures  and each layer was  composed of a fixed topology network of simple finite state machines                 In the Nouvelle AI approach   First  it is vitally important to test the Creatures we build in the real world  i e   in the same world that we humans inhabit  It is disastrous to fall into the temptation of testing them in a simplified world first  even with the best intentions of later transferring activity to an unsimplified world                 His emphasis on real world testing was in contrast to  Early work in AI concentrated on games  geometrical problems  symbolic algebra  theorem proving  and other formal systems               and the use of the blocks world in symbolic AI systems such as SHRDLU 

Current views edit 
Each approach symbolic  connectionist  and behavior based has advantages  but has been criticized by the other approaches  Symbolic AI has been criticized as disembodied  liable to the qualification problem  and poor in handling the perceptual problems where deep learning excels  In turn  connectionist AI has been criticized as poorly suited for deliberative step by step problem solving  incorporating knowledge  and handling planning  Finally  Nouvelle AI excels in reactive and real world robotics domains but has been criticized for difficulties in incorporating learning and knowledge 

Hybrid AIs incorporating one or more of these approaches are currently viewed as the path forward                                      Russell and Norvig conclude that Overall  Dreyfus saw areas where AI did not have complete answers and said that Al is therefore impossible  we now see many of these same areas undergoing continued research and development leading to increased capability  not impossibility              
See also edit 

Artificial intelligence
Automated planning and scheduling
Automated theorem proving
Belief revision
Case based reasoning
Cognitive architecture
Cognitive science
Connectionism
Constraint programming
Deep learning
First order logic
GOFAI
History of artificial intelligence
Inductive logic programming
Knowledge based systems
Knowledge representation and reasoning
Logic programming
Machine learning
Model checking
Model based reasoning
Multi agent system
Natural language processing
Neuro symbolic AI
Ontology
Philosophy of artificial intelligence
Physical symbol systems hypothesis
Semantic Web
Sequential pattern mining
Statistical relational learning
Symbolic mathematics
YAGO ontology
WordNet

Notes edit 


  
McCarthy once said   This is AI  so we don t care if it s psychologically real              McCarthy reiterated his position in      at the AI    conference where he said  Artificial intelligence is not  by definition  simulation of human intelligence               Pamela McCorduck writes that there are  two major branches of artificial intelligence  one aimed at producing intelligent behavior regardless of how it was accomplished  and the other aimed at modeling intelligent processes found in nature  particularly human ones                
Stuart Russell and Peter Norvig wrote  Aeronautical engineering texts do not define the goal of their field as making  machines that fly so exactly like pigeons that they can fool even other pigeons               


Citations edit 


  Garnelo  Marta  Shanahan  Murray  October         Reconciling deep learning with symbolic artificial intelligence  representing objects and relations   Current Opinion in Behavioral Sciences             doi         j cobeha              hdl               

  Thomason  Richmond  February             Logic Based Artificial Intelligence   In Zalta  Edward N   ed    Stanford Encyclopedia of Philosophy 

  Garnelo  Marta  Shanahan  Murray                Reconciling deep learning with symbolic artificial intelligence  representing objects and relations   Current Opinion in Behavioral Sciences             doi         j cobeha              hdl                S CID               

  a b Kolata      

  Kautz       pp               

  a b Russell  amp  Norvig       p          

  a b Russell  amp  Norvig       pp             

  a b Kautz       pp               

  a b c Kautz       p           

  Kautz       pp               

  a b Russell  amp  Norvig       p          

  Kautz       p           

  Kautz       pp               

  Rumelhart  David E   Hinton  Geoffrey E   Williams  Ronald J           Learning representations by back propagating errors   Nature                       Bibcode     Natur         R  doi               a   ISSN                 S CID                

  LeCun  Y   Boser  B   Denker  I   Henderson  D   Howard  R   Hubbard  W   Tackel  L           Backpropagation Applied to Handwritten Zip Code Recognition   Neural Computation                  doi         neco               S CID               

  a b Marcus  amp  Davis      

  a b 
Rossi  Francesca   Thinking Fast and Slow in AI   AAAI  Retrieved   July      

  a b 
Selman  Bart   AAAI Presidential Address  The State of AI   AAAI  Retrieved   July      

  a b c Kautz      

  Kautz       p           

  Newell  amp  Simon      

    amp  McCorduck       pp                                  EPAM  

  Crevier       pp               

  McCorduck       pp               

  Crevier       pp               

  a b Kautz       p           

  Russell  amp  Norvig       p     logicist AI   p      McCarthy s work  

  Maker      

  McCorduck       pp               

  Russell  amp  Norvig       p         

  McCorduck       pp               

  Crevier       pp               

  Howe      

  McCorduck       pp               

  Crevier       pp                       

  McCorduck       pp                        

  Crevier       p           

  McCorduck       p           

  Crevier       pp               

  Russell  amp  Norvig       p                

  Kautz       p           

  Russell  amp  Norvig       p          

  McCorduck       pp                                  

  Shustek  Len  June         An interview with Ed Feigenbaum   Communications of the ACM                 doi                          ISSN                 S CID                Retrieved            

  Lenat  Douglas B  Feigenbaum  Edward A          On the thresholds of knowledge   Proceedings of the International Workshop on Artificial Intelligence for Industrial Applications           doi         AIIA             S CID               

  Russell  amp  Norvig       pp             

  McCorduck       pp                        

  Crevier       pp                       

  a b Russell  amp  Norvig       p          

  a b Clancey      

  a b Shustek  Len          An interview with Ed Feigenbaum   Communications of the ACM                 doi                          ISSN                 S CID                Retrieved            

   The fascination with AI  what is artificial intelligence    IONOS Digitalguide  Retrieved            

  Hayes Roth  Murray  amp  Adelman      

  Hayes Roth  Barbara          A blackboard architecture for control   Artificial Intelligence                   doi                              

  Hayes Roth  Barbara         Human Planning Processes  RAND 

  Pearl      

  Spiegelhalter et al       

  Russell  amp  Norvig       pp               

  Russell  amp  Norvig       p           

  Quinlan  J  Ross   Chapter     Learning Efficient Classification Procedures and their Application to Chess End Games   In Michalski  Carbonell  amp  Mitchell        

  Quinlan  J  Ross               C     Programs for Machine Learning   st      ed    San Mateo  Calif  Morgan Kaufmann  ISBN                        

  Mitchell  Tom M   Utgoff  Paul E   Banerji  Ranan   Chapter    Learning by Experimentation  Acquiring and Refining Problem Solving Heuristics   In Michalski  Carbonell  amp  Mitchell        

  Valiant  L  G                 A theory of the learnable   Communications of the ACM                      doi                    ISSN                 S CID               

  Koedinger  K  R   Anderson  J  R   Hadley  W  H   Mark  M  A   others          Intelligent tutoring goes to school in the big city   International Journal of Artificial Intelligence in Education            Retrieved            

  Shapiro  Ehud Y          The Model Inference System   Proceedings of the  th international joint conference on Artificial intelligence  IJCAI  Vol          p            

  Manna  Zohar  Waldinger  Richard                A Deductive Approach to Program Synthesis   ACM Trans  Program  Lang  Syst                 doi                        S CID               

  Schank  Roger C                Dynamic Memory  A Theory of Reminding and Learning in Computers and People  Cambridge Cambridgeshire        New York  Cambridge University Press  ISBN                        

  Hammond  Kristian J                Case Based Planning  Viewing Planning as a Memory Task  Boston  Academic Press  ISBN                        

  Koza  John R                Genetic Programming  On the Programming of Computers by Means of Natural Selection   st      ed    Cambridge  Mass  A Bradford Book  ISBN                        

  Mostow  David Jack   Chapter     Machine Transformation of Advice into a Heuristic Search Procedure   In Michalski  Carbonell  amp  Mitchell        

  Bareiss  Ray  Porter  Bruce  Wier  Craig   Chapter    Protos  An Exemplar Based Learning Apprentice   In Michalski  Carbonell  amp  Mitchell         pp               

  Carbonell  Jaime   Chapter    Learning by Analogy  Formulating and Generalizing Plans from Past Experience   In Michalski  Carbonell  amp  Mitchell         pp               

  Carbonell  Jaime   Chapter     Derivational Analogy  A Theory of Reconstructive Problem Solving and Expertise Acquisition   In Michalski  Carbonell  amp  Mitchell         pp               

  Mitchell  Tom  Mabadevan  Sridbar  Steinberg  Louis   Chapter     LEAP  A Learning Apprentice for VLSI Design   In Kodratoff  amp  Michalski         pp               

  Lenat  Douglas   Chapter    The Role of Heuristics in Learning by Discovery  Three Case Studies   In Michalski  Carbonell  amp  Mitchell         pp               

  Korf  Richard E          Learning to Solve Problems by Searching for Macro Operators  Research Notes in Artificial Intelligence  Pitman Publishing  ISBN                    

  Valiant      

  a b Garcez et al       

  Marcus       p          

  Marcus       p          

  a b Rossi      

  a b Selman      

  Garcez  amp  Lamb       p         

  Garcez et al       

  Rockt schel  Tim  Riedel  Sebastian          Learning Knowledge Base Inference with Neural Theorem Provers   Proceedings of the  th Workshop on Automated Knowledge Base Construction  San Diego  CA  Association for Computational Linguistics  pp              doi          v  W         Retrieved            

  Serafini  Luciano  Garcez  Artur d Avila         Logic Tensor Networks  Deep Learning and Logical Reasoning from Data and Knowledge  arXiv           

  a b Garcez  Artur d Avila  Lamb  Luis C   Gabbay  Dov M          Neural Symbolic Cognitive Reasoning   st      ed    Berlin Heidelberg  Springer  Bibcode     nscr book     D  doi                            ISBN                         S CID               

  Kiczales  Gregor  Rivieres  Jim des  Bobrow  Daniel G                The Art of the Metaobject Protocol   st      ed    Cambridge  Mass  The MIT Press  ISBN                        

  Motik  Boris  Shearer  Rob  Horrocks  Ian                Hypertableau Reasoning for Description Logics   Journal of Artificial Intelligence Research               arXiv            doi         jair       ISSN                 S CID             

  Kuipers  Benjamin         Qualitative Reasoning  Modeling and Simulation with Incomplete Knowledge  MIT Press  ISBN                        

  Russell  amp  Norvig      

  Leo de Penning  Artur S  d Avila Garcez  Lu s C  Lamb  John Jules Ch  Meyer   A Neural Symbolic Cognitive Agent for Online Learning and Reasoning   IJCAI                

  McCarthy  amp  Hayes      

  McCarthy      

  Nilsson       p         

  Olazaran       pp               

  Olazaran       pp               

  Marcus       p          

  Garcez  amp  Lamb       p         

  Zhang  Heng  Jiang  Guifei  Quan  Donghui                A Theory of Formalisms for Representing Knowledge   Proceedings of the AAAI Conference on Artificial Intelligence                        arXiv             doi         aaai v  i          ISSN                

  a b Russell  amp  Norvig       p           

  Brooks       p           

  Brooks       p           

  Brooks       p           

  Brooks       p           


References edit 
Brooks  Rodney A           Intelligence without representation   Artificial Intelligence                   doi                            M  ISSN                 S CID                 Retrieved            
Clancey  William         Knowledge Based Tutoring  The GUIDON Program  MIT Press Series in Artificial Intelligence   Hardcover      ed   
Crevier  Daniel         AI  The Tumultuous Search for Artificial Intelligence  New York  NY  BasicBooks  ISBN                     
Dreyfus  Hubert L          From micro worlds to knowledge representation  AI at an impasse   PDF   Mind Design  MIT Press  Cambridge  MA          
Garcez  Artur S  d Avila  Broda  Krysia  Gabbay  Dov M   Gabbay  Augustus de Morgan Professor of Logic Dov M          Neural Symbolic Learning Systems  Foundations and Applications  Springer Science  amp  Business Media  ISBN                        
Garcez  Artur  Besold  Tarek  De Raedt  Luc  F ldi k  Peter  Hitzler  Pascal  Icard  Thomas  K hnberger  Kai Uwe  Lamb  Lu s  Miikkulainen  Risto  Silver  Daniel         Neural Symbolic Learning and Reasoning  Contributions and Challenges  AAI Spring Symposium   Knowledge Representation and Reasoning  Integrating Symbolic and Neural Approaches  Stanford  CA  AAAI Press  doi                        
Garcez  Artur d Avila  Gori  Marco  Lamb  Luis C   Serafini  Luciano  Spranger  Michael  Tran  Son N          Neural Symbolic Computing  An Effective Methodology for Principled Integration of Machine Learning and Reasoning  arXiv           
Garcez  Artur d Avila  Lamb  Luis C          Neurosymbolic AI  The  rd Wave  arXiv           
Haugeland  John         Artificial Intelligence  The Very Idea  Cambridge  Mass  MIT Press  ISBN                   
Hayes Roth  Frederick  Murray  William  Adelman  Leonard          Expert systems   AccessScience  doi                          
Honavar  Vasant  Uhr  Leonard         Symbolic Artificial Intelligence  Connectionist Networks  amp  Beyond  Technical report   Iowa State University Digital Repository  Computer Science Technical Reports      p         
Honavar  Vasant         Symbolic Artificial Intelligence and Numeric Artificial Neural Networks  Towards a Resolution of the Dichotomy  The Springer International Series In Engineering and Computer Science  Springer US  pp                doi                              
Howe  J   November         Artificial Intelligence at Edinburgh University  a Perspective   Archived from the original on    May       Retrieved    August      
Kautz  Henry               The Third AI Summer  Henry Kautz  AAAI      Robert S  Engelmore Memorial Award Lecture  Retrieved            
Kautz  Henry          The Third AI Summer  AAAI Robert S  Engelmore Memorial Lecture   AI Magazine                  doi         aimag v  i         ISSN                 S CID                 Retrieved            
Kodratoff  Yves  Michalski  Ryszard  eds          Machine Learning        an Artificial Intelligence Approach  Vol       III  San Mateo  Calif   Morgan Kaufman  ISBN                     OCLC                
Kolata  G           How can computers get common sense    Science                         Bibcode     Sci           K  doi         science                PMID               
Maker  Meg Houston          AI     AI Past  Present  Future   Dartmouth College  Archived from the original on   January       Retrieved    October      
Marcus  Gary  Davis  Ernest         Rebooting AI  Building Artificial Intelligence We Can Trust  New York  Pantheon Books  ISBN                     OCLC                 
Marcus  Gary         The Next Decade in AI  Four Steps Towards Robust Artificial Intelligence  arXiv           
McCarthy  John         PROGRAMS WITH COMMON SENSE  Symposium on Mechanization of Thought Processes  NATIONAL PHYSICAL LABORATORY  TEDDINGTON  UK  p         
McCarthy  John  Hayes  Patrick          Some Philosophical Problems From the Standpoint of Artificial Intelligence   Machine Intelligence    B  Meltzer  Donald Michie  eds            
McCorduck  Pamela         Machines Who Think   nd      ed    Natick  Massachusetts  A  K  Peters  ISBN                   
Michalski  Ryszard  Carbonell  Jaime  Mitchell  Tom  eds          Machine Learning        an Artificial Intelligence Approach  Vol       I  Palo Alto  Calif   Tioga Publishing Company  ISBN                     OCLC              
Michalski  Ryszard  Carbonell  Jaime  Mitchell  Tom  eds          Machine Learning        an Artificial Intelligence Approach  Vol       II  Los Altos  Calif   Morgan Kaufman  ISBN                    
Newell  Allen  Simon  Herbert A          Human Problem Solving   st      ed    Englewood Cliffs  New Jersey  Prentice Hall  ISBN                    
Newell  Allen  Simon  H  A           Computer Science as Empirical Inquiry  Symbols and Search   Communications of the ACM                   doi                       
Nilsson  Nils         Artificial Intelligence  A New Synthesis  Morgan Kaufmann  ISBN                         Archived from the original on    July       Retrieved    November      
Olazaran  Mikel                A Sociological History of the Neural Network Controversy   in Yovits  Marshall C   ed    Advances in Computers Volume     vol           Elsevier  pp                doi         S                      ISBN                     retrieved           
Pearl  J          Probabilistic Reasoning in Intelligent Systems  Networks of Plausible Inference  San Mateo  California  Morgan Kaufmann  ISBN                         OCLC                
Russell  Stuart J   Norvig  Peter         Artificial Intelligence  A Modern Approach   th      ed    Hoboken  Pearson  ISBN                         LCCN               
Rossi  Francesca                AAAI      Thinking Fast and Slow in AI  AAAI      Invited Talk    Retrieved            
Selman  Bart                AAAI      Presidential Address  The State of AI   Retrieved            
Serafini  Luciano  Garcez  Artur d Avila               Logic Tensor Networks  Deep Learning and Logical Reasoning from Data and Knowledge  arXiv           
Spiegelhalter  David J   Dawid  A  Philip  Lauritzen  Steffen  Cowell  Robert G           Bayesian analysis in expert systems   Statistical Science        
Turing  A  M           I  Computing Machinery and Intelligence   Mind  LIX                 doi         mind LIX          ISSN                 Retrieved            
Valiant  Leslie G          Knowledge Infusion  In Pursuit of Robustness in Artificial Intelligence   In Hariharan  R   Mukund  M   Vinay  V   eds    Foundations of Software Technology and Theoretical Computer Science  Bangalore   pp               
Xifan Yao  Jiajun Zhou  Jiangming Zhang  Claudio R  Boer         From Intelligent Manufacturing to Smart Manufacturing for Industry     Driven by Next Generation Artificial Intelligence and Further On        th International Conference on Enterprise Systems  ES   IEEE  doi         es         





Retrieved from  https   en wikipedia org w index php title Symbolic artificial intelligence amp oldid