Study of algorithms that improve automatically through experience
For the journal  see Machine Learning  journal  
 Statistical learning  redirects here  For statistical learning in linguistics  see statistical learning in language acquisition 
Part of a series onMachine learningand data mining
Paradigms
Supervised learning
Unsupervised learning
Semi supervised learning
Self supervised learning
Reinforcement learning
Meta learning
Online learning
Batch learning
Curriculum learning
Rule based learning
Neuro symbolic AI
Neuromorphic engineering
Quantum machine learning

Problems
Classification
Generative modeling
Regression
Clustering
Dimensionality reduction
Density estimation
Anomaly detection
Data cleaning
AutoML
Association rules
Semantic analysis
Structured prediction
Feature engineering
Feature learning
Learning to rank
Grammar induction
Ontology learning
Multimodal learning

Supervised learning classification                  regression  
Apprenticeship learning
Decision trees
Ensembles
Bagging
Boosting
Random forest
k NN
Linear regression
Naive Bayes
Artificial neural networks
Logistic regression
Perceptron
Relevance vector machine  RVM 
Support vector machine  SVM 

Clustering
BIRCH
CURE
Hierarchical
k means
Fuzzy
Expectation maximization  EM 
DBSCAN
OPTICS
Mean shift

Dimensionality reduction
Factor analysis
CCA
ICA
LDA
NMF
PCA
PGD
t SNE
SDL

Structured prediction
Graphical models
Bayes net
Conditional random field
Hidden Markov

Anomaly detection
RANSAC
k NN
Local outlier factor
Isolation forest

Artificial neural network
Autoencoder
Deep learning
Feedforward neural network
Recurrent neural network
LSTM
GRU
ESN
reservoir computing
Boltzmann machine
Restricted
GAN
Diffusion model
SOM
Convolutional neural network
U Net
LeNet
AlexNet
DeepDream
Neural radiance field
Transformer
Vision
Mamba
Spiking neural network
Memtransistor
Electrochemical RAM  ECRAM 

Reinforcement learning
Q learning
SARSA
Temporal difference  TD 
Multi agent
Self play

Learning with humans
Active learning
Crowdsourcing
Human in the loop
RLHF

Model diagnostics
Coefficient of determination
Confusion matrix
Learning curve
ROC curve

Mathematical foundations
Kernel machines
Bias variance tradeoff
Computational learning theory
Empirical risk minimization
Occam learning
PAC learning
Statistical learning
VC theory
Topological deep learning

Journals and conferences
ECML PKDD
NeurIPS
ICML
ICLR
IJCAI
ML
JMLR

Related articles
Glossary of artificial intelligence
List of datasets for machine learning research
List of datasets in computer vision and image processing
Outline of machine learning
vte
Part of a series onArtificial intelligence  AI 
Major goals
Artificial general intelligence
Intelligent agent
Recursive self improvement
Planning
Computer vision
General game playing
Knowledge reasoning
Natural language processing
Robotics
AI safety

Approaches
Machine learning
Symbolic
Deep learning
Bayesian networks
Evolutionary algorithms
Hybrid intelligent systems
Systems integration

Applications
Bioinformatics
Deepfake
Earth sciences
 Finance 
Generative AI
Art
Audio
Music
Government
Healthcare
Mental health
Industry
Translation
 Military 
Physics
Projects

Philosophy
Artificial consciousness
Chinese room
Friendly AI
Control problem Takeover
Ethics
Existential risk
Turing test
Uncanny valley

History
Timeline
Progress
AI winter
AI boom

Glossary
Glossary
vte


Machine learning  ML  is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data  and thus perform tasks without explicit instructions             Within a subdiscipline in machine learning  advances in the field of deep learning have allowed neural networks  a class of statistical algorithms  to surpass many previous machine learning approaches in performance            
ML finds application in many fields  including natural language processing  computer vision  speech recognition  email filtering  agriculture  and medicine                        The application of ML to business problems is known as predictive analytics 
Statistics and mathematical optimisation  mathematical programming  methods comprise the foundations of machine learning  Data mining is a related field of study  focusing on exploratory data analysis  EDA  via unsupervised learning                        
From a theoretical viewpoint  probably approximately correct learning provides a framework for describing machine learning 


History edit 
See also  Timeline of machine learning
The term machine learning was coined in      by Arthur Samuel  an IBM employee and pioneer in the field of computer gaming and artificial intelligence                        The synonym self teaching computers was also used in this time period                         
Although the earliest machine learning model was introduced in the     s when Arthur Samuel invented a program that calculated the winning chance in checkers for each side  the history of machine learning roots back to decades of human desire and effort to study human cognitive processes              In       Canadian psychologist Donald Hebb published the book The Organization of Behavior  in which he introduced a theoretical neural structure formed by certain interactions among nerve cells              Hebb s model of neurons interacting with one another set a groundwork for how AIs and machine learning algorithms work under nodes  or artificial neurons used by computers to communicate data              Other researchers who have studied human cognitive systems contributed to the modern machine learning technologies as well  including logician Walter Pitts and Warren McCulloch  who proposed the early mathematical models of neural networks to come up with algorithms that mirror human thought processes             
By the early     s  an experimental  learning machine  with punched tape memory  called Cybertron  had been developed by Raytheon Company to analyse sonar signals  electrocardiograms  and speech patterns using rudimentary reinforcement learning  It was repetitively  trained  by a human operator teacher to recognise patterns and equipped with a  goof  button to cause it to reevaluate incorrect decisions              A representative book on research into machine learning during the     s was Nilsson s book on Learning Machines  dealing mostly with machine learning for pattern classification              Interest related to pattern recognition continued into the     s  as described by Duda and Hart in                   In      a report was given on using teaching strategies so that an artificial neural network learns to recognise    characters     letters     digits  and   special symbols  from a computer terminal             
Tom M  Mitchell provided a widely quoted  more formal definition of the algorithms studied in the machine learning field   A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T  as measured by P   improves with experience E               This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms  This follows Alan Turing s proposal in his paper  Computing Machinery and Intelligence   in which the question  Can machines think   is replaced with the question  Can machines do what we  as thinking entities  can do               
Modern day machine learning has two objectives   One is to classify data based on models which have been developed  the other purpose is to make predictions for future outcomes based on these models  A hypothetical algorithm specific to classifying data may use computer vision of moles coupled with supervised learning in order to train it to classify the cancerous moles  A machine learning algorithm for stock trading may inform the trader of future potential predictions             

Relationships to other fields edit 
Artificial intelligence edit 
Machine learning as subfield of AI            
As a scientific endeavour  machine learning grew out of the quest for artificial intelligence  AI   In the early days of AI as an academic discipline  some researchers were interested in having machines learn from data  They attempted to approach the problem with various symbolic methods  as well as what were then termed  neural networks   these were mostly perceptrons and other models that were later found to be reinventions of the generalised linear models of statistics              Probabilistic reasoning was also employed  especially in automated medical diagnosis                                   
However  an increasing emphasis on the logical  knowledge based approach caused a rift between AI and machine learning  Probabilistic systems were plagued by theoretical and practical problems of data acquisition and representation                                    By       expert systems had come to dominate AI  and statistics was out of favour              Work on symbolic knowledge based learning did continue within AI  leading to inductive logic programming ILP   but the more statistical line of research was now outside the field of AI proper  in pattern recognition and information retrieval                                                   Neural networks research had been abandoned by AI and computer science around the same time  This line  too  was continued outside the AI CS field  as  connectionism   by researchers from other disciplines including John Hopfield  David Rumelhart  and Geoffrey Hinton  Their main success came in the mid     s with the reinvention of backpropagation                                  
Machine learning  ML   reorganised and recognised as its own field  started to flourish in the     s  The field changed its goal from achieving artificial intelligence to tackling solvable problems of a practical nature  It shifted focus away from the symbolic approaches it had inherited from AI  and toward methods and models borrowed from statistics  fuzzy logic  and probability theory             

Data compression edit 
This section is an excerpt from Data compression   Machine learning  edit 
There is a close connection between machine learning and compression  A system that predicts the posterior probabilities of a sequence given its entire history can be used for optimal data compression  by using arithmetic coding on the output distribution   Conversely  an optimal compressor can be used for prediction  by finding the symbol that compresses best  given the previous history   This equivalence has been used as a justification for using data compression as a benchmark for  general intelligence                                      
An alternative view can show compression algorithms implicitly map strings into implicit feature space vectors  and compression based similarity measures compute similarity within these feature spaces  For each compressor C    we define an associated vector space    such that C    maps an input string x  corresponding to the vector norm    x    An exhaustive examination of the feature spaces underlying all compression algorithms is precluded by space  instead  feature vectors chooses to examine three representative lossless compression methods  LZW  LZ    and PPM             
According to AIXI theory  a connection more directly explained in Hutter Prize  the best possible compression of x is the smallest possible software that generates x  For example  in that model  a zip file s compressed size includes both the zip file and the unzipping software  since you can not unzip it without both  but there may be an even smaller combined form 
Examples of AI powered audio video compression software include NVIDIA Maxine  AIVC              Examples of software that can perform AI powered image compression include OpenCV  TensorFlow  MATLAB s Image Processing Toolbox  IPT  and High Fidelity Generative Image Compression             
In unsupervised machine learning  k means clustering can be utilized to compress data by grouping similar data points into clusters  This technique simplifies handling extensive datasets that lack predefined labels and finds widespread use in fields such as image compression             
Data compression aims to reduce the size of data files  enhancing storage efficiency and speeding up data transmission  K means clustering  an unsupervised machine learning algorithm  is employed to partition a dataset into a specified number of clusters  k  each represented by the centroid of its points  This process condenses extensive datasets into a more compact set of representative points  Particularly beneficial in image and signal processing  k means clustering aids in data reduction by replacing groups of data points with their centroids  thereby preserving the core information of the original data while significantly decreasing the required storage space             

Large language models  LLMs  are also efficient lossless data compressors on some data sets  as demonstrated by DeepMind s research with the Chinchilla   B model  Developed by DeepMind  Chinchilla   B effectively compressed data  outperforming conventional methods such as Portable Network Graphics  PNG  for images and Free Lossless Audio Codec  FLAC  for audio  It achieved compression of image and audio data to       and       of their original sizes  respectively  There is  however  some reason to be concerned that the data set used for testing overlaps the LLM training data set  making it possible that the Chinchilla   B model is only an efficient compression tool on data it has already been trained on                         
Data mining edit 
Machine learning and data mining often employ the same methods and overlap significantly  but while machine learning focuses on prediction  based on known properties learned from the training data  data mining focuses on the discovery of  previously  unknown properties in the data  this is the analysis step of knowledge discovery in databases   Data mining uses many machine learning methods  but with different goals  on the other hand  machine learning also employs data mining methods as  unsupervised learning  or as a preprocessing step to improve learner accuracy  Much of the confusion between these two research communities  which do often have separate conferences and separate journals  ECML PKDD being a major exception  comes from the basic assumptions they work with  in machine learning  performance is usually evaluated with respect to the ability to reproduce known knowledge  while in knowledge discovery and data mining  KDD  the key task is the discovery of previously unknown knowledge  Evaluated with respect to known knowledge  an uninformed  unsupervised  method will easily be outperformed by other supervised methods  while in a typical KDD task  supervised methods cannot be used due to the unavailability of training data 
Machine learning also has intimate ties to optimisation  Many learning problems are formulated as minimisation of some loss function on a training set of examples  Loss functions express the discrepancy between the predictions of the model being trained and the actual problem instances  for example  in classification  one wants to assign a label to instances  and models are trained to correctly predict the preassigned labels of a set of examples              

Generalization edit 
Characterizing the generalisation of various learning algorithms is an active topic of current research  especially for deep learning algorithms 

Statistics edit 
Machine learning and statistics are closely related fields in terms of methods  but distinct in their principal goal  statistics draws population inferences from a sample  while machine learning finds generalisable predictive patterns              According to Michael I  Jordan  the ideas of machine learning  from methodological principles to theoretical tools  have had a long pre history in statistics              He also suggested the term data science as a placeholder to call the overall field             
Conventional statistical analyses require the a priori selection of a model most suitable for the study data set  In addition  only significant or theoretically relevant variables based on previous experience are included for analysis  In contrast  machine learning is not built on a pre structured model  rather  the data shape the model by detecting underlying patterns  The more variables  input  used to train the model  the more accurate the ultimate model will be             
Leo Breiman distinguished two statistical modelling paradigms  data model and algorithmic model              wherein  algorithmic model  means more or less the machine learning algorithms like Random Forest 
Some statisticians have adopted methods from machine learning  leading to a combined field that they call statistical learning             

Statistical physics edit 
Analytical and computational techniques derived from deep rooted physics of disordered systems can be extended to large scale problems  including machine learning  e g   to analyse the weight space of deep neural networks              Statistical physics is thus finding applications in the area of medical diagnostics             

 Theory edit 
Main articles  Computational learning theory and Statistical learning theory
A core objective of a learner is to generalise from its experience                         Generalisation in this context is the ability of a learning machine to perform accurately on new  unseen examples tasks after having experienced a learning data set  The training examples come from some generally unknown probability distribution  considered representative of the space of occurrences  and the learner has to build a general model about this space that enables it to produce sufficiently accurate predictions in new cases 
The computational analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as computational learning theory via the probably approximately correct learning  model  Because training sets are finite and the future is uncertain  learning theory usually does not yield guarantees of the performance of algorithms  Instead  probabilistic bounds on the performance are quite common  The bias variance decomposition is one way to quantify generalisation error 
For the best performance in the context of generalisation  the complexity of the hypothesis should match the complexity of the function underlying the data  If the hypothesis is less complex than the function  then the model has under fitted the data  If the complexity of the model is increased in response  then the training error decreases  But if the hypothesis is too complex  then the model is subject to overfitting and generalisation will be poorer             
In addition to performance bounds  learning theorists study the time complexity and feasibility of learning  In computational learning theory  a computation is considered feasible if it can be done in polynomial time  There are two kinds of time complexity results  Positive results show that a certain class of functions can be learned in polynomial time  Negative results show that certain classes cannot be learned in polynomial time 

Approaches edit 


In supervised learning  the training data is labelled with the expected answers  while in unsupervised learning  the model identifies patterns or structures in unlabelled data 
Machine learning approaches are traditionally divided into three broad categories  which correspond to learning paradigms  depending on the nature of the  signal  or  feedback  available to the learning system 

Supervised learning  The computer is presented with example inputs and their desired outputs  given by a  teacher   and the goal is to learn a general rule that maps inputs to outputs 
Unsupervised learning  No labels are given to the learning algorithm  leaving it on its own to find structure in its input  Unsupervised learning can be a goal in itself  discovering hidden patterns in data  or a means towards an end  feature learning  
Reinforcement learning  A computer program interacts with a dynamic environment in which it must perform a certain goal  such as driving a vehicle or playing a game against an opponent   As it navigates its problem space  the program is provided feedback that s analogous to rewards  which it tries to maximise            
Although each algorithm has advantages and limitations  no single algorithm works for all problems                                     

Supervised learning edit 
Main article  Supervised learning
A support vector machine is a supervised learning model that divides the data into regions separated by a linear boundary  Here  the linear boundary divides the black circles from the white 
Supervised learning algorithms build a mathematical model of a set of data that contains both the inputs and the desired outputs              The data  known as training data  consists of a set of training examples  Each training example has one or more inputs and the desired output  also known as a supervisory signal  In the mathematical model  each training example is represented by an array or vector  sometimes called a feature vector  and the training data is represented by a matrix  Through iterative optimisation of an objective function  supervised learning algorithms learn a function that can be used to predict the output associated with new inputs              An optimal function allows the algorithm to correctly determine the output for inputs that were not a part of the training data  An algorithm that improves the accuracy of its outputs or predictions over time is said to have learned to perform that task             
Types of supervised learning algorithms include active learning  classification and regression              Classification algorithms are used when the outputs are restricted to a limited set of values  while regression algorithms are used when the outputs can take any numerical value within a range  For example  in a classification algorithm that filters emails  the input is an incoming email  and the output is the folder in which to file the email  In contrast  regression is used for tasks such as predicting a person s height based on factors like age and genetics or forecasting future temperatures based on historical data             
Similarity learning is an area of supervised machine learning closely related to regression and classification  but the goal is to learn from examples using a similarity function that measures how similar or related two objects are  It has applications in ranking  recommendation systems  visual identity tracking  face verification  and speaker verification 

Unsupervised learning edit 
Main article  Unsupervised learningSee also  Cluster analysis
Unsupervised learning algorithms find structures in data that has not been labelled  classified or categorised  Instead of responding to feedback  unsupervised learning algorithms identify commonalities in the data and react based on the presence or absence of such commonalities in each new piece of data  Central applications of unsupervised machine learning include clustering  dimensionality reduction             and density estimation             
Cluster analysis is the assignment of a set of observations into subsets  called clusters  so that observations within the same cluster are similar according to one or more predesignated criteria  while observations drawn from different clusters are dissimilar  Different clustering techniques make different assumptions on the structure of the data  often defined by some similarity metric and evaluated  for example  by internal compactness  or the similarity between members of the same cluster  and separation  the difference between clusters  Other methods are based on estimated density and graph connectivity 
A special type of unsupervised learning called  self supervised learning involves training a model by generating the supervisory signal from the data itself                         

Semi supervised learning edit 
Main article  Semi supervised learning
Semi supervised learning falls between unsupervised learning  without any labelled training data  and supervised learning  with completely labelled training data   Some of the training examples are missing training labels  yet many machine learning researchers have found that unlabelled data  when used in conjunction with a small amount of labelled data  can produce a considerable improvement in learning accuracy 
In weakly supervised learning  the training labels are noisy  limited  or imprecise  however  these labels are often cheaper to obtain  resulting in larger effective training sets             

Reinforcement learning edit 
Main article  Reinforcement learning

Reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment so as to maximise some notion of cumulative reward  Due to its generality  the field is studied in many other disciplines  such as game theory  control theory  operations research  information theory  simulation based optimisation  multi agent systems  swarm intelligence  statistics and genetic algorithms  In reinforcement learning  the environment is typically represented as a Markov decision process  MDP   Many reinforcement learning algorithms use dynamic programming techniques              Reinforcement learning algorithms do not assume knowledge of an exact mathematical model of the MDP and are used when exact models are infeasible  Reinforcement learning algorithms are used in autonomous vehicles or in learning to play a game against a human opponent 

Dimensionality reduction edit 
Dimensionality reduction is a process of reducing the number of random variables under consideration by obtaining a set of principal variables              In other words  it is a process of reducing the dimension of the feature set  also called the  number of features   Most of the dimensionality reduction techniques can be considered as either feature elimination or extraction  One of the popular methods of dimensionality reduction is principal component analysis  PCA   PCA involves changing higher dimensional data  e g    D  to a smaller space  e g    D  
The manifold hypothesis proposes that high dimensional data sets lie along low dimensional manifolds  and many dimensionality reduction techniques make this assumption  leading to the area of manifold learning and manifold regularisation 

Other types edit 
Other approaches have been developed which do not fit neatly into this three fold categorisation  and sometimes more than one is used by the same machine learning system  For example  topic modelling  meta learning             

Self learning edit 
Self learning  as a machine learning paradigm was introduced in      along with a neural network capable of self learning  named crossbar adaptive array  CAA                           It gives a solution to the problem learning without any external reward  by introducing emotion as an internal reward  Emotion is used as state evaluation of a self learning agent  The CAA self learning algorithm computes  in a crossbar fashion  both decisions about actions and emotions  feelings  about consequence situations  The system is driven by the interaction between cognition and emotion             
The self learning algorithm updates a memory matrix W    w a s    such that in each iteration executes the following machine learning routine  

in situation s perform action a
receive a consequence situation s 
compute emotion of being in the consequence situation v s  
update crossbar memory  w  a s    w a s    v s  
It is a system with only one input  situation  and only one output  action  or behaviour  a  There is neither a separate reinforcement input nor an advice input from the environment  The backpropagated value  secondary reinforcement  is the emotion toward the consequence situation  The CAA exists in two environments  one is the behavioural environment where it behaves  and the other is the genetic environment  wherefrom it initially and only once receives initial emotions about situations to be encountered in the behavioural environment  After receiving the genome  species  vector from the genetic environment  the CAA learns a goal seeking behaviour  in an environment that contains both desirable and undesirable situations             

Feature learning edit 
Main article  Feature learning
Several learning algorithms aim at discovering better representations of the inputs provided during training              Classic examples include principal component analysis and cluster analysis  Feature learning algorithms  also called representation learning algorithms  often attempt to preserve the information in their input but also transform it in a way that makes it useful  often as a pre processing step before performing classification or predictions  This technique allows reconstruction of the inputs coming from the unknown data generating distribution  while not being necessarily faithful to configurations that are implausible under that distribution  This replaces manual feature engineering  and allows a machine to both learn the features and use them to perform a specific task 
Feature learning can be either supervised or unsupervised  In supervised feature learning  features are learned using labelled input data  Examples include artificial neural networks  multilayer perceptrons  and supervised dictionary learning  In unsupervised feature learning  features are learned with unlabelled input data   Examples include dictionary learning  independent component analysis  autoencoders  matrix factorisation             and various forms of clustering                                     
Manifold learning algorithms attempt to do so under the constraint that the learned representation is low dimensional  Sparse coding algorithms attempt to do so under the constraint that the learned representation is sparse  meaning that the mathematical model has many zeros  Multilinear subspace learning algorithms aim to learn low dimensional representations directly from tensor representations for multidimensional data  without reshaping them into higher dimensional vectors              Deep learning algorithms discover multiple levels of representation  or a hierarchy of features  with higher level  more abstract features defined in terms of  or generating  lower level features  It has been argued that an intelligent machine is one that learns a representation that disentangles the underlying factors of variation that explain the observed data             
Feature learning is motivated by the fact that machine learning tasks such as classification often require input that is mathematically and computationally convenient to process  However  real world data such as images  video  and sensory data has not yielded attempts to algorithmically define specific features  An alternative is to discover such features or representations through examination  without relying on explicit algorithms 

Sparse dictionary learning edit 
Main article  Sparse dictionary learning
Sparse dictionary learning is a feature learning method where a training example is represented as a linear combination of basis functions and assumed to be a sparse matrix  The method is strongly NP hard and difficult to solve approximately              A popular heuristic method for sparse dictionary learning is the k SVD algorithm  Sparse dictionary learning has been applied in several contexts  In classification  the problem is to determine the class to which a previously unseen training example belongs  For a dictionary where each class has already been built  a new training example is associated with the class that is best sparsely represented by the corresponding dictionary  Sparse dictionary learning has also been applied in image de noising  The key idea is that a clean image patch can be sparsely represented by an image dictionary  but the noise cannot             

Anomaly detection edit 
Main article  Anomaly detection
In data mining  anomaly detection  also known as outlier detection  is the identification of rare items  events or observations which raise suspicions by differing significantly from the majority of the data              Typically  the anomalous items represent an issue such as bank fraud  a structural defect  medical problems or errors in a text  Anomalies are referred to as outliers  novelties  noise  deviations and exceptions             
In particular  in the context of abuse and network intrusion detection  the interesting objects are often not rare objects  but unexpected bursts of inactivity  This pattern does not adhere to the common statistical definition of an outlier as a rare object  Many outlier detection methods  in particular  unsupervised algorithms  will fail on such data unless aggregated appropriately  Instead  a cluster analysis algorithm may be able to detect the micro clusters formed by these patterns             
Three broad categories of anomaly detection techniques exist              Unsupervised anomaly detection techniques detect anomalies in an unlabelled test data set under the assumption that the majority of the instances in the data set are normal  by looking for instances that seem to fit the least to the remainder of the data set  Supervised anomaly detection techniques require a data set that has been labelled as  normal  and  abnormal  and involves training a classifier  the key difference from many other statistical classification problems is the inherently unbalanced nature of outlier detection   Semi supervised anomaly detection techniques construct a model representing normal behaviour from a given normal training data set and then test the likelihood of a test instance to be generated by the model 

Robot learning edit 
Robot learning is inspired by a multitude of machine learning methods  starting from supervised learning  reinforcement learning                          and finally meta learning  e g  MAML  

Association rules edit 
Main article  Association rule learningSee also  Inductive logic programming
Association rule learning is a rule based machine learning method for discovering relationships between variables in large databases  It is intended to identify strong rules discovered in databases using some measure of  interestingness              
Rule based machine learning is a general term for any machine learning method that identifies  learns  or evolves  rules  to store  manipulate or apply knowledge  The defining characteristic of a rule based machine learning algorithm is the identification and utilisation of a set of relational rules that collectively represent the knowledge captured by the system  This is in contrast to other machine learning algorithms that commonly identify a singular model that can be universally applied to any instance in order to make a prediction              Rule based machine learning approaches include learning classifier systems  association rule learning  and artificial immune systems 
Based on the concept of strong rules  Rakesh Agrawal  Tomasz Imieli ski and Arun Swami introduced association rules for discovering regularities between products in large scale transaction data recorded by point of sale  POS  systems in supermarkets              For example  the rule 
  
    
      
         
        
          o
          n
          i
          o
          n
          s
           
          p
          o
          t
          a
          t
          o
          e
          s
        
         
          x  d  
         
        
          b
          u
          r
          g
          e
          r
        
         
      
    
      displaystyle    mathrm  onions potatoes     Rightarrow    mathrm  burger     
  
 found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together  they are likely to also buy hamburger meat  Such information can be used as the basis for decisions about marketing activities such as promotional pricing or product placements  In addition to market basket analysis  association rules are employed today in application areas including Web usage mining  intrusion detection  continuous production  and bioinformatics  In contrast with sequence mining  association rule learning typically does not consider the order of items either within a transaction or across transactions 
Learning classifier systems  LCS  are a family of rule based machine learning algorithms that combine a discovery component  typically a genetic algorithm  with a learning component  performing either supervised learning  reinforcement learning  or unsupervised learning  They seek to identify a set of context dependent rules that collectively store and apply knowledge in a piecewise manner in order to make predictions             
Inductive logic programming  ILP  is an approach to rule learning using logic programming as a uniform representation for input examples  background knowledge  and hypotheses  Given an encoding of the known background knowledge and a set of examples represented as a logical database of facts  an ILP system will derive a hypothesized logic program that entails all positive and no negative examples  Inductive programming is a related field that considers any kind of programming language for representing hypotheses  and not only logic programming   such as functional programs 
Inductive logic programming is particularly useful in bioinformatics and natural language processing  Gordon Plotkin and Ehud Shapiro laid the initial theoretical foundation for inductive machine learning in a logical setting                                      Shapiro built their first implementation  Model Inference System  in       a Prolog program that inductively inferred logic programs from positive and negative examples              The term inductive here refers to philosophical induction  suggesting a theory to explain observed facts  rather than mathematical induction  proving a property for all members of a well ordered set 

Models edit 
A machine learning model is a type of mathematical model that  once  trained  on a given dataset  can be used to make predictions or classifications on new data  During training  a learning algorithm iteratively adjusts the model s internal parameters to minimise errors in its predictions              By extension  the term  model  can refer to several levels of specificity  from a general class of models and their associated learning algorithms to a fully trained model with all its internal parameters tuned             
Various types of models have been used and researched for machine learning systems  picking the best model for a task is called model selection 

Artificial neural networks edit 
Main article  Artificial neural networkSee also  Deep learning
An artificial neural network is an interconnected group of nodes  akin to the vast network of neurons in a brain  Here  each circular node represents an artificial neuron and an arrow represents a connection from the output of one artificial neuron to the input of another 
Artificial neural networks  ANNs   or connectionist systems  are computing systems vaguely inspired by the biological neural networks that constitute animal brains  Such systems  learn  to perform tasks by considering examples  generally without being programmed with any task specific rules 
An ANN is a model based on a collection of connected units or nodes called  artificial neurons   which loosely model the neurons in a biological brain  Each connection  like the synapses in a biological brain  can transmit information  a  signal   from one artificial neuron to another  An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it  In common ANN implementations  the signal at a connection between artificial neurons is a real number  and the output of each artificial neuron is computed by some non linear function of the sum of its inputs  The connections between artificial neurons are called  edges   Artificial neurons and edges typically have a weight that adjusts as learning proceeds  The weight increases or decreases the strength of the signal at a connection  Artificial neurons may have a threshold such that the signal is only sent if the aggregate signal crosses that threshold  Typically  artificial neurons are aggregated into layers  Different layers may perform different kinds of transformations on their inputs  Signals travel from the first layer  the input layer  to the last layer  the output layer   possibly after traversing the layers multiple times 
The original goal of the ANN approach was to solve problems in the same way that a human brain would  However  over time  attention moved to performing specific tasks  leading to deviations from biology  Artificial neural networks have been used on a variety of tasks  including computer vision  speech recognition  machine translation  social network filtering  playing board and video games and medical diagnosis 
Deep learning consists of multiple hidden layers in an artificial neural network  This approach tries to model the way the human brain processes light and sound into vision and hearing  Some successful applications of deep learning are computer vision and speech recognition             

Decision trees edit 
Main article  Decision tree learning
A decision tree showing survival probability of passengers on the Titanic
Decision tree learning uses a decision tree as a predictive model to go from observations about an item  represented in the branches  to conclusions about the item s target value  represented in the leaves   It is one of the predictive modelling approaches used in statistics  data mining  and machine learning  Tree models where the target variable can take a discrete set of values are called classification trees  in these tree structures  leaves represent class labels  and branches represent conjunctions of features that lead to those class labels  Decision trees where the target variable can take continuous values  typically real numbers  are called regression trees  In decision analysis  a decision tree can be used to visually and explicitly represent decisions and decision making  In data mining  a decision tree describes data  but the resulting classification tree can be an input for decision making 

Random forest regression edit 
Random forest regression  RFR  falls under umbrella of decision tree based models  RFR is an ensemble learning method that builds multiple decision trees and averages their predictions to improve accuracy and to avoid overfitting        To build decision trees  RFR uses bootstrapped sampling  for instance each decision tree is trained on random data of from training set  This random selection of RFR for training enables model to reduce bias predictions and achieve accuracy  RFR generates independent decision trees  and it can work on single output data as well multiple regressor task  This makes RFR compatible to be used in various application                         

Support vector machines edit 
Main article  Support vector machine
Support vector machines  SVMs   also known as support vector networks  are a set of related supervised learning methods used for classification and regression  Given a set of training examples  each marked as belonging to one of two categories  an SVM training algorithm builds a model that predicts whether a new example falls into one category              An SVM training algorithm is a non probabilistic  binary  linear classifier  although methods such as Platt scaling exist to use SVM in a probabilistic classification setting  In addition to performing linear classification  SVMs can efficiently perform a non linear classification using what is called the kernel trick  implicitly mapping their inputs into high dimensional feature spaces 

Regression analysis edit 
Main article  Regression analysis
Illustration of linear regression on a data set
Regression analysis encompasses a large variety of statistical methods to estimate the relationship between input variables and their associated features  Its most common form is linear regression  where a single line is drawn to best fit the given data according to a mathematical criterion such as ordinary least squares  The latter is often extended by regularisation methods to mitigate overfitting and bias  as in ridge regression  When dealing with non linear problems  go to models include polynomial regression  for example  used for trendline fitting in Microsoft Excel               logistic regression  often used in statistical classification  or even kernel regression  which introduces non linearity by taking advantage of the kernel trick to implicitly map input variables to higher dimensional space 
Multivariate linear regression extends the concept of linear regression to handle multiple dependent variables simultaneously  This approach estimates the relationships between a set of input variables and several output variables by fitting a multidimensional linear model  It is particularly useful in scenarios where outputs are interdependent or share underlying patterns  such as predicting multiple economic indicators or reconstructing images              which are inherently multi dimensional 

Bayesian networks edit 
Main article  Bayesian network
A simple Bayesian network  Rain influences whether the sprinkler is activated  and both rain and the sprinkler influence whether the grass is wet 
A Bayesian network  belief network  or directed acyclic graphical model is a probabilistic graphical model that represents a set of random variables and their conditional independence with a directed acyclic graph  DAG   For example  a Bayesian network could represent the probabilistic relationships between diseases and symptoms  Given symptoms  the network can be used to compute the probabilities of the presence of various diseases  Efficient algorithms exist that perform inference and learning  Bayesian networks that model sequences of variables  like speech signals or protein sequences  are called dynamic Bayesian networks  Generalisations of Bayesian networks that can represent and solve decision problems under uncertainty are called influence diagrams 

Gaussian processes edit 
Main article  Gaussian processes
An example of Gaussian Process Regression  prediction  compared with other regression models            
A Gaussian process is a stochastic process in which every finite collection of the random variables in the process has a multivariate normal distribution  and it relies on a pre defined covariance function  or kernel  that models how pairs of points relate to each other depending on their locations 
Given a set of observed points  or input output examples  the distribution of the  unobserved  output of a new point as function of its input data can be directly computed by looking like the observed points and the covariances between those points and the new  unobserved point 
Gaussian processes are popular surrogate models in Bayesian optimisation used to do hyperparameter optimisation 

Genetic algorithms edit 
Main article  Genetic algorithm
A genetic algorithm  GA  is a search algorithm and heuristic technique that mimics the process of natural selection  using methods such as mutation and crossover to generate new genotypes in the hope of finding good solutions to a given problem  In machine learning  genetic algorithms were used in the     s and     s                          Conversely  machine learning techniques have been used to improve the performance of genetic and evolutionary algorithms             

Belief functions edit 
Main article  Dempster Shafer theory
The theory of belief functions  also referred to as evidence theory or Dempster Shafer theory  is a general framework for reasoning with uncertainty  with understood connections to other frameworks such as probability  possibility and  imprecise probability theories  These theoretical frameworks can be thought of as a kind of learner and have some analogous properties of how evidence is combined  e g    Dempster s rule of combination   just like how in a pmf based Bayesian approach would combine probabilities              However  there are many caveats to these beliefs functions when compared to Bayesian approaches in order to incorporate ignorance and uncertainty quantification  These belief function approaches that are implemented within the machine learning domain typically leverage a fusion approach of various ensemble methods to better handle the learner s decision boundary  low samples  and ambiguous class issues that standard machine learning approach tend to have difficulty resolving                        However  the computational complexity of these algorithms are dependent on the number of propositions  classes   and can lead to a much higher computation time when compared to other machine learning approaches 

Rule based models edit 
Main article  Rule based machine learning
Rule based machine learning  RBML  is a branch of machine learning that automatically discovers and learns  rules  from data  It provides interpretable models  making it useful for decision making in fields like healthcare  fraud detection  and cybersecurity  Key RBML techniques includes learning classifier systems              association rule learning               artificial immune systems               and other similar models  These methods extract patterns from data and evolve rules over time 

Training models edit 
Typically  machine learning models require a high quantity of reliable data to perform accurate predictions  When training a machine learning model  machine learning engineers need to target and collect a large and representative sample of data  Data from the training set can be as varied as a corpus of text  a collection of images  sensor data  and data collected from individual users of a service  Overfitting is something to watch out for when training a machine learning model  Trained models derived from biased or non evaluated data can result in skewed or undesired predictions  Biased models may result in detrimental outcomes  thereby furthering the negative impacts on society or objectives  Algorithmic bias is a potential result of data not being fully prepared for training  Machine learning ethics is becoming a field of study and notably  becoming integrated within machine learning engineering teams 

Federated learning edit 
Main article  Federated learning
Federated learning is an adapted form of distributed artificial intelligence to training machine learning models that decentralises the training process  allowing for users  privacy to be maintained by not needing to send their data to a centralised server  This also increases efficiency by decentralising the training process to many devices  For example  Gboard uses federated machine learning to train search query prediction models on users  mobile phones without having to send individual searches back to Google              

Applications edit 
There are many applications for machine learning  including 


Agriculture
Anatomy
Adaptive website
Affective computing
Astronomy
Automated decision making
Banking
Behaviorism
Bioinformatics
Brain machine interfaces
Cheminformatics
Citizen Science
Climate Science
Computer networks
Computer vision
Credit card fraud detection
Data quality
DNA sequence classification
Economics
Financial market analysis             
General game playing
Handwriting recognition
Healthcare
Information retrieval
Insurance
Internet fraud detection
Knowledge graph embedding
Linguistics
Machine learning control
Machine perception
Machine translation
Material Engineering
Marketing
Medical diagnosis
Natural language processing
Natural language understanding
Online advertising
Optimisation
Recommender systems
Robot locomotion
Search engines
Sentiment analysis
Sequence mining
Software engineering
Speech recognition
Structural health monitoring
Syntactic pattern recognition
Telecommunications
Theorem proving
Time series forecasting
Tomographic reconstruction             
User behaviour analytics

In       the media services provider Netflix held the first  Netflix Prize  competition to find a program to better predict user preferences and improve the accuracy of its existing Cinematch movie recommendation algorithm by at least      A joint team made up of researchers from AT amp T Labs Research in collaboration with the teams Big Chaos and Pragmatic Theory built an ensemble model to win the Grand Prize in      for    million               Shortly after the prize was awarded  Netflix realised that viewers  ratings were not the best indicators of their viewing patterns   everything is a recommendation   and they changed their recommendation engine accordingly               In      The Wall Street Journal wrote about the firm Rebellion Research and their use of machine learning to predict the financial crisis               In       co founder of Sun Microsystems  Vinod Khosla  predicted that     of medical doctors jobs would be lost in the next two decades to automated machine learning medical diagnostic software               In       it was reported that a machine learning algorithm had been applied in the field of art history to study fine art paintings and that it may have revealed previously unrecognised influences among artists               In      Springer Nature published the first research book created using machine learning               In       machine learning technology was used to help make diagnoses and aid researchers in developing a cure for COVID                  Machine learning was recently applied to predict the pro environmental behaviour of travellers               Recently  machine learning technology was also applied to optimise smartphone s performance and thermal behaviour based on the user s interaction with the phone                                         When applied correctly  machine learning algorithms  MLAs  can utilise a wide range of company characteristics to predict stock returns without overfitting  By employing effective feature engineering and combining forecasts  MLAs can generate results that far surpass those obtained from basic linear techniques like OLS              
Recent advancements in machine learning have extended into the field of quantum chemistry  where novel algorithms now enable the prediction of solvent effects on chemical reactions  thereby offering new tools for chemists to tailor experimental conditions for optimal outcomes              
Machine Learning is becoming a useful tool to investigate and predict evacuation decision making in large scale and small scale disasters  Different solutions have been tested to predict if and when householders decide to evacuate during wildfires and hurricanes                                         Other applications have been focusing on pre evacuation decisions in building fires                            
Machine learning is also emerging as a promising tool in geotechnical engineering  where it is used to support tasks such as ground classification  hazard prediction  and site characterization  Recent research emphasizes a move toward data centric methods in this field  where machine learning is not a replacement for engineering judgment  but a way to enhance it using site specific data and patterns              

Limitations edit 
Although machine learning has been transformative in some fields  machine learning programs often fail to deliver expected results                                         Reasons for this are numerous  lack of  suitable  data  lack of access to the data  data bias  privacy problems  badly chosen tasks and algorithms  wrong tools and people  lack of resources  and evaluation problems              
The  black box theory  poses another yet significant challenge  Black box refers to a situation where the algorithm or the process of producing an output is entirely opaque  meaning that even the coders of the algorithm cannot audit the pattern that the machine extracted out of the data               The House of Lords Select Committee  which claimed that such an  intelligence system  that could have a  substantial impact on an individual s life  would not be considered acceptable unless it provided  a full and satisfactory explanation for the decisions  it makes              
In       a self driving car from Uber failed to detect a pedestrian  who was killed after a collision               Attempts to use machine learning in healthcare with the IBM Watson system failed to deliver even after years of time and billions of dollars invested                            Microsoft s Bing Chat chatbot has been reported to produce hostile and offensive response against its users              
Machine learning has been used as a strategy to update the evidence related to a systematic review and increased reviewer burden related to the growth of biomedical literature  While it has improved with training sets  it has not yet developed sufficiently to reduce the workload burden without limiting the necessary sensitivity for the findings research themselves              

Explainability edit 
Main article  Explainable artificial intelligence
Explainable AI  XAI   or Interpretable AI  or Explainable Machine Learning  XML   is artificial intelligence  AI  in which humans can understand the decisions or predictions made by the AI               It contrasts with the  black box  concept in machine learning where even its designers cannot explain why an AI arrived at a specific decision               By refining the mental models of users of AI powered systems and dismantling their misconceptions  XAI promises to help users perform more effectively  XAI may be an implementation of the social right to explanation 

Overfitting edit 
Main article  Overfitting
The blue line could be an example of overfitting a linear function due to random noise 
Settling on a bad  overly complex theory gerrymandered to fit all the past training data is known as overfitting  Many systems attempt to reduce overfitting by rewarding a theory in accordance with how well it fits the data but penalising the theory in accordance with how complex the theory is              

Other limitations and vulnerabilities edit 
Learners can also disappoint by  learning the wrong lesson   A toy example is that an image classifier trained only on pictures of brown horses and black cats might conclude that all brown patches are likely to be horses               A real world example is that  unlike humans  current image classifiers often do not primarily make judgements from the spatial relationship between components of the picture  and they learn relationships between pixels that humans are oblivious to  but that still correlate with images of certain types of real objects  Modifying these patterns on a legitimate image can result in  adversarial  images that the system misclassifies                           
Adversarial vulnerabilities can also result in nonlinear systems  or from non pattern perturbations  For some systems  it is possible to change the output by only changing a single adversarially chosen pixel               Machine learning models are often vulnerable to manipulation or evasion via adversarial machine learning              
Researchers have demonstrated how backdoors can be placed undetectably into classifying  e g   for categories  spam  and well visible  not spam  of posts  machine learning models that are often developed or trained by third parties  Parties can change the classification of any input  including in cases for which a type of data software transparency is provided  possibly including white box access                                        

Model assessments edit 
Classification of machine learning models can be validated by accuracy estimation techniques like the holdout method  which splits the data in a training and test set  conventionally     training set and     test set designation  and evaluates the performance of the training model on the test set  In comparison  the K fold cross validation method randomly partitions the data into K subsets and then K experiments are performed each respectively considering   subset for evaluation and the remaining K   subsets for training the model  In addition to the holdout and cross validation methods  bootstrap  which samples n instances with replacement from the dataset  can be used to assess model accuracy              
In addition to overall accuracy  investigators frequently report sensitivity and specificity meaning true positive rate  TPR  and true negative rate  TNR  respectively  Similarly  investigators sometimes report the false positive rate  FPR  as well as the false negative rate  FNR   However  these rates are ratios that fail to reveal their numerators and denominators  Receiver operating characteristic  ROC  along with the accompanying Area Under the ROC Curve  AUC  offer additional tools for classification model assessment  Higher AUC is associated with a better performing model              

Ethics edit 
This section is an excerpt from Ethics of artificial intelligence  edit 

The ethics of artificial intelligence covers a broad range of topics within AI that are considered to have particular ethical stakes               This includes algorithmic biases  fairness               automated decision making  accountability  privacy  and regulation  It also covers various emerging or potential future challenges such as machine ethics  how to make machines that behave ethically   lethal autonomous weapon systems  arms race dynamics  AI safety and alignment  technological unemployment  AI enabled misinformation  how to treat certain AI systems if they have a moral status  AI welfare and rights   artificial superintelligence and existential risks              

Some application areas may also have particularly important ethical implications  like healthcare  education  criminal justice  or the military 
Bias edit 
Main article  Algorithmic bias
Different machine learning approaches can suffer from different data biases  A machine learning system trained specifically on current customers may not be able to predict the needs of new customer groups that are not represented in the training data  When trained on human made data  machine learning is likely to pick up the constitutional and unconscious biases already present in society              
Systems that are trained on datasets collected with biases may exhibit these biases upon use  algorithmic bias   thus digitising cultural prejudices               For example  in       the UK s Commission for Racial Equality found that St  George s Medical School had been using a computer program trained from data of previous admissions staff and that this program had denied nearly    candidates who were found to either be women or have non European sounding names               Using job hiring data from a firm with racist hiring policies may lead to a machine learning system duplicating the bias by scoring job applicants by similarity to previous successful applicants                            Another example includes predictive policing company Geolitica s predictive algorithm that resulted in  disproportionately high levels of over policing in low income and minority communities  after being trained with historical crime data              
While responsible collection of data and documentation of algorithmic rules used by a system is considered a critical part of machine learning  some researchers blame lack of participation and representation of minority population in the field of AI for machine learning s vulnerability to biases               In fact  according to research carried out by the Computing Research Association  CRA  in        female faculty merely make up        of all faculty members who focus on AI among several universities around the world               Furthermore  among the group of  new U S  resident AI PhD graduates       identified as white        as Asian       as Hispanic  and      as African American  which further demonstrates a lack of diversity in the field of AI              
Language models learned from data have been shown to contain human like biases                            Because human languages contain biases  machines trained on language corpora will necessarily also learn these biases                            In       Microsoft tested Tay  a chatbot that learned from Twitter  and it quickly picked up racist and sexist language              
In an experiment carried out by ProPublica  an investigative journalism organisation  a machine learning algorithm s insight into the recidivism rates among prisoners falsely flagged  black defendants high risk twice as often as white defendants                In       Google Photos once tagged a couple of black people as gorillas  which caused controversy  The gorilla label was subsequently removed  and in       it still cannot recognise gorillas               Similar issues with recognising non white people have been found in many other systems              
Because of such challenges  the effective use of machine learning may take longer to be adopted in other domains               Concern for fairness in machine learning  that is  reducing bias in machine learning and propelling its use for human good  is increasingly expressed by artificial intelligence scientists  including Fei Fei Li  who said that   t here s nothing artificial about AI  It s inspired by people  it s created by people  and most importantly it impacts people  It is a powerful tool we are only just beginning to understand  and that is a profound responsibility               

Financial incentives edit 
There are concerns among health care professionals that these systems might not be designed in the public s interest but as income generating machines  This is especially true in the United States where there is a long standing ethical dilemma of improving health care  but also increasing profits  For example  the algorithms could be designed to provide patients with unnecessary tests or medication in which the algorithm s proprietary owners hold stakes  There is potential for machine learning in health care to provide professionals an additional tool to diagnose  medicate  and plan recovery paths for patients  but this requires these biases to be mitigated              

Hardware edit 
Since the     s  advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks  a particular narrow subdomain of machine learning  that contain many layers of nonlinear hidden units               By       graphics processing units  GPUs   often with AI specific enhancements  had displaced CPUs as the dominant method of training large scale commercial cloud AI               OpenAI estimated the hardware compute used in the largest deep learning projects from AlexNet        to AlphaZero         and found a         fold increase in the amount of compute required  with a doubling time trendline of     months                           

Tensor Processing Units  TPUs  edit 
Tensor Processing Units  TPUs  are specialised hardware accelerators developed by Google specifically for machine learning workloads  Unlike general purpose GPUs and FPGAs  TPUs are optimised for tensor computations  making them particularly efficient for deep learning tasks such as training and inference  They are widely used in Google Cloud AI services and large scale machine learning models like Google s DeepMind AlphaFold and large language models  TPUs leverage matrix multiplication units and high bandwidth memory to accelerate computations while maintaining energy efficiency               Since their introduction in       TPUs have become a key component of AI infrastructure  especially in cloud based environments 

Neuromorphic computing edit 
Neuromorphic computing refers to a class of computing systems designed to emulate the structure and functionality of biological neural networks  These systems may be implemented through software based simulations on conventional hardware or through specialised hardware architectures              

physical neural networks edit 
A physical neural network is a specific type of neuromorphic hardware that relies on electrically adjustable materials  such as memristors  to emulate the function of neural synapses  The term  physical neural network  highlights the use of physical hardware for computation  as opposed to software based implementations  It broadly refers to artificial neural networks that use materials with adjustable resistance to replicate neural synapses                           

Embedded machine learning edit 
Embedded machine learning is a sub field of machine learning where models are deployed on embedded systems with limited computing resources  such as wearable computers  edge devices and microcontrollers                                                      Running models directly on these devices eliminates the need to transfer and store data on cloud servers for further processing  thereby reducing the risk of data breaches  privacy leaks and theft of intellectual property  personal data and business secrets  Embedded machine learning can be achieved through various techniques  such as hardware acceleration                            approximate computing               and model optimisation                            Common optimisation techniques include pruning  quantisation  knowledge distillation  low rank factorisation  network architecture search  and parameter sharing 

Software edit 
Software suites containing a variety of machine learning algorithms include the following 

Free and open source software edit 

Caffe
Deeplearning j
DeepSpeed
ELKI
Google JAX
Infer NET
Keras
Kubeflow
LightGBM
Mahout
Mallet
Microsoft Cognitive Toolkit
ML NET
mlpack
MXNet
OpenNN
Orange
pandas  software 
ROOT  TMVA with ROOT 
scikit learn
Shogun
Spark MLlib
SystemML
TensorFlow
Torch   PyTorch
Weka   MOA
XGBoost
Yooreeka

Proprietary software with free and open source editions edit 
KNIME
RapidMiner
Proprietary software edit 

Amazon Machine Learning
Angoss KnowledgeSTUDIO
Azure Machine Learning
IBM Watson Studio
Google Cloud Vertex AI
Google Prediction API
IBM SPSS Modeller
KXEN Modeller
LIONsolver
Mathematica
MATLAB
Neural Designer
NeuroSolutions
Oracle Data Mining
Oracle AI Platform Cloud Service
PolyAnalyst
RCASE
SAS Enterprise Miner
SequenceL
Splunk
STATISTICA Data Miner

Journals edit 
Journal of Machine Learning Research
Machine Learning
Nature Machine Intelligence
Neural Computation
IEEE Transactions on Pattern Analysis and Machine Intelligence
Conferences edit 
AAAI Conference on Artificial Intelligence
Association for Computational Linguistics  ACL 
European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases  ECML PKDD 
International Conference on Computational Intelligence Methods for Bioinformatics and Biostatistics  CIBB 
International Conference on Machine Learning  ICML 
International Conference on Learning Representations  ICLR 
International Conference on Intelligent Robots and Systems  IROS 
Conference on Knowledge Discovery and Data Mining  KDD 
Conference on Neural Information Processing Systems  NeurIPS 
See also edit 
Automated machine learning        Process of automating the application of machine learning
Big data        Extremely large or complex datasets
Deep learning   branch of ML concerned with artificial neural networks
Differentiable programming        Programming paradigm
List of datasets for machine learning research
M theory  learning framework 
Machine unlearning
Solomonoff s theory of inductive inference        A mathematical theory
References edit 


  The definition  without being explicitly programmed  is often attributed to Arthur Samuel  who coined the term  machine learning  in       but the phrase is not found verbatim in this publication  and may be a paraphrase that appeared later  Confer  Paraphrasing Arthur Samuel         the question is  How can computers learn to solve problems without being explicitly programmed   in Koza  John R   Bennett  Forrest H   Andre  David  Keane  Martin A           Automated Design of Both the Topology and Sizing of Analog Electrical Circuits Using Genetic Programming   Artificial Intelligence in Design      Artificial Intelligence in Design      Dordrecht  Netherlands  Springer Netherlands  pp                doi                              ISBN                        

   What is Machine Learning    IBM     September       Archived from the original on    December       Retrieved    June      

  Hu  Junyan  Niu  Hanlin  Carrasco  Joaquin  Lennox  Barry  Arvin  Farshad          Voronoi Based Multi Robot Autonomous Exploration in Unknown Environments via Deep Reinforcement Learning   PDF   IEEE Transactions on Vehicular Technology                        doi         tvt               ISSN                 S CID                

  a b Yoosefzadeh Najafabadi  Mohsen  Hugh  Earl  Tulpan  Dan  Sulik  John  Eskandari  Milad          Application of Machine Learning Algorithms in Plant Breeding  Predicting Yield From Hyperspectral Reflectance in Soybean    Front  Plant Sci              Bibcode     FrPS          Y  doi         fpls              PMC               PMID               

  a b c Bishop  C  M          Pattern Recognition and Machine Learning  Springer  ISBN                       

  Machine learning and pattern recognition  can be viewed as two facets of the same field                         vii       

  a b Friedman  Jerome H           Data Mining and Statistics  What s the connection    Computing Science and Statistics              

  Samuel  Arthur          Some Studies in Machine Learning Using the Game of Checkers   IBM Journal of Research and Development                  CiteSeerX                       doi         rd          S CID              

  a b R  Kohavi and F  Provost   Glossary of terms   Machine Learning  vol      no       pp                

  Gerovitch  Slava    April         How the Computer Got Its Revenge on the Soviet Union   Nautilus  Archived from the original on    September       Retrieved    September      

  Lindsay  Richard P     September         The Impact of Automation On Public Administration   Western Political Quarterly                 doi                             ISSN                 S CID                 Archived from the original on   October       Retrieved   October      

  a b c  History and Evolution of Machine Learning  A Timeline   WhatIs  Archived from the original on   December       Retrieved   December      

  Milner  Peter M           The Mind and Donald O  Hebb   Scientific American                    Bibcode     SciAm    a    M  doi         scientificamerican          ISSN                 JSTOR                PMID               Archived from the original on    December       Retrieved   December      

   Science  The Goof Button   Time  magazine      August      

  Nilsson N  Learning Machines  McGraw Hill       

  Duda  R   Hart P  Pattern Recognition and Scene Analysis  Wiley Interscience      

  S  Bozinovski  Teaching space  A representation concept for adaptive pattern classification  COINS Technical Report No         Computer and Information Science Department  University of Massachusetts at Amherst  MA        https   web cs umass edu publication docs      UM CS          pdf Archived    February      at the Wayback Machine

  a b Mitchell  T          Machine Learning  McGraw Hill  p          ISBN                        

  Harnad  Stevan          The Annotation Game  On Turing        on Computing  Machinery  and Intelligence   in Epstein  Robert  Peters  Grace  eds    The Turing Test Sourcebook  Philosophical and Methodological Issues in the Quest for the Thinking Computer  Kluwer  pp              ISBN                     archived from the original on   March       retrieved    December     

   Introduction to AI Part     Edzion    December       Archived from the original on    February       Retrieved   December      

  Sindhu V  Nivedha S  Prakash M  February         An Empirical Science Research on Bioinformatics in Machine Learning   Journal of Mechanics of Continua and Mathematical Sciences      doi          jmcms spl                 

  Sarle  Warren S           Neural Networks and statistical models   SUGI     proceedings of the Nineteenth Annual SAS Users Group International Conference  SAS Institute  pp                ISBN                     OCLC               

  a b c d Russell  Stuart  Norvig  Peter                Artificial Intelligence  A Modern Approach   nd      ed    Prentice Hall  ISBN                     

  a b Langley  Pat          The changing science of machine learning   Machine Learning                 doi         s               y 

  Mahoney  Matt   Rationale for a Large Text Compression Benchmark   Florida Institute of Technology  Retrieved   March      

  Shmilovici A   Kahiri Y   Ben Gal I   Hauser S           Measuring the Efficiency of the Intraday Forex Market with a Universal Data Compression Algorithm   PDF   Computational Economics                   CiteSeerX                       doi         s                  S CID                Archived  PDF  from the original on   July      

  I  Ben Gal          On the Use of Data Compression Measures to Analyze Robust Designs   PDF   IEEE Transactions on Reliability                   doi         TR              S CID              

  D  Scully  Carla E  Brodley          Compression and Machine Learning  A New Perspective on Feature Space Vectors   Data Compression Conference  DCC      p            doi         DCC          ISBN                     S CID               

  Gary Adcock    January         What Is AI Video Compression    massive io  Retrieved   April      

  Mentzer  Fabian  Toderici  George  Tschannen  Michael  Agustsson  Eirikur          High Fidelity Generative Image Compression   arXiv             eess IV  

   What is Unsupervised Learning    IBM   www ibm com     September       Retrieved   February      

   Differentially private clustering for large scale datasets   blog research google     May       Retrieved    March      

  Edwards  Benj     September         AI language models can exceed PNG and FLAC in lossless compression  says study   Ars Technica  Retrieved   March      

   Language Modeling Is Compression   arxiv org  Retrieved    January      

  Le Roux  Nicolas  Bengio  Yoshua  Fitzgibbon  Andrew          Improving First and Second Order Methods by Modeling Uncertainty   In Sra  Suvrit  Nowozin  Sebastian  Wright  Stephen J   eds    Optimization for Machine Learning  MIT Press  p            ISBN                     Archived from the original on    January       Retrieved    November      

  Bzdok  Danilo  Altman  Naomi  Krzywinski  Martin          Statistics versus Machine Learning   Nature Methods                   doi         nmeth       PMC               PMID               

  a b Michael I  Jordan     September         statistics and machine learning   reddit  Archived from the original on    October       Retrieved   October      

  Hung et al  Algorithms to Measure Surgeon Performance and Anticipate Clinical Outcomes in Robotic Surgery  JAMA Surg      

  Cornell University Library  August         Breiman  Statistical Modeling  The Two Cultures  with comments and a rejoinder by the author    Statistical Science          doi         ss             S CID                Archived from the original on    June       Retrieved   August      

  Gareth James  Daniela Witten  Trevor Hastie  Robert Tibshirani         An Introduction to Statistical Learning  Springer  p       vii  Archived from the original on    June       Retrieved    October      

  Ramezanpour  A   Beam  A L   Chen  J H   Mashaghi  A      November         Statistical Physics for Medical Diagnostics  Learning  Inference  and Optimization Algorithms   Diagnostics                doi         diagnostics          PMC               PMID               

  Mashaghi  A   Ramezanpour  A      March         Statistical physics of medical diagnostics  Study of a probabilistic model   Physical Review E                    arXiv             Bibcode     PhRvE    c    M  doi         PhysRevE            PMID                S CID              

  Mohri  Mehryar  Rostamizadeh  Afshin  Talwalkar  Ameet         Foundations of Machine Learning  US  Massachusetts  MIT Press  ISBN                    

  Alpaydin  Ethem         Introduction to Machine Learning  London  The MIT Press  ISBN                         Retrieved   February      

  Jordan  M  I   Mitchell  T  M      July         Machine learning  Trends  perspectives  and prospects   Science                       Bibcode     Sci           J  doi         science aaa      PMID                S CID             

  El Naqa  Issam  Murphy  Martin J           What is Machine Learning    Machine Learning in Radiation Oncology  pp             doi                              ISBN                         S CID                

  Okolie  Jude A   Savage  Shauna  Ogbaga  Chukwuma C   Gunes  Burcu  June         Assessing the potential of machine learning methods to study the removal of pharmaceuticals from wastewater using biochar or activated carbon   Total Environment Research Themes               Bibcode     TERT          O  doi         j totert              S CID                

  Russell  Stuart J   Norvig  Peter         Artificial Intelligence  A Modern Approach  Third      ed    Prentice Hall  ISBN                    

  Mohri  Mehryar  Rostamizadeh  Afshin  Talwalkar  Ameet         Foundations of Machine Learning  The MIT Press  ISBN                    

  Alpaydin  Ethem         Introduction to Machine Learning  MIT Press  p          ISBN                         Archived from the original on    January       Retrieved    November      

   Lecture   Notes  Supervised Learning   www cs cornell edu  Retrieved   July      

  Jordan  Michael I   Bishop  Christopher M           Neural Networks   In Allen B  Tucker  ed    Computer Science Handbook  Second Edition  Section VII  Intelligent Systems   Boca Raton  Florida  Chapman  amp  Hall CRC Press LLC  ISBN                        

  Misra  Ishan  Maaten  Laurens van der         Self Supervised Learning of Pretext Invariant Representations       IEEE CVF Conference on Computer Vision and Pattern Recognition  CVPR   Seattle  WA  USA  IEEE  pp                  arXiv             doi         CVPR                 

  Jaiswal  Ashish  Babu  Ashwin Ramesh  Zadeh  Mohammad Zaki  Banerjee  Debapriya  Makedon  Fillia  March         A Survey on Contrastive Self Supervised Learning   Technologies            arXiv             doi         technologies         ISSN                

  Alex Ratner  Stephen Bach  Paroma Varma  Chris   Weak Supervision  The New Programming Paradigm for Machine Learning   hazyresearch github io  referencing work by many other members of Hazy Research  Archived from the original on   June       Retrieved   June      

  van Otterlo  M   Wiering  M           Reinforcement Learning and Markov Decision Processes   Reinforcement Learning  Adaptation  Learning  and Optimization  Vol           pp             doi                              ISBN                        

  Roweis  Sam T   Saul  Lawrence K      December         Nonlinear Dimensionality Reduction by Locally Linear Embedding   Science                         Bibcode     Sci           R  doi         science                PMID                S CID               Archived from the original on    August       Retrieved    July      

  Pavel Brazdil  Christophe Giraud Carrier  Carlos Soares  Ricardo Vilalta         Metalearning  Applications to Data Mining  Fourth      ed    Springer Science Business Media  pp              passim  ISBN                     

  Bozinovski  S           A self learning system using secondary reinforcement   In Trappl  Robert  ed    Cybernetics and Systems Research  Proceedings of the Sixth European Meeting on Cybernetics and Systems Research  North Holland  pp           ISBN                        

  Bozinovski  S          Crossbar Adaptive Array  The first connectionist network that solved the delayed reinforcement learning problem  In A  Dobnikar  N  Steele  D  Pearson  R  Albert  eds   Artificial Neural Networks and Genetic Algorithms  Springer Verlag  p           ISBN               

  Bozinovski  Stevo         Modeling mechanisms of cognition emotion interaction in artificial neural networks  since        Procedia Computer Science p         

  Bozinovski  S          Self learning agents  A connectionist theory of emotion based on crossbar value judgment   Cybernetics and Systems               

  Y  Bengio  A  Courville  P  Vincent          Representation Learning  A Review and New Perspectives   IEEE Transactions on Pattern Analysis and Machine Intelligence                     arXiv            doi         tpami          PMID                S CID             

  Nathan Srebro  Jason D  M  Rennie  Tommi S  Jaakkola         Maximum Margin Matrix Factorization  NIPS 

  Coates  Adam  Lee  Honglak  Ng  Andrew Y          An analysis of single layer networks in unsupervised feature learning  PDF   Int l Conf  on AI and Statistics  AISTATS   Archived from the original  PDF  on    August       Retrieved    November      

  Csurka  Gabriella  Dance  Christopher C   Fan  Lixin  Willamowski  Jutta  Bray  C dric         Visual categorization with bags of keypoints  PDF   ECCV Workshop on Statistical Learning in Computer Vision  Archived  PDF  from the original on    July       Retrieved    August      

  Daniel Jurafsky  James H  Martin         Speech and Language Processing  Pearson Education International  pp               

  Lu  Haiping  Plataniotis  K N   Venetsanopoulos  A N           A Survey of Multilinear Subspace Learning for Tensor Data   PDF   Pattern Recognition                     Bibcode     PatRe         L  doi         j patcog              Archived  PDF  from the original on    July       Retrieved   September      

  Yoshua Bengio         Learning Deep Architectures for AI  Now Publishers Inc  pp            ISBN                         Archived from the original on    January       Retrieved    February      

  Tillmann  A  M           On the Computational Intractability of Exact and Approximate Dictionary Learning   IEEE Signal Processing Letters                 arXiv            Bibcode     ISPL          T  doi         LSP               S CID               

  Aharon  M  M Elad  and A Bruckstein         K SVD  An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation Archived            at the Wayback Machine   Signal Processing  IEEE Transactions on                   

  Zimek  Arthur  Schubert  Erich          Outlier Detection   Encyclopedia of Database Systems  Springer New York  pp            doi                                    ISBN                   

  Hodge  V  J   Austin  J           A Survey of Outlier Detection Methodologies   PDF   Artificial Intelligence Review                  CiteSeerX                       doi         s               y  S CID                Archived  PDF  from the original on    June       Retrieved    November      

  Dokas  Paul  Ertoz  Levent  Kumar  Vipin  Lazarevic  Aleksandar  Srivastava  Jaideep  Tan  Pang Ning          Data mining for network intrusion detection   PDF   Proceedings NSF Workshop on Next Generation Data Mining  Archived  PDF  from the original on    September       Retrieved    March      

  Chandola  V   Banerjee  A   Kumar  V           Anomaly detection  A survey   ACM Computing Surveys                doi                          S CID                

  Fleer  S   Moringen  A   Klatzky  R  L   Ritter  H           Learning efficient haptic shape exploration with a rigid tactile sensor array  S  Fleer  A  Moringen  R  Klatzky  H  Ritter   PLOS ONE          e         arXiv             doi         journal pone          PMC               PMID               

  Moringen  Alexandra  Fleer  Sascha  Walck  Guillaume  Ritter  Helge         Nisky  Ilana  Hartcher O Brien  Jess  Wiertlewski  Micha l  Smeets  Jeroen  eds     Attention Based Robot Learning of Haptic Interaction   Haptics  Science  Technology  Applications  Lecture Notes in Computer Science  vol              Cham  Springer International Publishing  pp                doi                               ISBN                         S CID               

  Piatetsky Shapiro  Gregory         Discovery  analysis  and presentation of strong rules  in Piatetsky Shapiro  Gregory  and Frawley  William J   eds   Knowledge Discovery in Databases  AAAI MIT Press  Cambridge  MA 

  Bassel  George W   Glaab  Enrico  Marquez  Julietta  Holdsworth  Michael J   Bacardit  Jaume    September         Functional Network Construction in Arabidopsis Using Rule Based Machine Learning on Large Scale Data Sets   The Plant Cell                     Bibcode     PlanC         B  doi         tpc             ISSN              X  PMC               PMID               

  Agrawal  R   Imieli ski  T   Swami  A           Mining association rules between sets of items in large databases   Proceedings of the      ACM SIGMOD international conference on Management of data   SIGMOD      p            CiteSeerX                      doi                        ISBN                      S CID             

  Urbanowicz  Ryan J   Moore  Jason H      September         Learning Classifier Systems  A Complete Introduction  Review  and Roadmap   Journal of Artificial Evolution and Applications              doi                      ISSN                

  Plotkin G D  Automatic Methods of Inductive Inference Archived    December      at the Wayback Machine  PhD thesis  University of Edinburgh       

  Shapiro  Ehud Y  Inductive inference of theories from facts Archived    August      at the Wayback Machine  Research Report      Yale University  Department of Computer Science        Reprinted in J  L  Lassez  G  Plotkin  Eds    Computational Logic  The MIT Press  Cambridge  MA        pp          

  Shapiro  Ehud Y          Algorithmic program debugging  Cambridge  Mass  MIT Press  ISBN                   

  Shapiro  Ehud Y   The model inference system Archived            at the Wayback Machine   Proceedings of the  th international joint conference on Artificial intelligence Volume    Morgan Kaufmann Publishers Inc        

  Burkov  Andriy         The hundred page machine learning book  Polen  Andriy Burkov  ISBN                        

  Russell  Stuart J   Norvig  Peter         Artificial intelligence  a modern approach  Pearson series in artificial intelligence  Fourth      ed    Hoboken  Pearson  ISBN                        

  Honglak Lee  Roger Grosse  Rajesh Ranganath  Andrew Y  Ng   Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations Archived            at the Wayback Machine  Proceedings of the   th Annual International Conference on Machine Learning       

   RandomForestRegressor   scikit learn  Retrieved    February      

   What Is Random Forest    IBM   www ibm com     October       Retrieved    February      

  Cortes  Corinna  Vapnik  Vladimir N           Support vector networks   Machine Learning                   doi         BF         

  Stevenson  Christopher   Tutorial  Polynomial Regression in Excel   facultystaff richmond edu  Archived from the original on   June       Retrieved    January      

  Wanta  Damian  Smolik  Aleksander  Smolik  Waldemar T   Midura  Mateusz  Wr blewski  Przemys aw          Image reconstruction using machine learned pseudoinverse in electrical capacitance tomography   Engineering Applications of Artificial Intelligence               doi         j engappai             

  The documentation for scikit learn also has similar examples Archived   November      at the Wayback Machine 

  Goldberg  David E   Holland  John H           Genetic algorithms and machine learning   PDF   Machine Learning                doi         bf          S CID                Archived  PDF  from the original on    May       Retrieved   September      

  Michie  D   Spiegelhalter  D  J   Taylor  C  C           Machine Learning  Neural and Statistical Classification   Ellis Horwood Series in Artificial Intelligence  Bibcode     mlns book     M 

  Zhang  Jun  Zhan  Zhi hui  Lin  Ying  Chen  Ni  Gong  Yue jiao  Zhong  Jing hui  Chung  Henry S H   Li  Yun  Shi  Yu hui          Evolutionary Computation Meets Machine Learning  A Survey   Computational Intelligence Magazine                doi         mci              S CID              

  Verbert  K   Babu ka  R   De Schutter  B     April         Bayesian and Dempster Shafer reasoning for knowledge based fault diagnosis A comparative study   Engineering Applications of Artificial Intelligence               doi         j engappai              ISSN                

  Urbanowicz  Ryan J   Moore  Jason H      September         Learning Classifier Systems  A Complete Introduction  Review  and Roadmap   Journal of Artificial Evolution and Applications              doi                      ISSN                

  Zhang  C  and Zhang  S         Association rule mining  models and algorithms  Springer Verlag 

  De Castro  Leandro Nunes  and Jonathan Timmis  Artificial immune systems  a new computational intelligence approach  Springer Science  amp  Business Media       

   Federated Learning  Collaborative Machine Learning without Centralized Training Data   Google AI Blog    April       Archived from the original on   June       Retrieved   June      

  Machine learning is included in the CFA Curriculum  discussion is top down   see  Kathleen DeRose and Christophe Le Lanno          Machine Learning  Archived    January      at the Wayback Machine 

  Ivanenko  Mikhail  Smolik  Waldemar T   Wanta  Damian  Midura  Mateusz  Wr blewski  Przemys aw  Hou  Xiaohan  Yan  Xiaoheng          Image Reconstruction Using Supervised Learning in Wearable Electrical Impedance Tomography of the Thorax   Sensors                 Bibcode     Senso         I  doi         s          PMC                PMID               

   BelKor Home Page  research att com

   The Netflix Tech Blog  Netflix Recommendations  Beyond the   stars  Part        April       Archived from the original on    May       Retrieved   August      

  Scott Patterson     July         Letting the Machines Decide   The Wall Street Journal  Archived from the original on    June       Retrieved    June      

  Vinod Khosla     January         Do We Need Doctors or Algorithms    Tech Crunch  Archived from the original on    June       Retrieved    October      

  When A Machine Learning Algorithm Studied Fine Art Paintings  It Saw Things Art Historians Had Never Noticed Archived   June      at the Wayback Machine  The Physics at ArXiv blog

  Vincent  James     April         The first AI generated textbook shows what robot writers are actually good at   The Verge  Archived from the original on   May       Retrieved   May      

  Vaishya  Raju  Javaid  Mohd  Khan  Ibrahim Haleem  Haleem  Abid    July         Artificial Intelligence  AI  applications for COVID    pandemic   Diabetes  amp  Metabolic Syndrome  Clinical Research  amp  Reviews                   doi         j dsx              PMC               PMID               

  Rezapouraghdam  Hamed  Akhshik  Arash  Ramkissoon  Haywantee     March         Application of machine learning to predict visitors  green behavior in marine protected areas  evidence from Cyprus   Journal of Sustainable Tourism                      doi                                hdl             

  Dey  Somdip  Singh  Amit Kumar  Wang  Xiaohang  McDonald Maier  Klaus     June         User Interaction Aware Reinforcement Learning for Power and Thermal Efficiency of CPU GPU Mobile MPSoCs        Design  Automation  amp  Test in Europe Conference  amp  Exhibition  DATE   PDF   pp                  doi          DATE                    ISBN                         S CID                 Archived from the original on    December       Retrieved    January      

  Quested  Tony   Smartphones get smarter with Essex innovation   Business Weekly  Archived from the original on    June       Retrieved    June      

  Williams  Rhiannon     July         Future smartphones  will prolong their own battery life by monitoring owners  behaviour    i  Archived from the original on    June       Retrieved    June      

  Rasekhschaffe  Keywan Christian  Jones  Robert C     July         Machine Learning for Stock Selection   Financial Analysts Journal                 doi                X               ISSN              X  S CID                 Archived from the original on    November       Retrieved    November      

  Chung  Yunsie  Green  William H           Machine learning from quantum chemistry to predict experimental solvent effects on reaction rates   Chemical Science                     doi         D SC     A  ISSN                 PMC                PMID               

  Sun  Yuran  Huang  Shih Kai  Zhao  Xilei    February         Predicting Hurricane Evacuation Decisions with Interpretable Machine Learning Methods   International Journal of Disaster Risk Science                   arXiv             Bibcode     IJDRS         S  doi         s                   ISSN                

  Sun  Yuran  Zhao  Xilei  Lovreglio  Ruggiero  Kuligowski  Erica    January        Naser  M  Z   ed         AI for large scale evacuation modeling  promises and challenges   Interpretable Machine Learning for the Analysis  Design  Assessment  and Informed Decision Making for Civil Infrastructure  Woodhead Publishing Series in Civil and Structural Engineering  Woodhead Publishing  pp                ISBN                         archived from the original on    May       retrieved    May     

  Xu  Ningzhe  Lovreglio  Ruggiero  Kuligowski  Erica D   Cova  Thomas J   Nilsson  Daniel  Zhao  Xilei    March         Predicting and Assessing Wildfire Evacuation Decision Making Using Machine Learning  Findings from the      Kincade Fire   Fire Technology                   doi         s                   ISSN                 Archived from the original on    May       Retrieved    May      

  Wang  Ke  Shi  Xiupeng  Goh  Algena Pei Xuan  Qian  Shunzhi    June         A machine learning based study on pedestrian movement dynamics under emergency evacuation   Fire Safety Journal                Bibcode     FirSJ         W  doi         j firesaf              hdl               ISSN                 Archived from the original on    May       Retrieved    May      

  Zhao  Xilei  Lovreglio  Ruggiero  Nilsson  Daniel    May         Modelling and interpreting pre evacuation decision making using machine learning   Automation in Construction               doi         j autcon              hdl              ISSN                 Archived from the original on    May       Retrieved    May      

  Phoon  Kok Kwang  Zhang  Wengang    January         Future of machine learning in geotechnics   Georisk  Assessment and Management of Risk for Engineered Systems and Geohazards                Bibcode     GAMRE         P  doi                                ISSN                

   Why Machine Learning Models Often Fail to Learn  QuickTake Q amp A   Bloomberg com     November       Archived from the original on    March       Retrieved    April      

   The First Wave of Corporate AI Is Doomed to Fail   Harvard Business Review     April       Archived from the original on    August       Retrieved    August      

   Why the A I  euphoria is doomed to fail   VentureBeat     September       Archived from the original on    August       Retrieved    August      

     Reasons why your machine learning project will fail   www kdnuggets com  Archived from the original on    August       Retrieved    August      

  a b Babuta  Alexander  Oswald  Marion  Rinik  Christine         Transparency and Intelligibility  Report   Royal United Services Institute  RUSI   pp              Archived from the original on   December       Retrieved   December      

   Why Uber s self driving car killed a pedestrian   The Economist  Archived from the original on    August       Retrieved    August      

   IBM s Watson recommended  unsafe and incorrect  cancer treatments   STAT   STAT     July       Archived from the original on    August       Retrieved    August      

  Hernandez  Daniela  Greenwald  Ted     August         IBM Has a Watson Dilemma   The Wall Street Journal  ISSN                 Archived from the original on    August       Retrieved    August      

  Allyn  Bobby     February         How Microsoft s experiment in artificial intelligence tech backfired   National Public Radio  Archived from the original on   December       Retrieved   December      

  Reddy  Shivani M   Patel  Sheila  Weyrich  Meghan  Fenton  Joshua  Viswanathan  Meera          Comparison of a traditional systematic review approach with review of reviews and semi automation as strategies to update the evidence   Systematic Reviews              doi         s                   ISSN                 PMC               PMID               

  Rudin  Cynthia          Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead   Nature Machine Intelligence                  doi         s               x  PMC               PMID               

  Hu  Tongxi  Zhang  Xuesong  Bohrer  Gil  Liu  Yanlan  Zhou  Yuyu  Martin  Jay  LI  Yang  Zhao  Kaiguang          Crop yield prediction via explainable AI and interpretable machine learning  Dangers of black box models for evaluating climate change impacts on crop yield   Agricultural and Forest Meteorology               doi         j agrformet              S CID                

  Domingos       Chapter    Chapter   

  Domingos       p           

   Single pixel change fools AI programs   BBC News    November       Archived from the original on    March       Retrieved    March      

   AI Has a Hallucination Problem That s Proving Tough to Fix   WIRED        Archived from the original on    March       Retrieved    March      

  Madry  A   Makelov  A   Schmidt  L   Tsipras  D   Vladu  A     September         Towards deep learning models resistant to adversarial attacks   arXiv             stat ML  

   Adversarial Machine Learning   CLTC UC Berkeley Center for Long Term Cybersecurity   CLTC  Archived from the original on    May       Retrieved    May      

   Machine learning models vulnerable to undetectable backdoors   The Register  Archived from the original on    May       Retrieved    May      

   Undetectable Backdoors Plantable In Any Machine Learning Algorithm   IEEE Spectrum     May       Archived from the original on    May       Retrieved    May      

  Goldwasser  Shafi  Kim  Michael P   Vaikuntanathan  Vinod  Zamir  Or     April         Planting Undetectable Backdoors in Machine Learning Models   arXiv             cs LG  

  Kohavi  Ron          A Study of Cross Validation and Bootstrap for Accuracy Estimation and Model Selection   PDF   International Joint Conference on Artificial Intelligence  Archived  PDF  from the original on    July       Retrieved    March      

  Catal  Cagatay          Performance Evaluation Metrics for Software Fault Prediction Studies   PDF   Acta Polytechnica Hungarica         Retrieved   October      

  a b M ller  Vincent C      April         Ethics of Artificial Intelligence and Robotics   Stanford Encyclopedia of Philosophy  Archived from the original on    October      

  Van Eyghen  Hans          AI Algorithms as  Un virtuous Knowers   Discover Artificial Intelligence         doi         s                z 

  a b Garcia  Megan          Racist in the Machine   World Policy Journal                   doi                           ISSN                 S CID                

  Bostrom  Nick          The Ethics of Artificial Intelligence   PDF   Archived from the original  PDF  on   March       Retrieved    April      

  Edionwe  Tolulope   The fight against racist algorithms   The Outline  Archived from the original on    November       Retrieved    November      

  Jeffries  Adrianne   Machine learning is racist because the internet is racist   The Outline  Archived from the original on    November       Retrieved    November      

  a b Silva  Selena  Kenney  Martin          Algorithms  Platforms  and Ethnic Bias  An Integrative Essay   PDF   Phylon         amp            ISSN                 JSTOR                Archived  PDF  from the original on    January      

  Wong  Carissa     March         AI  fairness  research held back by lack of diversity   Nature  doi         d                z  PMID                S CID                 Archived from the original on    April       Retrieved   December      

  a b Zhang  Jack Clark   Artificial Intelligence Index Report        PDF   Stanford Institute for Human Centered Artificial Intelligence  Archived  PDF  from the original on    May       Retrieved   December      

  Caliskan  Aylin  Bryson  Joanna J   Narayanan  Arvind     April         Semantics derived automatically from language corpora contain human like biases   Science                       arXiv             Bibcode     Sci           C  doi         science aal      ISSN                 PMID                S CID               

  Wang  Xinan  Dasgupta  Sanjoy         Lee  D  D   Sugiyama  M   Luxburg  U  V   Guyon  I   eds     An algorithm for L  nearest neighbor search via monotonic embedding   PDF   Advances in Neural Information Processing Systems     Curran Associates  Inc   pp                archived  PDF  from the original on   April       retrieved    August     

  M O R  Prates  P H C  Avelar  L C  Lamb     March         Assessing Gender Bias in Machine Translation   A Case Study with Google Translate   arXiv             cs CY  

  Narayanan  Arvind     August         Language necessarily contains human biases  and so will machines trained on language corpora   Freedom to Tinker  Archived from the original on    June       Retrieved    November      

  Metz  Rachel     March         Why Microsoft Accidentally Unleashed a Neo Nazi Sexbot   MIT Technology Review  Archived from the original on   November       Retrieved    August      

  Vincent  James     January         Google  fixed  its racist algorithm by removing gorillas from its image labeling tech   The Verge  Archived from the original on    August       Retrieved    August      

  Crawford  Kate     June         Opinion   Artificial Intelligence s White Guy Problem   New York Times  Archived from the original on    January       Retrieved    August      

  Simonite  Tom     March         Microsoft  AI Isn t Yet Adaptable Enough to Help Businesses   MIT Technology Review  Archived from the original on   November       Retrieved    August      

  Hempel  Jessi     November         Fei Fei Li s Quest to Make Machines Better for Humanity   Wired  ISSN                 Archived from the original on    December       Retrieved    February      

  Char  D  S   Shah  N  H   Magnus  D           Implementing Machine Learning in Health Care Addressing Ethical Challenges   New England Journal of Medicine                     doi         nejmp         PMC               PMID               

  Research  AI     October         Deep Neural Networks for Acoustic Modeling in Speech Recognition   airesearch com  Archived from the original on   February       Retrieved    October      

   GPUs Continue to Dominate the AI Accelerator Market for Now   InformationWeek  December       Archived from the original on    June       Retrieved    June      

  Ray  Tiernan          AI is changing the entire nature of compute   ZDNet  Archived from the original on    May       Retrieved    June      

   AI and Compute   OpenAI     May       Archived from the original on    June       Retrieved    June      

  Jouppi  Norman P   Young  Cliff  Patil  Nishant  Patterson  David  Agrawal  Gaurav  Bajwa  Raminder  Bates  Sarah  Bhatia  Suresh  Boden  Nan  Borchers  Al  Boyle  Rick  Cantin  Pierre luc  Chao  Clifford  Clark  Chris  Coriell  Jeremy     June         In Datacenter Performance Analysis of a Tensor Processing Unit   Proceedings of the   th Annual International Symposium on Computer Architecture  ISCA      New York  NY  USA  Association for Computing Machinery  pp             arXiv             doi                          ISBN                        

   What is neuromorphic computing  Everything you need to know about how it is changing the future of computing   ZDNET    December       Retrieved    November      

   Cornell  amp  NTT s Physical Neural Networks  A  Radical Alternative for Implementing Deep Neural Networks  That Enables Arbitrary Physical Systems Training   Synced     May       Archived from the original on    October       Retrieved    October      

   Nano spaghetti to solve neural network power consumption   The Register    October       Archived from the original on   October       Retrieved    October      

  Fafoutis  Xenofon  Marchegiani  Letizia  Elsts  Atis  Pope  James  Piechocki  Robert  Craddock  Ian    May         Extending the battery lifetime of wearable sensors with embedded machine learning        IEEE  th World Forum on Internet of Things  WF IoT   pp                doi         WF IoT               hdl      b fdb  b        c    e   ab   c    f  ISBN                         S CID                Archived from the original on    January       Retrieved    January      

   A Beginner s Guide To Machine learning For Embedded Systems   Analytics India Magazine    June       Archived from the original on    January       Retrieved    January      

  Synced     January         Google  Purdue  amp  Harvard U s Open Source Framework for TinyML Achieves up to   x Speedups on FPGAs   Synced   syncedreview com  Archived from the original on    January       Retrieved    January      

  AlSelek  Mohammad  Alcaraz Calero  Jose M   Wang  Qi          Dynamic AI IoT  Enabling Updatable AI Models in Ultralow Power  G IoT Devices   IEEE Internet of Things Journal                       doi         JIOT              

  Giri  Davide  Chiu  Kuan Lin  Di Guglielmo  Giuseppe  Mantovani  Paolo  Carloni  Luca P      June         ESP ML  Platform Based Design of Systems on Chip for Embedded Machine Learning        Design  Automation  amp  Test in Europe Conference  amp  Exhibition  DATE   pp                  arXiv             doi          DATE                    ISBN                         S CID                 Archived from the original on    January       Retrieved    January      

  Louis  Marcia Sahaya  Azad  Zahra  Delshadtehrani  Leila  Gupta  Suyog  Warden  Pete  Reddi  Vijay Janapa  Joshi  Ajay          Towards Deep Learning using TensorFlow Lite on RISC V   Harvard University  Archived from the original on    January       Retrieved    January      

  Ibrahim  Ali  Osta  Mario  Alameh  Mohamad  Saleh  Moustafa  Chible  Hussein  Valle  Maurizio     January         Approximate Computing Methods for Embedded Machine Learning          th IEEE International Conference on Electronics  Circuits and Systems  ICECS   pp                doi         ICECS               ISBN                         S CID                Archived from the original on    January       Retrieved    January      

   dblp  TensorFlow Eager  A Multi Stage  Python Embedded DSL for Machine Learning   dblp org  Archived from the original on    January       Retrieved    January      

  Branco  S rgio  Ferreira  Andr  G   Cabral  Jorge    November         Machine Learning in Resource Scarce Embedded Systems  FPGAs  and End Devices  A Survey   Electronics                doi         electronics         hdl             ISSN                


Sources edit 
Domingos  Pedro     September        The Master Algorithm  How the Quest for the Ultimate Learning Machine Will Remake Our World  Basic Books  ISBN                     
Nilsson  Nils         Artificial Intelligence  A New Synthesis  Morgan Kaufmann  ISBN                         Archived from the original on    July       Retrieved    November      
Poole  David  Mackworth  Alan  Goebel  Randy         Computational Intelligence  A Logical Approach  New York  Oxford University Press  ISBN                         Archived from the original on    July       Retrieved    August      
Russell  Stuart J   Norvig  Peter         Artificial Intelligence  A Modern Approach   nd      ed    Upper Saddle River  New Jersey  Prentice Hall  ISBN                    
Further reading edit 

Alpaydin  Ethem         Introduction to Machine Learning    th edition  MIT Press  ISBN                    
Bishop  Christopher         Neural Networks for Pattern Recognition  Oxford University Press  ISBN                    
Bishop  Christopher        Pattern Recognition and Machine Learning  Springer  ISBN                       
Domingos  Pedro  September        The Master Algorithm  Basic Books  ISBN                       
Duda  Richard O   Hart  Peter E   Stork  David G         Pattern classification   nd edition   Wiley  New York  ISBN                    
Hastie  Trevor  Tibshirani  Robert  amp  Friedman  Jerome H         The Elements of Statistical Learning  Springer  doi                           ISBN                    
MacKay  David J  C  Information Theory  Inference  and Learning Algorithms Cambridge  Cambridge University Press        ISBN                   
Murphy  Kevin P           Probabilistic Machine Learning  An Introduction Archived    April      at the Wayback Machine  MIT Press 
Nilsson  Nils J         Introduction to Machine Learning Archived    August      at the Wayback Machine 
Russell  Stuart  amp   Norvig  Peter         Artificial Intelligence   A Modern Approach    th edition  Pearson  ISBN                     
Solomonoff  Ray         An Inductive Inference Machine Archived    April      at the Wayback Machine A privately circulated report from the      Dartmouth Summer Research Conference on AI 
Witten  Ian H   amp  Frank  Eibe         Data Mining  Practical machine learning tools and techniques Morgan Kaufmann     pp   ISBN                        

External links edit 
International Machine Learning Society
mloss is an academic database of open source machine learning software 
vteArtificial intelligence  AI History  timeline Concepts
Parameter
Hyperparameter
Loss functions
Regression
Bias variance tradeoff
Double descent
Overfitting
Clustering
Gradient descent
SGD
Quasi Newton method
Conjugate gradient method
Backpropagation
Attention
Convolution
Normalization
Batchnorm
Activation
Softmax
Sigmoid
Rectifier
Gating
Weight initialization
Regularization
Datasets
Augmentation
Prompt engineering
Reinforcement learning
Q learning
SARSA
Imitation
Policy gradient
Diffusion
Latent diffusion model
Autoregression
Adversary
RAG
Uncanny valley
RLHF
Self supervised learning
Recursive self improvement
Word embedding
Hallucination
Applications
Machine learning
In context learning
Artificial neural network
Deep learning
Language model
Large language model
NMT
Artificial general intelligence  AGI 
ImplementationsAudio visual
AlexNet
WaveNet
Human image synthesis
HWR
OCR
Speech synthesis
   ai
ElevenLabs
Speech recognition
Whisper
Facial recognition
AlphaFold
Text to image models
Aurora
DALL E
Firefly
Flux
Ideogram
Imagen
Midjourney
Stable Diffusion
Text to video models
Dream Machine
Runway Gen
Hailuo AI
Kling
Sora
Veo
Music generation
Suno AI
Udio
Text
Word vec
Seq seq
GloVe
BERT
T 
Llama
Chinchilla AI
PaLM
GPT
 
 
 
J
ChatGPT
 
 o
o 
o 
   
   
o 
Claude
Gemini
chatbot
Grok
LaMDA
BLOOM
Project Debater
IBM Watson
IBM Watsonx
Granite
PanGu  
DeepSeek
Qwen
Decisional
AlphaGo
AlphaZero
OpenAI Five
Self driving car
MuZero
Action selection
AutoGPT
Robot control
People
Alan Turing
Warren Sturgis McCulloch
Walter Pitts
John von Neumann
Claude Shannon
Marvin Minsky
John McCarthy
Nathaniel Rochester
Allen Newell
Cliff Shaw
Herbert A  Simon
Oliver Selfridge
Frank Rosenblatt
Bernard Widrow
Joseph Weizenbaum
Seymour Papert
Seppo Linnainmaa
Paul Werbos
J rgen Schmidhuber
Yann LeCun
Geoffrey Hinton
John Hopfield
Yoshua Bengio
Lotfi A  Zadeh
Stephen Grossberg
Alex Graves
Andrew Ng
Fei Fei Li
Alex Krizhevsky
Ilya Sutskever
Demis Hassabis
David Silver
Ian Goodfellow
Andrej Karpathy
James Goodnight
Architectures
Neural Turing machine
Differentiable neural computer
Transformer
Vision transformer  ViT 
Recurrent neural network  RNN 
Long short term memory  LSTM 
Gated recurrent unit  GRU 
Echo state network
Multilayer perceptron  MLP 
Convolutional neural network  CNN 
Residual neural network  RNN 
Highway network
Mamba
Autoencoder
Variational autoencoder  VAE 
Generative adversarial network  GAN 
Graph neural network  GNN 

 Portals
Technology
 Category
Artificial neural networks
Machine learning
 List
Companies
Projects

vteComputer scienceNote  This template roughly follows the      ACM Computing Classification System Hardware
Printed circuit board
Peripheral
Integrated circuit
Very Large Scale Integration
Systems on Chip  SoCs 
Energy consumption  Green computing 
Electronic design automation
Hardware acceleration
Processor
Size   Form
Computer systems organization
Computer architecture
Computational complexity
Dependability
Embedded system
Real time computing
Networks
Network architecture
Network protocol
Network components
Network scheduler
Network performance evaluation
Network service
Software organization
Interpreter
Middleware
Virtual machine
Operating system
Software quality
Software notations and tools
Programming paradigm
Programming language
Compiler
Domain specific language
Modeling language
Software framework
Integrated development environment
Software configuration management
Software library
Software repository
Software development
Control variable
Software development process
Requirements analysis
Software design
Software construction
Software deployment
Software engineering
Software maintenance
Programming team
Open source model
Theory of computation
Model of computation
Stochastic
Formal language
Automata theory
Computability theory
Computational complexity theory
Logic
Semantics
Algorithms
Algorithm design
Analysis of algorithms
Algorithmic efficiency
Randomized algorithm
Computational geometry
Mathematics of computing
Discrete mathematics
Probability
Statistics
Mathematical software
Information theory
Mathematical analysis
Numerical analysis
Theoretical computer science
Information systems
Database management system
Information storage systems
Enterprise information system
Social information systems
Geographic information system
Decision support system
Process control system
Multimedia information system
Data mining
Digital library
Computing platform
Digital marketing
World Wide Web
Information retrieval
Security
Cryptography
Formal methods
Security hacker
Security services
Intrusion detection system
Hardware security
Network security
Information security
Application security
Human computer interaction
Interaction design
Augmented reality
Virtual reality
Social computing
Ubiquitous computing
Visualization
Accessibility
Concurrency
Concurrent computing
Parallel computing
Distributed computing
Multithreading
Multiprocessing
Artificial intelligence
Natural language processing
Knowledge representation and reasoning
Computer vision
Automated planning and scheduling
Search methodology
Control method
Philosophy of artificial intelligence
Distributed artificial intelligence
Machine learning
Supervised learning
Unsupervised learning
Reinforcement learning
Multi task learning
Cross validation
Graphics
Animation
Rendering
Photograph manipulation
Graphics processing unit
Image compression
Solid modeling
Applied computing
Quantum Computing
E commerce
Enterprise software
Computational mathematics
Computational physics
Computational chemistry
Computational biology
Computational social science
Computational engineering
Differentiable computing
Computational healthcare
Digital art
Electronic publishing
Cyberwarfare
Electronic voting
Video games
Word processing
Operations research
Educational technology
Document management

 Category
 Outline
 Glossaries

Portals  Computer programming Mathematics Systems science TechnologyMachine learning at Wikipedia s sister projects Definitions from WiktionaryMedia from CommonsQuotations from WikiquoteTextbooks from WikibooksResources from WikiversityData from Wikidata
Authority control databases  National GermanyUnited StatesJapanCzech RepublicIsrael





Retrieved from  https   en wikipedia org w index php title Machine learning amp oldid