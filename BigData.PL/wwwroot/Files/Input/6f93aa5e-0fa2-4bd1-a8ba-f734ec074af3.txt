Type of artificial neural network
Part of a series onMachine learningand data mining
Paradigms
Supervised learning
Unsupervised learning
Semi supervised learning
Self supervised learning
Reinforcement learning
Meta learning
Online learning
Batch learning
Curriculum learning
Rule based learning
Neuro symbolic AI
Neuromorphic engineering
Quantum machine learning

Problems
Classification
Generative modeling
Regression
Clustering
Dimensionality reduction
Density estimation
Anomaly detection
Data cleaning
AutoML
Association rules
Semantic analysis
Structured prediction
Feature engineering
Feature learning
Learning to rank
Grammar induction
Ontology learning
Multimodal learning

Supervised learning classification                  regression  
Apprenticeship learning
Decision trees
Ensembles
Bagging
Boosting
Random forest
k NN
Linear regression
Naive Bayes
Artificial neural networks
Logistic regression
Perceptron
Relevance vector machine  RVM 
Support vector machine  SVM 

Clustering
BIRCH
CURE
Hierarchical
k means
Fuzzy
Expectation maximization  EM 
DBSCAN
OPTICS
Mean shift

Dimensionality reduction
Factor analysis
CCA
ICA
LDA
NMF
PCA
PGD
t SNE
SDL

Structured prediction
Graphical models
Bayes net
Conditional random field
Hidden Markov

Anomaly detection
RANSAC
k NN
Local outlier factor
Isolation forest

Artificial neural network
Autoencoder
Deep learning
Feedforward neural network
Recurrent neural network
LSTM
GRU
ESN
reservoir computing
Boltzmann machine
Restricted
GAN
Diffusion model
SOM
Convolutional neural network
U Net
LeNet
AlexNet
DeepDream
Neural radiance field
Transformer
Vision
Mamba
Spiking neural network
Memtransistor
Electrochemical RAM  ECRAM 

Reinforcement learning
Q learning
SARSA
Temporal difference  TD 
Multi agent
Self play

Learning with humans
Active learning
Crowdsourcing
Human in the loop
RLHF

Model diagnostics
Coefficient of determination
Confusion matrix
Learning curve
ROC curve

Mathematical foundations
Kernel machines
Bias variance tradeoff
Computational learning theory
Empirical risk minimization
Occam learning
PAC learning
Statistical learning
VC theory
Topological deep learning

Journals and conferences
ECML PKDD
NeurIPS
ICML
ICLR
IJCAI
ML
JMLR

Related articles
Glossary of artificial intelligence
List of datasets for machine learning research
List of datasets in computer vision and image processing
Outline of machine learning
vte
A convolutional neural network  CNN  is a type of feedforward neural network that learns features via filter  or kernel  optimization  This type of deep learning network has been applied to process and make predictions from many different types of data including text  images and audio             Convolution based networks are the de facto standard in deep learning based approaches to computer vision            and image processing  and have only recently been replaced in some cases by newer deep learning architectures such as the transformer 
Vanishing gradients and exploding gradients  seen during backpropagation in earlier neural networks  are prevented by the regularization that comes from using shared weights over fewer connections                        For example  for each neuron in the fully connected layer         weights would be required for processing an image sized           pixels  However  applying cascaded convolution  or cross correlation  kernels                        only    weights for each convolutional layer are required to process  x  sized tiles                        Higher layer features are extracted from wider context windows  compared to lower layer features 
Some applications of CNNs include  

image and video recognition            
recommender systems             
image classification 
image segmentation 
medical image analysis 
natural language processing             
brain computer interfaces              and
financial time series             
CNNs are also known as shift invariant or space invariant artificial neural networks  based on the shared weight architecture of the convolution kernels or filters that slide along input features and provide translation equivariant responses known as feature maps                          Counter intuitively  most convolutional neural networks are not invariant to translation  due to the downsampling operation they apply to the input             
Feedforward neural networks are usually fully connected networks  that is  each neuron in one layer is connected to all neurons in the next layer  The  full connectivity  of these networks makes them prone to overfitting data  Typical ways of regularization  or preventing overfitting  include  penalizing parameters during training  such as weight decay  or trimming connectivity  skipped connections  dropout  etc   Robust datasets also increase the probability that CNNs will learn the generalized principles that characterize a given dataset rather than the biases of a poorly populated set             
Convolutional networks were inspired by biological processes                                                 in that the connectivity pattern between neurons resembles the organization of the animal visual cortex  Individual cortical neurons respond to stimuli only in a restricted region of the visual field known as the receptive field  The receptive fields of different neurons partially overlap such that they cover the entire visual field 
CNNs use relatively little pre processing compared to other image classification algorithms  This means that the network learns to optimize the filters  or kernels  through automated learning  whereas in traditional algorithms these filters are hand engineered  This simplifies and automates the process  enhancing efficiency and scalability overcoming human intervention bottlenecks 


Architecture edit 
Comparison of the LeNet and AlexNet convolution  pooling and dense layers
Main article  Layer  deep learning 
A convolutional neural network consists of an input layer  hidden layers and an output layer  In a convolutional neural network  the hidden layers include one or more layers that perform convolutions  Typically this includes a layer that performs a dot product of the convolution kernel with the layer s input matrix  This product is usually the Frobenius inner product  and its activation function is commonly ReLU  As the convolution kernel slides along the input matrix for the layer  the convolution operation generates a feature map  which in turn contributes to the input of the next layer  This is followed by other layers such as pooling layers  fully connected layers  and normalization layers 
Here it should be noted how close a convolutional neural network is to a matched filter             

Convolutional layers edit 
In a CNN  the input is a tensor with shape 
 number of inputs     input height     input width     input channels 
After passing through a convolutional layer  the image becomes abstracted to a feature map  also called an activation map  with shape 
 number of inputs     feature map height     feature map width     feature map channels  
Convolutional layers convolve the input and pass its result to the next layer  This is similar to the response of a neuron in the visual cortex to a specific stimulus              Each convolutional neuron processes data only for its receptive field  

 D convolutional neural network feed forward example
Although fully connected feedforward neural networks can be used to learn features and classify data  this architecture is generally impractical for larger inputs  e g   high resolution images   which would require massive numbers of neurons because each pixel is a relevant input feature  A fully connected layer for an image of size           has        weights for each neuron in the second layer  Convolution reduces the number of free parameters  allowing the network to be deeper             For example  using a       tiling region  each with the same shared weights  requires only    neurons  Using shared weights means there are many fewer parameters  which helps avoid the vanishing gradients and exploding gradients problems seen during backpropagation in earlier neural networks                       
To speed processing  standard convolutional layers can be replaced by depthwise separable convolutional layers              which are based on a depthwise convolution followed by a pointwise convolution  The depthwise convolution is a spatial convolution applied independently over each channel of the input tensor  while the pointwise convolution is a standard convolution restricted to the use of 
  
    
      
         
          xd  
         
      
    
      displaystyle   times   
  
 kernels 

Pooling layers edit 
Convolutional networks may include local and or global pooling layers along with traditional convolutional layers  Pooling layers reduce the dimensions of data by combining the outputs of neuron clusters at one layer into a single neuron in the next layer  Local pooling combines small clusters  tiling sizes such as       are commonly used  Global pooling acts on all the neurons of the feature map                          There are two common types of pooling in popular use  max and average  Max pooling uses the maximum value of each local cluster of neurons in the feature map                          while average pooling takes the average value 

Fully connected layers edit 
Fully connected layers connect every neuron in one layer to every neuron in another layer  It is the same as a traditional multilayer perceptron neural network  MLP   The flattened matrix goes through a fully connected layer to classify the images 

Receptive field edit 
In neural networks  each neuron receives input from some number of locations in the previous layer  In a convolutional layer  each neuron receives input from only a restricted area of the previous layer called the neuron s receptive field  Typically the area is a square  e g    by   neurons   Whereas  in a fully connected layer  the receptive field is the entire previous layer  Thus  in each convolutional layer  each neuron takes input from a larger area in the input than previous layers  This is due to applying the convolution over and over  which takes the value of a pixel into account  as well as its surrounding pixels  When using dilated layers  the number of pixels in the receptive field remains constant  but the field is more sparsely populated as its dimensions grow when combining the effect of several layers 
To manipulate the receptive field size as desired  there are some alternatives to the standard convolutional layer  For example  atrous or dilated convolution                         expands the receptive field size without increasing the number of parameters by interleaving visible and blind regions  Moreover  a single dilated convolutional layer can comprise filters with multiple dilation ratios              thus having a variable receptive field size 

Weights edit 
Each neuron in a neural network computes an output value by applying a specific function to the input values received from the receptive field in the previous layer  The function that is applied to the input values is determined by a vector of weights and a bias  typically real numbers   Learning consists of iteratively adjusting these biases and weights 
The vectors of weights and biases are called filters and represent particular features of the input  e g   a particular shape   A distinguishing feature of CNNs is that many neurons can share the same filter  This reduces the memory footprint because a single bias and a single vector of weights are used across all receptive fields that share that filter  as opposed to each receptive field having its own bias and vector weighting             

Deconvolutional edit 

A deconvolutional neural network is essentially the reverse of a CNN  It consists of deconvolutional layers and unpooling layers              
A deconvolutional layer is the transpose of a convolutional layer  Specifically  a convolutional layer can be written as a multiplication with a matrix  and a deconvolutional layer is multiplication with the transpose of that matrix             
An unpooling layer expands the layer  The max unpooling layer is the simplest  as it simply copies each entry multiple times  For example  a   by   max unpooling layer is 
  
    
      
         
        x
         
          x  a  
        
          
             
            
              
                
                  x
                
                
                  x
                
              
              
                
                  x
                
                
                  x
                
              
            
             
          
        
      
    
      displaystyle  x  mapsto   begin bmatrix x amp x  x amp x end bmatrix   
  
 
Deconvolution layers are used in image generators  By default  it creates periodic checkerboard artifact  which can be fixed by upscale then convolve             

History edit 
CNN are often compared to the way the brain achieves vision processing in living organisms             

Receptive fields in the visual cortex edit 
Work by Hubel and Wiesel in the     s and     s showed that cat visual cortices contain neurons that individually respond to small regions of the visual field  Provided the eyes are not moving  the region of visual space within which visual stimuli affect the firing of a single neuron is known as its receptive field              Neighboring cells have similar and overlapping receptive fields  Receptive field size and location varies systematically across the cortex to form a complete map of visual space      citation needed      The cortex in each hemisphere represents the contralateral visual field      citation needed     
Their      paper identified two basic visual cell types in the brain             

simple cells  whose output is maximized by straight edges having particular orientations within their receptive field
complex cells  which have larger receptive fields  whose output is insensitive to the exact position of the edges in the field 
Hubel and Wiesel also proposed a cascading model of these two types of cells for use in pattern recognition tasks                         

Fukushima s analog threshold elements in a vision model edit 
In       Kunihiko Fukushima introduced a multilayer visual feature detection network  inspired by the above mentioned work of Hubel and Wiesel  in which  All the elements in one layer have the same set of interconnecting coefficients  the arrangement of the elements and their interconnections are all homogeneous over a given layer    This is the essential core of a convolutional network  but the weights were not trained   In the same paper  Fukushima also introduced the ReLU  rectified linear unit  activation function                          

Neocognitron  origin of the trainable CNN architecture edit 
The  neocognitron              was introduced by Fukushima in                                            The neocognitron introduced the two basic types of layers 

 S layer   a shared weights receptive field layer  later known as a convolutional layer  which contains units whose receptive fields cover a patch of the previous layer  A shared weights receptive field group  a  plane  in neocognitron terminology  is often called a filter  and a layer typically has several such filters 
 C layer   a downsampling layer that contain units whose receptive fields cover patches of previous convolutional layers  Such a unit typically computes a weighted average of the activations of the units in its patch  and applies inhibition  divisive normalization  pooled from a somewhat larger patch and across different filters in a layer  and applies a saturating activation function  The patch weights are nonnegative and are not trainable in the original neocognitron  The downsampling and competitive inhibition help to classify features and objects in visual scenes even when the objects are shifted 
Several supervised and unsupervised learning algorithms have been proposed over the decades to train the weights of a neocognitron              Today  however  the CNN architecture is usually trained through backpropagation 
Fukushima s ReLU activation function was not used in his neocognitron since all the weights were nonnegative  lateral inhibition was used instead  The rectifier has become a very popular activation function for CNNs and deep neural networks in general             

Convolution in time edit 
The term  convolution  first appears in neural networks in a paper by Toshiteru Homma  Les Atlas  and Robert Marks II at the first Conference on Neural Information Processing Systems in       Their paper replaced multiplication with convolution in time  inherently providing shift invariance  motivated by and connecting more directly to the signal processing concept of a filter  and demonstrated it on a speech recognition task             They also pointed out that as a data trainable system  convolution is essentially equivalent to correlation since reversal of the weights does not affect the final learned function   For convenience  we denote   as correlation instead of convolution  Note that convolving a t  with b t  is equivalent to correlating a  t  with b t                 Modern CNN implementations typically do correlation and call it convolution  for convenience  as they did here 

Time delay neural networks edit 
The time delay neural network  TDNN  was introduced in      by Alex Waibel et al  for phoneme recognition and was an early convolutional network exhibiting shift invariance              A TDNN is a   D convolutional neural net where the convolution is performed along the time axis of the data  It is the first CNN utilizing weight sharing in combination with a training by gradient descent  using backpropagation              Thus  while also using a pyramidal structure as in the neocognitron  it performed a global optimization of the weights instead of a local one             
TDNNs are convolutional networks that share weights along the temporal dimension              They allow speech signals to be processed time invariantly  In      Hampshire and Waibel introduced a variant that performs a two dimensional convolution              Since these TDNNs operated on spectrograms  the resulting phoneme recognition system was invariant to both time and frequency shifts  as with images processed by a neocognitron 
TDNNs improved the performance of far distance speech recognition             

Image recognition with CNNs trained by gradient descent edit 
Denker et al         designed a   D CNN system to recognize hand written ZIP Code numbers              However  the lack of an efficient training method to determine the kernel coefficients of the involved convolutions meant that all the coefficients had to be laboriously hand designed             
Following the advances in the training of   D CNNs by Waibel et al          Yann LeCun et al                     used back propagation to learn the convolution kernel coefficients directly from images of hand written numbers  Learning was thus fully automatic  performed better than manual coefficient design  and was suited to a broader range of image recognition problems and image types  
Wei Zhang et al                                 used back propagation to train the convolution kernels of a CNN for alphabets recognition  The model was called shift invariant pattern recognition neural network before the name CNN was coined later in the early     s  Wei Zhang et al  also applied the same CNN without the last fully connected layer for medical image object segmentation                    and breast cancer detection in mammograms                    
This approach became a foundation of modern computer vision 

Max pooling edit 
In      Yamaguchi et al  introduced the concept of max pooling  a fixed filtering operation that calculates and propagates the maximum value of a given region  They did so by combining TDNNs with max pooling to realize a speaker independent isolated word recognition system              In their system they used several TDNNs per word  one for each syllable  The results of each TDNN over the input signal were combined using max pooling and the outputs of the pooling layers were then passed on to networks performing the actual word classification 
In a variant of the neocognitron called the cresceptron  instead of using Fukushima s spatial averaging with inhibition and saturation  J  Weng et al  in      used max pooling  where a downsampling unit computes the maximum of the activations of the units in its patch              introducing this method into the vision field  
Max pooling is often used in modern CNNs             

LeNet   edit 
Main article  LeNet
LeNet    a pioneering   level convolutional network by LeCun et al  in                   classifies hand written numbers on checks  British English  cheques  digitized in   x   pixel images  The ability to process higher resolution images requires larger and more layers of convolutional neural networks  so this technique is constrained by the availability of computing resources 
It was superior than other commercial courtesy amount reading systems  as of        The system was integrated in NCR s check reading systems  and fielded in several American banks since June       reading millions of checks per day             

Shift invariant neural network edit 
A shift invariant neural network was proposed by Wei Zhang et al  for image character recognition in                               It is a modified Neocognitron by keeping only the convolutional interconnections between the image feature layers and the last fully connected layer  The model was trained with back propagation  The training algorithm was further improved in                  to improve its generalization ability  The model architecture was modified by removing the last fully connected layer and applied for medical image segmentation                    and automatic detection of breast cancer in mammograms                    
A different convolution based design was proposed in                  for application to decomposition of one dimensional electromyography convolved signals via de convolution  This design was modified in      to other de convolution based designs                         

GPU implementations edit 
Although CNNs were invented in the     s  their breakthrough in the     s required fast implementations on graphics processing units  GPUs  
In       it was shown by K  S  Oh and K  Jung that standard neural networks can be greatly accelerated on GPUs  Their implementation was    times faster than an equivalent implementation on CPU              In       another paper also emphasised the value of GPGPU for machine learning             
The first GPU implementation of a CNN was described in      by K  Chellapilla et al  Their implementation was   times faster than an equivalent implementation on CPU              In the same period  GPUs were also used for unsupervised training of deep belief networks                                                 
In       Dan Ciresan et al  at IDSIA trained deep feedforward networks on GPUs              In       they extended this to CNNs  accelerating by    compared to training CPU              In       the network won an image recognition contest where they achieved superhuman performance for the first time              Then they won more competitions and achieved state of the art on several benchmarks                                     
Subsequently  AlexNet  a similar GPU based CNN by Alex Krizhevsky et al  won the ImageNet Large Scale Visual Recognition Challenge                   It was an early catalytic event for the AI boom 
Compared to the training of CNNs using GPUs  not much attention was given to CPU   Viebke et al       parallelizes CNN by thread  and SIMD level parallelism that is available on the Intel Xeon Phi                         

Distinguishing features edit 
In the past  traditional multilayer perceptron  MLP  models were used for image recognition      example needed      However  the full connectivity between nodes caused the curse of dimensionality  and was computationally intractable with higher resolution images  A           pixel image with RGB color channels has   million weights per fully connected neuron  which is too high to feasibly process efficiently at scale 

CNN layers arranged in   dimensions
For example  in CIFAR     images are only of size             wide     high    color channels   so a single fully connected neuron in the first hidden layer of a regular neural network would have                 weights  A         image  however  would lead to neurons that have                     weights 
Also  such network architecture does not take into account the spatial structure of data  treating input pixels which are far apart in the same way as pixels that are close together  This ignores locality of reference in data with a grid topology  such as images   both computationally and semantically  Thus  full connectivity of neurons is wasteful for purposes such as image recognition that are dominated by spatially local input patterns 
Convolutional neural networks are variants of multilayer perceptrons  designed to emulate the behavior of a visual cortex  These models mitigate the challenges posed by the MLP architecture by exploiting the strong spatially local correlation present in natural images  As opposed to MLPs  CNNs have the following distinguishing features 

 D volumes of neurons  The layers of a CNN have neurons arranged in   dimensions  width  height and depth              Where each neuron inside a convolutional layer is connected to only a small region of the layer before it  called a receptive field  Distinct types of layers  both locally and completely connected  are stacked to form a CNN architecture 
Local connectivity  following the concept of receptive fields  CNNs exploit spatial locality by enforcing a local connectivity pattern between neurons of adjacent layers  The architecture thus ensures that the learned  filters  produce the strongest response to a spatially local input pattern  Stacking many such layers leads to nonlinear filters that become increasingly global  i e  responsive to a larger region of pixel space  so that the network first creates representations of small parts of the input  then from them assembles representations of larger areas 
Shared weights  In CNNs  each filter is replicated across the entire visual field  These replicated units share the same parameterization  weight vector and bias  and form a feature map  This means that all the neurons in a given convolutional layer respond to the same feature within their specific response field  Replicating units in this way allows for the resulting activation map to be equivariant under shifts of the locations of input features in the visual field  i e  they grant translational equivariance given that the layer has a stride of one             
Pooling  In a CNN s pooling layers  feature maps are divided into rectangular sub regions  and the features in each rectangle are independently down sampled to a single value  commonly by taking their average or maximum value  In addition to reducing the sizes of feature maps  the pooling operation grants a degree of local translational invariance to the features contained therein  allowing the CNN to be more robust to variations in their positions             
Together  these properties allow CNNs to achieve better generalization on vision problems  Weight sharing dramatically reduces the number of free parameters learned  thus lowering the memory requirements for running the network and allowing the training of larger  more powerful networks 

Building blocks edit 
A CNN architecture is formed by a stack of distinct layers that transform the input volume into an output volume  e g  holding the class scores  through a differentiable function  A few distinct types of layers are commonly used  These are further discussed below Neurons of a convolutional layer  blue   connected to their receptive field  red 
Convolutional layer edit 
A worked example of performing a convolution  The convolution has stride    zero padding  with kernel size   by    The convolution kernel is a discrete Laplacian operator 
The convolutional layer is the core building block of a CNN  The layer s parameters consist of a set of learnable filters  or kernels   which have a small receptive field  but extend through the full depth of the input volume  During the forward pass  each filter is convolved across the width and height of the input volume  computing the dot product between the filter entries and the input  producing a   dimensional activation map of that filter  As a result  the network learns filters that activate when it detects some specific type of feature at some spatial position in the input                  nb       
Stacking the activation maps for all filters along the depth dimension forms the full output volume of the convolution layer  Every entry in the output volume can thus also be interpreted as an output of a neuron that looks at a small region in the input  Each entry in an activation map use the same set of parameters that define the filter 
Self supervised learning has been adapted for use in convolutional layers by using sparse patches with a high mask ratio and a global response normalization layer      citation needed     

Local connectivity edit 
Typical CNN architecture
When dealing with high dimensional inputs such as images  it is impractical to connect neurons to all neurons in the previous volume because such a network architecture does not take the spatial structure of the data into account  Convolutional networks exploit spatially local correlation by enforcing a sparse local connectivity pattern between neurons of adjacent layers  each neuron is connected to only a small region of the input volume 
The extent of this connectivity is a hyperparameter called the receptive field of the neuron  The connections are local in space  along width and height   but always extend along the entire depth of the input volume  Such an architecture ensures that the learned filters produce the strongest response to a spatially local input pattern             

Spatial arrangement edit 
Three hyperparameters control the size of the output volume of the convolutional layer  the depth  stride  and padding size 

The depth of the output volume controls the number of neurons in a layer that connect to the same region of the input volume  These neurons learn to activate for different features in the input  For example  if the first convolutional layer takes the raw image as input  then different neurons along the depth dimension may activate in the presence of various oriented edges  or blobs of color 
Stride controls how depth columns around the width and height are allocated  If the stride is    then we move the filters one pixel at a time  This leads to heavily overlapping receptive fields between the columns  and to large output volumes  For any integer 
  
    
      
        S
         gt 
         
         
      
    
      textstyle S gt    
  
 a stride S means that the filter is translated S units at a time per output  In practice  
  
    
      
        S
          x     
         
      
    
      textstyle S geq   
  
 is rare  A greater stride means smaller overlap of receptive fields and smaller spatial dimensions of the output volume             
Sometimes  it is convenient to pad the input with zeros  or other values  such as the average of the region  on the border of the input volume  The size of this padding is a third hyperparameter  Padding provides control of the output volume s spatial size  In particular  sometimes it is desirable to exactly preserve the spatial size of the input volume  this is commonly referred to as  same  padding 
Three example padding conditions  Replication condition means that the pixel outside is padded with the closest pixel inside  The reflection padding is where the pixel outside is padded with the pixel inside  reflected across the boundary of the image  The circular padding is where the pixel outside wraps around to the other side of the image 
The spatial size of the output volume is a function of the input volume size 
  
    
      
        W
      
    
      displaystyle W 
  
  the kernel field size 
  
    
      
        K
      
    
      displaystyle K 
  
 of the convolutional layer neurons  the stride 
  
    
      
        S
      
    
      displaystyle S 
  
  and the amount of zero padding 
  
    
      
        P
      
    
      displaystyle P 
  
 on the border  The number of neurons that  fit  in a given volume is then 


  
    
      
        
          
            
              W
                x     
              K
               
               
              P
            
            S
          
        
         
          
      
    
      displaystyle   frac  W K  P  S      
  

If this number is not an integer  then the strides are incorrect and the neurons cannot be tiled to fit across the input volume in a symmetric way  In general  setting zero padding to be 
  
    
      
        P
         
         
        K
          x     
         
         
        
           
        
         
      
    
      textstyle P  K      
  
 when the stride is 
  
    
      
        S
         
         
      
    
      displaystyle S   
  
 ensures that the input volume and output volume will have the same size spatially  However  it is not always completely necessary to use all of the neurons of the previous layer  For example  a neural network designer may decide to use just a portion of padding 

Parameter sharing edit 
A parameter sharing scheme is used in convolutional layers to control the number of free parameters  It relies on the assumption that if a patch feature is useful to compute at some spatial position  then it should also be useful to compute at other positions  Denoting a single   dimensional slice of depth as a depth slice  the neurons in each depth slice are constrained to use the same weights and bias 
Since all neurons in a single depth slice share the same parameters  the forward pass in each depth slice of the convolutional layer can be computed as a convolution of the neuron s weights with the input volume      nb        Therefore  it is common to refer to the sets of weights as a filter  or a kernel   which is convolved with the input  The result of this convolution is an activation map  and the set of activation maps for each different filter are stacked together along the depth dimension to produce the output volume  Parameter sharing contributes to the translation invariance of the CNN architecture             
Sometimes  the parameter sharing assumption may not make sense  This is especially the case when the input images to a CNN have some specific centered structure  for which we expect completely different features to be learned on different spatial locations  One practical example is when the inputs are faces that have been centered in the image  we might expect different eye specific or hair specific features to be learned in different parts of the image  In that case it is common to relax the parameter sharing scheme  and instead simply call the layer a  locally connected layer  

Pooling layer edit 
Main article  Pooling layer
Worked example of  x  maxpooling with stride   
Max pooling with a  x  filter and stride    
Another important concept of CNNs is pooling  which is used as a form of non linear down sampling  Pooling provides downsampling because it reduces the spatial dimensions  height and width  of the input feature maps while retaining the most important information  There are several non linear functions to implement pooling  where max pooling and average pooling are the most common  Pooling aggregates information from small regions of the input creating partitions of the input feature map  typically using a fixed size window  like  x   and applying a stride  often    to move the window across the input              Note that without using a stride greater than    pooling would not perform downsampling  as it would simply move the pooling window across the input one step at a time  without reducing the size of the feature map  In other words  the stride is what actually causes the downsampling by determining how much the pooling window moves over the input 
Intuitively  the exact location of a feature is less important than its rough location relative to other features  This is the idea behind the use of pooling in convolutional neural networks  The pooling layer serves to progressively reduce the spatial size of the representation  to reduce the number of parameters  memory footprint and amount of computation in the network  and hence to also control overfitting  This is known as down sampling  It is common to periodically insert a pooling layer between successive convolutional layers  each one typically followed by an activation function  such as a ReLU layer  in a CNN architecture                                        While pooling layers contribute to local translation invariance  they do not provide global translation invariance in a CNN  unless a form of global pooling is used                          The pooling layer commonly operates independently on every depth  or slice  of the input and resizes it spatially  A very common form of max pooling is a layer with filters of size      applied with a stride of    which subsamples every depth slice in the input by   along both width and height  discarding     of the activations 
  
    
      
        
          f
          
            X
             
            Y
          
        
         
        S
         
         
        
          max
          
            a
             
            b
             
             
          
          
             
          
        
        
          S
          
             
            X
             
            a
             
             
            Y
             
            b
          
        
         
      
    
      displaystyle f  X Y  S   max   a b       S   X a  Y b   
  

In this case  every max operation is over   numbers  The depth dimension remains unchanged  this is true for other forms of pooling as well  
In addition to max pooling  pooling units can use other functions  such as average pooling or    norm pooling  Average pooling was often used historically but has recently fallen out of favor compared to max pooling  which generally performs better in practice             
Due to the effects of fast spatial reduction of the size of the representation      which       there is a recent trend towards using smaller filters             or discarding pooling layers altogether             

RoI pooling to size  x   In this example region proposal  an input parameter  has size  x  
Channel max pooling edit 
A channel max pooling  CMP  operation layer conducts the MP operation along the channel side among the corresponding positions of the consecutive feature maps for the purpose of redundant information elimination  The CMP makes the significant features gather together within fewer channels  which is important for fine grained image classification that needs more discriminating features  Meanwhile  another advantage of the CMP operation is to make the channel number of feature maps smaller before it connects to the first fully connected  FC  layer  Similar to the MP operation  we denote the input feature maps and output feature maps of a CMP layer as F   R C M N  and C   R c M N   respectively  where C and c are the channel numbers of the input and output feature maps  M and N are the widths and the height of the feature maps  respectively  Note that the CMP operation only changes the channel number of the feature maps  The width and the height of the feature maps are not changed  which is different from the MP operation             
See                          for reviews for pooling methods 

ReLU layer edit 
ReLU is the abbreviation of rectified linear unit  It was proposed by Alston Householder in                   and used in CNN by Kunihiko Fukushima in                   ReLU applies the non saturating activation function 
  
    
      
        f
         
        x
         
         
        max
         
         
         
        x
         
      
    
      textstyle f x   max   x  
  
              It effectively removes negative values from an activation map by setting them to zero              It introduces nonlinearity to the decision function and in the overall network without affecting the receptive fields of the convolution layers 
In       Xavier Glorot  Antoine Bordes and Yoshua Bengio found that ReLU enables better training of deeper networks              compared to widely used activation functions prior to      
Other functions can also be used to increase nonlinearity  for example the saturating hyperbolic tangent 
  
    
      
        f
         
        x
         
         
        tanh
          x     
         
        x
         
      
    
      displaystyle f x   tanh x  
  
  
  
    
      
        f
         
        x
         
         
        
           
        
        tanh
          x     
         
        x
         
        
           
        
      
    
      displaystyle f x    tanh x   
  
  and the sigmoid function 
  
    
      
          x c  
         
        x
         
         
         
         
         
        
          e
          
              x     
            x
          
        
        
           
          
              x     
             
          
        
      
    
      textstyle  sigma  x     e   x        
  
  ReLU is often preferred to other functions because it trains the neural network several times faster without a significant penalty to generalization accuracy             

Fully connected layer edit 
After several convolutional and max pooling layers  the final classification is done via fully connected layers  Neurons in a fully connected layer have connections to all activations in the previous layer  as seen in regular  non convolutional  artificial neural networks  Their activations can thus be computed as an affine transformation  with matrix multiplication followed by a bias offset  vector addition of a learned or fixed bias term  

Loss layer edit 
Main articles  Loss function and Loss functions for classification
The  loss layer   or  loss function   exemplifies how training penalizes the deviation between the predicted output of the network  and the true data labels  during supervised learning   Various loss functions can be used  depending on the specific task 
The Softmax loss function is used for predicting a single class of K mutually exclusive classes      nb        Sigmoid cross entropy loss is used for predicting K independent probability values in 
  
    
      
         
         
         
         
         
      
    
      displaystyle       
  
  Euclidean loss is used for regressing to real valued labels 
  
    
      
         
          x     
          x   e 
         
          x   e 
         
      
    
      displaystyle    infty   infty   
  
 

Hyperparameters edit 
This section needs additional citations for verification  Please help improve this article by adding citations to reliable sources     in this section  Unsourced material may be challenged and removed    June        Learn how and when to remove this message 
Hyperparameters are various settings that are used to control the learning process  CNNs use more hyperparameters than a standard multilayer perceptron  MLP  

Kernel size edit 
The kernel is the number of pixels processed together  It is typically expressed as the kernel s dimensions  e g    x   or  x  

Padding edit 
Padding is the addition of  typically    valued pixels on the borders of an image  This is done so that the border pixels are not undervalued  lost  from the output because they would ordinarily participate in only a single receptive field instance  The padding applied is typically one less than the corresponding kernel dimension  For example  a convolutional layer using  x  kernels would receive a   pixel pad  that is   pixel on each side of the image      citation needed     

Stride edit 
The stride is the number of pixels that the analysis window moves on each iteration  A stride of   means that each kernel is offset by   pixels from its predecessor 

Number of filters edit 
Since feature map size decreases with depth  layers near the input layer tend to have fewer filters while higher layers can have more  To equalize computation at each layer  the product of feature values va with pixel position is kept roughly constant across layers  Preserving more information about the input would require keeping the total number of activations  number of feature maps times number of pixel positions  non decreasing from one layer to the next 
The number of feature maps directly controls the capacity and depends on the number of available examples and task complexity 

Filter size edit 
Common filter sizes found in the literature vary greatly  and are usually chosen based on the data set  Typical filter sizes range from  x  to  x   As two famous examples  AlexNet used  x    x   and   x    Inceptionv  used  x    x   and  x  
The challenge is to find the right level of granularity so as to create abstractions at the proper scale  given a particular data set  and without overfitting 

Pooling type and size edit 
Max pooling is typically used  often with a  x  dimension  This implies that the input is drastically downsampled  reducing processing cost 
Greater pooling reduces the dimension of the signal  and may result in unacceptable information loss  Often  non overlapping pooling windows perform best             

Dilation edit 
Dilation involves ignoring pixels within a kernel  This reduces processing memory potentially without significant signal loss  A dilation of   on a  x  kernel expands the kernel to  x   while still processing    evenly spaced  pixels  Specifically  the processed pixels after the dilation are the cells                                                                where  i j  denotes the cell of the i th row and j th column in the expanded  x  kernel  Accordingly  dilation of   expands the kernel to  x       citation needed     

Translation equivariance and aliasing edit 
It is commonly assumed that CNNs are invariant to shifts of the input  Convolution or pooling layers within a CNN that do not have a stride greater than one are indeed equivariant to translations of the input              However  layers with a stride greater than one ignore the Nyquist Shannon sampling theorem and might lead to aliasing of the input signal             While  in principle  CNNs are capable of implementing anti aliasing filters  it has been observed that this does not happen in practice              and therefore yield models that are not equivariant to translations 
Furthermore  if a CNN makes use of fully connected layers  translation equivariance does not imply translation invariance  as the fully connected layers are not invariant to shifts of the input                          One solution for complete translation invariance is avoiding any down sampling throughout the network and applying global average pooling at the last layer              Additionally  several other partial solutions have been proposed  such as anti aliasing before downsampling operations              spatial transformer networks              data augmentation  subsampling combined with pooling              and capsule neural networks             

Evaluation edit 
The accuracy of the final model is typically estimated on a sub part of the dataset set apart at the start  often called a test set  Alternatively  methods such as k fold cross validation are applied  Other strategies include using conformal prediction                         

Regularization methods edit 
Main article  Regularization  mathematics 
This section needs additional citations for verification  Please help improve this article by adding citations to reliable sources     in this section  Unsourced material may be challenged and removed    June        Learn how and when to remove this message 
Regularization is a process of introducing additional information to solve an ill posed problem or to prevent overfitting  CNNs use various types of regularization 

Empirical edit 
Dropout edit 
Because networks have so many parameters  they are prone to overfitting  One method to reduce overfitting is dropout  introduced in                   At each training stage  individual nodes are either  dropped out  of the net  ignored  with probability 
  
    
      
         
          x     
        p
      
    
      displaystyle   p 
  
 or kept with probability 
  
    
      
        p
      
    
      displaystyle p 
  
  so that a reduced network is left  incoming and outgoing edges to a dropped out node are also removed  Only the reduced network is trained on the data in that stage  The removed nodes are then reinserted into the network with their original weights 
In the training stages  
  
    
      
        p
      
    
      displaystyle p 
  
 is usually      for input nodes  it is typically much higher because information is directly lost when input nodes are ignored 
At testing time after training has finished  we would ideally like to find a sample average of all possible 
  
    
      
        
           
          
            n
          
        
      
    
      displaystyle    n  
  
 dropped out networks  unfortunately this is unfeasible for large values of 
  
    
      
        n
      
    
      displaystyle n 
  
  However  we can find an approximation by using the full network with each node s output weighted by a factor of 
  
    
      
        p
      
    
      displaystyle p 
  
  so the expected value of the output of any node is the same as in the training stages  This is the biggest contribution of the dropout method  although it effectively generates 
  
    
      
        
           
          
            n
          
        
      
    
      displaystyle    n  
  
 neural nets  and as such allows for model combination  at test time only a single network needs to be tested 
By avoiding training all nodes on all training data  dropout decreases overfitting  The method also significantly improves training speed  This makes the model combination practical  even for deep neural networks  The technique seems to reduce node interactions  leading them to learn more robust features     clarification needed      that better generalize to new data 

DropConnect edit 
DropConnect is the generalization of dropout in which each connection  rather than each output unit  can be dropped with probability 
  
    
      
         
          x     
        p
      
    
      displaystyle   p 
  
  Each unit thus receives input from a random subset of units in the previous layer             
DropConnect is similar to dropout as it introduces dynamic sparsity within the model  but differs in that the sparsity is on the weights  rather than the output vectors of a layer  In other words  the fully connected layer with DropConnect becomes a sparsely connected layer in which the connections are chosen at random during the training stage 

Stochastic pooling edit 
A major drawback to dropout is that it does not have the same benefits for convolutional layers  where the neurons are not fully connected 
Even before dropout  in      a technique called stochastic pooling              the conventional deterministic pooling operations were replaced with a stochastic procedure  where the activation within each pooling region is picked randomly according to a multinomial distribution  given by the activities within the pooling region  This approach is free of hyperparameters and can be combined with other regularization approaches  such as dropout and data augmentation 
An alternate view of stochastic pooling is that it is equivalent to standard max pooling but with many copies of an input image  each having small local deformations  This is similar to explicit elastic deformations of the input images              which delivers excellent performance on the MNIST data set              Using stochastic pooling in a multilayer model gives an exponential number of deformations since the selections in higher layers are independent of those below 

Artificial data edit 
Main article  Data augmentation
Because the degree of model overfitting is determined by both its power and the amount of training it receives  providing a convolutional network with more training examples can reduce overfitting  Because there is often not enough available data to train  especially considering that some part should be spared for later testing  two approaches are to either generate new data from scratch  if possible  or perturb existing data to create new ones  The latter one is used since mid     s              For example  input images can be cropped  rotated  or rescaled to create new examples with the same labels as the original training set              

Explicit edit 
Early stopping edit 
Main article  Early stopping
One of the simplest methods to prevent overfitting of a network is to simply stop the training before overfitting has had a chance to occur  It comes with the disadvantage that the learning process is halted 

Number of parameters edit 
Another simple way to prevent overfitting is to limit the number of parameters  typically by limiting the number of hidden units in each layer or limiting network depth  For convolutional networks  the filter size also affects the number of parameters  Limiting the number of parameters restricts the predictive power of the network directly  reducing the complexity of the function that it can perform on the data  and thus limits the amount of overfitting  This is equivalent to a  zero norm  

Weight decay edit 
A simple form of added regularizer is weight decay  which simply adds an additional error  proportional to the sum of weights  L  norm  or squared magnitude  L  norm  of the weight vector  to the error at each node  The level of acceptable model complexity can be reduced by increasing the proportionality constant  alpha  hyperparameter   thus increasing the penalty for large weight vectors 
L  regularization is the most common form of regularization  It can be implemented by penalizing the squared magnitude of all parameters directly in the objective  The L  regularization has the intuitive interpretation of heavily penalizing peaky weight vectors and preferring diffuse weight vectors  Due to multiplicative interactions between weights and inputs this has the useful property of encouraging the network to use all of its inputs a little rather than some of its inputs a lot 
L  regularization is also common  It makes the weight vectors sparse during optimization  In other words  neurons with L  regularization end up using only a sparse subset of their most important inputs and become nearly invariant to the noisy inputs  L  with L  regularization can be combined  this is called elastic net regularization 

Max norm constraints edit 
Another form of regularization is to enforce an absolute upper bound on the magnitude of the weight vector for every neuron and use projected gradient descent to enforce the constraint  In practice  this corresponds to performing the parameter update as normal  and then enforcing the constraint by clamping the weight vector 
  
    
      
        
          
            
              w
                x     
            
          
        
      
    
      displaystyle   vec  w   
  
 of every neuron to satisfy 
  
    
      
          x     
        
          
            
              w
                x     
            
          
        
        
            x     
          
             
          
        
         lt 
        c
      
    
      displaystyle     vec  w         lt c 
  
  Typical values of 
  
    
      
        c
      
    
      displaystyle c 
  
 are order of      Some papers report improvements              when using this form of regularization 

Hierarchical coordinate frames edit 
Pooling loses the precise spatial relationships between high level parts  such as nose and mouth in a face image   These relationships are needed for identity recognition  Overlapping the pools so that each feature occurs in multiple pools  helps retain the information  Translation alone cannot extrapolate the understanding of geometric relationships to a radically new viewpoint  such as a different orientation or scale  On the other hand  people are very good at extrapolating  after seeing a new shape once they can recognize it from a different viewpoint              
An earlier common way to deal with this problem is to train the network on transformed data in different orientations  scales  lighting  etc  so that the network can cope with these variations  This is computationally intensive for large data sets  The alternative is to use a hierarchy of coordinate frames and use a group of neurons to represent a conjunction of the shape of the feature and its pose relative to the retina  The pose relative to the retina is the relationship between the coordinate frame of the retina and the intrinsic features  coordinate frame              
Thus  one way to represent something is to embed the coordinate frame within it  This allows large features to be recognized by using the consistency of the poses of their parts  e g  nose and mouth poses make a consistent prediction of the pose of the whole face   This approach ensures that the higher level entity  e g  face  is present when the lower level  e g  nose and mouth  agree on its prediction of the pose  The vectors of neuronal activity that represent pose   pose vectors   allow spatial transformations modeled as linear operations that make it easier for the network to learn the hierarchy of visual entities and generalize across viewpoints  This is similar to the way the human visual system imposes coordinate frames in order to represent shapes              

Applications edit 
Image recognition edit 
CNNs are often used in image recognition systems  In       an error rate of       on the MNIST database was reported              Another paper on using CNN for image classification reported that the learning process was  surprisingly fast   in the same paper  the best published results as of      were achieved in the MNIST database and the NORB database              Subsequently  a similar CNN called AlexNet              won the ImageNet Large Scale Visual Recognition Challenge      
When applied to facial recognition  CNNs achieved a large decrease in error rate               Another paper reported a       recognition rate on        still images of more than    subjects               CNNs were used to assess video quality in an objective way after manual training  the resulting system had a very low root mean square error              
The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object classification and detection  with millions of images and hundreds of object classes  In the ILSVRC                    a large scale visual recognition challenge  almost every highly ranked team used CNN as their basic framework  The winner GoogLeNet               the foundation of DeepDream  increased the mean average precision of object detection to           and reduced classification error to          the best result to date  Its network applied more than    layers  That performance of convolutional neural networks on the ImageNet tests was close to that of humans               The best algorithms still struggle with objects that are small or thin  such as a small ant on a stem of a flower or a person holding a quill in their hand  They also have trouble with images that have been distorted with filters  an increasingly common phenomenon with modern digital cameras  By contrast  those kinds of images rarely trouble humans  Humans  however  tend to have trouble with other issues  For example  they are not good at classifying objects into fine grained categories such as the particular breed of dog or species of bird  whereas convolutional neural networks handle this      citation needed     
In       a many layered CNN demonstrated the ability to spot faces from a wide range of angles  including upside down  even when partially occluded  with competitive performance  The network was trained on a database of         images that included faces at various angles and orientations and a further    million images without faces  They used batches of     images over        iterations              

Video analysis edit 
Compared to image data domains  there is relatively little work on applying CNNs to video classification  Video is more complex than images since it has another  temporal  dimension  However  some extensions of CNNs into the video domain have been explored  One approach is to treat space and time as equivalent dimensions of the input and perform convolutions in both time and space                            Another way is to fuse the features of two convolutional neural networks  one for the spatial and one for the temporal stream                                         Long short term memory  LSTM  recurrent units are typically incorporated after the CNN to account for inter frame or inter clip dependencies                            Unsupervised learning schemes for training spatio temporal features have been introduced  based on Convolutional Gated Restricted Boltzmann Machines              and Independent Subspace Analysis               Its application can be seen in text to video model      citation needed     

Natural language processing edit 
CNNs have also been explored for natural language processing  CNN models are effective for various NLP problems and achieved excellent results in semantic parsing               search query retrieval               sentence modeling               classification               prediction              and other traditional NLP tasks              
Compared to traditional language processing methods such as recurrent neural networks  CNNs can represent different contextual realities of language that do not rely on a series sequence assumption  while RNNs are better suitable when classical time series modeling is required                                                     

Anomaly detection edit 
A CNN with   D convolutions was used on time series in the frequency domain  spectral residual  by an unsupervised model to detect anomalies in the time domain              

Drug discovery edit 
CNNs have been used in drug discovery  Predicting the interaction between molecules and biological proteins can identify potential treatments  In       Atomwise introduced AtomNet  the first deep learning neural network for structure based drug design               The system trains directly on   dimensional representations of chemical interactions  Similar to how image recognition networks learn to compose smaller  spatially proximate features into larger  complex structures               AtomNet discovers chemical features  such as aromaticity  sp  carbons  and hydrogen bonding  Subsequently  AtomNet was used to predict novel candidate biomolecules for multiple disease targets  most notably treatments for the Ebola virus              and multiple sclerosis              

Checkers game edit 
CNNs have been used in the game of checkers  From      to       Fogel and Chellapilla published papers showing how a convolutional neural network could learn to play checkers using co evolution  The learning process did not use prior human professional games  but rather focused on a minimal set of information contained in the checkerboard  the location and type of pieces  and the difference in number of pieces between the two sides  Ultimately  the program  Blondie    was tested on     games against players and ranked in the highest                                 It also earned a win against the program Chinook at its  expert  level of play              

Go edit 
CNNs have been used in computer Go  In December       Clark and Storkey published a paper showing that a CNN trained by supervised learning from a database of human professional games could outperform GNU Go and win some games against Monte Carlo tree search Fuego     in a fraction of the time it took Fuego to play               Later it was announced that a large    layer convolutional neural network had correctly predicted the professional move in     of positions  equalling the accuracy of a   dan human player  When the trained convolutional network was used directly to play games of Go  without any search  it beat the traditional search program GNU Go in     of games  and matched the performance of the Monte Carlo tree search program Fuego simulating ten thousand playouts  about a million positions  per move              
A couple of CNNs for choosing moves to try   policy network   and evaluating positions   value network   driving MCTS were used by AlphaGo  the first to beat the best human player at the time              

Time series forecasting edit 
Recurrent neural networks are generally considered the best neural network architectures for time series forecasting  and sequence modeling in general   but recent studies show that convolutional networks can perform comparably or even better                           Dilated convolutions              might enable one dimensional convolutional neural networks to effectively learn time series dependences               Convolutions can be implemented more efficiently than RNN based solutions  and they do not suffer from vanishing  or exploding  gradients               Convolutional networks can provide an improved forecasting performance when there are multiple similar time series to learn from               CNNs can also be applied to further tasks in time series analysis  e g   time series classification              or quantile forecasting               

Cultural heritage and  D datasets edit 
As archaeological findings such as clay tablets with cuneiform writing are increasingly acquired using  D scanners  benchmark datasets are becoming available  including HeiCuBeDa              providing almost      normalized   D and   D datasets prepared with the GigaMesh Software Framework               So curvature based measures are used in conjunction with geometric neural networks  GNNs   e g  for period classification of those clay tablets being among the oldest documents of human history                           

Fine tuning edit 
For many applications  training data is not very available  Convolutional neural networks usually require a large amount of training data in order to avoid overfitting  A common technique is to train the network on a larger data set from a related domain  Once the network parameters have converged an additional training step is performed using the in domain data to fine tune the network weights  this is known as transfer learning  Furthermore  this technique allows convolutional network architectures to successfully be applied to problems with tiny training sets              

Human interpretable explanations edit 
End to end training and prediction are common practice in computer vision  However  human interpretable explanations are required for critical systems such as a self driving cars               With recent advances in visual salience  spatial attention  and temporal attention  the most critical spatial regions temporal instants could be visualized to justify the CNN predictions                           

Related architectures edit 
Deep Q networks edit 
A deep Q network  DQN  is a type of deep learning model that combines a deep neural network with Q learning  a form of reinforcement learning  Unlike earlier reinforcement learning agents  DQNs that utilize CNNs can learn directly from high dimensional sensory inputs via reinforcement learning              
Preliminary results were presented in       with an accompanying paper in February                    The research described an application to Atari      gaming  Other deep reinforcement learning models preceded it              

Deep belief networks edit 
Main article  Deep belief network
Convolutional deep belief networks  CDBN  have structure very similar to convolutional neural networks and are trained similarly to deep belief networks  Therefore  they exploit the  D structure of images  like CNNs do  and make use of pre training like deep belief networks  They provide a generic structure that can be used in many image and signal processing tasks  Benchmark results on standard image datasets like CIFAR              have been obtained using CDBNs              Neural abstraction pyramid
Neural abstraction pyramid edit 
The feed forward architecture of convolutional neural networks was extended in the neural abstraction pyramid              by lateral and feedback connections  The resulting recurrent convolutional network allows for the flexible incorporation of contextual information to iteratively resolve local ambiguities  In contrast to previous models  image like outputs at the highest resolution were generated  e g   for semantic segmentation  image reconstruction  and object localization tasks 

Notable libraries edit 
Caffe  A library for convolutional neural networks  Created by the Berkeley Vision and Learning Center  BVLC   It supports both CPU and GPU  Developed in C    and has Python and MATLAB wrappers 
Deeplearning j  Deep learning in Java and Scala on multi GPU enabled Spark  A general purpose deep learning library for the JVM production stack running on a C   scientific computing engine  Allows the creation of custom layers  Integrates with Hadoop and Kafka 
Dlib  A toolkit for making real world machine learning and data analysis applications in C   
Microsoft Cognitive Toolkit  A deep learning toolkit written by Microsoft with several unique features enhancing scalability over multiple nodes  It supports full fledged interfaces for training in C   and Python and with additional support for model inference in C  and Java 
TensorFlow  Apache     licensed Theano like library with support for CPU  GPU  Google s proprietary tensor processing unit  TPU                and mobile devices 
Theano  The reference deep learning library for Python with an API largely compatible with the popular NumPy library  Allows user to write symbolic mathematical expressions  then automatically generates their derivatives  saving the user from having to code gradients or backpropagation  These symbolic expressions are automatically compiled to CUDA code for a fast  on the GPU implementation 
Torch  A scientific computing framework with wide support for machine learning algorithms  written in C and Lua 
See also edit 
Attention  machine learning 
Convolution
Deep learning
Natural language processing
Neocognitron
Scale invariant feature transform
Time delay neural network
Vision processing unit
Notes edit 


  When applied to other types of data than image data  such as sound data   spatial position  may variously correspond to different points in the time domain  frequency domain  or other mathematical spaces 

  hence the name  convolutional layer 

  So called categorical data 


References edit 


  LeCun  Yann  Bengio  Yoshua  Hinton  Geoffrey                Deep learning   Nature                       Bibcode     Natur         L  doi         nature       ISSN                 PMID               

  LeCun  Y   Boser  B   Denker  J  S   Henderson  D   Howard  R  E   Hubbard  W   Jackel  L  D   December         Backpropagation Applied to Handwritten Zip Code Recognition   Neural Computation                  doi         neco               ISSN                

  a b Venkatesan  Ragav  Li  Baoxin               Convolutional Neural Networks in Visual Computing  A Concise Guide  CRC Press  ISBN                         Archived from the original on             Retrieved            

  a b Balas  Valentina E   Kumar  Raghvendra  Srivastava  Rajshree               Recent Trends and Advances in Artificial Intelligence and Internet of Things  Springer Nature  ISBN                         Archived from the original on             Retrieved            

  Zhang  Yingjie  Soon  Hong Geok  Ye  Dongsen  Fuh  Jerry Ying Hsi  Zhu  Kunpeng  September         Powder Bed Fusion Process Monitoring by Machine Vision With Hybrid Convolutional Neural Networks   IEEE Transactions on Industrial Informatics                     doi         TII               ISSN                 S CID                 Archived from the original on             Retrieved            

  Chervyakov  N I   Lyakhov  P A   Deryabin  M A   Nagornov  N N   Valueva  M V   Valuev  G V   September         Residue Number System Based Solution for Reducing the Hardware Cost of a Convolutional Neural Network   Neurocomputing                doi         j neucom              S CID                 Archived from the original on             Retrieved             Convolutional neural networks represent deep learning architectures that are currently used in a wide range of applications  including computer vision  speech recognition  malware dedection  time series analysis in finance  and many others 

  a b Habibi  Aghdam  Hamed               Guide to convolutional neural networks        a practical application to traffic sign detection and classification  Heravi  Elnaz Jahani  Cham  Switzerland  ISBN                     OCLC                  cite book     CS  maint  location missing publisher  link  CS  maint  multiple names  authors list  link 

  a b c Homma  Toshiteru  Les Atlas  Robert Marks II          An Artificial Neural Network for Spatio Temporal Bipolar Patterns  Application to Phoneme Classification   PDF   Advances in Neural Information Processing Systems            Archived  PDF  from the original on             Retrieved             The notion of convolution or correlation used in the models presented is popular in engineering disciplines and has been applied extensively to designing filters  control systems  etc 

  Valueva  M V   Nagornov  N N   Lyakhov  P A   Valuev  G V   Chervyakov  N I           Application of the residue number system to reduce hardware costs of the convolutional neural network implementation   Mathematics and Computers in Simulation       Elsevier BV           doi         j matcom              ISSN                 S CID                 Convolutional neural networks are a promising tool for solving the problem of pattern recognition 

  van den Oord  Aaron  Dieleman  Sander  Schrauwen  Benjamin               Burges  C  J  C   Bottou  L   Welling  M   Ghahramani  Z   Weinberger  K  Q   eds    Deep content based music recommendation  PDF   Curran Associates  Inc  pp                  Archived  PDF  from the original on             Retrieved            

  Collobert  Ronan  Weston  Jason                A unified architecture for natural language processing   Proceedings of the   th international conference on Machine learning   ICML      New York  NY  US  ACM  pp                doi                          ISBN                         S CID              

  Avilov  Oleksii  Rimbert  Sebastien  Popov  Anton  Bougrain  Laurent  July         Deep Learning Techniques to Improve Intraoperative Awareness Detection from Electroencephalographic Signals          nd Annual International Conference of the IEEE Engineering in Medicine  amp  Biology Society  EMBC   PDF   Vol             Montreal  QC  Canada  IEEE  pp                doi         EMBC                    ISBN                         PMID                S CID                 Archived  PDF  from the original on             Retrieved            

  a b Tsantekidis  Avraam  Passalis  Nikolaos  Tefas  Anastasios  Kanniainen  Juho  Gabbouj  Moncef  Iosifidis  Alexandros  July         Forecasting Stock Prices from the Limit Order Book Using Convolutional Neural Networks        IEEE   th Conference on Business Informatics  CBI   Thessaloniki  Greece  IEEE  pp             doi         CBI          ISBN                         S CID              

  a b c Zhang  Wei          Shift invariant pattern recognition neural network and its optical architecture   Proceedings of Annual Conference of the Japan Society of Applied Physics  Archived from the original on             Retrieved            

  a b c Zhang  Wei          Parallel distributed processing model with local space invariant interconnections and its optical architecture   Applied Optics                   Bibcode     ApOpt         Z  doi         AO            PMID                Archived from the original on             Retrieved            

  a b c d e f Mouton  Coenraad  Myburgh  Johannes C   Davel  Marelie H           Stride and Translation Invariance in CNNs   In Gerber  Aurona  ed    Artificial Intelligence Research  Communications in Computer and Information Science  Vol             Cham  Springer International Publishing  pp                arXiv             doi                               ISBN                         S CID                 Archived from the original on             Retrieved            

  Kurtzman  Thomas  August             Hidden bias in the DUD E dataset leads to misleading performance of deep learning in structure based virtual screening   PLOS ONE          e         Bibcode     PLoSO         C  doi         journal pone          PMC               PMID               

  a b c Fukushima  K           Neocognitron   Scholarpedia               Bibcode     SchpJ         F  doi         scholarpedia      

  a b Hubel  D  H   Wiesel  T  N                 Receptive fields and functional architecture of monkey striate cortex   The Journal of Physiology                    doi         jphysiol      sp        ISSN                 PMC               PMID              

  a b Fukushima  Kunihiko          Neocognitron  A Self organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position   PDF   Biological Cybernetics                   doi         BF          PMID               S CID                 Archived  PDF  from the original on   June       Retrieved    November      

  a b Matusugu  Masakazu  Katsuhiko Mori  Yusuke Mitari  Yuji Kaneda          Subject independent facial expression recognition with robust face detection using a convolutional neural network   PDF   Neural Networks                   doi         S                      PMID                Archived  PDF  from the original on    December       Retrieved    November      

  Convolutional Neural Networks Demystified  A Matched Filtering Perspective Based Tutorial https   arxiv org abs           v 

   Convolutional Neural Networks  LeNet    DeepLearning     documentation   DeepLearning      LISA Lab  Archived from the original on    December       Retrieved    August      

  Chollet  Fran ois                Xception  Deep Learning with Depthwise Separable Convolutions   arXiv             cs CV  

  a b c Ciresan  Dan  Ueli Meier  Jonathan Masci  Luca M  Gambardella  Jurgen Schmidhuber          Flexible  High Performance Convolutional Neural Networks for Image Classification   PDF   Proceedings of the Twenty Second International Joint Conference on Artificial Intelligence Volume Volume Two                Archived  PDF  from the original on   April       Retrieved    November      

  Krizhevsky  Alex   ImageNet Classification with Deep Convolutional Neural Networks   PDF   Archived  PDF  from the original on    April       Retrieved    November      

  a b Yamaguchi  Kouichi  Sakamoto  Kenji  Akabane  Toshio  Fujimoto  Yoshiji  November        A Neural Network for Speaker Independent Isolated Word Recognition  First International Conference on Spoken Language Processing  ICSLP      Kobe  Japan  Archived from the original on             Retrieved            

  a b c d Ciresan  Dan  Meier  Ueli  Schmidhuber  J rgen  June         Multi column deep neural networks for image classification        IEEE Conference on Computer Vision and Pattern Recognition  New York  NY  Institute of Electrical and Electronics Engineers  IEEE   pp                  arXiv            CiteSeerX                       doi         CVPR               ISBN                         OCLC                 S CID              

  Yu  Fisher  Koltun  Vladlen                Multi Scale Context Aggregation by Dilated Convolutions   arXiv             cs CV  

  Chen  Liang Chieh  Papandreou  George  Schroff  Florian  Adam  Hartwig                Rethinking Atrous Convolution for Semantic Image Segmentation   arXiv             cs CV  

  Duta  Ionut Cosmin  Georgescu  Mariana Iuliana  Ionescu  Radu Tudor                Contextual Convolutional Neural Networks   arXiv             cs CV  

  LeCun  Yann   LeNet    convolutional neural networks   Archived from the original on    February       Retrieved    November      

  Zeiler  Matthew D   Taylor  Graham W   Fergus  Rob  November         Adaptive deconvolutional networks for mid and high level feature learning        International Conference on Computer Vision  IEEE  pp                  doi         iccv               ISBN                        

  Dumoulin  Vincent  Visin  Francesco               A guide to convolution arithmetic for deep learning  arXiv           

  Odena  Augustus  Dumoulin  Vincent  Olah  Chris                Deconvolution and Checkerboard Artifacts   Distill          e   doi          distill        ISSN                

  van Dyck  Leonard Elia  Kwitt  Roland  Denzler  Sebastian Jochen  Gruber  Walter Roland          Comparing Object Recognition in Humans and Deep Convolutional Neural Networks An Eye Tracking Study   Frontiers in Neuroscience              doi         fnins              ISSN              X  PMC               PMID               

  a b Hubel  DH  Wiesel  TN  October         Receptive fields of single neurones in the cat s striate cortex   J  Physiol                   doi         jphysiol      sp        PMC               PMID               

  David H  Hubel and Torsten N  Wiesel         Brain and visual perception  the story of a    year collaboration  Oxford University Press US  p            ISBN                         Archived from the original on             Retrieved            

  a b Fukushima  K           Visual feature extraction by a multilayered network of analog threshold elements   IEEE Transactions on Systems Science and Cybernetics                  doi         TSSC             

  Schmidhuber  Juergen          Annotated History of Modern AI and Deep Learning   arXiv             cs NE  

  LeCun  Yann  Bengio  Yoshua  Hinton  Geoffrey          Deep learning   PDF   Nature                       Bibcode     Natur         L  doi         nature       PMID                S CID              

  Ramachandran  Prajit  Barret  Zoph  Quoc  V  Le  October             Searching for Activation Functions   arXiv             cs NE  

  a b Waibel  Alex     December        Phoneme Recognition Using Time Delay Neural Networks  PDF   Meeting of the Institute of Electrical  Information and Communication Engineers  IEICE   Tokyo  Japan 

  Alexander Waibel et al   Phoneme Recognition Using Time Delay Neural Networks Archived            at the Wayback Machine IEEE Transactions on Acoustics  Speech  and Signal Processing  Volume     No     pp             March      

  LeCun  Yann  Bengio  Yoshua          Convolutional networks for images  speech  and time series   In Arbib  Michael A   ed    The handbook of brain theory and neural networks  Second      ed    The MIT press  pp                Archived from the original on             Retrieved            

  John B  Hampshire and Alexander Waibel  Connectionist Architectures for Multi Speaker Phoneme Recognition Archived            at the Wayback Machine   Advances in Neural Information Processing Systems        Morgan Kaufmann 

  Ko  Tom  Peddinti  Vijayaditya  Povey  Daniel  Seltzer  Michael L   Khudanpur  Sanjeev  March        A Study on Data Augmentation of Reverberant Speech for Robust Speech Recognition  PDF   The   nd IEEE International Conference on Acoustics  Speech and Signal Processing  ICASSP        New Orleans  LA  US  Archived  PDF  from the original on             Retrieved            

  Denker  J S  Gardner  W R  Graf  H  P  Henderson  D  Howard  R E  Hubbard  W  Jackel  L D  BaIrd  H S  and Guyon        Neural network recognizer for hand written zip code digits Archived            at the Wayback Machine  AT amp T Bell Laboratories

  a b Y  LeCun  B  Boser  J  S  Denker  D  Henderson  R  E  Howard  W  Hubbard  L  D  Jackel  Backpropagation Applied to Handwritten Zip Code Recognition Archived            at the Wayback Machine  AT amp T Bell Laboratories

  a b Zhang  Wei          Image processing of human corneal endothelium based on a learning network   Applied Optics                   Bibcode     ApOpt         Z  doi         AO            PMID                Archived from the original on             Retrieved            

  a b Zhang  Wei          Computerized detection of clustered microcalcifications in digital mammograms using a shift invariant artificial neural network   Medical Physics                  Bibcode     MedPh         Z  doi                   PMID               Archived from the original on             Retrieved            

  Weng  J  Ahuja  N  Huang  TS          Learning recognition and segmentation of   D objects from   D images          th  International Conference on Computer Vision  IEEE  pp                doi         ICCV              ISBN                     S CID              

  a b Schmidhuber  J rgen          Deep Learning   Scholarpedia                    CiteSeerX                      doi         neco                 PMID                S CID               Archived from the original on             Retrieved            

  a b Lecun  Y   Jackel  L  D   Bottou  L   Cortes  C   Denker  J  S   Drucker  H   Guyon  I   Muller  U  A   Sackinger  E   Simard  P   Vapnik  V   August        Learning algorithms for classification  A comparison on handwritten digit recognition  PDF   World Scientific  pp                doi               ISBN                         Archived  PDF  from the original on   May      

  Lecun  Y   Bottou  L   Bengio  Y   Haffner  P   November         Gradient based learning applied to document recognition   Proceedings of the IEEE                      doi                  

  Zhang  Wei          Error Back Propagation with Minimum Entropy Weights  A Technique for Better Generalization of   D Shift Invariant NNs   Proceedings of the International Joint Conference on Neural Networks  Archived from the original on             Retrieved            

  Daniel Graupe  Ruey Wen Liu  George S Moschytz  Applications of neural networks to medical signal processing Archived            at the Wayback Machine   In Proc    th IEEE Decision and Control Conf    pp                

  Daniel Graupe  Boris Vern  G  Gruener  Aaron Field  and Qiu Huang   Decomposition of surface EMG signals into single fiber action potentials by means of neural network Archived            at the Wayback Machine   Proc  IEEE International Symp  on Circuits and Systems  pp                  

  Qiu Huang  Daniel Graupe  Yi Fang Huang  Ruey Wen Liu  Identification of firing patterns of neuronal signals     dead link        In Proc    th IEEE Decision and Control Conf   pp                 https   ieeexplore ieee org document       Archived            at the Wayback Machine

  Oh  KS  Jung  K          GPU implementation of neural networks   Pattern Recognition                     Bibcode     PatRe         O  doi         j patcog             

  Dave Steinkraus  Patrice Simard  Ian Buck          Using GPUs for Machine Learning Algorithms     th International Conference on Document Analysis and Recognition  ICDAR        pp                  doi         ICDAR           Archived from the original on             Retrieved            

  Kumar Chellapilla  Sid Puri  Patrice Simard          High Performance Convolutional Neural Networks for Document Processing   In Lorette  Guy  ed    Tenth International Workshop on Frontiers in Handwriting Recognition  Suvisoft  Archived from the original on             Retrieved            

  Hinton  GE  Osindero  S  Teh  YW  Jul         A fast learning algorithm for deep belief nets   Neural Computation                   CiteSeerX                      doi         neco                 PMID                S CID              

  Bengio  Yoshua  Lamblin  Pascal  Popovici  Dan  Larochelle  Hugo          Greedy Layer Wise Training of Deep Networks   PDF   Advances in Neural Information Processing Systems           Archived  PDF  from the original on             Retrieved            

  Ranzato  MarcAurelio  Poultney  Christopher  Chopra  Sumit  LeCun  Yann          Efficient Learning of Sparse Representations with an Energy Based Model   PDF   Advances in Neural Information Processing Systems  Archived  PDF  from the original on             Retrieved            

  Raina  R  Madhavan  A  Ng  Andrew     June         Large scale deep unsupervised learning using graphics processors   PDF   Proceedings of the   th Annual International Conference on Machine Learning  ICML      Proceedings of the   th Annual International Conference on Machine Learning  pp                doi                          ISBN                     S CID              Archived  PDF  from the original on   December       Retrieved    December      

  Ciresan  Dan  Meier  Ueli  Gambardella  Luca  Schmidhuber  J rgen          Deep big simple neural nets for handwritten digit recognition   Neural Computation                      arXiv            doi         NECO a        PMID                S CID              

   IJCNN      Competition result table   OFFICIAL IJCNN     COMPETITION        Archived from the original on             Retrieved            

  Schmidhuber  J rgen     March         History of computer vision contests won by deep CNNs on GPU   Archived from the original on    December       Retrieved    January      

  a b Krizhevsky  Alex  Sutskever  Ilya  Hinton  Geoffrey E                 ImageNet classification with deep convolutional neural networks   PDF   Communications of the ACM                 doi                  ISSN                 S CID                 Archived  PDF  from the original on             Retrieved            

  
Viebke  Andre  Memeti  Suejb  Pllana  Sabri  Abraham  Ajith          CHAOS  a parallelization scheme for training convolutional neural networks on Intel Xeon Phi   The Journal of Supercomputing                   arXiv             doi         s               x  S CID               

  Viebke  Andre  Pllana  Sabri          The Potential of the Intel  R  Xeon Phi for Supervised Deep Learning        IEEE   th International Conference on High Performance Computing and Communications       IEEE  th International Symposium on Cyberspace Safety and Security  and      IEEE   th International Conference on Embedded Software and Systems  IEEE Xplore  IEEE       pp                doi         HPCC CSS ICESS          ISBN                         S CID                Archived from the original on             Retrieved            

  Hinton  Geoffrey          ImageNet Classification with Deep Convolutional Neural Networks   NIPS     Proceedings of the   th International Conference on Neural Information Processing Systems   Volume                  Archived from the original on             Retrieved                    via ACM 

  a b c d e Azulay  Aharon  Weiss  Yair          Why do deep convolutional networks generalize so poorly to small image transformations    Journal of Machine Learning Research                  ISSN                 Archived from the original on             Retrieved            

  a b G ron  Aur lien         Hands on Machine Learning with Scikit Learn  Keras  and TensorFlow  Sebastopol  CA  O Reilly Media  ISBN                          pp     

  Li  Zewen  Liu  Fan  Yang  Wenjie  Peng  Shouheng  Zhou  Jun  December         A Survey of Convolutional Neural Networks  Analysis  Applications  and Prospects   IEEE Transactions on Neural Networks and Learning Systems                      arXiv             doi         TNNLS               hdl               PMID                Retrieved   March      

   CS   n Convolutional Neural Networks for Visual Recognition   cs   n github io  Archived from the original on             Retrieved            

  Nirthika  Rajendran  Manivannan  Siyamalan  Ramanan  Amirthalingam  Wang  Ruixuan                Pooling in convolutional neural networks for medical image analysis  a survey and an empirical study   Neural Computing and Applications                     doi         s                   ISSN                 PMC               PMID               

  a b Scherer  Dominik  M ller  Andreas C   Behnke  Sven          Evaluation of Pooling Operations in Convolutional Architectures for Object Recognition   PDF   Artificial Neural Networks  ICANN     th International Conference on  Thessaloniki  Greece  Springer  pp               Archived  PDF  from the original on             Retrieved            

  Graham  Benjamin                Fractional Max Pooling   arXiv            cs CV  

  Springenberg  Jost Tobias  Dosovitskiy  Alexey  Brox  Thomas  Riedmiller  Martin                Striving for Simplicity  The All Convolutional Net   arXiv            cs LG  

  Ma  Zhanyu  Chang  Dongliang  Xie  Jiyang  Ding  Yifeng  Wen  Shaoguo  Li  Xiaoxu  Si  Zhongwei  Guo  Jun          Fine Grained Vehicle Classification With Channel Max Pooling Modified CNNs   IEEE Transactions on Vehicular Technology          Institute of Electrical and Electronics Engineers  IEEE              doi         tvt               ISSN                 S CID               

  Zafar  Afia  Aamir  Muhammad  Mohd Nawi  Nazri  Arshad  Ali  Riaz  Saman  Alruban  Abdulrahman  Dutta  Ashit Kumar  Almotairi  Sultan                A Comparison of Pooling Methods for Convolutional Neural Networks   Applied Sciences                 doi         app          ISSN                

  Gholamalinezhad  Hossein  Khosravi  Hossein               Pooling Methods in Deep Neural Networks  a Review  arXiv           

  Householder  Alston S   June         A theory of steady state activity in nerve fiber networks  I  Definitions and preliminary lemmas   The Bulletin of Mathematical Biophysics                doi         BF          ISSN                

  Romanuke  Vadim          Appropriate number and allocation of ReLUs in convolutional neural networks   Research Bulletin of NTUU  Kyiv Polytechnic Institute                 doi                                 

  Xavier Glorot  Antoine Bordes  Yoshua Bengio         Deep sparse rectifier neural networks  PDF   AISTATS  Archived from the original  PDF  on             Retrieved             Rectifier and softplus activation functions  The second one is a smooth version of the first 

  Krizhevsky  A   Sutskever  I   Hinton  G  E           Imagenet classification with deep convolutional neural networks   PDF   Advances in Neural Information Processing Systems                Archived  PDF  from the original on             Retrieved            

  Ribeiro  Antonio H   Sch n  Thomas B           How Convolutional Neural Networks Deal with Aliasing   ICASSP             IEEE International Conference on Acoustics  Speech and Signal Processing  ICASSP   pp                  arXiv             doi         ICASSP                    ISBN                         S CID                

  Myburgh  Johannes C   Mouton  Coenraad  Davel  Marelie H           Tracking Translation Invariance in CNNS   In Gerber  Aurona  ed    Artificial Intelligence Research  Communications in Computer and Information Science  Vol             Cham  Springer International Publishing  pp                arXiv             doi                               ISBN                         S CID                 Archived from the original on             Retrieved            

  Richard  Zhang               Making Convolutional Networks Shift Invariant Again  OCLC                 

  Jadeberg  Simonyan  Zisserman  Kavukcuoglu  Max  Karen  Andrew  Koray          Spatial Transformer Networks   PDF   Advances in Neural Information Processing Systems      Archived  PDF  from the original on             Retrieved                    via NIPS   cite journal     CS  maint  multiple names  authors list  link 

  E  Sabour  Sara Frosst  Nicholas Hinton  Geoffrey               Dynamic Routing Between Capsules  OCLC                   cite book     CS  maint  multiple names  authors list  link 

  Matiz  Sergio  Barner  Kenneth E                 Inductive conformal predictor for convolutional neural networks  Applications to active learning for image classification   Pattern Recognition               Bibcode     PatRe         M  doi         j patcog              ISSN                 S CID                 Archived from the original on             Retrieved            

  Wieslander  H kan  Harrison  Philip J   Skogberg  Gabriel  Jackson  Sonya  Frid n  Markus  Karlsson  Johan  Spjuth  Ola  W hlby  Carolina  February         Deep Learning With Conformal Prediction for Hierarchical Analysis of Large Scale Whole Slide Tissue Images   IEEE Journal of Biomedical and Health Informatics                   doi         JBHI               ISSN                 PMID                S CID                

  Srivastava  Nitish  C  Geoffrey Hinton  Alex Krizhevsky  Ilya Sutskever  Ruslan Salakhutdinov          Dropout  A Simple Way to Prevent Neural Networks from overfitting   PDF   Journal of Machine Learning Research                     Archived  PDF  from the original on             Retrieved            

   Regularization of Neural Networks using DropConnect   ICML        JMLR W amp CP   jmlr org                         Archived from the original on             Retrieved            

  Zeiler  Matthew D   Fergus  Rob                Stochastic Pooling for Regularization of Deep Convolutional Neural Networks   arXiv            cs LG  

  a b Platt  John  Steinkraus  Dave  Simard  Patrice Y   August         Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis   Microsoft Research   Microsoft Research  Archived from the original on             Retrieved            

  Hinton  Geoffrey E   Srivastava  Nitish  Krizhevsky  Alex  Sutskever  Ilya  Salakhutdinov  Ruslan R           Improving neural networks by preventing co adaptation of feature detectors   arXiv            cs NE  

   Dropout  A Simple Way to Prevent Neural Networks from Overfitting   jmlr org  Archived from the original on             Retrieved            

  Hinton  Geoffrey          Some demonstrations of the effects of structural descriptions in mental imagery   Cognitive Science                  doi         s                     

  Rock  Irvin   The frame of reference   The legacy of Solomon Asch  Essays in cognition and social psychology                 

  J  Hinton  Coursera lectures on Neural Networks        Url  https   www coursera org learn neural networks Archived            at the Wayback Machine

  Dave Gershgorn     June         The inside story of how AI got good enough to dominate Silicon Valley   Quartz  Archived from the original on    December       Retrieved   October      

  Lawrence  Steve  C  Lee Giles  Ah Chung Tsoi  Andrew D  Back          Face Recognition  A Convolutional Neural Network Approach   IEEE Transactions on Neural Networks                 CiteSeerX                      doi                    PMID                S CID              

  Le Callet  Patrick  Christian Viard Gaudin  Dominique Barba          A Convolutional Neural Network Approach for Objective Video Quality Assessment   PDF   IEEE Transactions on Neural Networks                     doi         TNN              PMID                S CID                 Archived  PDF  from the original on    February       Retrieved    November      

   ImageNet Large Scale Visual Recognition Competition       ILSVRC        Archived from the original on   February       Retrieved    January      

  Szegedy  Christian  Liu  Wei  Jia  Yangqing  Sermanet  Pierre  Reed  Scott E   Anguelov  Dragomir  Erhan  Dumitru  Vanhoucke  Vincent  Rabinovich  Andrew          Going deeper with convolutions   IEEE Conference on Computer Vision and Pattern Recognition  CVPR       Boston  MA  USA  June             IEEE Computer Society  pp            arXiv            doi         CVPR               ISBN                        

  Russakovsky  Olga  Deng  Jia  Su  Hao  Krause  Jonathan  Satheesh  Sanjeev  Ma  Sean  Huang  Zhiheng  Karpathy  Andrej  Khosla  Aditya  Bernstein  Michael  Berg  Alexander C   Fei Fei  Li          Image Net Large Scale Visual Recognition Challenge   arXiv            cs CV  

   The Face Detection Algorithm Set To Revolutionize Image Search   Technology Review  February           Archived from the original on    September       Retrieved    October      

  Baccouche  Moez  Mamalet  Franck  Wolf  Christian  Garcia  Christophe  Baskurt  Atilla                Sequential Deep Learning for Human Action Recognition   In Salah  Albert Ali  Lepri  Bruno  eds    Human Behavior Unterstanding  Lecture Notes in Computer Science  Vol             Springer Berlin Heidelberg  pp              CiteSeerX                       doi                              ISBN                        

  Ji  Shuiwang  Xu  Wei  Yang  Ming  Yu  Kai                 D Convolutional Neural Networks for Human Action Recognition   IEEE Transactions on Pattern Analysis and Machine Intelligence                   CiteSeerX                       doi         TPAMI          ISSN                 PMID                S CID              

  Huang  Jie  Zhou  Wengang  Zhang  Qilin  Li  Houqiang  Li  Weiping          Video based Sign Language Recognition without Temporal Segmentation   arXiv             cs CV  

  Karpathy  Andrej  et al   Large scale video classification with convolutional neural networks Archived            at the Wayback Machine   IEEE Conference on Computer Vision and Pattern Recognition  CVPR        

  Simonyan  Karen  Zisserman  Andrew          Two Stream Convolutional Networks for Action Recognition in Videos   arXiv            cs CV          

  Wang  Le  Duan  Xuhuan  Zhang  Qilin  Niu  Zhenxing  Hua  Gang  Zheng  Nanning                Segment Tube  Spatio Temporal Action Localization in Untrimmed Videos with Per Frame Segmentation   PDF   Sensors                Bibcode     Senso         W  doi         s          ISSN                 PMC               PMID                Archived  PDF  from the original on             Retrieved            

  Duan  Xuhuan  Wang  Le  Zhai  Changbo  Zheng  Nanning  Zhang  Qilin  Niu  Zhenxing  Hua  Gang          Joint Spatio Temporal Action Localization in Untrimmed Videos with Per Frame Segmentation          th IEEE International Conference on Image Processing  ICIP     th IEEE International Conference on Image Processing  ICIP   pp                doi         icip               ISBN                        

  Taylor  Graham W   Fergus  Rob  LeCun  Yann  Bregler  Christoph               Convolutional Learning of Spatio temporal Features  Proceedings of the   th European Conference on Computer Vision  Part VI  ECCV     Berlin  Heidelberg  Springer Verlag  pp                ISBN                         Archived from the original on             Retrieved            

  Le  Q  V   Zou  W  Y   Yeung  S  Y   Ng  A  Y                 Learning hierarchical invariant spatio temporal features for action recognition with independent subspace analysis   CVPR       CVPR      Washington  DC  US  IEEE Computer Society  pp                  CiteSeerX                       doi         CVPR               ISBN                         S CID              

  Grefenstette  Edward  Blunsom  Phil  de Freitas  Nando  Hermann  Karl Moritz                A Deep Architecture for Semantic Parsing   arXiv            cs CL  

  Mesnil  Gregoire  Deng  Li  Gao  Jianfeng  He  Xiaodong  Shen  Yelong  April         Learning Semantic Representations Using Convolutional Neural Networks for Web Search   Microsoft Research   Microsoft Research  Archived from the original on             Retrieved            

  Kalchbrenner  Nal  Grefenstette  Edward  Blunsom  Phil                A Convolutional Neural Network for Modelling Sentences   arXiv            cs CL  

  Kim  Yoon                Convolutional Neural Networks for Sentence Classification   arXiv            cs CL  

  Collobert  Ronan  and Jason Weston   A unified architecture for natural language processing  Deep neural networks with multitask learning Archived            at the Wayback Machine  Proceedings of the   th international conference on Machine learning  ACM       

  Collobert  Ronan  Weston  Jason  Bottou  Leon  Karlen  Michael  Kavukcuoglu  Koray  Kuksa  Pavel                Natural Language Processing  almost  from Scratch   arXiv            cs LG  

  Yin  W  Kann  K  Yu  M  Sch tze  H                Comparative study of CNN and RNN for natural language processing   arXiv             cs LG  

  Bai  S   Kolter  J S   Koltun  V           An empirical evaluation of generic convolutional and recurrent networks for sequence modeling   arXiv             cs LG  

  Gruber  N           Detecting dynamics of action in text with a recurrent neural network   Neural Computing and Applications                        doi         S                   S CID                

  Haotian  J   Zhong  Li  Qianxiao  Li          Approximation Theory of Convolutional Architectures for Time Series Modelling   International Conference on Machine Learning  arXiv            

  Ren  Hansheng  Xu  Bixiong  Wang  Yujing  Yi  Chao  Huang  Congrui  Kou  Xiaoyu  Xing  Tony  Yang  Mao  Tong  Jie  Zhang  Qi         Time Series Anomaly Detection Service at Microsoft   Proceedings of the   th ACM SIGKDD International Conference on Knowledge Discovery  amp  Data Mining  arXiv             doi                          S CID                

  Wallach  Izhar  Dzamba  Michael  Heifets  Abraham                AtomNet  A Deep Convolutional Neural Network for Bioactivity Prediction in Structure based Drug Discovery   arXiv             cs LG  

  Yosinski  Jason  Clune  Jeff  Nguyen  Anh  Fuchs  Thomas  Lipson  Hod                Understanding Neural Networks Through Deep Visualization   arXiv             cs CV  

   Toronto startup has a faster way to discover effective medicines   The Globe and Mail  Archived from the original on             Retrieved            

   Startup Harnesses Supercomputers to Seek Cures   KQED Future of You              Archived from the original on             Retrieved            

  Chellapilla  K  Fogel  DB          Evolving neural networks to play checkers without relying on expert knowledge   IEEE Trans Neural Netw                   doi                    PMID               

  Chellapilla  K   Fogel  D B           Evolving an expert checkers playing program without using human expertise   IEEE Transactions on Evolutionary Computation                  doi                     

  Fogel  David         Blondie    Playing at the Edge of AI  San Francisco  CA  Morgan Kaufmann  ISBN                     

  Clark  Christopher  Storkey  Amos          Teaching Deep Convolutional Neural Networks to Play Go   arXiv            cs AI  

  Maddison  Chris J   Huang  Aja  Sutskever  Ilya  Silver  David          Move Evaluation in Go Using Deep Convolutional Neural Networks   arXiv            cs LG  

   AlphaGo   Google DeepMind   Archived from the original on    January       Retrieved    January      

  Bai  Shaojie  Kolter  J  Zico  Koltun  Vladlen                An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling   arXiv             cs LG  

  Yu  Fisher  Koltun  Vladlen                Multi Scale Context Aggregation by Dilated Convolutions   arXiv             cs CV  

  Borovykh  Anastasia  Bohte  Sander  Oosterlee  Cornelis W                 Conditional Time Series Forecasting with Convolutional Neural Networks   arXiv             stat ML  

  Mittelman  Roni                Time series modeling with undecimated fully convolutional neural networks   arXiv             stat ML  

  Chen  Yitian  Kang  Yanfei  Chen  Yixiong  Wang  Zizhuo                Probabilistic Forecasting with Temporal Convolutional Neural Network   arXiv             stat ML  

  Zhao  Bendong  Lu  Huanzhang  Chen  Shangfeng  Liu  Junliang  Wu  Dongya                Convolutional neural networks for time series classi   Journal of Systems Engineering and Electronics                   doi          JSEE            

  Petneh zi  G bor                QCNN  Quantile Convolutional Neural Network   arXiv             cs LG  

  
Hubert Mara               HeiCuBeDa Hilprecht   Heidelberg Cuneiform Benchmark Dataset for the Hilprecht Collection  in German   heiDATA   institutional repository for research data of Heidelberg University  doi          data IE CCN

  
Hubert Mara and Bartosz Bogacz          Breaking the Code on Broken Tablets  The Learning Challenge for Annotated Cuneiform Script in Normalized  D and  D Datasets   Proceedings of the   th International Conference on Document Analysis and Recognition  ICDAR   in German   Sydney  Australien  pp                doi         ICDAR             ISBN                         S CID               

  
Bogacz  Bartosz  Mara  Hubert          Period Classification of  D Cuneiform Tablets with Geometric Neural Networks   Proceedings of the   th International Conference on Frontiers of Handwriting Recognition  ICFHR   Dortmund  Germany

  Presentation of the ICFHR paper on Period Classification of  D Cuneiform Tablets with Geometric Neural Networks on YouTube

  Durjoy Sen Maitra  Ujjwal Bhattacharya  S K  Parui   CNN based common approach to handwritten character recognition of multiple scripts  Archived            at the Wayback Machine  in Document Analysis and Recognition  ICDAR          th International Conference on  vol   no   pp                  Aug      

   NIPS        Interpretable ML Symposium              Archived from the original on             Retrieved            

  Zang  Jinliang  Wang  Le  Liu  Ziyi  Zhang  Qilin  Hua  Gang  Zheng  Nanning          Attention Based Temporal Weighted Convolutional Neural Network for Action Recognition   Artificial Intelligence Applications and Innovations  IFIP Advances in Information and Communication Technology  Vol            Cham  Springer International Publishing  pp               arXiv             doi                              ISBN                         ISSN                 S CID              

  Wang  Le  Zang  Jinliang  Zhang  Qilin  Niu  Zhenxing  Hua  Gang  Zheng  Nanning                Action Recognition by an Attention Aware Temporal Weighted Convolutional Neural Network   PDF   Sensors                Bibcode     Senso         W  doi         s          ISSN                 PMC               PMID                Archived  PDF  from the original on             Retrieved            

  Ong  Hao Yi  Chavez  Kevin  Hong  Augustus                Distributed Deep Q Learning   arXiv           v   cs LG  

  Mnih  Volodymyr  et      al           Human level control through deep reinforcement learning   Nature                       Bibcode     Natur         M  doi         nature       PMID                S CID                

  Sun  R   Sessions  C   June         Self segmentation of sequences  automatic formation of hierarchies of sequential behaviors   IEEE Transactions on Systems  Man  and Cybernetics   Part B  Cybernetics                   CiteSeerX                     doi                      ISSN                 PMID               

   Convolutional Deep Belief Networks on CIFAR      PDF   Archived  PDF  from the original on             Retrieved            

  Lee  Honglak  Grosse  Roger  Ranganath  Rajesh  Ng  Andrew Y     January         Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations   Proceedings of the   th Annual International Conference on Machine Learning  ACM  pp                CiteSeerX                       doi                          ISBN                     S CID               

  Behnke  Sven         Hierarchical Neural Networks for Image Interpretation  PDF   Lecture Notes in Computer Science  Vol             Springer  doi         b       ISBN                         S CID               Archived  PDF  from the original on             Retrieved            

   Introduction to Machine Learning  Neural Networks  and Deep Learning   Wired  February       Archived from the original on January           Retrieved March            cite news          first  missing       last   help CS  maint  multiple names  authors list  link 


External links edit 
CS   n  Convolutional Neural Networks for Visual Recognition   Andrej Karpathy s Stanford computer science course on CNNs in computer vision
vdumoulin conv arithmetic  A technical report on convolution arithmetic in the context of deep learning  Animations of convolutions 
vteArtificial intelligence  AI History  timeline Concepts
Parameter
Hyperparameter
Loss functions
Regression
Bias variance tradeoff
Double descent
Overfitting
Clustering
Gradient descent
SGD
Quasi Newton method
Conjugate gradient method
Backpropagation
Attention
Convolution
Normalization
Batchnorm
Activation
Softmax
Sigmoid
Rectifier
Gating
Weight initialization
Regularization
Datasets
Augmentation
Prompt engineering
Reinforcement learning
Q learning
SARSA
Imitation
Policy gradient
Diffusion
Latent diffusion model
Autoregression
Adversary
RAG
Uncanny valley
RLHF
Self supervised learning
Recursive self improvement
Word embedding
Hallucination
Applications
Machine learning
In context learning
Artificial neural network
Deep learning
Language model
Large language model
NMT
Artificial general intelligence  AGI 
ImplementationsAudio visual
AlexNet
WaveNet
Human image synthesis
HWR
OCR
Speech synthesis
   ai
ElevenLabs
Speech recognition
Whisper
Facial recognition
AlphaFold
Text to image models
Aurora
DALL E
Firefly
Flux
Ideogram
Imagen
Midjourney
Stable Diffusion
Text to video models
Dream Machine
Runway Gen
Hailuo AI
Kling
Sora
Veo
Music generation
Suno AI
Udio
Text
Word vec
Seq seq
GloVe
BERT
T 
Llama
Chinchilla AI
PaLM
GPT
 
 
 
J
ChatGPT
 
 o
o 
o 
   
   
o 
Claude
Gemini
chatbot
Grok
LaMDA
BLOOM
Project Debater
IBM Watson
IBM Watsonx
Granite
PanGu  
DeepSeek
Qwen
Decisional
AlphaGo
AlphaZero
OpenAI Five
Self driving car
MuZero
Action selection
AutoGPT
Robot control
People
Alan Turing
Warren Sturgis McCulloch
Walter Pitts
John von Neumann
Claude Shannon
Marvin Minsky
John McCarthy
Nathaniel Rochester
Allen Newell
Cliff Shaw
Herbert A  Simon
Oliver Selfridge
Frank Rosenblatt
Bernard Widrow
Joseph Weizenbaum
Seymour Papert
Seppo Linnainmaa
Paul Werbos
J rgen Schmidhuber
Yann LeCun
Geoffrey Hinton
John Hopfield
Yoshua Bengio
Lotfi A  Zadeh
Stephen Grossberg
Alex Graves
Andrew Ng
Fei Fei Li
Alex Krizhevsky
Ilya Sutskever
Demis Hassabis
David Silver
Ian Goodfellow
Andrej Karpathy
James Goodnight
Architectures
Neural Turing machine
Differentiable neural computer
Transformer
Vision transformer  ViT 
Recurrent neural network  RNN 
Long short term memory  LSTM 
Gated recurrent unit  GRU 
Echo state network
Multilayer perceptron  MLP 
Convolutional neural network  CNN 
Residual neural network  RNN 
Highway network
Mamba
Autoencoder
Variational autoencoder  VAE 
Generative adversarial network  GAN 
Graph neural network  GNN 

 Portals
Technology
 Category
Artificial neural networks
Machine learning
 List
Companies
Projects






Retrieved from  https   en wikipedia org w index php title Convolutional neural network amp oldid