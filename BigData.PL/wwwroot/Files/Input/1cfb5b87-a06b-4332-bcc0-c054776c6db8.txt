Usage of artificial intelligence to generate music


Part of a series onArtificial intelligence  AI 
Major goals
Artificial general intelligence
Intelligent agent
Recursive self improvement
Planning
Computer vision
General game playing
Knowledge reasoning
Natural language processing
Robotics
AI safety

Approaches
Machine learning
Symbolic
Deep learning
Bayesian networks
Evolutionary algorithms
Hybrid intelligent systems
Systems integration

Applications
Bioinformatics
Deepfake
Earth sciences
 Finance 
Generative AI
Art
Audio
Music
Government
Healthcare
Mental health
Industry
Translation
 Military 
Physics
Projects

Philosophy
Artificial consciousness
Chinese room
Friendly AI
Control problem Takeover
Ethics
Existential risk
Turing test
Uncanny valley

History
Timeline
Progress
AI winter
AI boom

Glossary
Glossary
vte
Music and artificial intelligence  music and AI  is the development of music software programs which use AI to generate music             As with applications in other fields  AI in music also simulates mental tasks  A prominent feature is the capability of an AI algorithm to learn based on past data  such as in computer accompaniment technology  wherein the AI is capable of listening to a human performer and performing accompaniment             Artificial intelligence also drives interactive composition technology  wherein a computer composes music in response to a live performance  There are other AI applications in music that cover not only music composition  production  and performance but also how music is marketed and consumed  Several music player programs have also been developed to use voice recognition and natural language processing technology for music voice control  Current research includes the application of AI in music composition  performance  theory and digital sound processing  Composers artists like Jennifer Walshe or Holly Herndon have been exploring aspects of music AI for years in their performances and musical works  Another original approach of humans  imitating AI  can be found in the    hour sound installation String Quartet s  by Georges Lentz 
  th century art historian Erwin Panofsky proposed that in all art  there existed three levels of meaning  primary meaning  or the natural subject  secondary meaning  or the conventional subject  and tertiary meaning  the intrinsic content of the subject                        AI music explores the foremost of these  creating music without the  intention  which is usually behind it  leaving composers who listen to machine generated pieces feeling unsettled by the lack of apparent meaning            


History edit 
In the     s and the     s  music made by artificial intelligence was not fully original  but generated from templates that people had already defined and given to the AI  with this being known as rule based systems  As time passed  computers became more powerful  which allowed machine learning and artificial neural networks to help in the music industry by giving AI large amounts of data to learn how music is made instead of predefined templates  By the early     s  more advancements in artificial intelligence had been made  with generative adversarial networks  GANs  and deep learning being used to help AI compose more original music that is more complex and varied than possible before  Notable AI driven projects  such as OpenAI s MuseNet and Google s Magenta  have demonstrated AI s ability to generate compositions that mimic various musical styles            

Timeline edit 
Artificial intelligence finds its beginnings in music with the transcription problem  accurately recording a performance into musical notation as it is played  P re Engramelle s schematic of a  piano roll   a mode of automatically recording note timing and duration in a way which could be easily transcribed to proper musical notation by hand  was first implemented by German engineers J F  Unger and J  Hohlfield in                 
In       the ILLIAC I  Illinois Automatic Computer  produced the  Illiac Suite for String Quartet   a completely computer generated piece of music  The computer was programmed to accomplish this by composer Lejaren Hiller and mathematician Leonard Isaacson                        v vii       
In       Russian researcher Rudolf Zaripov published worldwide first paper on algorithmic music composing using the Ural   computer            
In       inventor Ray Kurzweil developed software capable of recognizing musical patterns and synthesizing new compositions from them  The computer first appeared on the quiz show I ve Got a Secret that same year            
By       Yamaha Corporation s Kansei Music System had gained momentum  and a paper was published on its development in       The software utilized music information processing and artificial intelligence techniques to essentially solve the transcription problem for simpler melodies  although higher level melodies and musical complexities are regarded even today as difficult deep learning tasks  and near perfect transcription is still a subject of research                        
In       an artificial intelligence program named Experiments in Musical Intelligence  EMI  appeared to outperform a human composer at the task of composing a piece of music to imitate the style of Bach              EMI would later become the basis for a more sophisticated algorithm called Emily Howell  named for its creator 
In       the music research team at the Sony Computer Science Laboratory Paris  led by French composer and scientist Fran ois Pachet  designed the Continuator  an algorithm uniquely capable of resuming a composition after a live musician stopped             
Emily Howell would continue to make advancements in musical artificial intelligence  publishing its first album From Darkness  Light in                   Since then  many more pieces by artificial intelligence and various groups have been published 
In       Iamus became the first AI to produce a fragment of original contemporary classical music  in its own style   Iamus  Opus     Located at the Universidad de Mal ga  Mal ga University  in Spain  the computer can generate a fully original piece in a variety of musical styles                                                   In August       a large dataset consisting of        MIDI songs  each with their lyrics and melodies              was created to investigate the feasibility of neural melody generation from lyrics using a deep conditional LSTM GAN method 
With progress in generative AI  models capable of creating complete musical compositions  including lyrics  from a simple text description have begun to emerge  Two notable web applications in this field are Suno AI  launched in December       and Udio  which followed in April                  

Software applications edit 
ChucK edit 
Main article  ChucK
Developed at Princeton University by Ge Wang and Perry Cook  ChucK is a text based  cross platform language              By extracting and classifying the theoretical techniques it finds in musical pieces  the software is able to synthesize entirely new pieces from the techniques it has learned              The technology is used by SLOrk  Stanford Laptop Orchestra              and PLOrk  Princeton Laptop Orchestra  

Jukedeck edit 
Main article  Jukedeck
Jukedeck was a website that let people use artificial intelligence to generate original  royalty free music for use in videos                          The team started building the music generation technology in                   formed a company around it in                   and launched the website publicly in                   The technology used was originally a rule based algorithmic composition system              which was later replaced with artificial neural networks              The website was used to create over   million pieces of music  and brands that used it included Coca Cola  Google  UKTV  and the Natural History Museum  London              In       the company was acquired by ByteDance                                     

MorpheuS edit 
MorpheuS             is a research project by Dorien Herremans and Elaine Chew at Queen Mary University of London  funded by a Marie Sk odowsk  Curie EU project  The system uses an optimization approach based on a variable neighborhood search algorithm to morph existing template pieces into novel pieces with a set level of tonal tension that changes dynamically throughout the piece  This optimization approach allows for the integration of a pattern detection technique in order to enforce long term structure and recurring themes in the generated music  Pieces composed by MorpheuS have been performed at concerts in both Stanford and London 

AIVA edit 
Main article  AIVA
Created in February       in Luxembourg  AIVA is a program that produces soundtracks for any type of media  The algorithms behind AIVA are based on deep learning architectures             AIVA has also been used to compose a Rock track called On the Edge              as well as a pop tune Love Sick             in collaboration with singer Taryn Southern              for the creation of her      album  I am AI  

Google Magenta edit 
   second music clip generated by MusicLM using the prompt  hypnotic ambient electronic music 
Google s Magenta team has published several AI music applications and technical papers since their launch in                   In      they released the NSynth algorithm and dataset              and an open source hardware musical instrument  designed to facilitate musicians in using the algorithm              The instrument was used by notable artists such as Grimes and YACHT in their albums                          In       they released a piano improvisation app called Piano Genie  This was later followed by Magenta Studio  a suite of   MIDI plugins that allow music producers to elaborate on existing music in their DAW              In       their machine learning team published a technical paper on GitHub that described MusicLM  a private text to music generator which they d developed                         

Riffusion edit 
This section is an excerpt from Riffusion  edit 
Generated spectrogram from the prompt  bossa nova with electric guitar   top   and the resulting audio after conversion  bottom 
Riffusion is a neural network  designed by Seth Forsgren and Hayk Martiros  that generates music using images of sound rather than audio              
The resulting music has been described as  de otro mundo   otherworldly               although unlikely to replace man made music              The model was made available on December           with the code also freely available on GitHub              
The first version of Riffusion was created as a fine tuning of Stable Diffusion  an existing open source model for generating images from text prompts  on spectrograms              resulting in a model which used text prompts to generate image files which could then be put through an inverse Fourier transform and converted into audio files              While these files were only several seconds long  the model could also use latent space between outputs to interpolate different files together                          using the img img capabilities of SD               It was one of many models derived from Stable Diffusion             
In December       Mubert             similarly used Stable Diffusion to turn descriptive text into music loops  In January       Google published a paper on their own text to music generator called MusicLM                         

Forsgren and Martiros formed a startup  also called Riffusion  and raised    million in venture capital funding in October                               
Spike AI edit 
Spike AI is an AI based audio plug in  developed by Spike Stent in collaboration with his son Joshua Stent and friend Henry Ramsey  that analyzes tracks and provides suggestions to increase clarity and other aspects during mixing  Communication is done by using a chatbot trained on Spike Stent s personal data  The plug in integrates into digital audio workstation                         

Musical applications edit 
Artificial intelligence can potentially impact how producers create music by giving reiterations of a track that follow a prompt given by the creator  These prompts allow the AI to follow a certain style that the artist is trying to go for             AI has also been seen in musical analysis where it has been used for feature extraction  pattern recognition  and musical recommendations              New tools that are powered by artificial intelligence have been made to help aid in generating original music compositions  like AIVA  Artificial Intelligence Virtual Artist  and Udio  This is done by giving an AI model data of already existing music and having it analyze the data using deep learning techniques to generate music in many different genres  such as classical music or electronic music             


Ethical and legal considerations edit 
Further information  Artificial intelligence and copyrightWhile helpful in generating new music  many issues have come up since artificial intelligence has begun making music  Some major concerns include how the economy will be impacted with AI taking over music production  who truly owns music generated by AI  and a lower demand for human made musical compositions  Some critics argue that AI diminishes the value of human creativity  while proponents see it as an augmentative tool that expands artistic possibilities rather than replacing human musicians              
Additionally  concerns have been raised about AI s potential to homogenize music  AI driven models often generate compositions based on existing trends  which some fear could limit musical diversity  Addressing this concern  researchers are working on AI systems that incorporate more nuanced creative elements  allowing for greater stylistic variation             
Another major concern about artificial intelligence in music is copyright laws  Many questions have been asked about who owns AI generated music and productions  as today s copyright laws require the work to be human authorized in order to be granted copyright protection  One proposed solution is to create hybrid laws that recognize both the artificial intelligence that generated the creation and the humans that contributed to the creation 
In the United States  the current legal framework tends to apply traditional copyright laws to AI  despite its differences with the human creative process              However  music outputs solely generated by AI are not granted copyright protection  In the compendium of the U S  Copyright Office Practices  the Copyright Office has stated that it would not grant copyrights to  works that lack human authorship  and  the Office will not register works produced by a machine or mere mechanical process that operates randomly or automatically without any creative input or intervention from a human author               In February       the Copyright Review Board rejected an application to copyright AI generated artwork on the basis that it  lacked the required human authorship necessary to sustain a claim in copyright               The usage of copyrighted music in training AI has also been a topic of contention  One instance of this was seen when SACEM  a professional organization of songwriters  composers  and music publishers demanded that PozaLabs  an AI music generation startup refrain from utilizing any music affiliated with them for training models              
The situation in the European Union  EU  is similar to the US  because its legal framework also emphasizes the role of human involvement in a copyright protected work              According to the European Union Intellectual Property Office and the recent jurisprudence of the Court of Justice of the European Union  the originality criterion requires the work to be the author s own intellectual creation  reflecting the personality of the author evidenced by the creative choices made during its production  requires distinct level of human involvement              The reCreating Europe project  funded by the European Union s Horizon      research and innovation program  delves into the challenges posed by AI generated contents including music  suggesting legal certainty and balanced protection that encourages innovation while respecting copyright norms              The recognition of AIVA marks a significant departure from traditional views on authorship and copyrights in the realm of music composition  allowing AI artists capable of releasing music and earning royalties  This acceptance marks AIVA as a pioneering instance where an AI has been formally acknowledged within the music production              
The recent advancements in artificial intelligence made by groups such as Stability AI  OpenAI  and Google has incurred an enormous sum of copyright claims leveled against generative technology  including AI music  Should these lawsuits succeed  the machine learning models behind these technologies would have their datasets restricted to the public domain              Strides towards addressing ethical issues have been made as well  such as the collaboration between Sound Ethics a company promoting ethical AI usage in the music industry  and UC Irvine  focusing on ethical frameworks and the responsible usage of AI             

Musical deepfakes edit 
A more nascent development of AI in music is the application of audio deepfakes to cast the lyrics or musical style of a pre existing song to the voice or style of another artist  This has raised many concerns regarding the legality of technology  as well as the ethics of employing it  particularly in the context of artistic identity              Furthermore  it has also raised the question of to whom the authorship of these works is attributed  As AI cannot hold authorship of its own  current speculation suggests that there will be no clear answer until further rulings are made regarding machine learning technologies as a whole              Most recent preventative measures have started to be developed by Google and Universal Music group who have taken into royalties and credit attribution to allow producers to replicated the voices and styles of artists             

 Heart on My Sleeve  edit 
In       an artist known as ghostwriter    created a musical deepfake called  Heart on My Sleeve  that cloned the voices of Drake and The Weeknd      by inputting an assortment of vocal only tracks from the respective artists into a deep learning algorithm  creating an artificial model of the voices of each artist  to which this model could be mapped onto original reference vocals with original lyrics              The track was submitted for Grammy consideration for the best rap song and song of the year                   It went viral and gained traction on TikTok and received a positive response from the audience  leading to its official release on Apple Music  Spotify  and YouTube in April                   Many believed the track was fully composed by an AI software  but the producer claimed the songwriting  production  and original vocals  pre conversion  were still done by him              It would later be rescinded from any Grammy considerations due to it not following the guidelines necessary to be considered for a Grammy award                   The track would end up being removed from all music platforms by Universal Music Group              The song was a watershed moment for AI voice cloning  and models have since been created for hundreds  if not thousands  of popular singers and rappers 

 Where That Came From  edit 
In       country music singer Randy Travis suffered a stroke which left him unable to sing  In the meantime  vocalist James Dupr  toured on his behalf  singing his songs for him  Travis and longtime producer Kyle Lehning released a new song in May      titled  Where That Came From   Travis s first new song since his stroke  The recording uses AI technology to re create Travis s singing voice  having been composited from over    existing vocal recordings alongside those of Dupr                          

Technical approaches edit 
Artificial intelligence music encompasses a number of technical approaches used for music composition  analysis  classification  and suggestion  Techniques used are drawn from deep learning  machine learning  natural language processing  and signal processing  Current systems are able to compose entire musical compositions  parse affective content  accompany human players in real time  and acquire patterns of user and context dependent preferences                                                 

Symbolic music composition edit 
Symbolic music generation is the generation of music in discrete symbolic forms such as MIDI  where note and timing are precisely defined  Early systems employed rule based systems and Markov models  but modern systems employ deep learning to a large extent  Recurrent Neural Networks  RNNs   and more precisely Long Short Term Memory  LSTM  networks  have been employed in modeling temporal dependencies of musical sequences  They may be used to generate melodies  harmonies  and counterpoints in various musical genres             
Transformer models such as Music Transformer and MuseNet became more popular for symbolic generation due to their ability to model long range dependencies and scalability  These models were employed to generate multi instrument polyphonic music and stylistic imitations             

Audio based music generation edit 
This method generates music as raw audio waveforms instead of symbolic notation  DeepMind s WaveNet is an early example that uses autoregressive sampling to generate high fidelity audio  Generative Adversarial Networks  GANs  and Variational Autoencoders  VAEs  are being used more and more in new audio texture synthesis and timbre combination of different instruments             
NSynth  Neural Synthesizer   a Google Magenta project  uses a WaveNet like autoencoder to learn latent audio representations and thereby generate completely novel instrumental sounds             

Music information retrieval  MIR  edit 
Music Information Retrieval  MIR  is the extraction of musically relevant information from audio recordings to be utilized in applications such as genre classification  instrument recognition  mood recognition  beat detection  and similarity estimation  CNNs on spectrogram features have been very accurate on these tasks               SVMs and k Nearest Neighbors  k NN  are also used for classification on features such as Mel frequency cepstral coefficients  MFCCs  

Hybrid and interactive systems edit 
Hybrid systems combine symbolic and sound based methods to draw on their respective strengths  They can compose high level symbolic compositions and synthesize them as natural sound  Interactive systems in real time allow for AI to instantaneously respond to human input to support live performance  Reinforcement learning and rule based agents tend to be utilized to allow for human AI co creation in improvisation contexts             

Affective computing and emotion aware music systems edit 
Affective computing techniques enable AI systems to classify or create music based on some affective content  The models use musical features such as tempo  mode  and timbre to classify or influence listener emotions  Deep learning models have been trained for classifying music based on affective content and even creating music intended to have affective impacts             

AI based music recommendation systems edit 
Music recommenders employ AI to suggest tracks to users based on what they have heard  their tastes  and information available in context  Collaborative filtering  content based filtering  and hybrid filtering are most widely applied  deep learning being utilized for fine tuning  Graph based and matrix factorization methods are used within commercial systems like Spotify and YouTube Music to represent complex user item relationships             

AI for automatic mixing and mastering edit 
AI is also used in audio engineering automation such as mixing and mastering  Such systems level  equalize  pan  and compress to give well balanced sound outputs  Software such as LANDR and iZotope Ozone utilize machine learning in emulating professional audio engineers  decisions             

Lyrics generation and songwriting aid edit 
Natural language generation also applies to songwriting assistance and lyrics generation  Transformer language models like GPT   have also been proven to be able to generate stylistic and coherent lyrics from input prompts  themes  or feeling  There even exist AI programs that assist with rhyme scheme  syllable count  and poem form               

Multimodal and cross modal systems edit 
Recent developments include multimodal AI systems that integrate music with other media  e g   dance  video  and text  These can generate background scores in synchronization with video sequences or generate dance choreography from audio input  Cross modal retrieval systems allow one to search for music using images  text  or gestures             

Cultural impact edit 
This section may incorporate text from a large language model  It may include hallucinated information or fictitious references  Copyright violations or claims lacking verification should be removed  Additional guidance is available on the associated project page    April      
The advent of AI music has caused heated cultural debates  especially its impacts on creativity  morality  and audience  As much as there have been praises about the democratization of music production  there have been fears raised about its impacts on producers  audience  and society in general 

Reactions and controversies edit 
The most contentious application of AI music creation has been its misuse to produce offensive work  The music AI platforms have been used in several instances to produce songs with offensive lyrics that were racist  antisemitic  or contained violence and have tested moderation and accountability in generative AI platforms                The case has renewed argument about accountability in users and developers in producing moral outputs in generative models 
Aside from that  there have been several producers and artists denouncing the use of AI music due to threats to originality  handmade craftsmanship  and cultural authenticity  The music created by AIs lacks the emotional intelligence and lived life upon which human work relies  according to its critics  The concern comes in an era when there are steadily more songs made from AIs appearing on platforms and which others consider lowering human artistry               

Musicians vs  consumers edit 
Interestingly enough  while professional musicians have been generally more dismissive about using AI in music production  the general consumer or listener has been receptive or neutral to the idea  Surveys have found that in a commercial context  the average consumer often doesn t know or even care whether they hear music made by human beings or AI and that a high percentage says that it doesn t affect their enjoyment                The contrast between artist sentiment and consumer sentiment may hold far reaching consequences in terms of the future economics within the music industry and the worth assigned to human creativity 

Public perception and general perception edit 
The cultural value placed on AI music is similarly related to overall popular perceptions regarding generative AI  How generative AI produced work whether music or writing is received in human terms has been found to be dependent upon such factors as emotional meaning and authenticity                As long as the output from AI proves persuasive and engaging  audiences may in some cases be willing to accept music whose author is not a human being  with the potential to reshape conventions regarding creators and creativity 

Future directions edit 
This section may incorporate text from a large language model  It may include hallucinated information or fictitious references  Copyright violations or claims lacking verification should be removed  Additional guidance is available on the associated project page    March      
The field of music and artificial intelligence is still evolving  Some of the key future directions for advancement include advancements in generation models  changes in how humans and AI collaborate musically  and the development of legal and ethical frameworks to address the technology s impact 

Advancements in generation models edit 
Future research and development is expected to move beyond established techniques such as Generative Adversarial Networks  GANs  and Variational Autoencoders  VAEs   More recent architectures such as diffusion models and transformer based networks             are showing promise for generating more complex  nuanced  and stylistically coherent music  These models may lead to higher quality audio generation and better long term structure in music compositions 

Human AI collaboration edit 
Besides the act of generation itself  a significant future direction of interest involves deepening the collaboration between human musicians and AI  Developments are increasingly focused on understanding the way these collaborations can occur  and how they can be facilitated to be ethically sound              This involves studying musicians perceptions and experiences with AI tools to inform the design of future systems  
Research actively explores these collaborative models in different domains  For instance  studies investigate how AI can be co designed with professionals such as music therapists to act as supportive partners in complex creative and therapeutic processes              showing a trend towards developing AI not just as an output tool  but as an integrated component designed to augment human skills 

Regulatory changes and ethical considerations edit 
As AI generated music becomes more capable and widespread  legal and ethical frameworks worldwide are expected to continue adapting  Current policy discussions have been focusing on copyright ownership  the use of AI to mimic artists  deepfakes   and fair compensation for artists              Recent legislative efforts and debates  such as those concerning AI safety and regulation in places like California  show the challenges involved in balancing innovation with potential risks and societal impacts              Tracking these developments is crucial for understanding the future of AI in the music industry             

See also edit 
Algorithmic composition
Automatic content recognition
Computational models of musical creativity
Generative artificial intelligence
Generative music
List of music software
Music information retrieval
OpenAI        Music generation
References edit 


  D  Herremans  C H   Chuan  E  Chew          A Functional Taxonomy of Music Generation Systems   ACM Computing Surveys                   arXiv             doi                  S CID              

  Dannenberg  Roger   Artificial Intelligence  Machine Learning  and Music Understanding   PDF   Semantic Scholar  S CID                Archived from the original  PDF  on    August       Retrieved    August      

   Erwin Panofsky  Studies in Iconology  Humanistic Themes in the Art of the Renaissance  Oxford        PDF   Archived  PDF  from the original on    December       Retrieved   March      

  Dilly  Heinrich         Arnold  Heinz Ludwig  ed     Panofsky  Erwin  Zum Problem der Beschreibung und Inhaltsdeutung von Werken der bildenden Kunst   Kindlers Literatur Lexikon  KLL   in German   Stuttgart  J B  Metzler  pp            doi                                    ISBN                         retrieved   March     

  a b c d Miranda  Eduardo Reck  ed           Handbook of Artificial Intelligence for Music   SpringerLink  doi                            ISBN                         Archived from the original on    September       Retrieved    September      

   AI and the Sound of Music   www yalelawjournal org  Retrieved    February      

  a b Roads  Curtis          Research in music and artificial intelligence   ACM Computing Surveys                   doi                    Archived from the original on   April       Retrieved   March      

  Zaripov  Rudolf                                                                 On algorithmic description of process of music composition    Proceedings of the USSR Academy of Sciences          

   Ray Kurzweil   National Science and Technology Medals Foundation  Archived from the original on    September       Retrieved    September      

  Katayose  Haruhiro  Inokuchi  Seiji          The Kansei Music System   Computer Music Journal                 doi                  ISSN                 JSTOR               Archived from the original on    March       Retrieved   March      

  Johnson  George     November         Undiscovered Bach  No  a Computer Wrote It   The New York Times  Archived from the original on    March       Retrieved    April       Dr  Larson was hurt when the audience concluded that his piece    a simple  engaging form called a two part invention    was written by the computer  But he felt somewhat mollified when the listeners went on to decide that the invention composed by EMI  pronounced Emmy  was genuine Bach 

  Pachet  Fran ois  September         The Continuator  Musical Interaction With Style   Journal of New Music Research                   doi         jnmr                 hdl      spo bbp               ISSN                

  Lawson  Mark     October         This artificially intelligent music may speak to our minds  but not our souls   The Guardian  ISSN                 Retrieved    September      

   Iamus  Is this the   st century s answer to Mozart    BBC News    January       Archived from the original on    September       Retrieved    September      

  yy lab     November        yy lab Lyrics Conditioned Neural Melody Generation  archived from the original on   January       retrieved    November       citation     CS  maint  numeric names  authors list  link 

  Nair  Vandana     April         AI Music Platform Race Accelerates with Udio   Analytics India Magazine  Archived from the original on    April       Retrieved    April      

  ChucK   gt  Strongly timed  On the fly Audio Programming Language Archived    November      at the Wayback Machine  Chuck cs princeton edu  Retrieved on            

   Foundations of On the fly Learning in the ChucK Programming Language   PDF   Archived  PDF  from the original on    April       Retrieved   March      

  Driver  Dustin               Pro   Profiles   Stanford Laptop Orchestra  SLOrk   pg    Archived    January      at the Wayback Machine  Apple  Retrieved on            

  a b  From Jingles to Pop Hits  A I  Is Music to Some Ears   The New York Times     January       Archived from the original on    February       Retrieved   January      

  a b  Need Music For A Video  Jukedeck s AI Composer Makes Cheap  Custom Soundtracks   techcrunch com    December       Archived from the original on   January       Retrieved   January      

   What Will Happen When Machines Write Songs Just as Well as Your Favorite Musician    motherjones com  Archived from the original on   February       Retrieved   January      

  Cookson  Robert    December         Jukedeck s computer composes music at touch of a button   Financial Times  Archived from the original on   January       Retrieved   January      

   Jukedeck  the software that writes music by itself  note by note   Wired UK  Archived from the original on   January       Retrieved   January      

   Robot rock  how AI singstars use machine learning to write harmonies   standard co uk  March       Archived from the original on   January       Retrieved   January      

   TIKTOK OWNER BYTEDANCE BUYS AI MUSIC COMPANY JUKEDECK   musicbusinessworldwide com     July       Archived from the original on   February       Retrieved   January      

   As TikTok s Music Licensing Reportedly Expires  Owner ByteDance Purchases AI Music Creation Startup JukeDeck   digitalmusicnews com     July       Archived from the original on   January       Retrieved   January      

   An AI generated music app is now part of the TikTok group   sea mashable com     July       Archived from the original on    January       Retrieved   January      

  D  Herremans  E  Chew          MorpheuS  Automatic music generation with recurrent pattern constraints and tension profiles   IEEE Transactions on Affective Computing  arXiv             doi         TAFFC               S CID               

   A New AI Can Write Music as Well as a Human Composer   Futurism    March       Archived from the original on    April       Retrieved    April      

  Technologies  Aiva     October         The Making of AI generated Rock Music with AIVA   Medium  Archived from the original on    October       Retrieved    April      

  Lovesick   Composed with AIVA Artificial Intelligence   Official Video with Lyrics   Taryn Southern    May       Archived from the original on    July       Retrieved    October      

  Southern  Taryn     May         Algo Rhythms  The future of album collaboration   TechCrunch  Archived from the original on    October       Retrieved    April      

   Welcome to Magenta    Magenta    June       Archived from the original on   February       Retrieved    April      

  Engel  Jesse  Resnick  Cinjon  Roberts  Adam  Dieleman  Sander  Eck  Douglas  Simonyan  Karen  Norouzi  Mohammad          Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders   PMLR  arXiv            

  Open NSynth Super  Google Creative Lab     February       archived from the original on    December       retrieved    February     

   Cover Story  Grimes is ready to play the villain   Crack Magazine  Archived from the original on   June       Retrieved    February      

   What Machine Learning Taught the Band YACHT About Themselves   Los Angeleno     September       Archived from the original on    January       Retrieved    February      

   Magenta Studio   Magenta  Archived from the original on    January       Retrieved    April      

   MusicLM   google research github io        Archived from the original on   February       Retrieved    April      

  Sandzer Bell  Ezra     February         Best Alternatives to Google s AI Powered MusicLM and MusicFX   AudioCipher  Archived from the original on   February       Retrieved    April      

  a b c Coldewey  Devin     December         Try  Riffusion   an AI model that composes music by visualizing it  

  a b Llano  Eutropio     December         El generador de im genes AI tambi n puede producir m sica  con resultados de otro mundo   

  a b Nasi  Michele     December         Riffusion  creare tracce audio con l intelligenza artificiale   IlSoftware it 

   Essayez  Riffusion   un mod le d IA qui compose de la musique en la visualisant      December      

  a b                    AI Riffusion        AI Stable Diffusion                  GIGAZINE     December      

   Mubert launches Text to Music interface   a completely new way to generate music from a single text prompt      December      

   MusicLM  Generating Music From Text      January      

     Reasons Google s MusicLM AI Text to Music App is Different      January      

  Gal  Dr  Itay     February         Free A I  music creation platform launches  competing with Suno   The Jerusalem Post  Retrieved    February      

  Nu ez  Michael     January         Riffusion s free AI music platform could be the Spotify of the future   VentureBeat  Retrieved    February      

  Levine  Mike    October         Spike AI   A Mix Product of the Week   Mix  Future US  Archived from the original on    November       Retrieved    November      

   Spike Stent offers his expertise in Spike AI   Sound on Sound  Archived from the original on    December       Retrieved    November      

  Zhang  Yifei  December         Utilizing Computational Music Analysis and AI for Enhanced Music Composition  Exploring Pre  and Post Analysis   Journal of Advanced Zoology      S                doi          jaz v  is        S CID                

  Ma dziuk  Jacek     November         Artificial intelligence in music  recent trends and challenges   ResearchGate 

   Applications and Advances of Artificial Intelligence in Music Generation A Review   arxiv org  Retrieved    February      

  Ma dziuk  Jacek     November         Artificial intelligence in music  recent trends and challenges   ResearchGate 

   Art created by AI cannot be copyrighted  says US officials   what does this mean for music    MusicTech  Archived from the original on   April       Retrieved    October      

   Can  and should  AI generated works be protected by copyright    Hypebot     February       Archived from the original on    October       Retrieved    October      

  Re  Second Request for Reconsideration for Refusal to Register A Recent Entrance to Paradise  Correspondence ID    ZPC C   SR                  PDF   Report   Copyright Review Board  United States Copyright Office     February       Archived  PDF  from the original on    July       Retrieved    October      

  PozaLabs  December            Pozalabs Responds to SACEM  Addresses Ethical AI Music Generation Concerns   GlobalNewswire  Retrieved April  th        https   www globenewswire com news release                      en Pozalabs Responds to SACEM Addresses Ethical AI Music Generation Concerns html

  a b c Bulayenko  Oleksandr  Quintais  Jo o Pedro  Gervais  Daniel J   Poort  Joost  February             AI Music Outputs  Challenges to the Copyright Legal Framework  Archived    March      at the Wayback Machine  reCreating Europe Report  Retrieved            

  Ahuja  Virendra  June             Artificial Intelligence and Copyright  Issues and Challenges  Archived    April      at the Wayback Machine  ILI Law Review Winter Issue       Retrieved            

  Samuelson  Pamela     July         Generative AI meets copyright   Science                       doi         science x  PMID               

  SoundEthics  February            Sound Ethics and UC Irvine Partner to Shape the Future of Ethical AI in the Music Industry   Newswire  Retrieved April  th        https   www newswire com news sound ethics and uc irvine partner to shape the future of ethical ai         

   DeepDrake ft  BTS GAN and TayloRVC  An Exploratory Analysis of Musical Deepfakes and Hosting Platforms   PDF   Archived  PDF  from the original on    March       Retrieved   March      

   AI and Deepfake Voice Cloning  Innovation  Copyright and Artists  Rights   PDF   Archived  PDF  from the original on   June       Retrieved   March      

  Murgia  Madhumita  Nicolaou  Anna    August         Google and Universal Music negotiate deal over AI  deepfakes    Financial Times  Archived from the original on    March       Retrieved   April      

  a b Robinson  Kristin     October         Ghostwriter  the Mastermind Behind the Viral Drake AI Song  Speaks For the First Time   Billboard  Archived from the original on   April       Retrieved   April      

   Drake The Weeknd deepfake song  Heart on My Sleeve  submitted to Grammys   The FADER  Archived from the original on   April       Retrieved   April      

  a b c  The AI deepfake of Drake and The Weeknd will not be eligible for a GRAMMY   Mixmag  Archived from the original on   April       Retrieved   April      

  Marcus K  Dowling    May         Randy Travis  shocks music industry with AI pairing for  Where That Came From   How the song came together   The Tennesseean  Retrieved   May      

  Maria Sherman    May         With help from AI  Randy Travis got his voice back  Here s how his first song post stroke came to be   AP News  Archived from the original on   May       Retrieved   May      

  Mycka  Jan  Ma dziuk  Jacek          Artificial intelligence in music  recent trends and challenges   Neural Computing and Applications                   doi         s                x 

  Briot  Jean Pierre  Hadjeres  Ga tan  Pachet  Fran ois David          Deep learning techniques for music generation   A survey   arXiv             cs SD  

  Herremans  Dorien  Chuan  Ching Hua  Chew  Elaine          A functional taxonomy of music generation systems   ACM Computing Surveys              arXiv             doi                 

  Sturm  Bob L   S ndergaard  Martin          Music Information Retrieval and Artificial Intelligence  Best Friends or Worst Enemies    Transactions of the International Society for Music Information Retrieval               doi         tismir     inactive   April         cite journal     CS  maint  DOI inactive as of April       link 

  Briot  Jean Pierre  Hadjeres  Ga tan  Pachet  Fran ois David          Deep learning techniques for music generation   A survey   arXiv             cs SD  

  Huang  Cheng Zhi Anna          Music Transformer  Generating Music with Long Term Structure   International Conference on Learning Representations  arXiv            

  Briot  Jean Pierre  Hadjeres  Ga tan  Pachet  Fran ois David          Deep learning techniques for music generation   A survey   arXiv             cs SD  

  Engel  Jesse          Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders   Proceedings of the   th International Conference on Machine Learning  arXiv            

  Sturm  Bob L   S ndergaard  Martin          Music Information Retrieval and Artificial Intelligence  Best Friends or Worst Enemies    Transactions of the International Society for Music Information Retrieval               doi         tismir     inactive   April         cite journal     CS  maint  DOI inactive as of April       link 

  Herremans  Dorien  Chuan  Ching Hua  Chew  Elaine          A functional taxonomy of music generation systems   ACM Computing Surveys              arXiv             doi                 

  Kim  Yejin  Elliott  Mark T   Kim  Youngmoo E           Modeling Musical Affect Using Deep Neural Networks   Proceedings of the International Society for Music Information Retrieval  ISMIR  

  Schedl  Markus          Deep Learning in Music Recommendation Systems  A Survey   Journal of New Music Research                   doi                                inactive   April         cite journal     CS  maint  DOI inactive as of April       link 

  Bocko  Mark          The Role of Artificial Intelligence in Automated Music Production   Audio Engineering Society Conference 

  Vechtomova  Olga          Lyrics Generation with Neural Networks  Challenges and Opportunities   Transactions of the International Society for Music Information Retrieval 

  Choi  Keunwoo          Theoretical model for the Seebeck coefficient in superlattice materials with energy relaxation   Journal of Applied Physics           arXiv             Bibcode     JAP      e    V  doi                   

  Segarra  Edward   Many musicians are speaking out against AI in music  But how do consumers feel    USA TODAY  Retrieved   April      

  a b Wiggers  Kyle    June         People are using AI music generators to create hateful songs   TechCrunch  Retrieved   April      

  Chu  Haoran  Liu  Sixiao    October         Can AI tell good stories  Narrative transportation and persuasion with ChatGPT   Journal of Communication                   doi         joc jqae     ISSN                

  Chen  Yanxu  Huang  Linshu  Gou  Tian          Applications and Advances of Artificial Intelligence in Music Generation A Review   arXiv             cs SD  

  Newman  Michele  Morris  Lidia  Lee  Jin Ha    December         Human AI Music Creation  Understanding the Perceptions and Experiences of Music Creators for Ethical and Productive Collaboration   Zenodo  doi         zenodo         

  Sun  Jingjing  Yang  Jingyi  Zhou  Guyue  Jin  Yucheng  Gong  Jiangtao          Understanding Human AI Collaboration in Music Therapy Through Co Design with Therapists   Proceedings of the CHI Conference on Human Factors in Computing Systems  pp             doi                          ISBN                        

   Innovation and Artists  Rights in the Age of Generative AI   Georgetown Journal of International Affairs     July       Retrieved March           https   gjia georgetown edu            innovation and artists rights in the age of generative ai 

  Mehmood  Irfan  Mahroof  Kamran  October            California s governor blocked landmark AI safety laws  Here s why it s such a key ruling for the future of AI worldwide   The Conversation  Retrieved March           https   theconversation com californias governor blocked landmark ai safety laws heres why its such a key ruling for the future of ai worldwide       

  Hight  Jewly     April         AI music isn t going away  Here are   big questions about what s next   NPR  Retrieved March           https   www npr org                       generative ai music law technology


Further reading edit 
Understanding Music with AI  Perspectives on Music Cognition Archived            at the Wayback Machine  Edited by Mira Balaban  Kemal Ebcioglu  and Otto Laske  AAAI Press 
Proceedings of a Workshop held as part of AI ED     World Conference on Artificial Intelligence in Education on Music Education  An Artificial Intelligence Approach
Tanguiane  Tangian   Andranick         Artificial Perception and Music Recognition  Lecture Notes in Artificial Intelligence  Vol            Berlin Heidelberg  Springer  ISBN                        
Artificial Intelligence   Intelligent Art  Human Machine Interaction and Creative Practice   Digital Society   Digitale Gesellschaft   Edited by Voigts  Eckart  Robin Auer  Dietmar Elflein  Sebastian Kunas  Jan R hnert  Christoph Seelinger Bielefeld  transcript      
External links edit 
The Music Informatics Research Group
Institut de Recherche et Coordination Acoustique  Musique
Interdisciplinary Centre for Research in Music
Mixdevil   Is AI Good Gor Music Producers
OpenDream
vteArtificial intelligence  AI History  timeline Concepts
Parameter
Hyperparameter
Loss functions
Regression
Bias variance tradeoff
Double descent
Overfitting
Clustering
Gradient descent
SGD
Quasi Newton method
Conjugate gradient method
Backpropagation
Attention
Convolution
Normalization
Batchnorm
Activation
Softmax
Sigmoid
Rectifier
Gating
Weight initialization
Regularization
Datasets
Augmentation
Prompt engineering
Reinforcement learning
Q learning
SARSA
Imitation
Policy gradient
Diffusion
Latent diffusion model
Autoregression
Adversary
RAG
Uncanny valley
RLHF
Self supervised learning
Recursive self improvement
Word embedding
Hallucination
Applications
Machine learning
In context learning
Artificial neural network
Deep learning
Language model
Large language model
NMT
Artificial general intelligence  AGI 
ImplementationsAudio visual
AlexNet
WaveNet
Human image synthesis
HWR
OCR
Speech synthesis
   ai
ElevenLabs
Speech recognition
Whisper
Facial recognition
AlphaFold
Text to image models
Aurora
DALL E
Firefly
Flux
Ideogram
Imagen
Midjourney
Stable Diffusion
Text to video models
Dream Machine
Runway Gen
Hailuo AI
Kling
Sora
Veo
Music generation
Suno AI
Udio
Text
Word vec
Seq seq
GloVe
BERT
T 
Llama
Chinchilla AI
PaLM
GPT
 
 
 
J
ChatGPT
 
 o
o 
o 
   
   
o 
Claude
Gemini
chatbot
Grok
LaMDA
BLOOM
Project Debater
IBM Watson
IBM Watsonx
Granite
PanGu  
DeepSeek
Qwen
Decisional
AlphaGo
AlphaZero
OpenAI Five
Self driving car
MuZero
Action selection
AutoGPT
Robot control
People
Alan Turing
Warren Sturgis McCulloch
Walter Pitts
John von Neumann
Claude Shannon
Marvin Minsky
John McCarthy
Nathaniel Rochester
Allen Newell
Cliff Shaw
Herbert A  Simon
Oliver Selfridge
Frank Rosenblatt
Bernard Widrow
Joseph Weizenbaum
Seymour Papert
Seppo Linnainmaa
Paul Werbos
J rgen Schmidhuber
Yann LeCun
Geoffrey Hinton
John Hopfield
Yoshua Bengio
Lotfi A  Zadeh
Stephen Grossberg
Alex Graves
Andrew Ng
Fei Fei Li
Alex Krizhevsky
Ilya Sutskever
Demis Hassabis
David Silver
Ian Goodfellow
Andrej Karpathy
James Goodnight
Architectures
Neural Turing machine
Differentiable neural computer
Transformer
Vision transformer  ViT 
Recurrent neural network  RNN 
Long short term memory  LSTM 
Gated recurrent unit  GRU 
Echo state network
Multilayer perceptron  MLP 
Convolutional neural network  CNN 
Residual neural network  RNN 
Highway network
Mamba
Autoencoder
Variational autoencoder  VAE 
Generative adversarial network  GAN 
Graph neural network  GNN 

 Portals
Technology
 Category
Artificial neural networks
Machine learning
 List
Companies
Projects

vteComputer musicPeople
Marc Battier
Richard Boulanger
David Cope
John Chowning
Giuseppe di Giugno
Charles Dodge
Gottfried Michael Koenig
Paul Lansky
Max Mathews
G rard Pape
Miller Puckette
Roger Reynolds
Jean Claude Risset
Curtis Roads
Laurie Spiegel
The Hub
Trimpin
Barry Vercoe
Iannis Xenakis

Programs andinstruments
ChucK
Composers Desktop Project
Csound
FAUST
HMSL
Kyma
Laptop orchestra
Max MSP
MIDI controller
Music Mouse
Pure Data
MUSIC N
Radiodrum
Riffusion
Sonic Pi
SuperCollider
TidalCycles
UPIC
Places
Bell Labs
CCRMA
CEMAMu
Computer Music Center at Columbia
Experimental Music Studios
ICEM
ICMA
IRCAM
Center for New Music and Audio Technologies
Princeton Sound Lab
Oberlin TIMARA Labs
IEM
Techniques
Algorithmic composition
Artificial intelligence
Sound synthesis
Digital synthesis
Compositions
Illiac Suite
Mortuos Plango  Vivos Voco






Retrieved from  https   en wikipedia org w index php title Music and artificial intelligence amp oldid