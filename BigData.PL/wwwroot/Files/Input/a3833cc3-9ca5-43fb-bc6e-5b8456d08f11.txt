Machine learning technique
In deep learning  fine tuning is an approach to transfer learning in which the parameters of a pre trained neural network model are trained on new data             Fine tuning can be done on the entire neural network  or on only a subset of its layers  in which case the layers that are not being fine tuned are  frozen   i e   not changed during backpropagation              A model may also be augmented with  adapters  that consist of far fewer parameters than the original model  and fine tuned in a parameter efficient way by tuning the weights of the adapters and leaving the rest of the model s weights frozen            
For some architectures  such as convolutional neural networks  it is common to keep the earlier layers  those closest to the input layer  frozen  as they capture lower level features  while later layers often discern high level features that can be more related to the task that the model is trained on                       
Models that are pre trained on large  general corpora are usually fine tuned by reusing their parameters as a starting point and adding a task specific layer trained from scratch             Fine tuning the full model is also common and often yields better results  but is more computationally expensive            
Fine tuning is typically accomplished via supervised learning  but there are also techniques to fine tune a model using weak supervision             Fine tuning can be combined with a reinforcement learning from human feedback based objective to produce language models such as ChatGPT  a fine tuned version of GPT models  and Sparrow                       


Robustness edit 
Fine tuning can degrade a model s robustness to distribution shifts                          One mitigation is to linearly interpolate a fine tuned model s weights with the weights of the original model  which can greatly increase out of distribution performance while largely retaining the in distribution performance of the fine tuned model             

Variants edit 
Low rank adaptation edit 
Low rank adaptation  LoRA  is an adapter based technique for efficiently fine tuning models  The basic idea is to design a low rank matrix that is then added to the original matrix              An adapter  in this context  is a collection of low rank matrices which  when added to a base model  produces a fine tuned model  It allows for performance that approaches full model fine tuning with lower space requirements  A language model with billions of parameters may be LoRA fine tuned with only several millions of parameters 
LoRA based fine tuning has become popular in the Stable Diffusion community              Support for LoRA was integrated into the Diffusers library from Hugging Face              Support for LoRA and similar techniques is also available for a wide range of other models through Hugging Face s Parameter Efficient Fine Tuning  PEFT  package             

Representation fine tuning edit 
This section relies largely or entirely upon a single source  Relevant discussion may be found on the talk page  Please help improve this article by introducing citations to additional sources at this section Find sources        Representation fine tuning  ReFT               news        newspapers        books        scholar        JSTOR   May        Learn how and when to remove this message 
Representation fine tuning  ReFT  is a technique developed by researchers at Stanford University aimed at fine tuning large language models  LLMs  by modifying less than    of their representations  Unlike traditional parameter efficient fine tuning  PEFT  methods  which mainly focus on updating weights  ReFT targets specific parts of the model relevant to the task being fine tuned  This approach is based on the understanding that deep learning models encode rich semantic information in their representations  suggesting that modifying representations might be a more effective strategy than updating weights             
ReFT methods operate on a frozen base model and learn task specific interventions on hidden representations and train interventions that manipulate a small fraction of model representations to steer model behaviors towards solving downstream tasks at inference time  One specific method within the ReFT family is Low rank Linear Subspace ReFT  LoReFT   which intervenes on hidden representations in the linear subspace spanned by a low rank projection matrix              LoReFT can be seen as the representation based equivalent of Low rank Adaptation  LoRA  

Applications edit 
Natural language processing edit 
Fine tuning is common in natural language processing  NLP   especially in the domain of language modeling  Large language models like OpenAI s series of GPT foundation models can be fine tuned on data for specific downstream NLP tasks  tasks that use a pre trained model  to improve performance over the unmodified pre trained model            

Commercial models edit 
Commercially offered large language models can sometimes be fine tuned if the provider offers a fine tuning API  As of June           language model fine tuning APIs are offered by OpenAI and Microsoft Azure s Azure OpenAI Service for a subset of their models  as well as by Google Cloud Platform for some of their PaLM models  and by others                                     

See also edit 
Catastrophic forgetting
Continual learning
Domain adaptation
Foundation model
Hyperparameter optimization
Overfitting
References edit 


  Quinn  Joanne         Dive into deep learning  tools for engagement  Thousand Oaks  California  p            ISBN                         Archived from the original on January           Retrieved January            cite book     CS  maint  location missing publisher  link 

  a b  CS   n Convolutional Neural Networks for Visual Recognition   cs   n github io  Retrieved   March      

  Liu  Haokun  Tam  Derek  Muqeeth  Mohammed  Mohta  Jay  Huang  Tenghao  Bansal  Mohit  Raffel  Colin A         Koyejo  S   Mohamed  S   Agarwal  A   Belgrave  D   Cho  K   Oh  A   eds    Few Shot Parameter Efficient Fine Tuning is Better and Cheaper than In Context Learning  PDF   Advances in Neural Information Processing Systems  Vol           Curran Associates  Inc  pp                 

  Zeiler  Matthew D  Fergus  Rob          Visualizing and Understanding Convolutional Networks   ECCV  arXiv           

  Dodge  Jesse  Ilharco  Gabriel  Schwartz  Roy  Farhadi  Ali  Hajishirzi  Hannaneh  Smith  Noah          Fine Tuning Pretrained Language Models  Weight Initializations  Data Orders  and Early Stopping   arXiv               cite journal    Cite journal requires       journal   help 

  a b Dingliwal  Saket  Shenoy  Ashish  Bodapati  Sravan  Gandhe  Ankur  Gadde  Ravi Teja  Kirchhoff  Katrin          Prompt Tuning GPT   language model for parameter efficient domain adaptation of ASR systems   InterSpeech  arXiv            

  Yu  Yue  Zuo  Simiao  Jiang  Haoming  Ren  Wendi  Zhao  Tuo  Zhang  Chao          Fine Tuning Pre trained Language Model with Weak Supervision  A Contrastive Regularized Self Training Approach   Association for Computational Linguistics  arXiv            

   Introducing ChatGPT   openai com  Retrieved   March      

  Glaese  Amelia  McAleese  Nat  Tr bacz  Maja  Aslanides  John  Firoiu  Vlad  Ewalds  Timo  Rauh  Maribeth  Weidinger  Laura  Chadwick  Martin  Thacker  Phoebe  Campbell Gillingham  Lucy  Uesato  Jonathan  Huang  Po Sen  Comanescu  Ramona  Yang  Fan  See  Abigail  Dathathri  Sumanth  Greig  Rory  Chen  Charlie  Fritz  Doug  Elias  Jaume Sanchez  Green  Richard  Mokr   So a  Fernando  Nicholas  Wu  Boxi  Foley  Rachel  Young  Susannah  Gabriel  Iason  Isaac  William  Mellor  John  Hassabis  Demis  Kavukcuoglu  Koray  Hendricks  Lisa Anne  Irving  Geoffrey          Improving alignment of dialogue agents via targeted human judgements   DeepMind  arXiv            

  Radford  Alec  Kim  Jong Wook  Hallacy  Chris  Ramesh  Aditya  Goh  Gabriel  Agarwal  Sandhini  Sastry  Girish  Askell  Amanda  Mishkin  Pamela  Clark  Jack  Krueger  Gretchen  Sutskever  Ilya          Learning Transferable Visual Models From Natural Language Supervision   arXiv             cs CV  

  Kumar  Ananya  Raghunathan  Aditi  Jones  Robbie  Ma  Tengyu  Liang  Percy          Fine Tuning can Distort Pretrained Features and Underperform Out of Distribution   ICLR  arXiv            

  Wortsman  Mitchell  Ilharco  Gabriel  Kim  Jong Wook  Li  Mike  Kornblith  Simon  Roelofs  Rebecca  Gontijo Lopes  Raphael  Hajishirzi  Hannaneh  Farhadi  Ali  Namkoong  Hongseok  Schmidt  Ludwig          Robust fine tuning of zero shot models   arXiv             cs CV  

  Hu  Edward J   Shen  Yelong  Wallis  Phillip  Allen Zhu  Zeyuan  Li  Yuanzhi  Wang  Shean  Wang  Lu  Chen  Weizhu                LoRA  Low Rank Adaptation of Large Language Models   ICLR  arXiv            

  Ryu  Simo  February             Using Low rank adaptation to quickly fine tune diffusion models   GitHub  Retrieved June          

  Cuenca  Pedro  Paul  Sayak  January             Using LoRA for Efficient Stable Diffusion Fine Tuning   Hugging Face  Retrieved June          

   Parameter Efficient Fine Tuning using    PEFT   huggingface co  Retrieved            

  a b Wu  Zhengxuan  Arora  Aryaman  Wang  Zheng  Geiger  Atticus  Jurafsky  Dan  Manning  Christopher D   Potts  Christopher               ReFT  Representation Finetuning for Language Models  arXiv           

   Fine tuning   OpenAI  Retrieved            

   Learn how to customize a model for your application   Microsoft  Retrieved            

   Tune text foundation models   Retrieved            







Retrieved from  https   en wikipedia org w index php title Fine tuning  deep learning  amp oldid