Statistical Markov model

A hidden Markov model  HMM  is a Markov model in which the observations are dependent on a latent  or hidden  Markov process  referred to as 
  
    
      
        X
      
    
      displaystyle X 
  
   An HMM requires that there be an observable process 
  
    
      
        Y
      
    
      displaystyle Y 
  
 whose outcomes depend on the outcomes of 
  
    
      
        X
      
    
      displaystyle X 
  
 in a known way  Since 
  
    
      
        X
      
    
      displaystyle X 
  
 cannot be observed directly  the goal is to learn about state of 
  
    
      
        X
      
    
      displaystyle X 
  
 by observing 
  
    
      
        Y
      
    
      displaystyle Y 
  
  By definition of being a Markov model  an HMM has an additional requirement that the outcome of 
  
    
      
        Y
      
    
      displaystyle Y 
  
 at time 
  
    
      
        t
         
        
          t
          
             
          
        
      
    
      displaystyle t t     
  
 must be  influenced  exclusively by the outcome of 
  
    
      
        X
      
    
      displaystyle X 
  
 at 
  
    
      
        t
         
        
          t
          
             
          
        
      
    
      displaystyle t t     
  
 and that the outcomes of 
  
    
      
        X
      
    
      displaystyle X 
  
 and 
  
    
      
        Y
      
    
      displaystyle Y 
  
 at 
  
    
      
        t
         lt 
        
          t
          
             
          
        
      
    
      displaystyle t lt t     
  
 must be conditionally independent of 
  
    
      
        Y
      
    
      displaystyle Y 
  
 at 
  
    
      
        t
         
        
          t
          
             
          
        
      
    
      displaystyle t t     
  
 given 
  
    
      
        X
      
    
      displaystyle X 
  
 at time 
  
    
      
        t
         
        
          t
          
             
          
        
      
    
      displaystyle t t     
  
  Estimation of the parameters in an HMM can be performed using maximum likelihood estimation  For linear chain HMMs  the Baum Welch algorithm can be used to estimate parameters 
Hidden Markov models are known for their applications to thermodynamics  statistical mechanics  physics  chemistry  economics  finance  signal processing  information theory  pattern recognition such as speech             handwriting  gesture recognition             part of speech tagging  musical score following             partial discharges            and bioinformatics                       


Definition edit 
Let 
  
    
      
        
          X
          
            n
          
        
      
    
      displaystyle X  n  
  
 and 
  
    
      
        
          Y
          
            n
          
        
      
    
      displaystyle Y  n  
  
 be discrete time stochastic processes and 
  
    
      
        n
          x     
         
      
    
      displaystyle n geq   
  
  The pair 
  
    
      
         
        
          X
          
            n
          
        
         
        
          Y
          
            n
          
        
         
      
    
      displaystyle  X  n  Y  n   
  
 is a hidden Markov model if


  
    
      
        
          X
          
            n
          
        
      
    
      displaystyle X  n  
  
 is a Markov process whose behavior is not directly observable   hidden   

  
    
      
        
          
            P
          
        
          x     
        
          
             
          
        
        
          Y
          
            n
          
        
          x     
        A
          xa  
        
          
             
          
        
          xa  
        
          X
          
             
          
        
         
        
          x
          
             
          
        
         
          x     
         
        
          X
          
            n
          
        
         
        
          x
          
            n
          
        
        
          
             
          
        
         
        
          
            P
          
        
          x     
        
          
             
          
        
        
          Y
          
            n
          
        
          x     
        A
          xa  
        
          
             
          
        
          xa  
        
          X
          
            n
          
        
         
        
          x
          
            n
          
        
        
          
             
          
        
      
    
      displaystyle  operatorname   mathbf  P      bigl   Y  n  in A    bigl     X     x      ldots  X  n  x  n   bigr     operatorname   mathbf  P      bigl   Y  n  in A    bigl     X  n  x  n   bigr    
  
 
for every 
  
    
      
        n
          x     
         
      
    
      displaystyle n geq   
  
  
  
    
      
        
          x
          
             
          
        
         
          x     
         
        
          x
          
            n
          
        
      
    
      displaystyle x      ldots  x  n  
  
  and every Borel set 
  
    
      
        A
      
    
      displaystyle A 
  
 
Let 
  
    
      
        
          X
          
            t
          
        
      
    
      displaystyle X  t  
  
 and 
  
    
      
        
          Y
          
            t
          
        
      
    
      displaystyle Y  t  
  
 be continuous time stochastic processes  The pair 
  
    
      
         
        
          X
          
            t
          
        
         
        
          Y
          
            t
          
        
         
      
    
      displaystyle  X  t  Y  t   
  
 is a hidden Markov model if


  
    
      
        
          X
          
            t
          
        
      
    
      displaystyle X  t  
  
 is a Markov process whose behavior is not directly observable   hidden   

  
    
      
        
          
            P
          
        
          x     
         
        
          Y
          
            
              t
              
                 
              
            
          
        
          x     
        A
          x     
         
        
          X
          
            t
          
        
          x     
        
          B
          
            t
          
        
        
           
          
            t
              x     
            
              t
              
                 
              
            
          
        
         
         
        
          
            P
          
        
          x     
         
        
          Y
          
            
              t
              
                 
              
            
          
        
          x     
        A
          x     
        
          X
          
            
              t
              
                 
              
            
          
        
          x     
        
          B
          
            
              t
              
                 
              
            
          
        
         
      
    
      displaystyle  operatorname   mathbf  P     Y  t      in A mid   X  t  in B  t     t leq t        operatorname   mathbf  P     Y  t      in A mid X  t      in B  t       
  
 
for every 
  
    
      
        
          t
          
             
          
        
      
    
      displaystyle t     
  
  every Borel set 
  
    
      
        A
      
    
      displaystyle A 
  
  and every family of Borel sets 
  
    
      
         
        
          B
          
            t
          
        
        
           
          
            t
              x     
            
              t
              
                 
              
            
          
        
      
    
      displaystyle   B  t     t leq t      
  
 
Terminology edit 
The states of the process 
  
    
      
        
          X
          
            n
          
        
      
    
      displaystyle X  n  
  
  resp  
  
    
      
        
          X
          
            t
          
        
         
      
    
      displaystyle X  t   
  
 are called hidden states  and 
  
    
      
        
          
            P
          
        
          x     
        
          
             
          
        
        
          Y
          
            n
          
        
          x     
        A
          x     
        
          X
          
            n
          
        
         
        
          x
          
            n
          
        
        
          
             
          
        
      
    
      displaystyle  operatorname   mathbf  P      bigl   Y  n  in A mid X  n  x  n   bigr    
  
  resp  
  
    
      
        
          
            P
          
        
          x     
        
          
             
          
        
        
          Y
          
            t
          
        
          x     
        A
          x     
        
          X
          
            t
          
        
          x     
        
          B
          
            t
          
        
        
          
             
          
        
         
      
    
      displaystyle  operatorname   mathbf  P      bigl   Y  t  in A mid X  t  in B  t   bigr     
  
 is called emission probability or output probability 

Examples edit 
Drawing balls from hidden urns edit 
 Figure    Probabilistic parameters of a hidden Markov model  example  X   states y   possible observations a   state transition probabilities b   output probabilities
In its discrete form  a hidden Markov process can be visualized as a generalization of the urn problem with replacement  where each item from the urn is returned to the original urn before the next step              Consider this example  in a room that is not visible to an observer there is a genie  The room contains urns X   X   X       each of which contains a known mix of balls  with each ball having a unique label y   y   y         The genie chooses an urn in that room and randomly draws a ball from that urn  It then puts the ball onto a conveyor belt  where the observer can observe the sequence of the balls but not the sequence of urns from which they were drawn  The genie has some procedure to choose urns  the choice of the urn for the n th ball depends only upon a random number and the choice of the urn for the  n      th ball  The choice of urn does not directly depend on the urns chosen before this single previous urn  therefore  this is called a Markov process  It can be described by the upper part of Figure   
The Markov process cannot be observed  only the sequence of labeled balls  thus this arrangement is called a hidden Markov process  This is illustrated by the lower part of the diagram shown in Figure    where one can see that balls y   y   y   y  can be drawn at each state  Even if the observer knows the composition of the urns and has just observed a sequence of three balls  e g  y   y  and y  on the conveyor belt  the observer still cannot be sure which urn  i e   at which state  the genie has drawn the third ball from  However  the observer can work out other information  such as the likelihood that the third ball came from each of the urns 

Weather guessing game edit 
Consider two friends  Alice and Bob  who live far apart from each other and who talk together daily over the telephone about what they did that day  Bob is only interested in three activities  walking in the park  shopping  and cleaning his apartment  The choice of what to do is determined exclusively by the weather on a given day  Alice has no definite information about the weather  but she knows general trends  Based on what Bob tells her he did each day  Alice tries to guess what the weather must have been like 
Alice believes that the weather operates as a discrete Markov chain  There are two states   Rainy  and  Sunny   but she cannot observe them directly  that is  they are hidden from her  On each day  there is a certain chance that Bob will perform one of the following activities  depending on the weather   walk    shop   or  clean   Since Bob tells Alice about his activities  those are the observations  The entire system is that of a hidden Markov model  HMM  
Alice knows the general weather trends in the area  and what Bob likes to do on average  In other words  the parameters of the HMM are known  They can be represented as follows in Python 

states     quot Rainy quot    quot Sunny quot  

observations     quot walk quot    quot shop quot    quot clean quot  

start probability     quot Rainy quot         quot Sunny quot       

transition probability    
     quot Rainy quot     quot Rainy quot         quot Sunny quot        
     quot Sunny quot     quot Rainy quot         quot Sunny quot        
 

emission probability    
     quot Rainy quot     quot walk quot         quot shop quot         quot clean quot        
     quot Sunny quot     quot walk quot         quot shop quot         quot clean quot        
 

In this piece of code  start probability represents Alice s belief about which state the HMM is in when Bob first calls her  all she knows is that it tends to be rainy on average   The particular probability distribution used here is not the equilibrium one  which is  given the transition probabilities  approximately   Rainy          Sunny          The transition probability represents the change of the weather in the underlying Markov chain  In this example  there is only a     chance that tomorrow will be sunny if today is rainy  The emission probability represents how likely Bob is to perform a certain activity on each day  If it is rainy  there is a     chance that he is cleaning his apartment  if it is sunny  there is a     chance that he is outside for a walk 

Graphical representation of the given HMM
A similar example is further elaborated in the Viterbi algorithm page 

Structural architecture edit 
The diagram below shows the general architecture of an instantiated HMM  Each oval shape represents a random variable that can adopt any of a number of values  The random variable x t  is the hidden state at time t  with the model from the above diagram  x t      x   x   x      The random variable y t  is the observation at time t  with y t      y   y   y   y      The arrows in the diagram  often called a trellis diagram  denote conditional dependencies 
From the diagram  it is clear that the conditional probability distribution of the hidden variable x t  at time t  given the values of the hidden variable x at all times  depends only on the value of the hidden variable x t       the values at time t     and before have no influence  This is called the Markov property  Similarly  the value of the observed variable y t  depends on only the value of the hidden variable x t   both at time t  
In the standard type of hidden Markov model considered here  the state space of the hidden variables is discrete  while the observations themselves can either be discrete  typically generated from a categorical distribution  or continuous  typically from a Gaussian distribution   The parameters of a hidden Markov model are of two types  transition probabilities and emission probabilities  also known as output probabilities   The transition probabilities control the way the hidden state at time t is chosen given the hidden state at time 
  
    
      
        t
          x     
         
      
    
      displaystyle t   
  
 
The hidden state space is assumed to consist of one of N possible values  modelled as a categorical distribution   See the section below on extensions for other possibilities   This means that for each of the N possible states that a hidden variable at time t can be in  there is a transition probability from this state to each of the N possible states of the hidden variable at time 
  
    
      
        t
         
         
      
    
      displaystyle t   
  
  for a total of 
  
    
      
        
          N
          
             
          
        
      
    
      displaystyle N     
  
 transition probabilities  The set of transition probabilities for transitions from any given state must sum to    Thus  the 
  
    
      
        N
          xd  
        N
      
    
      displaystyle N times N 
  
 matrix of transition probabilities is a Markov matrix  Because any transition probability can be determined once the others are known  there are a total of 
  
    
      
        N
         
        N
          x     
         
         
      
    
      displaystyle N N    
  
 transition parameters 
In addition  for each of the N possible states  there is a set of emission probabilities governing the distribution of the observed variable at a particular time given the state of the hidden variable at that time  The size of this set depends on the nature of the observed variable  For example  if the observed variable is discrete with M possible values  governed by a categorical distribution  there will be 
  
    
      
        M
          x     
         
      
    
      displaystyle M   
  
 separate parameters  for a total of 
  
    
      
        N
         
        M
          x     
         
         
      
    
      displaystyle N M    
  
 emission parameters over all hidden states  On the other hand  if the observed variable is an M dimensional vector distributed according to an arbitrary multivariate Gaussian distribution  there will be M parameters controlling the means and 
  
    
      
        
          
            
              M
               
              M
               
               
               
            
             
          
        
      
    
      displaystyle   frac  M M         
  
 parameters controlling the covariance matrix  for a total of 
  
    
      
        N
        
           
          
            M
             
            
              
                
                  M
                   
                  M
                   
                   
                   
                
                 
              
            
          
           
        
         
        
          
            
              N
              M
               
              M
               
               
               
            
             
          
        
         
        O
         
        N
        
          M
          
             
          
        
         
      
    
      displaystyle N left M   frac  M M         right    frac  NM M         O NM      
  
 emission parameters   In such a case  unless the value of M is small  it may be more practical to restrict the nature of the covariances between individual elements of the observation vector  e g  by assuming that the elements are independent of each other  or less restrictively  are independent of all but a fixed number of adjacent elements  

Temporal evolution of a hidden Markov model
Inference edit 
The state transition and output probabilities of an HMM are indicated by the line opacity in the upper part of the diagram  Given that the output sequence is observed in the lower part of the diagram  interest occurs in the most likely sequence of states that could have produced it  Based on the arrows that are present in the diagram  the following state sequences are candidates                                      The most likely sequence can be found by evaluating the joint probability of both the state sequence and the observations for each case  simply by multiplying the probability values  which here correspond to the opacities of the arrows involved   In general  this type of problem  i e   finding the most likely explanation for an observation sequence  can be solved efficiently using the Viterbi algorithm 
Several inference problems are associated with hidden Markov models  as outlined below 

Probability of an observed sequence edit 
The task is to compute in a best way  given the parameters of the model  the probability of a particular output sequence  This requires summation over all possible state sequences 
The probability of observing a sequence


  
    
      
        Y
         
        y
         
         
         
         
        y
         
         
         
         
          x     
         
        y
         
        L
          x     
         
         
         
      
    
      displaystyle Y y    y     dots  y L     
  

of length L is given by


  
    
      
        P
         
        Y
         
         
        
            x     
          
            X
          
        
        P
         
        Y
          x     
        X
         
        P
         
        X
         
         
      
    
      displaystyle P Y   sum   X P Y mid X P X   
  

where the sum runs over all possible hidden node sequences


  
    
      
        X
         
        x
         
         
         
         
        x
         
         
         
         
          x     
         
        x
         
        L
          x     
         
         
         
      
    
      displaystyle X x    x     dots  x L     
  

Applying the principle of dynamic programming  this problem  too  can be handled efficiently using the forward algorithm 

Probability of the latent variables edit 
A number of related tasks ask about the probability of one or more of the latent variables  given the model s parameters and a sequence of observations 
  
    
      
        y
         
         
         
         
          x     
         
        y
         
        t
         
      
    
      displaystyle y     dots  y t  
  
 

Filtering edit 
The task is to compute  given the model s parameters and a sequence of observations  the distribution over hidden states of the last latent variable at the end of the sequence  i e  to compute 
  
    
      
        P
         
        x
         
        t
         
          x     
        y
         
         
         
         
          x     
         
        y
         
        t
         
         
      
    
      displaystyle P x t  mid y     dots  y t   
  
  This task is used when the sequence of latent variables is thought of as the underlying states that a process moves through at a sequence of points in time  with corresponding observations at each point  Then  it is natural to ask about the state of the process at the end 
This problem can be handled efficiently using the forward algorithm  An example is when the algorithm is applied to a Hidden Markov Network to determine 
  
    
      
        
          P
        
        
          
             
          
        
        
          h
          
            t
          
        
          x     
        
          v
          
             
             
            t
          
        
        
          
             
          
        
      
    
      displaystyle  mathrm  P    big   h  t  mid v    t   big    
  
 

Smoothing edit 
This is similar to filtering but asks about the distribution of a latent variable somewhere in the middle of a sequence  i e  to compute 
  
    
      
        P
         
        x
         
        k
         
          x     
        y
         
         
         
         
          x     
         
        y
         
        t
         
         
      
    
      displaystyle P x k  mid y     dots  y t   
  
 for some 
  
    
      
        k
         lt 
        t
      
    
      displaystyle k lt t 
  
  From the perspective described above  this can be thought of as the probability distribution over hidden states for a point in time k in the past  relative to time t 
The forward backward algorithm is a good method for computing the smoothed values for all hidden state variables 

Most likely explanation edit 
The task  unlike the previous two  asks about the joint probability of the entire sequence of hidden states that generated a particular sequence of observations  see illustration on the right   This task is generally applicable when HMM s are applied to different sorts of problems from those for which the tasks of filtering and smoothing are applicable  An example is part of speech tagging  where the hidden states represent the underlying parts of speech corresponding to an observed sequence of words  In this case  what is of interest is the entire sequence of parts of speech  rather than simply the part of speech for a single word  as filtering or smoothing would compute 
This task requires finding a maximum over all possible state sequences  and can be solved efficiently by the Viterbi algorithm 

Statistical significance edit 
For some of the above problems  it may also be interesting to ask about statistical significance  What is the probability that a sequence drawn from some null distribution will have an HMM probability  in the case of the forward algorithm  or a maximum state sequence probability  in the case of the Viterbi algorithm  at least as large as that of a particular output sequence              When an HMM is used to evaluate the relevance of a hypothesis for a particular output sequence  the statistical significance indicates the false positive rate associated with failing to reject the hypothesis for the output sequence 

Learning edit 
The parameter learning task in HMMs is to find  given an output sequence or a set of such sequences  the best set of state transition and emission probabilities  The task is usually to derive the maximum likelihood estimate of the parameters of the HMM given the set of output sequences  No tractable algorithm is known for solving this problem exactly  but a local maximum likelihood can be derived efficiently using the Baum Welch algorithm or the Baldi Chauvin algorithm  The Baum Welch algorithm is a special case of the expectation maximization algorithm  
If the HMMs are used for time series prediction  more sophisticated Bayesian inference methods  like Markov chain Monte Carlo  MCMC  sampling are proven to be favorable over finding a single maximum likelihood model both in terms of accuracy and stability             Since MCMC imposes significant computational burden  in cases where computational scalability is also of interest  one may alternatively resort to variational approximations to Bayesian inference  e g              Indeed  approximate variational inference offers computational efficiency comparable to expectation maximization  while yielding an accuracy profile only slightly inferior to exact MCMC type Bayesian inference 

Applications edit 
A profile HMM modelling a multiple sequence alignment of proteins in Pfam
HMMs can be applied in many fields where the goal is to recover a data sequence that is not immediately observable  but other data that depend on the sequence are   Applications include 

Computational finance                        
Single molecule kinetic analysis            
Neuroscience                        
Cryptanalysis
Speech recognition  including Siri            
Speech synthesis
Part of speech tagging
Document separation in scanning solutions
Machine translation
Partial discharge
Gene prediction
Handwriting recognition            
Alignment of bio sequences
Time series analysis
Activity recognition
Protein folding            
Sequence classification            
Metamorphic virus detection            
Sequence motif discovery  DNA and proteins             
DNA hybridization kinetics                        
Chromatin state discovery            
Transportation forecasting            
Solar irradiance variability                                    
History edit 
Hidden Markov models were described in a series of statistical papers by Leonard E  Baum and other authors in the second half of the     s                                                              One of the first applications of HMMs was speech recognition  starting in the mid     s                                                  From the linguistics point of view  hidden Markov models are equivalent to stochastic regular grammar             
In the second half of the     s  HMMs began to be applied to the analysis of biological sequences              in particular DNA  Since then  they have become ubiquitous in the field of bioinformatics             

Extensions edit 
General state spaces edit 
In the hidden Markov models considered above  the state space of the hidden variables is discrete  while the observations themselves can either be discrete  typically generated from a categorical distribution  or continuous  typically from a Gaussian distribution   Hidden Markov models can also be generalized to allow continuous state spaces  Examples of such models are those where the Markov process over hidden variables is a linear dynamical system  with a linear relationship among related variables and where all hidden and observed variables follow a Gaussian distribution  In simple cases  such as the linear dynamical system just mentioned  exact inference is tractable  in this case  using the Kalman filter   however  in general  exact inference in HMMs with continuous latent variables is infeasible  and approximate methods must be used  such as the extended Kalman filter or the particle filter 
Nowadays  inference in hidden Markov models is performed in nonparametric settings  where the dependency structure enables  identifiability of the model             and the learnability limits are still under exploration             

Bayesian modeling of the transitions probabilities edit 
Hidden Markov models are generative models  in which the joint distribution of observations and hidden states  or equivalently both the prior distribution of hidden states  the transition probabilities  and conditional distribution of observations given states  the emission probabilities   is modeled  The above algorithms implicitly assume a uniform prior distribution over the transition probabilities  However  it is also possible to create hidden Markov models with other types of prior distributions  An obvious candidate  given the categorical distribution of the transition probabilities  is the Dirichlet distribution  which is the conjugate prior distribution of the categorical distribution  Typically  a symmetric Dirichlet distribution is chosen  reflecting ignorance about which states are inherently more likely than others  The single parameter of this distribution  termed the concentration parameter  controls the relative density or sparseness of the resulting transition matrix  A choice of   yields a uniform distribution  Values greater than   produce a dense matrix  in which the transition probabilities between pairs of states are likely to be nearly equal  Values less than   result in a sparse matrix in which  for each given source state  only a small number of destination states have non negligible transition probabilities  It is also possible to use a two level prior Dirichlet distribution  in which one Dirichlet distribution  the upper distribution  governs the parameters of another Dirichlet distribution  the lower distribution   which in turn governs the transition probabilities  The upper distribution governs the overall distribution of states  determining how likely each state is to occur  its concentration parameter determines the density or sparseness of states  Such a two level prior distribution  where both concentration parameters are set to produce sparse distributions  might be useful for example in unsupervised part of speech tagging  where some parts of speech occur much more commonly than others  learning algorithms that assume a uniform prior distribution generally perform poorly on this task  The parameters of models of this sort  with non uniform prior distributions  can be learned using Gibbs sampling or extended versions of the expectation maximization algorithm 
An extension of the previously described hidden Markov models with Dirichlet priors uses a Dirichlet process in place of a Dirichlet distribution  This type of model allows for an unknown and potentially infinite number of states  It is common to use a two level Dirichlet process  similar to the previously described model with two levels of Dirichlet distributions  Such a model is called a hierarchical Dirichlet process hidden Markov model  or HDP HMM for short  It was originally described under the name  Infinite Hidden Markov Model              and was further formalized in  Hierarchical Dirichlet Processes              

Discriminative approach edit 
A different type of extension uses a discriminative model in place of the generative model of standard HMMs  This type of model directly models the conditional distribution of the hidden states given the observations  rather than modeling the joint distribution  An example of this model is the so called maximum entropy Markov model  MEMM   which models the conditional distribution of the states using logistic regression  also known as a  maximum entropy model    The advantage of this type of model is that arbitrary features  i e  functions  of the observations can be modeled  allowing domain specific knowledge of the problem at hand to be injected into the model  Models of this sort are not limited to modeling direct dependencies between a hidden state and its associated observation  rather  features of nearby observations  of combinations of the associated observation and nearby observations  or in fact of arbitrary observations at any distance from a given hidden state can be included in the process used to determine the value of a hidden state  Furthermore  there is no need for these features to be statistically independent of each other  as would be the case if such features were used in a generative model  Finally  arbitrary features over pairs of adjacent hidden states can be used rather than simple transition probabilities  The disadvantages of such models are      The types of prior distributions that can be placed on hidden states are severely limited      It is not possible to predict the probability of seeing an arbitrary observation  This second limitation is often not an issue in practice  since many common usages of HMM s do not require such predictive probabilities 
A variant of the previously described discriminative model is the linear chain conditional random field  This uses an undirected graphical model  aka Markov random field  rather than the directed graphical models of MEMM s and similar models  The advantage of this type of model is that it does not suffer from the so called label bias problem of MEMM s  and thus may make more accurate predictions  The disadvantage is that training can be slower than for MEMM s 

Other extensions edit 
Yet another variant is the factorial hidden Markov model  which allows for a single observation to be conditioned on the corresponding hidden variables of a set of 
  
    
      
        K
      
    
      displaystyle K 
  
 independent Markov chains  rather than a single Markov chain  It is equivalent to a single HMM  with 
  
    
      
        
          N
          
            K
          
        
      
    
      displaystyle N  K  
  
 states  assuming there are 
  
    
      
        N
      
    
      displaystyle N 
  
 states for each chain   and therefore  learning in such a model is difficult  for a sequence of length 
  
    
      
        T
      
    
      displaystyle T 
  
  a straightforward Viterbi algorithm has complexity 
  
    
      
        O
         
        
          N
          
             
            K
          
        
        
        T
         
      
    
      displaystyle O N   K   T  
  
  To find an exact solution  a junction tree algorithm could be used  but it results in an 
  
    
      
        O
         
        
          N
          
            K
             
             
          
        
        
        K
        
        T
         
      
    
      displaystyle O N  K     K  T  
  
 complexity  In practice  approximate techniques  such as variational approaches  could be used             
All of the above models can be extended to allow for more distant dependencies among hidden states  e g  allowing for a given state to be dependent on the previous two or three states rather than a single previous state  i e  the transition probabilities are extended to encompass sets of three or four adjacent states  or in general 
  
    
      
        K
      
    
      displaystyle K 
  
 adjacent states   The disadvantage of such models is that dynamic programming algorithms for training them have an 
  
    
      
        O
         
        
          N
          
            K
          
        
        
        T
         
      
    
      displaystyle O N  K   T  
  
 running time  for 
  
    
      
        K
      
    
      displaystyle K 
  
 adjacent states and 
  
    
      
        T
      
    
      displaystyle T 
  
 total observations  i e  a length 
  
    
      
        T
      
    
      displaystyle T 
  
 Markov chain   This extension has been widely used in bioinformatics  in the modeling of DNA sequences 
Another recent extension is the triplet Markov model              in which an auxiliary underlying process is added to model some data specificities  Many variants of this model have been proposed  One should also mention the interesting link that has been established between the theory of evidence and the triplet Markov models             and which allows to fuse data in Markovian context             and to model nonstationary data                          Alternative multi stream data fusion strategies have also been proposed in recent literature  e g              
Finally  a different rationale towards addressing the problem of modeling nonstationary data by means of hidden Markov models was suggested in                   It consists in employing a small recurrent neural network  RNN   specifically a reservoir network              to capture the evolution of the temporal dynamics in the observed data  This information  encoded in the form of a high dimensional vector  is used as a conditioning variable of the HMM state transition probabilities  Under such a setup  eventually is obtained a nonstationary HMM  the transition probabilities of which evolve over time in a manner that is inferred from the data  in contrast to some unrealistic ad hoc model of temporal evolution 
In       two innovative algorithms were introduced for the Hidden Markov Model  These algorithms enable the computation of the posterior distribution of the HMM without the necessity of explicitly modeling the joint distribution  utilizing only the conditional distributions                          Unlike traditional methods such as the Forward Backward and Viterbi algorithms  which require knowledge of the joint law of the HMM and can be computationally intensive to learn  the Discriminative Forward Backward and Discriminative Viterbi algorithms circumvent the need for the observation s law                          This breakthrough allows the HMM to be applied as a discriminative model  offering a more efficient and versatile approach to leveraging Hidden Markov Models in various applications 
The model suitable in the context of longitudinal data is named      latent Markov model              The basic version of this model has been extended to include individual covariates  random effects and to model more complex data structures such as multilevel data  A complete overview of the latent Markov models  with special attention to the model assumptions and  to their practical use is provided in            

Measure theory edit 
See also  Subshift of finite type
The hidden part of a hidden Markov model  whose observable states is non Markovian 
Given a Markov transition matrix and an invariant distribution on the states  a probability measure can be imposed on the set of subshifts  For example  consider the Markov chain given on the left on the states 
  
    
      
        A
         
        
          B
          
             
          
        
         
        
          B
          
             
          
        
      
    
      displaystyle A B     B     
  
  with invariant distribution 
  
    
      
          x c  
         
         
         
        
           
        
         
         
         
        
           
        
         
         
         
        
           
        
         
         
      
    
      displaystyle  pi                
  
  By ignoring the distinction between 
  
    
      
        
          B
          
             
          
        
         
        
          B
          
             
          
        
      
    
      displaystyle B     B     
  
  this space of subshifts is projected on 
  
    
      
        A
         
        
          B
          
             
          
        
         
        
          B
          
             
          
        
      
    
      displaystyle A B     B     
  
 into another space of subshifts on 
  
    
      
        A
         
        B
      
    
      displaystyle A B 
  
  and this projection also projects the probability measure down to a probability measure on the subshifts on 
  
    
      
        A
         
        B
      
    
      displaystyle A B 
  
 
The curious thing is that the probability measure on the subshifts on 
  
    
      
        A
         
        B
      
    
      displaystyle A B 
  
 is not created by a Markov chain on 
  
    
      
        A
         
        B
      
    
      displaystyle A B 
  
  not even multiple orders  Intuitively  this is because if one observes a long sequence of 
  
    
      
        
          B
          
            n
          
        
      
    
      displaystyle B  n  
  
  then one would become increasingly sure that the 
  
    
      
        Pr
         
        A
          x     
        
          B
          
            n
          
        
         
          x     
        
          
             
             
          
        
      
    
      displaystyle  Pr A mid B  n   to   frac         
  
  meaning that the observable part of the system can be affected by something infinitely in the past                         
Conversely  there exists a space of subshifts on   symbols  projected to subshifts on   symbols  such that any Markov measure on the smaller subshift has a preimage measure that is not Markov of any order  example                  

See also edit 

Andrey Markov
Baum Welch algorithm
Bayesian inference
Bayesian programming
Richard James Boys
Conditional random field
Estimation theory
HH suite  HHpred  HHsearch  free server and software for protein sequence searching
HMMER  a free hidden Markov model program for protein sequence analysis
Hidden Bernoulli model
Hidden semi Markov model
Hierarchical hidden Markov model
Layered hidden Markov model
Sequential dynamical system
Stochastic context free grammar
Time series analysis
Variable order Markov model
Viterbi algorithm

References edit 


   Google Scholar  

  Thad Starner  Alex Pentland  Real Time American Sign Language Visual Recognition From Video Using Hidden Markov Models  Master s Thesis  MIT  Feb       Program in Media Arts

  B  Pardo and W  Birmingham  Modeling Form for On line Following of Musical Performances Archived            at the Wayback Machine  AAAI    Proc   July      

  Satish L  Gururaj BI  April         Use of hidden Markov models for partial discharge pattern classification   IEEE Transactions on Dielectrics and Electrical Insulation 

  Li  N  Stephens  M  December         Modeling linkage disequilibrium and identifying recombination hotspots using single nucleotide polymorphism data   Genetics                    doi         genetics             PMC               PMID               

  Ernst  Jason  Kellis  Manolis  March         ChromHMM  automating chromatin state discovery and characterization   Nature Methods                  doi         nmeth       PMC               PMID               

  Lawrence R  Rabiner  February         A tutorial on Hidden Markov Models and selected applications in speech recognition   PDF   Proceedings of the IEEE                   CiteSeerX                       doi                  S CID                   

  Newberg  L           Error statistics of hidden Markov model and hidden Boltzmann model results   BMC Bioinformatics           doi                           PMC               PMID                

  Sipos  I  R bert  Parallel stratified MCMC sampling of AR HMMs for stochastic time series prediction  In  Proceedings   th Stochastic Modeling Techniques and Data Analysis International Conference with Demographics Workshop  SMTDA       pp           Valletta        PDF

  Chatzis  Sotirios P   Kosmopoulos  Dimitrios I           A variational Bayesian methodology for hidden Markov models utilizing Student s t mixtures   PDF   Pattern Recognition                   Bibcode     PatRe         C  CiteSeerX                       doi         j patcog              Archived from the original  PDF  on             Retrieved            

  Sipos  I  R bert  Ceffer  Attila  Levendovszky  J nos          Parallel Optimization of Sparse Portfolios with AR HMMs   Computational Economics                   doi         s               y  S CID               

  Petropoulos  Anastasios  Chatzis  Sotirios P   Xanthopoulos  Stylianos          A novel corporate credit rating system based on Student s t hidden Markov models   Expert Systems with Applications              doi         j eswa             

  Nicolai  Christopher          Solving Ion Channel Kinetics with the QuB Software   Biophysical Reviews and Letters      n              doi         S                 

  Higgins  Cameron  Vidaurre  Diego  Kolling  Nils  Liu  Yunzhe  Behrens  Tim  Woolrich  Mark          Spatiotemporally Resolved Multivariate Pattern Analysis for M EEG   Human Brain Mapping                      doi         hbm        PMC               PMID               

  Diomedi  S   Vaccari  F  E   Galletti  C   Hadjidimitrakis  K   Fattori  P                 Motor like neural dynamics in two parietal areas during arm reaching   Progress in Neurobiology               doi         j pneurobio              hdl               ISSN                 PMID                S CID                

  Domingos  Pedro         The Master Algorithm  How the Quest for the Ultimate Learning Machine Will Remake Our World  Basic Books  p           ISBN                    

  Kundu  Amlan  Yang He  and Paramvir Bahl   Recognition of handwritten word  first and second order hidden Markov model based approach     dead link        Pattern recognition                      

  Stigler  J   Ziegler  F   Gieseke  A   Gebhardt  J  C  M   Rief  M           The Complex Folding Network of Single Calmodulin Molecules   Science                       Bibcode     Sci           S  doi         science          PMID                S CID              

  Blasiak  S   Rangwala  H           A Hidden Markov Model Variant for Sequence Classification   IJCAI Proceedings International Joint Conference on Artificial Intelligence           

  Wong  W   Stamp  M           Hunting for metamorphic engines   Journal in Computer Virology                  doi         s                  S CID              

  Wong  K   C   Chan  T   M   Peng  C   Li  Y   Zhang  Z           DNA motif elucidation using belief propagation   Nucleic Acids Research           e     doi         nar gkt     PMC               PMID               

  Shah  Shalin  Dubey  Abhishek K   Reif  John                Improved Optical Multiplexing with Temporal DNA Barcodes   ACS Synthetic Biology                    doi         acssynbio  b       PMID                S CID               

  Shah  Shalin  Dubey  Abhishek K   Reif  John                Programming Temporal DNA Barcodes for Single Molecule Fingerprinting   Nano Letters                     Bibcode     NanoL         S  doi         acs nanolett  b       ISSN                 PMID                S CID               

   ChromHMM  Chromatin state discovery and characterization   compbio mit edu  Retrieved            

  El Zarwi  Feraz  May         Modeling and Forecasting the Evolution of Preferences over Time  A Hidden Markov Model of Travel Behavior   arXiv             stat AP  

  Morf  H   Feb         The stochastic two state solar irradiance model  STSIM    Solar Energy                   Bibcode     SoEn          M  doi         S        X            

  Munkhammar  J   Wid n  J   Aug         A Markov chain probability distribution mixture approach to the clear sky index   Solar Energy                Bibcode     SoEn          M  doi         j solener              S CID                

  Munkhammar  J   Wid n  J   Oct         An N state Markov chain mixture distribution model of the clear sky index   Solar Energy                Bibcode     SoEn          M  doi         j solener              S CID                

  Baum  L  E   Petrie  T           Statistical Inference for Probabilistic Functions of Finite State Markov Chains   The Annals of Mathematical Statistics                     doi         aoms            

  Baum  L  E   Eagon  J  A           An inequality with applications to statistical estimation for probabilistic functions of Markov processes and to a model for ecology   Bulletin of the American Mathematical Society               doi         S                        Zbl                 

  Baum  L  E   Sell  G  R           Growth transformations for functions on manifolds   Pacific Journal of Mathematics                   doi         pjm             

  Baum  L  E   Petrie  T   Soules  G   Weiss  N           A Maximization Technique Occurring in the Statistical Analysis of Probabilistic Functions of Markov Chains   The Annals of Mathematical Statistics                   doi         aoms             JSTOR               MR               Zbl                 

  Baum  L E           An Inequality and Associated Maximization Technique in Statistical Estimation of Probabilistic Functions of a Markov Process   Inequalities         

  Baker  J           The DRAGON system An overview   IEEE Transactions on Acoustics  Speech  and Signal Processing             doi         TASSP              

  Jelinek  F   Bahl  L   Mercer  R           Design of a linguistic statistical decoder for the recognition of continuous speech   IEEE Transactions on Information Theory               doi         TIT              

  Xuedong Huang  M  Jack  Y  Ariki         Hidden Markov Models for Speech Recognition  Edinburgh University Press  ISBN                        

  Xuedong Huang  Alex Acero  Hsiao Wuen Hon         Spoken Language Processing  Prentice Hall  ISBN                        

  Carrasco  Rafael C   Oncina  Jose          Learning stochastic regular grammars by means of a state merging method   In Carrasco  Rafael C   Oncina  Jose  eds    Grammatical Inference and Applications  Lecture Notes in Computer Science  Vol            Berlin  Heidelberg  Springer  pp                doi                            ISBN                        

  M  Bishop and E  Thompson          Maximum Likelihood Alignment of DNA Sequences   Journal of Molecular Biology                    doi                               PMID                subscription required  

  Durbin  Richard M   Eddy  Sean R   Krogh  Anders  Mitchison  Graeme         Biological Sequence Analysis  Probabilistic Models of Proteins and Nucleic Acids   st      ed    Cambridge  New York  Cambridge University Press  ISBN                     OCLC               

  Gassiat  E   Cleynen  A   Robin  S                 Inference in finite state space non parametric Hidden Markov Models and applications   Statistics and Computing                 doi         s                  ISSN                

  Abraham  Kweku  Gassiat  Elisabeth  Naulet  Zacharie  March         Fundamental Limits for Learning Hidden Markov Model Parameters   IEEE Transactions on Information Theory                     arXiv             doi         TIT               ISSN                

  Beal  Matthew J   Zoubin Ghahramani  and Carl Edward Rasmussen   The infinite hidden Markov model   Advances in neural information processing systems                    

  Teh  Yee Whye  et al   Hierarchical dirichlet processes   Journal of the American Statistical Association                

  Ghahramani  Zoubin  Jordan  Michael I           Factorial Hidden Markov Models   Machine Learning                     doi         A               

  Pieczynski  Wojciech          Cha  nes de Markov Triplet   PDF   Comptes Rendus Math matique                    doi         S        X            

  Pieczynski  Wojciech          Multisensor triplet Markov chains and theory of evidence   International Journal of Approximate Reasoning            doi         j ijar             

  Boudaren et al  Archived            at the Wayback Machine  M  Y  Boudaren  E  Monfrini  W  Pieczynski  and A  Aissani  Dempster Shafer fusion of multisensor signals in nonstationary Markovian context  EURASIP Journal on Advances in Signal Processing  No            

  Lanchantin et al   P  Lanchantin and W  Pieczynski  Unsupervised restoration of hidden non stationary Markov chain using evidential priors  IEEE Transactions on Signal Processing  Vol      No     pp                  

  Boudaren et al   M  Y  Boudaren  E  Monfrini  and W  Pieczynski  Unsupervised segmentation of random discrete data hidden with switching noise distributions  IEEE Signal Processing Letters  Vol      No      pp           October      

  Sotirios P  Chatzis  Dimitrios Kosmopoulos   Visual Workflow Recognition Using a Variational Bayesian Treatment of Multistream Fused Hidden Markov Models   IEEE Transactions on Circuits and Systems for Video Technology  vol      no     pp             July      

  Chatzis  Sotirios P   Demiris  Yiannis          A Reservoir Driven Non Stationary Hidden Markov Model   Pattern Recognition                      Bibcode     PatRe         C  doi         j patcog              hdl               

  M  Lukosevicius  H  Jaeger        Reservoir computing approaches to recurrent neural network training  Computer Science Review            

  Azeraf  E   Monfrini  E    amp  Pieczynski  W          Equivalence between LC CRF and HMM  and Discriminative Computing of HMM Based MPM and MAP  Algorithms             

  Azeraf  E   Monfrini  E   Vignon  E    amp  Pieczynski  W          Hidden markov chains  entropic forward backward  and part of speech tagging  arXiv preprint arXiv            

  Azeraf  E   Monfrini  E    amp  Pieczynski  W          Deriving discriminative classifiers from generative models  arXiv preprint arXiv            

  Ng  A    amp  Jordan  M          On discriminative vs  generative classifiers  A comparison of logistic regression and naive bayes  Advances in neural information processing systems     

  Wiggins  L  M          Panel Analysis  Latent Probability Models for Attitude and Behaviour Processes  Amsterdam  Elsevier 

  Bartolucci  F   Farcomeni  A   Pennoni  F          Latent Markov models for longitudinal data  Boca Raton  Chapman and Hall CRC  ISBN                        

  Sofic Measures  Characterizations of Hidden Markov Chains by Linear Algebra  Formal Languages  and Symbolic Dynamics   Karl Petersen  Mathematics      Spring       University of North Carolina at Chapel Hill

  a b Boyle  Mike  Petersen  Karl               Hidden Markov processes in the context of symbolic dynamics  arXiv          


External links edit 



Wikimedia Commons has media related to Hidden Markov Model 

Concepts edit 
Teif  V  B   Rippe  K           Statistical mechanical lattice models for protein DNA binding in chromatin   J  Phys   Condens  Matter                   arXiv            Bibcode     JPCM     O    T  doi                                 PMID                S CID             
A Revealing Introduction to Hidden Markov Models by Mark Stamp  San Jose State University 
Fitting HMM s with expectation maximization   complete derivation
A step by step tutorial on HMMs Archived            at the Wayback Machine  University of Leeds 
Hidden Markov Models  an exposition using basic mathematics 
Hidden Markov Models  by Narada Warakagoda 
Hidden Markov Models  Fundamentals and Applications Part    Part    by V  Petrushin 
Lecture on a Spreadsheet by Jason Eisner  Video and interactive spreadsheet
vteStochastic processesDiscrete time
Bernoulli process
Branching process
Chinese restaurant process
Galton Watson process
Independent and identically distributed random variables
Markov chain
Moran process
Random walk
Loop erased
Self avoiding
 Biased
Maximal entropy
Continuous time
Additive process
Bessel process
Birth death process
pure birth
Brownian motion
Bridge
Excursion
Fractional
Geometric
Meander
Cauchy process
Contact process
Continuous time random walk
Cox process
Diffusion process
Dyson Brownian motion
Empirical process
Feller process
Fleming Viot process
Gamma process
Geometric process
Hawkes process
Hunt process
Interacting particle systems
It  diffusion
It  process
Jump diffusion
Jump process
L vy process
Local time
Markov additive process
McKean Vlasov process
Ornstein Uhlenbeck process
Poisson process
Compound
Non homogeneous
Quasimartingale
Schramm Loewner evolution
Semimartingale
Sigma martingale
Stable process
Superprocess
Telegraph process
Variance gamma process
Wiener process
Wiener sausage
Both
Branching process
Gaussian process
Hidden Markov model  HMM 
Markov process
Martingale
Differences
Local
Sub 
Super 
Random dynamical system
Regenerative process
Renewal process
Stochastic chains with memory of variable length
White noise
Fields and other
Dirichlet process
Gaussian random field
Gibbs measure
Hopfield model
Ising model
Potts model
Boolean network
Markov random field
Percolation
Pitman Yor process
Point process
Cox
Poisson
Random field
Random graph
Time series models
Autoregressive conditional heteroskedasticity  ARCH  model
Autoregressive integrated moving average  ARIMA  model
Autoregressive  AR  model
Autoregressive moving average  ARMA  model
Generalized autoregressive conditional heteroskedasticity  GARCH  model
Moving average  MA  model
Financial models
Binomial options pricing model
Black Derman Toy
Black Karasinski
Black Scholes
Chan Karolyi Longstaff Sanders  CKLS 
Chen
Constant elasticity of variance  CEV 
Cox Ingersoll Ross  CIR 
Garman Kohlhagen
Heath Jarrow Morton  HJM 
Heston
Ho Lee
Hull White
Korn Kreer Lenssen
LIBOR market
Rendleman Bartter
SABR volatility
Va   ek
Wilkie
Actuarial models
B hlmann
Cram r Lundberg
Risk process
Sparre Anderson
Queueing models
Bulk
Fluid
Generalized queueing network
M G  
M M  
M M c
Properties
C dl g paths
Continuous
Continuous paths
Ergodic
Exchangeable
Feller continuous
Gauss Markov
Markov
Mixing
Piecewise deterministic
Predictable
Progressively measurable
Self similar
Stationary
Time reversible
Limit theorems
Central limit theorem
Donsker s theorem
Doob s martingale convergence theorems
Ergodic theorem
Fisher Tippett Gnedenko theorem
Large deviation principle
Law of large numbers  weak strong 
Law of the iterated logarithm
Maximal ergodic theorem
Sanov s theorem
Zero one laws  Blumenthal  Borel Cantelli  Engelbert Schmidt  Hewitt Savage   Kolmogorov  L vy 
Inequalities
Burkholder Davis Gundy
Doob s martingale
Doob s upcrossing
Kunita Watanabe
Marcinkiewicz Zygmund
Tools
Cameron Martin formula
Convergence of random variables
Dol ans Dade exponential
Doob decomposition theorem
Doob Meyer decomposition theorem
Doob s optional stopping theorem
Dynkin s formula
Feynman Kac formula
Filtration
Girsanov theorem
Infinitesimal generator
It  integral
It  s lemma
Karhunen Lo ve theorem
Kolmogorov continuity theorem
Kolmogorov extension theorem
L vy Prokhorov metric
Malliavin calculus
Martingale representation theorem
Optional stopping theorem
Prokhorov s theorem
Quadratic variation
Reflection principle
Skorokhod integral
Skorokhod s representation theorem
Skorokhod space
Snell envelope
Stochastic differential equation
Tanaka
Stopping time
Stratonovich integral
Uniform integrability
Usual hypotheses
Wiener space
Classical
Abstract
Disciplines
Actuarial mathematics
Control theory
Econometrics
Ergodic theory
Extreme value theory  EVT 
Large deviations theory
Mathematical finance
Mathematical statistics
Probability theory
Queueing theory
Renewal theory
Ruin theory
Signal processing
Statistics
Stochastic analysis
Time series analysis
Machine learning

List of topics
Category

Authority control databases  National GermanyUnited StatesIsrael





Retrieved from  https   en wikipedia org w index php title Hidden Markov model amp oldid