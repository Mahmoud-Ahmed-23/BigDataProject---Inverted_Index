Technology for sentiment analysis
Multimodal sentiment analysis is a technology for traditional text based sentiment analysis  which includes modalities such as audio and visual data             It can be bimodal  which includes different combinations of two modalities  or trimodal  which incorporates three modalities             With the extensive amount of social media data available online in different forms such as videos and images  the conventional text based sentiment analysis has evolved into more complex models of multimodal sentiment analysis                        which can be applied in the development of  virtual assistants             analysis of YouTube movie reviews             analysis of news videos             and emotion recognition  sometimes known as emotion detection  such as depression monitoring             among others 
Similar to the traditional sentiment analysis  one of the most basic task in multimodal sentiment analysis is sentiment classification  which classifies different sentiments into categories such as positive  negative  or neutral             The complexity of analyzing text  audio  and visual features to perform such a task requires the application of different fusion techniques  such as feature level  decision level  and hybrid fusion             The performance of these fusion techniques and the classification algorithms applied  are influenced by the type of textual  audio  and visual features employed in the analysis             


Features edit 
Feature engineering  which involves the selection of features that are fed into machine learning algorithms  plays a key role in the sentiment classification performance              In multimodal sentiment analysis  a combination of different textual  audio  and visual features are employed            

Textual features edit 
Similar to the conventional text based sentiment analysis  some of the most commonly used textual features in multimodal sentiment analysis are unigrams and n grams  which are basically a sequence of words in a given textual document              These features are applied using bag of words or bag of concepts feature representations  in which words or concepts are represented as vectors in a suitable space                         

Audio features edit 
Sentiment and emotion characteristics are prominent in different phonetic and prosodic properties contained in audio features              Some of the most important audio features employed in multimodal sentiment analysis are  mel frequency cepstrum  MFCC   spectral centroid  spectral flux  beat histogram  beat sum  strongest beat  pause duration  and pitch             OpenSMILE             and Praat are popular open source toolkits for extracting such audio features             

Visual features edit 
One of the main advantages of analyzing videos with respect to texts alone  is the presence of rich sentiment cues in visual data              Visual features include facial expressions  which are of paramount importance in capturing sentiments and emotions  as they are a main channel of forming a person s present state of mind             Specifically  smile  is considered to be one of the most predictive visual cues in multimodal sentiment analysis              OpenFace is an open source facial analysis toolkit available for extracting and understanding such visual features             

Fusion techniques edit 
Unlike the traditional text based sentiment analysis  multimodal sentiment analysis undergo a fusion process in which data from different modalities  text  audio  or visual  are fused and analyzed together             The existing approaches in multimodal sentiment analysis data fusion can be grouped into three main categories  feature level  decision level  and hybrid fusion  and the performance of the sentiment classification depends on which type of fusion technique is employed            

Feature level fusion edit 
Feature level fusion  sometimes known as early fusion  gathers all the features from each modality  text  audio  or visual  and joins them together into a single feature vector  which is eventually fed into a classification algorithm              One of the difficulties in implementing this technique is the integration of the heterogeneous features            

Decision level fusion edit 
Decision level fusion  sometimes known as late fusion   feeds data from each modality  text  audio  or visual  independently into its own classification algorithm  and obtains the final sentiment classification results by fusing each result into a single decision vector              One of the advantages of this fusion technique is that it eliminates the need to fuse heterogeneous data  and each modality can utilize its most appropriate classification algorithm            

Hybrid fusion edit 
Hybrid fusion is a combination of feature level and decision level fusion techniques  which exploits complementary information from both methods during the classification process             It usually involves a two step procedure wherein feature level fusion is initially performed between two modalities  and decision level fusion is then applied as a second step  to fuse the initial results from the feature level fusion  with the remaining modality                         

Applications edit 
Similar to text based sentiment analysis  multimodal sentiment analysis can be applied in the development of different forms of recommender systems such as in the analysis of user generated videos of movie reviews            and general product reviews              to predict the sentiments of customers  and subsequently create product or service recommendations              Multimodal sentiment analysis also plays an important role in the advancement of virtual assistants through the application of natural language processing  NLP  and machine learning techniques             In the healthcare domain  multimodal sentiment analysis can be utilized to detect certain medical conditions such as stress  anxiety  or depression             Multimodal sentiment analysis can also be applied in understanding the sentiments contained in video news programs  which is considered as a complicated and challenging domain  as sentiments expressed by reporters tend to be less obvious or neutral             

References edit 


  Soleymani  Mohammad  Garcia  David  Jou  Brendan  Schuller  Bj rn  Chang  Shih Fu  Pantic  Maja  September         A survey of multimodal sentiment analysis   Image and Vision Computing            doi         j imavis              S CID               

  Karray  Fakhreddine  Milad  Alemzadeh  Saleh  Jamil Abou  Mo Nours  Arab          Human Computer Interaction  Overview on State of the Art   PDF   International Journal on Smart Sensing and Intelligent Systems              doi          ijssis          

  a b c d e f g h i Poria  Soujanya  Cambria  Erik  Bajpai  Rajiv  Hussain  Amir  September         A review of affective computing  From unimodal analysis to multimodal fusion   Information Fusion              doi         j inffus              hdl             S CID                

  Nguyen  Quy Hoang  Nguyen  Minh Van Truong  Van Nguyen  Kiet                New Benchmark Dataset and Fine Grained Cross Modal Fusion Framework for Vietnamese Multimodal Aspect Category Sentiment Analysis   arXiv             cs CL  

  a b  Google AI to make phone calls for you   BBC News    May       Retrieved    June      

  a b c Wollmer  Martin  Weninger  Felix  Knaup  Tobias  Schuller  Bjorn  Sun  Congkai  Sagae  Kenji  Morency  Louis Philippe  May         YouTube Movie Reviews  Sentiment Analysis in an Audio Visual Context   PDF   IEEE Intelligent Systems                 doi         MIS          S CID               

  Pereira  Mois s H  R   P dua  Fl vio L  C   Pereira  Adriano C  M   Benevenuto  Fabr cio  Dalip  Daniel H     April         Fusing Audio  Textual and Visual Features for Sentiment Analysis of News Videos   arXiv             cs CL  

  a b Zucco  Chiara  Calabrese  Barbara  Cannataro  Mario  November         Sentiment analysis and affective computing for depression monitoring        IEEE International Conference on Bioinformatics and Biomedicine  BIBM   IEEE  pp                  doi         bibm               ISBN                         S CID               

  Pang  Bo  Lee  Lillian         Opinion mining and sentiment analysis  Hanover  MA  Now Publishers  ISBN                     

  a b Sun  Shiliang  Luo  Chen  Chen  Junyu  July         A review of natural language processing techniques for opinion mining systems   Information Fusion             doi         j inffus             

  Yadollahi  Ali  Shahraki  Ameneh Gholipour  Zaiane  Osmar R      May         Current State of Text Sentiment Analysis from Opinion to Emotion Mining   ACM Computing Surveys                doi                  S CID              

  a b Perez Rosas  Veronica  Mihalcea  Rada  Morency  Louis Philippe  May         Multimodal Sentiment Analysis of Spanish Online Videos   IEEE Intelligent Systems                 doi         MIS         S CID              

  Poria  Soujanya  Cambria  Erik  Hussain  Amir  Huang  Guang Bin  March         Towards an intelligent framework for multimodal affective data analysis   Neural Networks               doi         j neunet              hdl             PMID                S CID             

  Chung Hsien Wu  Wei Bin Liang  January         Emotion Recognition of Affective Speech Based on Multiple Classifiers Using Acoustic Prosodic Information and Semantic Labels   IEEE Transactions on Affective Computing                doi         T AFFC          S CID               

  Eyben  Florian  W llmer  Martin  Schuller  Bj rn          OpenEAR   Introducing the munich open source emotion and affect recognition toolkit   OpenEAR   Introducing the munich open source emotion and affect recognition toolkit   IEEE Conference Publication  p          doi         ACII               ISBN                         S CID              

  Morency  Louis Philippe  Mihalcea  Rada  Doshi  Payal     November         Towards multimodal sentiment analysis   Towards multimodal sentiment analysis  harvesting opinions from the web  ACM  pp                doi                          ISBN                     S CID              

  Poria  Soujanya  Cambria  Erik  Hazarika  Devamanyu  Majumder  Navonil  Zadeh  Amir  Morency  Louis Philippe          Context Dependent Sentiment Analysis in User Generated Videos   Proceedings of the   th Annual Meeting of the Association for Computational Linguistics  Volume    Long Papers            doi          v  p        

  OpenFace  An open source facial behavior analysis toolkit   IEEE Conference Publication  March       doi         WACV               ISBN                         S CID              

  a b Poria  Soujanya  Cambria  Erik  Howard  Newton  Huang  Guang Bin  Hussain  Amir  January         Fusing audio  visual and textual clues for sentiment analysis from multimodal content   Neurocomputing              doi         j neucom              S CID               

  Shahla  Shahla  Naghsh Nilchi  Ahmad Reza          Exploiting evidential theory in the fusion of textual  audio  and visual modalities for affective music video retrieval   IEEE Conference Publication   doi         PRIA               S CID                  cite journal    Cite journal requires       journal   help 

  Poria  Soujanya  Peng  Haiyun  Hussain  Amir  Howard  Newton  Cambria  Erik  October         Ensemble application of convolutional neural networks and multiple kernel learning for multimodal sentiment analysis   Neurocomputing                doi         j neucom             

  P rez Rosas  Ver nica  Mihalcea  Rada  Morency  Louis Philippe    January         Utterance level multimodal sentiment analysis   Long Papers  Association for Computational Linguistics  ACL  

  Chui  Michael  Manyika  James  Miremadi  Mehdi  Henke  Nicolaus  Chung  Rita  Nel  Pieter  Malhotra  Sankalp   Notes from the AI frontier  Insights from hundreds of use cases   McKinsey  amp  Company  Retrieved    June      

  Ellis  Joseph G   Jou  Brendan  Chang  Shih Fu     November         Why We Watch the News   Why We Watch the News  A Dataset for Exploring Sentiment in Broadcast Video News  ACM  pp                doi                          ISBN                     S CID               







Retrieved from  https   en wikipedia org w index php title Multimodal sentiment analysis amp oldid