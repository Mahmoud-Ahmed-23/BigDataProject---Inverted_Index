Philosopher and writer  born      


Nick BostromBostrom in     BornNiklas Bostr m                 March       age         Helsingborg  SwedenSpouseSusan           EducationEducationUniversity of Gothenburg  BA Stockholm University  MA King s College London  MSc London School of Economics  PhD ThesisObservational Selection Effects and Probability            Philosophical workEraContemporary philosophyRegionWestern philosophySchoolAnalytic philosophy           InstitutionsYale UniversityUniversity of OxfordFuture of Humanity InstituteMain interestsPhilosophy of artificial intelligenceBioethicsNotable ideasAnthropic biasReversal testSimulation hypothesisExistential risk studiesSingletonAncestor simulationInformation hazardInfinitarian paralysis           Self indication assumptionSelf sampling assumption
Websitenickbostrom comTranshumanism
Issues
Accelerating change
Eradication of suffering
Fourth Industrial Revolution
Human enhancement
Genetic
Moral
Neuro 
Cognitive liberty
New eugenics
Eugenics
Human nature
Meliorism
Post politics
Post scarcity


People
Andrews
Bostrom
Church
Jos  Luis Cordeiro
Drexler
Fahy
FM     
Freitas
Fyodorov
Fuller
de Garis
Gasson
Goertzel
de Grey
Haldane
Hanson
Harari
Harbisson
Harris
Huxley
Hughes
Istvan
Kurzweil
Land
Ole Martin Moen
Hans Moravec
More
Elon Musk
Osborn
Pearce
Martine Rothblatt
Sandberg
Savulescu
Sorgner
Spencer
Stock
Stolyarov
Teilhard de Chardin
Vernor Vinge
Vita More
Mark Alan Walker
Warwick
Wiener
Eliezer Yudkowsky


Influential works
Oration on the Dignity of Man       
Thus Spoke Zarathustra       
Looking Backward        
The Will to Power        
Daedalus       
La raza c smica       
The Phenomenon of Man       
The Dialectic of Sex        
Metaman       
The Hedonistic Imperative       
Regeln f r den Menschenpark       
The Age of Spiritual Machines       
Citizen Cyborg       
The Singularity Is Near       
Human Enhancement       
Fanged Noumena       
The Transhumanist Wager       
Sapiens       
Homo Deus       
The Transhumanist Bill of Rights       
The Age of Em       
The Precipice       
What We Owe the Future       
 Techno Optimist Manifesto        


Variants
Accelerationism
Effective
Cypherpunk
Dataism
Extropianism
Immortalism
Longtermism
Postgenderism
Posthumanism
Russian Cosmism
Singularitarianism
Technogaianism
Technolibertarianism
Technological utopianism
Techno progressivism


Related topics
Dyson sphere
Technologies
Emerging
Disruptive
Hypothetical

vte
Nick Bostrom    b str m  BOST r m  Swedish  Niklas Bostr m       n  k las  b  str m       born    March                  is a philosopher known for his work on existential risk  the anthropic principle  human enhancement ethics  whole brain emulation  superintelligence risks  and the reversal test  He was the founding director of the now dissolved Future of Humanity Institute at the University of Oxford            and is now Principal Researcher at the Macrostrategy Research Initiative            
Bostrom is the author of Anthropic Bias  Observation Selection Effects in Science and Philosophy         Superintelligence  Paths  Dangers  Strategies        and Deep Utopia  Life and Meaning in a Solved World        
Bostrom believes that advances in artificial intelligence  AI  may lead to superintelligence  which he defines as  any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest   He views this as a major source of opportunities and existential risks                       


Early life and education edit 
Born as Niklas Bostr m in      in Helsingborg  Sweden             he disliked school at a young age and spent his last year of high school learning from home  He was interested in a wide variety of academic areas  including anthropology  art  literature  and science            
He received a B A  degree from the University of Gothenburg in                  He then earned an M A  degree in philosophy and physics from Stockholm University and an MSc degree in computational neuroscience from King s College London in       During his time at Stockholm University  he researched the relationship between language and reality by studying the analytic philosopher W  V  Quine             He also did some turns on London s stand up comedy circuit             In       he was awarded a PhD degree in philosophy from the London School of Economics  His thesis was titled Observational selection effects and probability             He held a teaching position at Yale University from      to       and was a British Academy Postdoctoral Fellow at the University of Oxford from      to                  

Research and writing edit 
Existential risk edit 
Bostrom s research concerns the future of humanity and long term outcomes                         He discusses existential risk             which he defines as one in which an  adverse outcome would either annihilate Earth originating intelligent life or permanently and drastically curtail its potential   Bostrom is mostly concerned about anthropogenic risks  which are risks arising from human activities  particularly from new technologies such as advanced artificial intelligence  molecular nanotechnology  or synthetic biology             
In       Bostrom founded the Future of Humanity Institute which             until its shutdown in       researched the far future of human civilization                          He is also an adviser to the Centre for the Study of Existential Risk             
In the      essay collection  Global Catastrophic Risks  editors Bostrom and Milan M   irkovi  characterize the relationship between existential risk and the broader class of global catastrophic risks  and link existential risk to observer selection effects             and the Fermi paradox             

Vulnerable world hypothesis edit 
Main article  Vulnerable world hypothesis
In a paper called  The Vulnerable World Hypothesis               Bostrom suggests that there may be some technologies that destroy human civilization by default     a      when discovered  Bostrom proposes a framework for classifying and dealing with these vulnerabilities  He also gives counterfactual thought experiments of how such vulnerabilities could have historically occurred  e g  if nuclear weapons had been easier to develop or had ignited the atmosphere  as Robert Oppenheimer had feared              

Digital sentience edit 
Bostrom supports the substrate independence principle  the idea that consciousness can emerge on various types of physical substrates  not only in  carbon based biological neural networks  like the human brain              He considers that  sentience is a matter of degree              and that digital minds can in theory be engineered to have a much higher rate and intensity of subjective experience than humans  using less resources  Such highly sentient machines  which he calls  super beneficiaries   would be extremely efficient at achieving happiness  He recommends finding  paths that will enable digital minds and biological minds to coexist  in a mutually beneficial way where all of these different forms can flourish and thrive              

Anthropic reasoning edit 
Bostrom has published numerous articles on anthropic reasoning  as well as the book Anthropic Bias  Observation Selection Effects in Science and Philosophy  In the book  he criticizes previous formulations of the anthropic principle  including those of Brandon Carter  John Leslie  John Barrow  and Frank Tipler             
Bostrom believes that the mishandling of indexical information is a common flaw in many areas of inquiry  including cosmology  philosophy  evolution theory  game theory  and quantum physics   He argues that an anthropic theory is needed to deal with these  He introduces the self sampling assumption  SSA  and analyzes the self indication assumption  SIA   shows how they lead to different conclusions in a number of cases  and identifies how each is affected by paradoxes or counterintuitive implications in certain thought experiments  He argues against SIA and proposes refining SSA into the strong self sampling assumption  SSSA   which replaces  observers  in the SSA definition with  observer moments              
In later work  he proposed with Milan M   irkovi  and Anders Sandberg the phenomenon of anthropic shadow  an observation selection effect that prevents observers from observing certain kinds of catastrophes in their recent geological and evolutionary past  They suggest that events that lie in the anthropic shadow are likely to be underestimated unless statistical corrections are made                         

Simulation argument edit 
Main article  Simulation hypothesis
Bostrom s simulation argument posits that at least one of the following statements is very likely to be true                         

The fraction of human level civilizations that reach a posthuman stage is very close to zero 
The fraction of posthuman civilizations that are interested in running ancestor simulations is very close to zero 
The fraction of all people with our kind of experiences that are living in a simulation is very close to one 
Ethics of human enhancement edit 
Bostrom is favorably disposed toward  human enhancement   or  self improvement and human perfectibility through the ethical application of science   as well as a critic of bio conservative views             
In       Bostrom co founded  with David Pearce  the World Transhumanist Association              which has since changed its name to Humanity    In       he co founded  with James Hughes  the Institute for Ethics and Emerging Technologies              although he is no longer involved with either of these organisations 
In       Bostrom published the short story  The Fable of the Dragon Tyrant  in the Journal of Medical Ethics  A shorter version was published in      in Philosophy Now              The fable personifies death as a dragon that demands a tribute of thousands of people every day  The story explores how status quo bias and learned helplessness can prevent people from taking action to defeat aging even when the means to do so are at their disposal  YouTuber CGP Grey created an animated version of the story             
With philosopher Toby Ord  he proposed the reversal test in       Given humans  irrational status quo bias  how can one distinguish between valid criticisms of proposed changes in a human trait and criticisms merely motivated by resistance to change  The reversal test attempts to do this by asking whether it would be a good thing if the trait was altered in the opposite direction             
Bostrom s work also considers potential dysgenic effects in human populations but he thinks genetic engineering can provide a solution and that  In any case  the time scale for human natural genetic evolution seems much too grand for such developments to have any significant effect before other developments will have made the issue moot              

Technology strategy edit 
See also  Differential technological development
Bostrom has suggested that technology policy aimed at reducing existential risk should seek to influence the order in which various technological capabilities are attained  proposing the principle of differential technological development  This principle states that we ought to retard the development of dangerous technologies  particularly ones that raise the level of existential risk  and accelerate the development of beneficial technologies  particularly those that protect against the existential risks posed by nature or by other technologies             
In       Bostrom founded the Oxford Martin Program on the Impacts of Future Technology             
Bostrom s theory of the unilateralist s curse has been cited as a reason for the scientific community to avoid controversial dangerous research such as reanimating pathogens             

Books edit 
Superintelligence  Paths  Dangers  Strategies edit 
In       Bostrom published Superintelligence  Paths  Dangers  Strategies  which became a New York Times Best Seller             
The book argues that superintelligence is possible and explores different types of superintelligences  their cognition  the associated risks  He also presents technical and strategic considerations on how to make it safe 

Characteristics of a superintelligence edit 
Bostrom explores multiple possible paths to superintelligence  including whole brain emulation and human intelligence enhancement  but focuses on artificial general intelligence  explaining that electronic devices have many advantages over biological brains             
Bostrom draws a distinction between final goals and instrumental goals  A final goal is what an agent tries to achieve for its own intrinsic value  Instrumental goals are just intermediary steps towards final goals  Bostrom contends there are instrumental goals that will be shared by most sufficiently intelligent agents because they are generally useful to achieve any objective  e g  preserving the agent s own existence or current goals  acquiring resources  improving its cognition      this is the concept of instrumental convergence  On the other side  he writes that virtually any level of intelligence can in theory be combined with virtually any final goal  even absurd final goals  e g  making paperclips   a concept he calls the orthogonality thesis             
He argues that an AI with the ability to improve itself might initiate an intelligence explosion  resulting  potentially rapidly  in a superintelligence              Such a superintelligence could have vastly superior capabilities  notably in strategizing  social manipulation  hacking or economic productivity  With such capabilities  a superintelligence could outwit humans and take over the world  establishing a singleton  which is  a world order in which there is at the global level a single decision making agency      b       and optimizing the world according to its final goals             
Bostrom argues that giving simplistic final goals to a superintelligence could be catastrophic 

Suppose we give an A I  the goal to make humans smile  When the A I  is weak  it performs useful or amusing actions that cause its user to smile  When the A I  becomes superintelligent  it realizes that there is a more effective way to achieve this goal  take control of the world and stick electrodes into the facial muscles of humans to cause constant  beaming grins             
Mitigating the risk edit 
Bostrom explores several pathways to reduce the existential risk from AI  He emphasizes the importance of international collaboration  notably to reduce race to the bottom and AI arms race dynamics  He suggests potential techniques to help control AI  including containment  stunting AI capabilities or knowledge  narrowing the operating context  e g  to question answering   or  tripwires   diagnostic mechanisms that can lead to a shutdown               But Bostrom contends that  we should not be confident in our ability to keep a superintelligent genie locked up in its bottle forever  Sooner or later  it will out   He thus suggests that in order to be safe for humanity  superintelligence must be aligned with morality or human values so that it is  fundamentally on our side               Potential AI normativity frameworks include Yudkowsky s coherent extrapolated volition  human values improved via extrapolation   moral rightness  doing what is morally right   and moral permissibility  following humanity s coherent extrapolated volition except when it s morally impermissible              
Bostrom warns that an existential catastrophe can also occur from AI being misused by humans for destructive purposes  or from humans failing to take into account the potential moral status of digital minds  Despite these risks  he says that machine superintelligence seems involved at some point in  all the plausible paths to a really great future             

Public reception edit 
The book became a New York Times Best Seller and received positive feedback from personalities such as Stephen Hawking  Bill Gates  Elon Musk  Peter Singer and Derek Parfit  It was praised for offering clear and compelling arguments on a neglected yet important topic  It was sometimes criticized for spreading pessimism about the potential of AI  or for focusing on longterm and speculative risks              Some skeptics such as Daniel Dennett or Oren Etzioni contended that superintelligence is too far away for the risk to be significant                          Yann LeCun considers that there is no existential risk  asserting that superintelligent AI will have no desire for self preservation             and that experts can be trusted to make it safe             
Raffi Khatchadourian wrote that Bostrom s book on superintelligence  is not intended as a treatise of deep originality  Bostrom s contribution is to impose the rigors of analytic philosophy on a messy corpus of ideas that emerged at the margins of academic thought              

Deep Utopia  Life and Meaning in a Solved World edit 
In his      book  Deep Utopia  Life and Meaning in a Solved World  Bostrom explores the concept of an ideal life  if humanity transitions successfully into a post superintelligence world  Bostrom notes that the question is  not how interesting a future is to look at  but how good it is to live in   He outlines some technologies that he considers physically possible in theory and available at technological maturity  such as cognitive enhancement  reversal of aging  arbitrary sensory inputs  taste  sound      or the precise control of motivation  mood  well being and personality  According to him  not only machines would be better than humans at working  but they would also undermine the purpose of many leisure activities  providing extreme welfare while challenging the quest for meaning                         

Public engagement edit 
Bostrom has provided policy advice and consulted for many governments and organizations  He gave evidence to the House of Lords  Select Committee on Digital Skills              He is an advisory board member for the Machine Intelligence Research Institute              Future of Life Institute              and an external advisor for the Cambridge Centre for the Study of Existential Risk             

     email incident edit 
In January       Bostrom issued an apology             for a      listserv email             he sent as a postgrad where he had stated that he thought  Blacks are more stupid than whites   and where he also used the word  niggers  in a description of how he thought this statement might be perceived by others                          The apology  posted on his website              stated that  the invocation of a racial slur was repulsive  and that he  completely repudiate d  this disgusting email               
The email has been described as  racist  in several news sources                                                  According to Andrew Anthony of The Guardian   The apology did little to placate Bostrom s critics  not least because he conspicuously failed to withdraw his central contention regarding race and intelligence  and seemed to make a partial defence of eugenics              
Shortly afterward  Oxford University condemned the language used in the email and started an investigation                          The investigation concluded on    August         W e do not consider you to be a racist or that you hold racist views  and we consider that the apology you posted in January      was sincere                          

Personal life edit 
Bostrom met his wife Susan in       As of       she lived in Montreal and Bostrom in Oxford  They have one son            

Selected works edit 
Books edit 
       Anthropic Bias  Observation Selection Effects in Science and Philosophy  ISBN                   
       Global Catastrophic Risks  edited by Bostrom and Milan M   irkovi   ISBN                       
       Human Enhancement  edited by Bostrom and Julian Savulescu  ISBN                   
       Superintelligence  Paths  Dangers  Strategies  ISBN                       
       Deep Utopia  Life and Meaning in a Solved World  ISBN                    
Journal articles edit 
Bostrom  Nick          How Long Before Superintelligence    Journal of Future Studies    
         January         Observer relative chances in anthropic reasoning    Erkenntnis                  doi         A                JSTOR                S CID                
         October         The Meta Newcomb Problem   Analysis                   doi                          JSTOR              
         March         Existential Risks  Analyzing Human Extinction Scenarios and Related Hazards   Journal of Evolution and Technology        
         April         Are You Living in a Computer Simulation    PDF   Philosophical Quarterly                     doi                          JSTOR              
                 The Mysteries of Self Locating Belief and Anthropic Reasoning   PDF   Harvard Review of Philosophy      Spring          doi         harvardreview         
         November         Astronomical Waste  The Opportunity Cost of Delayed Technological Development   Utilitas                   CiteSeerX                       doi         S                  S CID               
         June         In Defense of Posthuman Dignity   Bioethics                   doi         j                      x  PMID               
with Tegmark  Max  December         How Unlikely is a Doomsday Catastrophe    Nature                   arXiv astro ph          Bibcode     Natur         T  doi               a  PMID                S CID              
                 What is a Singleton    Linguistic and Philosophical Investigations               
with Ord  Toby  July         The Reversal Test  Eliminating Status Quo Bias in Applied Ethics   PDF   Ethics                    doi                 PMID                S CID               
with Sandberg  Anders  December         Converging Cognitive Enhancements   PDF   Annals of the New York Academy of Sciences                     Bibcode     NYASA         S  CiteSeerX                       doi         annals           PMID                S CID               
         January         Drugs can be used to treat more than disease   PDF   Nature                   Bibcode     Natur         B  doi               b  PMID                S CID              
                 The doomsday argument   Think                    doi         S                  S CID                
                 Where Are They  Why I hope the search for extraterrestrial life finds nothing   PDF   Technology Review  May June         
Bostrom  Nick          Letter from Utopia   Studies in Ethics  Law  and Technology         doi                        
with Sandberg  Anders  September         Cognitive Enhancement  Methods  Ethics  Regulatory Challenges   PDF   Science and Engineering Ethics                   CiteSeerX                       doi         s                  PMID                S CID              
                 Pascal s Mugging   PDF   Analysis                   doi         analys anp     JSTOR               
with  irkovi   Milan  Sandberg  Anders          Anthropic Shadow  Observation Selection Effects and Human Extinction Risks   PDF   Risk Analysis                      Bibcode     RiskA         C  doi         j                      x  PMID                S CID              
                 Information Hazards  A Typology of Potential Harms from Knowledge   PDF   Review of Contemporary Philosophy             ProQuest                
Bostrom  Nick          THE ETHICS OF ARTIFICIAL INTELLIGENCE   PDF   Cambridge Handbook of Artificial Intelligence  Archived from the original  PDF  on   March       Retrieved    February      
Bostrom  Nick          Infinite Ethics   PDF   Analysis and Metaphysics           
         May         The Superintelligent Will  Motivation and Instrumental Rationality in Advanced Artificial Agents   PDF   Minds and Machines                 doi         s                  S CID              
with Armstrong  Stuart  Sandberg  Anders  November         Thinking Inside the Box  Controlling and Using Oracle AI   PDF   Minds and Machines                   CiteSeerX                      doi         s                  S CID              
         February         Existential Risk Reduction as Global Priority   Global Policy                doi                         
with Shulman  Carl  February         Embryo Selection for Cognitive Enhancement  Curiosity or Game changer    PDF   Global Policy                CiteSeerX                       doi                         
with Muehlhauser  Luke          Why we need friendly AI   PDF   Think                  doi         S                  S CID                
Bostrom  Nick  September         The Vulnerable World Hypothesis   Global Policy                   doi                         
See also edit 

Doomsday argument
Dream argument
Effective altruism
Pascal s mugging

Notes edit 


  Bostrom says that the risk can be reduced if society sufficiently exits what he calls a  semi anarchic default condition   which roughly means limited capabilities for preventive policing and global governance  and having individuals with diverse motivations             

  Bostrom notes that  the concept of a singleton is an abstract one  a singleton could be democracy  a tyranny  a single dominant AI  a strong set of global norms that include effective provisions for their own enforcement  or even
an alien overlord its defining characteristic being simply that it is some form of
agency that can solve all major global coordination problems             


References edit 


  a b c d e f g Khatchadourian  Raffi     November         The Doomsday Invention   The New Yorker  Vol       XCI  no           pp              ISSN              X 

   Infinite Ethics   PDF   nickbostrom com  Retrieved    February      

   nickbostrom com   Nickbostrom com  Archived from the original on    August       Retrieved    October      

  a b c Shead  Sam     May         How Britain s oldest universities are trying to protect humanity from risky A I   CNBC  Retrieved   June      

   Nick Bostrom s Home Page   nickbostrom com  Retrieved    April      

  a b  Nick Bostrom on the birth of superintelligence   Big Think  Retrieved    August      

  a b Thornhill  John     July         Artificial intelligence  can we control it    Financial Times  Archived from the original on    December       Retrieved    August        subscription required 

  Bostrom  Nick   CV   PDF  

  Bostrom  Nick         Observational selection effects and probability  PhD   London School of Economics and Political Science  Retrieved    June      

   Nick Bostrom on artificial intelligence   Oxford University Press    September       Retrieved   March      

  a b Andersen  Ross   Omens   Aeon  Archived from the original on    October       Retrieved   September      

  Andersen  Ross    March         We re Underestimating the Risk of Human Extinction   The Atlantic  Retrieved   July      

  Maiberg  Emanuel     April         Institute That Pioneered AI  Existential Risk  Research Shuts Down       Media  Retrieved    September      

   Future of Humanity Institute      April       Archived from the original on    April       Retrieved    April      

  Tegmark  Max  Bostrom  Nick          Astrophysics  is a doomsday catastrophe likely    PDF   Nature                   Bibcode     Natur         T  doi               a  PMID                S CID               Archived from the original  PDF  on   July      

  Overbye  Dennis    August         The Flip Side of Optimism About Life on Other Planets   The New York Times  Retrieved    October      

  Bostrom  Nick  November         The Vulnerable World Hypothesis   PDF   Global Policy                   doi                         

  Abhijeet  Katte     December         AI Doomsday Can Be Avoided If We Establish  World Government   Nick Bostrom   Analytics India Magazine 

  Piper  Kelsey     November         How technological progress is making it likelier than ever that humans will destroy ourselves   Vox  Retrieved   July      

  Bostrom  Nick          Are You Living In a Computer Simulation    PDF   Philosophical Quarterly                     doi                         

  Jackson  Lauren     April         What if A I  Sentience Is a Question of Degree    The New York Times  ISSN                 Retrieved   July      

  Fisher  Richard     November         The intelligent monster that you should let eat you   BBC  Retrieved   July      

  Bostrom  Nick         Anthropic Bias  Observation Selection Effects in Science and Philosophy  PDF   New York  Routledge  pp              ISBN                         Retrieved    July      

  Manson  Neil    February         Anthropic Bias  Observation Selection Effects in Science and Philosophy   Notre Dame Philosophical Reviews 

  Brannen  Peter     March         Why Earth s History Appears So Miraculous   The Atlantic  Retrieved    September      

   Anthropic Shadow  Observation Selection Effects and Human Extinction Risks   PDF   Nickbostrom com  Retrieved    October      

  Sutter  Paul     January         Could our Universe be a simulation  How would we even tell    Ars Technica  Retrieved    September      

  Nesbit  Jeff   Proof of the Simulation Argument   US News  Retrieved    March      

  a b Sutherland  John    May         The ideas interview  Nick Bostrom  John Sutherland meets a transhumanist who wrestles with the ethics of technologically enhanced human beings   The Guardian 

   A Philosophical History of Transhumanism   Philosophy Now        Retrieved    September      

  Bostrom  Nick     June         The Fable of the Dragon Tyrant   Philosophy Now          

  Fable of the Dragon Tyrant  Video      April      

  Bostrom  Nick  Ord  Toby          The reversal test  eliminating status quo bias in applied ethics   PDF   Ethics                    doi                 PMID                S CID               

  a b c Bostrom  Nick          Existential Risks   Analyzing Human Extinction Scenarios and Related Hazards   Journal of Evolution and Technology 

   Professor Nick Bostrom        People   Oxford Martin School  Archived from the original on    September       Retrieved    October      

  Lewis  Gregory     February         Horsepox synthesis  A case of the unilateralist s curse    Bulletin of the Atomic Scientists  Archived from the original on    February       Retrieved    February      

   Best Selling Science Books   The New York Times    September       Retrieved    February      

  a b c d e Bostrom  Nick         Superintelligence  Oxford University Press  pp               ISBN                         OCLC                

  Bostrom  Nick     September         You Should Be Terrified of Superintelligent Machines   Slate  ISSN                 Retrieved    September      

   Clever cogs   The Economist  ISSN                 Retrieved    August      

  Bostrom  Nick  March         What happens when our computers get smarter than we are    TED 

  a b Khatchadourian  Raffi     November         The Doomsday Invention   The New Yorker  Retrieved    August      

   Is Superintelligence Impossible    Edge  Retrieved    August      

  Oren Etzioni          No  the Experts Don t Think Superintelligent AI is a Threat to Humanity   MIT Technology Review 

  Arul  Akashdeep     January         Yann LeCun sparks a debate on AGI vs human level AI   Analytics India Magazine  Retrieved    August      

  Taylor  Chloe     June         Almost half of CEOs fear A I  could destroy humanity five to    years from now but  A I  godfather  says an existential threat is  preposterously ridiculous    Fortune  Retrieved    August      

  Coy  Peter    April         If A I  Takes All Our Jobs  Will It Also Take Our Purpose    The New York Times  ISSN                 Retrieved   July      

  Bostrom  Nick          Technological maturity   Deep utopia  life and meaning in a solved world  Washington  DC  Ideapress Publishing  ISBN                        

   Digital Skills Committee   timeline   UK Parliament  Retrieved    March      

   Team   Machine Intelligence Research Institute   Machine Intelligence Research Institute  Retrieved    March      

   Team   Future of Life Institute   Future of Life Institute  Retrieved    March      

  McBain  Sophie    October         Apocalypse Soon  Meet The Scientists Preparing For the End Times   New Republic  Retrieved    March      

  a b Bostrom  Nick   Apology for old email   PDF   nickbostrom com  Retrieved    January      

   extropians  Re  Offending People s Minds      April       Archived from the original on    April       Retrieved    June      

  a b c d Ladden Hall  Dan     January         Top Oxford Philosopher Nick Bostrom Admits Writing  Disgusting  N Word Mass Email   The Daily Beast  Retrieved    January       Nick Bostrom posted a note on his website apologizing for the appallingly racist listserv email 

  Robins Early  Nick     April         Oxford shuts down institute run by Elon Musk backed philosopher   The Guardian  The closure of Bostrom s center is a further blow to the effective altruism and long termism movements that the philosopher had spent decades championing  and which in recent years have become mired in scandals related to racism  sexual harassment and financial fraud  Bostrom himself issued an apology last year after a decades old email surfaced in which he claimed  Blacks are more stupid than whites  and used the N word 

  Weinberg  Justin     January         Why a Philosopher s Racist Email from    Years Ago is News Today   The Daily Nous  Influential Oxford philosopher Nick Bostrom  well known for his work on philosophical questions related to ethics  the future  and technology  existential risk  artificial intelligence  simulation   posted an apology for a blatantly racist email he sent to a listserv    years ago 

  a b Bilyard  Dylan     January         Investigation Launched into Oxford Don s Racist Email   The Oxford Blue 

  Gault  Matthew  Pearson  Jordan     January         Prominent AI Philosopher and  Father  of Longtermism Sent Very Racist Email to a   s Philosophy Listserv   Vice  Nick Bostrom  an influential philosopher at the University of Oxford who has been called the  father  of the longtermism movement  has apologized for a racist email he sent in the mid   s  In the email  Bostrom said that  Blacks are more stupid than whites   adding   I like that sentence and think it is true   and used a racial slur 

  a b Anthony  Andrew     April          Eugenics on steroids   the toxic and contested legacy of Oxford s Future of Humanity Institute   The Observer  ISSN                 Retrieved   July       The apology did little to placate Bostrom s critics  not least because he conspicuously failed to withdraw his central contention regarding race and intelligence  and seemed to make a partial defence of eugenics  Although  after an investigation  Oxford University did accept that Bostrom was not a racist  the whole episode left a stain on the institute s reputation

  Bostrom  Nick   Apology for an Old Email   PDF   nickbostrom com  we do not consider you to be a racist or that you hold racist views  and we consider that the apology you posted in January      was sincere    we believe that your apology  your acknowledgement of the distress your actions caused  and your appreciation for the care and time that everyone has given to this process has been genuine and sincere  We were also encouraged that you have already embarked on a journey of deep and meaningful reflection  which includes exploring the learning and self education from this process 


External links edit 



Wikiquote has quotations related to Nick Bostrom 




Wikimedia Commons has media related to Nick Bostrom 

Official website
Nick Bostrom at TED 
vteEffective altruismConcepts
Aid effectiveness
Charity assessment
Demandingness objection
Disability adjusted life year
Disease burden
Distributional cost effectiveness analysis
Earning to give
Equal consideration of interests
Longtermism
Marginal utility
Moral circle expansion
Psychological barriers to effective altruism
Quality adjusted life year
Utilitarianism
Venture philanthropy
Key figures
Sam Bankman Fried
Liv Boeree
Nick Bostrom
Hilary Greaves
Holden Karnofsky
William MacAskill
Dustin Moskovitz
Yew Kwang Ng
Toby Ord
Derek Parfit
Peter Singer
Cari Tuna
Eliezer Yudkowsky
Organizations
       Hours
Against Malaria Foundation
Animal Charity Evaluators
Animal Ethics
Centre for Effective Altruism
Centre for Enabling EA Learning  amp  Research
Center for High Impact Philanthropy
Centre for the Study of Existential Risk
Development Media International
Evidence Action
Faunalytics
Fistula Foundation
Future of Humanity Institute
Future of Life Institute
Founders Pledge
GiveDirectly
GiveWell
Giving Multiplier
Giving What We Can
Good Food Fund
The Good Food Institute
Good Ventures
The Humane League
Mercy for Animals
Machine Intelligence Research Institute
Malaria Consortium
Open Philanthropy
Raising for Effective Giving
Sentience Institute
Unlimit Health
Wild Animal Initiative
Focus areas
Biotechnology risk
Climate change
Cultured meat
Economic stability
Existential risk from artificial general intelligence
Global catastrophic risk
Global health
Global poverty
Intensive animal farming
Land use reform
Life extension
Malaria prevention
Mass deworming
Neglected tropical diseases
Risk of astronomical suffering
Wild animal suffering
Literature
Doing Good Better
The End of Animal Farming
Famine  Affluence  and Morality
The Life You Can Save
Living High and Letting Die
The Most Good You Can Do
Practical Ethics
The Precipice
Superintelligence  Paths  Dangers  Strategies
What We Owe the Future
Events
Effective Altruism Global

vteExistential risk from artificial intelligenceConcepts
AGI
AI alignment
AI capability control
AI safety
AI takeover
Consequentialism
Effective accelerationism
Ethics of artificial intelligence
Existential risk from artificial intelligence
Friendly artificial intelligence
Instrumental convergence
Vulnerable world hypothesis
Intelligence explosion
Longtermism
Machine ethics
Suffering risks
Superintelligence
Technological singularity
Organizations
Alignment Research Center
Center for AI Safety
Center for Applied Rationality
Center for Human Compatible Artificial Intelligence
Centre for the Study of Existential Risk
EleutherAI
Future of Humanity Institute
Future of Life Institute
Google DeepMind
Humanity 
Institute for Ethics and Emerging Technologies
Leverhulme Centre for the Future of Intelligence
Machine Intelligence Research Institute
OpenAI
People
Scott Alexander
Sam Altman
Yoshua Bengio
Nick Bostrom
Paul Christiano
Eric Drexler
Sam Harris
Stephen Hawking
Dan Hendrycks
Geoffrey Hinton
Bill Joy
Shane Legg
Elon Musk
Steve Omohundro
Huw Price
Martin Rees
Stuart J  Russell
Jaan Tallinn
Max Tegmark
Frank Wilczek
Roman Yampolskiy
Eliezer Yudkowsky
Other
Statement on AI risk of extinction
Human Compatible
Open letter on artificial intelligence       
Our Final Invention
The Precipice
Superintelligence  Paths  Dangers  Strategies
Do You Trust This Computer 
Artificial Intelligence Act
 Category
vteFuture of Humanity InstitutePeople
Nick Bostrom
K  Eric Drexler
Robin Hanson
Toby Ord
Anders Sandberg
Rebecca Roache
Concepts
Differential technological development
Global catastrophic risk
Great Filter
Pascal s mugging
Reversal test
Self indication assumption
Self sampling assumption
Simulation hypothesis
Singleton
Works
Anthropic Bias
Global Catastrophic Risks
Human Enhancement
The Precipice
Superintelligence  Paths  Dangers  Strategies

vteTranshumanismOverviews
Transhuman
Transhumanism in fiction
Currents
Accelerationism
Effective
Antinaturalism
Cypherpunk
Dataism
Eradication of suffering
Extropianism
Immortalism
Postgenderism
Posthumanism
Postpoliticism
Russian cosmism
Singularitarianism
Technogaianism
Technolibertarianism
Technological utopianism
Techno progressivism
Organizations
Foresight Institute
Humanity 
Institute for Ethics and Emerging Technologies
Future of Humanity Institute
LessWrong
US Transhumanist Party
People
Andrews
Bostrom
Church
Jos  Luis Cordeiro
K  Eric Drexler
Fahy
FM     
Freitas
Fuller
Fyodorov
de Garis
Gasson
David Gobel
Ben Goertzel
de Grey
Haldane
Hanson
Harari
Harbisson
Harris
Huxley
Hughes
Zoltan Istvan
Ray Kurzweil
Land
Ole Martin Moen
Hans Moravec
Max More
Elon Musk
Osborn
David Pearce
Martine Rothblatt
Anders Sandberg
Savulescu
Sorgner
Spencer
Stock
Gennady Stolyarov II
Teilhard de Chardin
Vernor Vinge
Natasha Vita More
Mark Alan Walker
Warwick
Eliezer Yudkowsky

 Category

Authority control databases InternationalISNIVIAFFASTWorldCatNationalGermanyUnited StatesFranceBnF dataJapanCzech RepublicSpainPortugalNetherlandsNorwayLatviaCroatiaKoreaSwedenPolandIsraelCataloniaAcademicsCiNiiMathematics Genealogy ProjectScopusGoogle ScholarDBLPPhilPeopleMathSciNetArtistsMusicBrainzPeopleDDBOtherIdRef





Retrieved from  https   en wikipedia org w index php title Nick Bostrom amp oldid