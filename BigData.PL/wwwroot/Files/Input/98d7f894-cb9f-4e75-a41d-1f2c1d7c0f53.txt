Hypothetical point in time when technological growth becomes uncontrollable and irreversible
 The Singularity  redirects here  For other uses  see Singularity  disambiguation  


Futures studies
Concepts
Accelerating change
Cashless society
Global catastrophic risk
Future
Earth
Mathematics
Race
Climate
Space exploration
Universe
Historical materialism
Kondratiev wave
Kardashev scale
Moore s law
Peak oil
Population cycle
Resource depletion
Singularity
Swanson s law

Techniques
Backcasting
Causal layered analysis
Chain linked model
Consensus forecast
Cross impact analysis
Delphi
Real time Delphi
Foresight
Future proof
Futures wheel
Future workshop
Horizon scanning
Reference class forecasting
Scenario planning
Systems analysis
Threatcasting
Trend analysis

Technology assessment and forecasting
Critical design
Design fiction
Exploratory engineering
FTA
Hype cycle
Science fiction prototyping
Speculative design
TRL
Technology scouting

Related topics
Futarchy
Transhumanism
vte
The technological singularity or simply the singularity            is a hypothetical point in time at which technological growth becomes uncontrollable and irreversible  resulting in unforeseeable consequences for human civilization                        According to the most popular version of the singularity hypothesis  I  J  Good s intelligence explosion model of       an upgradable intelligent agent could eventually enter a positive feedback loop of successive self improvement cycles  more intelligent generations would appear more and more rapidly  causing a rapid increase   explosion   in intelligence which would culminate in a powerful superintelligence  far surpassing all human intelligence            
The Hungarian American mathematician John von Neumann             became the first known person to use the concept of a  singularity  in the technological context                       
Alan Turing  often regarded as the father of modern computer science  laid a crucial foundation for contemporary discourse on the technological singularity  His pivotal      paper   Computing Machinery and Intelligence   introduced the idea of a machine s ability to exhibit intelligent behavior equivalent to or indistinguishable from that of a human            
Stanislaw Ulam reported in      an earlier discussion with von Neumann  centered on the accelerating progress of technology and changes in human life  which gives the appearance of approaching some essential singularity in the history of the race beyond which human affairs  as we know them  could not continue              Subsequent authors have echoed this viewpoint                       
The concept and the term  singularity  were popularized by Vernor Vinge  first in       in an article that claimed that  once humans create intelligences greater than their own  there will be a technological and social transition similar in some sense to  the knotted space time at the center of a black hole               and later in his      essay  The Coming Technological Singularity                         in which he wrote that it would signal the end of the human era  as the new superintelligence would continue to upgrade itself and would advance technologically at an incomprehensible rate  and he would be surprised if it occurred before      or after                  
Another significant contribution to wider circulation of the notion was Ray Kurzweil s      book The Singularity Is Near  predicting singularity by                 
Some scientists  including Stephen Hawking  have expressed concerns that artificial superintelligence  ASI  could result in human extinction                          The consequences of a technological singularity and its potential benefit or harm to the human race have been intensely debated      citation needed     
Prominent technologists and academics dispute the plausibility of a technological singularity and the associated artificial intelligence explosion  including Paul Allen              Jeff Hawkins              John Holland  Jaron Lanier  Steven Pinker              Theodore Modis              Gordon Moore              and Roger Penrose              One claim made was that artificial intelligence growth is likely to run into decreasing returns instead of accelerating ones  as was observed in previously developed human technologies      citation needed     


Intelligence explosion edit 
Further information  Recursive self improvement
Although technological progress has been accelerating in most areas  it has been limited by the basic intelligence of the human brain  which has not  according to Paul R  Ehrlich  changed significantly for millennia              However  with the increasing power of computers and other technologies  it might eventually be possible to build a machine that is significantly more intelligent than humans             
If a superhuman intelligence were to be invented either through the amplification of human intelligence or through artificial intelligence it would  in theory  vastly improve over human problem solving and inventive skills  Such an AI is referred to as Seed AI                         because if an AI were created with engineering capabilities that matched or surpassed those of its human creators  it would have the potential to autonomously improve its own software and hardware to design an even more capable machine  which could repeat the process in turn  This recursive self improvement could accelerate  potentially allowing enormous qualitative change before any upper limits imposed by the laws of physics or theoretical computation set in  It is speculated that over many iterations  such an AI would far surpass human cognitive abilities 
I  J  Good speculated that superhuman intelligence might bring about an intelligence explosion                         

Let an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever  Since the design of machines is one of these intellectual activities  an ultraintelligent machine could design even better machines  there would then unquestionably be an  intelligence explosion   and the intelligence of man would be left far behind  Thus the first ultraintelligent machine is the last invention that man need ever make  provided that the machine is docile enough to tell us how to keep it under control         Speculations Concerning the First Ultraintelligent Machine       
One version of intelligence explosion is where computing power approaches infinity in a finite amount of time  In this version  once AIs are performing the research to improve themselves  speed doubles e g  after   years  then   year  then   months  then   months  then     months  etc   where the infinite sum of the doubling periods is   years  Unless prevented by physical limits of computation and time quantization  this process would achieve infinite computing power in   years  properly earning the name  singularity  for the final state  This form of intelligence explosion is described in Yudkowsky                    

Emergence of superintelligence edit 
Further information  Superintelligence
A superintelligence  hyperintelligence  or superhuman intelligence is a hypothetical agent that possesses intelligence far surpassing that of the brightest and most gifted human minds               Superintelligence  may also refer to the form or degree of intelligence possessed by such an agent  John von Neumann  Vernor Vinge and Ray Kurzweil define the concept in terms of the technological creation of super intelligence  arguing that it is difficult or impossible for present day humans to predict what human beings  lives would be like in a post singularity world                        
The related concept  speed superintelligence  describes an AI that can function like a human mind  only much faster              For example  with a million fold increase in the speed of information processing relative to that of humans  a subjective year would pass in    physical seconds              Such a difference in information processing speed could drive the singularity             
Technology forecasters and researchers disagree regarding when  or whether  human intelligence will likely be surpassed  Some argue that advances in artificial intelligence  AI  will probably result in general reasoning systems that bypass human cognitive limitations  Others believe that humans will evolve or directly modify their biology so as to achieve radically greater intelligence                          A number of futures studies focus on scenarios that combine these possibilities  suggesting that humans are likely to interface with computers  or upload their minds to computers  in a way that enables substantial intelligence amplification  The      book The Age of Em by Robin Hanson describes a hypothetical future scenario in which human brains are scanned and digitized  creating  uploads  or digital versions of human consciousness  In this future  the development of these uploads may precede or coincide with the emergence of superintelligent artificial intelligence             

Variations edit 
Non AI singularity edit 
Some writers use  the singularity  in a broader way to refer to any radical changes in society brought about by new technology  such as molecular nanotechnology                                       although Vinge and other writers specifically state that without superintelligence  such changes would not qualify as a true singularity            

Predictions edit 
Progress of AI performance on various benchmarks compared to human level performance             
There have been numerous dates predicted for the attainment of singularity 
In       Good wrote that it was more probable than not that an ultra intelligent machine would be built within the twentieth century             
That computing capabilities for human level AI would be available in supercomputers before      was predicted in      by Moravec  assuming that the current rate of improvement continued             
The attainment of greater than human intelligence between      and      was predicted by Vinge in                 
A singularity in      was predicted by Yudkowsky in                  
Human level AI around      and the singularity in      was predicted by Kurzweil in                               He reaffirmed these predictions in      in The Singularity is Nearer             
Human level AI by       and intelligence far beyond human by      was predicted in      by Moravec  revising his earlier prediction             
A confidence of     that human level AI would be developed by           was the outcome of four polls of AI researchers  conducted in      and      by Bostrom and M ller                         
Elon Musk in March      predicted that AI would be smarter than any individual human  in the next year or two  and that AI would be smarter than all humans combined by      or       along with an    percent chance that AI would have a  good outcome   while there was a    percent chance of  annihilation              

Plausibility edit 
Prominent technologists and academics dispute the plausibility of a technological singularity  including Paul Allen              Jeff Hawkins              John Holland  Jaron Lanier  Steven Pinker              Theodore Modis              and Gordon Moore              whose law is often cited in support of the concept             
Most proposed methods for creating superhuman or transhuman minds fall into one of two categories  intelligence amplification of human brains and artificial intelligence  The many speculated ways to augment human intelligence include bioengineering  genetic engineering  nootropic drugs  AI assistants  direct brain computer interfaces and mind uploading  These multiple possible paths to an intelligence explosion  all of which will presumably be pursued  makes a singularity more likely             
Robin Hanson expressed skepticism of human intelligence augmentation  writing that once the  low hanging fruit  of easy methods for increasing human intelligence have been exhausted  further improvements will become increasingly difficult              Despite all of the speculated ways for amplifying human intelligence  non human artificial intelligence  specifically seed AI  is the most popular option among the hypotheses that would advance the singularity      citation needed     
The possibility of an intelligence explosion depends on three factors              The first accelerating factor is the new intelligence enhancements made possible by each previous improvement  However  as the intelligences become more advanced  further advances will become more and more complicated  possibly outweighing the advantage of increased intelligence  Each improvement should generate at least one more improvement  on average  for movement towards singularity to continue  Finally  the laws of physics may eventually prevent further improvement 
There are two logically independent  but mutually reinforcing  causes of intelligence improvements  increases in the speed of computation  and improvements to the algorithms used             The former is predicted by Moore s Law and the forecasted improvements in hardware              and is comparatively similar to previous technological advances  But Schulman and Sandberg             argue that software will present more complex challenges than simply operating on hardware capable of running at human intelligence levels or beyond 
A      email survey of authors with publications at the      NeurIPS and ICML machine learning conferences asked about the chance that  the intelligence explosion argument is broadly correct   Of the respondents      said it was  quite likely       said it was  likely       said it was  about even       said it was  unlikely  and     said it was  quite unlikely              

Speed improvements edit 
Both for human and artificial intelligence  hardware improvements increase the rate of future hardware improvements  An analogy to Moore s Law suggests that if the first doubling of speed took    months  the second would take    subjective months  or   external months  whereafter  four months  two months  and so on towards a speed singularity                          Some upper limit on speed may eventually be reached  Jeff Hawkins has stated that a self improving computer system would inevitably run into upper limits on computing power   in the end there are limits to how big and fast computers can run  We would end up in the same place  we d just get there a bit faster  There would be no singularity              
It is difficult to directly compare silicon based hardware with neurons  But Berglas        notes that computer speech recognition is approaching human capabilities  and that this capability seems to require       of the volume of the brain  This analogy suggests that modern computer hardware is within a few orders of magnitude of being as powerful as the human brain  as well as taking up a lot less space  However  the costs of training systems with deep learning may be larger      citation needed          a     

Exponential growth edit 
Ray Kurzweil writes that  due to paradigm shifts  a trend of exponential growth extends Moore s law from integrated circuits to earlier transistors  vacuum tubes  relays  and electromechanical computers  He predicts that the exponential growth will continue  and that in a few decades the computing power of all computers will exceed that of   unenhanced   human brains  with superhuman artificial intelligence appearing around the same time 
	

An updated version of Moore s law over     Years  based on Kurzweil s graph   The   most recent data points are all Nvidia GPUs 
The exponential growth in computing technology suggested by Moore s law is commonly cited as a reason to expect a singularity in the relatively near future  and a number of authors have proposed generalizations of Moore s law  Computer scientist and futurist Hans Moravec proposed in a      book             that the exponential growth curve could be extended back through earlier computing technologies prior to the integrated circuit 
Ray Kurzweil postulates a law of accelerating returns in which the speed of technological change  and more generally  all evolutionary processes              increases exponentially  generalizing Moore s law in the same manner as Moravec s proposal  and also including material technology  especially as applied to nanotechnology   medical technology and others              Between      and       machines  application specific capacity to compute information per capita roughly doubled every    months  the per capita capacity of the world s general purpose computers has doubled every    months  the global telecommunication capacity per capita doubled every    months  and the world s storage capacity per capita doubled every    months              On the other hand  it has been argued that the global acceleration pattern having the   st century singularity as its parameter should be characterized as hyperbolic rather than exponential             
Kurzweil reserves the term  singularity  for a rapid increase in artificial intelligence  as opposed to other technologies   writing for example that  The Singularity will allow us to transcend these limitations of our biological bodies and brains     There will be no distinction  post Singularity  between human and machine               He also defines his predicted date of the singularity        in terms of when he expects computer based intelligences to significantly exceed the sum total of human brainpower  writing that advances in computing before that date  will not represent the Singularity  because they do  not yet correspond to a profound expansion of our intelligence              

Accelerating change edit 
According to Kurzweil  his logarithmic graph of    lists of paradigm shifts for key historic events shows an exponential trend 
Main article  Accelerating change
Some singularity proponents argue its inevitability through extrapolation of past trends  especially those pertaining to shortening gaps between improvements to technology  In one of the first uses of the term  singularity  in the context of technological progress  Stanislaw Ulam tells of a conversation with John von Neumann about accelerating change  One conversation centered on the ever accelerating progress of technology and changes in the mode of human life  which gives the appearance of approaching some essential singularity in the history of the race beyond which human affairs  as we know them  could not continue            
Kurzweil claims that technological progress follows a pattern of exponential growth  following what he calls the  law of accelerating returns   Whenever technology approaches a barrier  Kurzweil writes  new technologies will surmount it  He predicts paradigm shifts will become increasingly common  leading to  technological change so rapid and profound it represents a rupture in the fabric of human history               Kurzweil believes that the singularity will occur by approximately                   His predictions differ from Vinge s in that he predicts a gradual ascent to the singularity  rather than Vinge s rapidly self improving superhuman intelligence 
Oft cited dangers include those commonly associated with molecular nanotechnology and genetic engineering  These threats are major issues for both singularity advocates and critics  and were the subject of Bill Joy s April      Wired magazine article  Why The Future Doesn t Need Us                         

Algorithm improvements edit 
Some intelligence technologies  like  seed AI                           may also have the potential to not just make themselves faster  but also more efficient  by modifying their source code  These improvements would make further improvements possible  which would make further improvements possible  and so on 
The mechanism for a recursively self improving set of algorithms differs from an increase in raw computation speed in two ways  First  it does not require external influence  machines designing faster hardware would still require humans to create the improved hardware  or to program factories appropriately      citation needed      An AI rewriting its own source code could do so while contained in an AI box 
Second  as with Vernor Vinge s conception of the singularity  it is much harder to predict the outcome  While speed increases seem to be only a quantitative difference from human intelligence  actual algorithm improvements would be qualitatively different  Eliezer Yudkowsky compares it to the changes that human intelligence brought  humans changed the world thousands of times quicker than evolution had done  and in totally different ways  Similarly  the evolution of life was a massive departure and acceleration from the previous geological rates of change  and improved intelligence could cause change to be as different again             
There are substantial dangers associated with an intelligence explosion singularity originating from a recursively self improving set of algorithms  First  the goal structure of the AI might self modify  potentially causing the AI to optimise for something other than what was originally intended                         
Secondly  AIs could compete for the same scarce resources humankind uses to survive                          While not actively malicious  AIs would promote the goals of their programming  not necessarily broader human goals  and thus might crowd out humans                                     
Carl Shulman and Anders Sandberg suggest that algorithm improvements may be the limiting factor for a singularity  while hardware efficiency tends to improve at a steady pace  software innovations are more unpredictable and may be bottlenecked by serial  cumulative research  They suggest that in the case of a software limited singularity  intelligence explosion would actually become more likely than with a hardware limited singularity  because in the software limited case  once human level AI is developed  it could run serially on very fast hardware  and the abundance of cheap hardware would make AI research less constrained              An abundance of accumulated hardware that can be unleashed once the software figures out how to use it has been called  computing overhang              

Criticism edit 
Some critics  like philosophers Hubert Dreyfus             and John Searle              assert that computers or machines cannot achieve human intelligence  Others  like physicist Stephen Hawking              object that whether machines can achieve a true intelligence or merely something similar to intelligence is irrelevant if the net result is the same 
Psychologist Steven Pinker stated in        There is not the slightest reason to believe in a coming singularity  The fact that you can visualize a future in your imagination is not evidence that it is likely or even possible  Look at domed cities  jet pack commuting  underwater cities  mile high buildings  and nuclear powered automobiles all staples of futuristic fantasies when I was a child that have never arrived  Sheer processing power is not a pixie dust that magically solves all your problems              
Martin Ford             postulates a  technology paradox  in that before the singularity could occur most routine jobs in the economy would be automated  since this would require a level of technology inferior to that of the singularity  This would cause massive unemployment and plummeting consumer demand  which in turn would destroy the incentive to invest in the technologies that would be required to bring about the singularity  Job displacement is increasingly no longer limited to those types of work traditionally considered to be  routine              
Theodore Modis             and Jonathan Huebner             argue that the rate of technological innovation has not only ceased to rise  but is actually now declining  Evidence for this decline is that the rise in computer clock rates is slowing  even while Moore s prediction of exponentially increasing circuit density continues to hold  This is due to excessive heat build up from the chip  which cannot be dissipated quickly enough to prevent the chip from melting when operating at higher speeds  Advances in speed may be possible in the future by virtue of more power efficient CPU designs and multi cell processors             
Theodore Modis holds the singularity cannot happen                                      He claims the  technological singularity  and especially Kurzweil lack scientific rigor  Kurzweil is alleged to mistake the logistic function  S function  for an exponential function  and to see a  knee  in an exponential function where there can in fact be no such thing              In a      article  Modis pointed out that no milestones                  breaks in historical perspective comparable in importance to the Internet  DNA  the transistor  or nuclear energy                  had been observed in the previous twenty years while five of them would have been expected according to the exponential trend advocated by the proponents of the technological singularity             
AI researcher J rgen Schmidhuber stated that the frequency of subjectively  notable events  appears to be approaching a   st century singularity  but cautioned readers to take such plots of subjective events with a grain of salt  perhaps differences in memory of recent and distant events could create an illusion of accelerating change where none exists             
Microsoft co founder Paul Allen argued the opposite of accelerating returns  the complexity brake              the more progress science makes towards understanding intelligence  the more difficult it becomes to make additional progress  A study of the number of patents shows that human creativity does not show accelerating returns  but in fact  as suggested by Joseph Tainter in his The Collapse of Complex Societies              a law of diminishing returns  The number of patents per thousand peaked in the period from      to       and has been declining since              The growth of complexity eventually becomes self limiting  and leads to a widespread  general systems collapse  
Hofstadter        raises concern that Ray Kurzweil is not sufficiently scientifically rigorous  that an exponential tendency of technology is not a scientific law like one of physics  and that exponential curves have no  knees               Nonetheless  he did not rule out the singularity in principle in the distant future             and in the light of ChatGPT and other recent advancements has revised his opinion significantly towards dramatic technological change in the near future             
Jaron Lanier denies that the singularity is inevitable   I do not think the technology is creating itself  It s not an autonomous process               Furthermore   The reason to believe in human agency over technological determinism is that you can then have an economy where people earn their own way and invent their own lives  If you structure a society on not emphasizing individual human agency  it s the same thing operationally as denying people clout  dignity  and self determination     to embrace  the idea of the Singularity  would be a celebration of bad data and bad politics              
Economist Robert J  Gordon points out that measured economic growth slowed around      and slowed even further since the financial crisis of            and argues that the economic data show no trace of a coming Singularity as imagined by mathematician I  J  Good             
Philosopher and cognitive scientist Daniel Dennett said in        The whole singularity stuff  that s preposterous  It distracts us from much more pressing problems   adding  AI tools that we become hyper dependent on  that is going to happen  And one of the dangers is that we will give them more authority than they warrant              
In addition to general criticisms of the singularity concept  several critics have raised issues with Kurzweil s iconic chart  One line of criticism is that a log log chart of this nature is inherently biased toward a straight line result  Others identify selection bias in the points that Kurzweil chooses to use  For example  biologist PZ Myers points out that many of the early evolutionary  events  were picked arbitrarily              Kurzweil has rebutted this by charting evolutionary events from    neutral sources  and showing that they fit a straight line on a log log chart  Kelly        argues that the way the Kurzweil chart is constructed with x axis having time before present  it always points to the singularity being  now   for any date on which one would construct such a chart  and shows this visually on Kurzweil s chart             
Some critics suggest religious motivations or implications of singularity  especially Kurzweil s version of it  The buildup towards the singularity is compared with Christian end of time scenarios  Beam calls it  a Buck Rogers vision of the hypothetical Christian Rapture               John Gray says  the Singularity echoes apocalyptic myths in which history is about to be interrupted by a world transforming event              
David Streitfeld in The New York Times questioned whether  it might manifest first and foremost thanks  in part  to the bottom line obsession of today s Silicon Valley as a tool to slash corporate America s head count              

Potential impacts edit 
Dramatic changes in the rate of economic growth have occurred in the past because of technological advancement  Based on population growth  the economy doubled every         years from the Paleolithic era until the Neolithic Revolution  The new agricultural economy doubled every     years  a remarkable increase  In the current era  beginning with the Industrial Revolution  the world s economic output doubles every fifteen years  sixty times faster than during the agricultural era  If the rise of superhuman intelligence causes a similar revolution  argues Robin Hanson  one would expect the economy to double at least quarterly and possibly on a weekly basis             

Uncertainty and risk edit 
Further information  Existential risk from artificial general intelligence
The term  technological singularity  reflects the idea that such change may happen suddenly  and that it is difficult to predict how the resulting new world would operate                          It is unclear whether an intelligence explosion resulting in a singularity would be beneficial or harmful  or even an existential threat                           Because AI is a major factor in singularity risk  a number of organizations pursue a technical theory of aligning AI goal systems with human values  including the Future of Humanity Institute  until        the Machine Intelligence Research Institute              the Center for Human Compatible Artificial Intelligence  and the Future of Life Institute 

Physicist Stephen Hawking said in      that  Success in creating AI would be the biggest event in human history  Unfortunately  it might also be the last  unless we learn how to avoid the risks                Hawking believed that in the coming decades  AI could offer  incalculable benefits and risks  such as  technology outsmarting financial markets  out inventing human researchers  out manipulating human leaders  and developing weapons we cannot even understand                Hawking suggested that artificial intelligence should be taken more seriously and that more should be done to prepare for the singularity              So  facing possible futures of incalculable benefits and risks  the experts are surely doing everything possible to ensure the best outcome  right  Wrong  If a superior alien civilisation sent us a message saying   We ll arrive in a few decades   would we just reply   OK  call us when you get here                  we ll leave the lights on   Probably not                  but this is more or less what is happening with AI 
Berglas        claims that there is no direct evolutionary motivation for an AI to be friendly to humans  Evolution has no inherent tendency to produce outcomes valued by humans  and there is little reason to expect an arbitrary optimisation process to promote an outcome desired by humankind  rather than inadvertently leading to an AI behaving in a way not intended by its creators                                         Anders Sandberg has also elaborated on this scenario  addressing various common counter arguments               AI researcher Hugo de Garis suggests that artificial intelligences may simply eliminate the human race for access to scarce resources                          and humans would be powerless to stop them               Alternatively  AIs developed under evolutionary pressure to promote their own survival could outcompete humanity             
Bostrom        discusses human extinction scenarios  and lists superintelligence as a possible cause 

When we create the first superintelligent entity  we might make a mistake and give it goals that lead it to annihilate humankind  assuming its enormous intellectual advantage gives it the power to do so  For example  we could mistakenly elevate a subgoal to the status of a supergoal  We tell it to solve a mathematical problem  and it complies by turning all the matter in the solar system into a giant calculating device  in the process killing the person who asked the question 
According to Eliezer Yudkowsky  a significant problem in AI safety is that unfriendly artificial intelligence is likely to be much easier to create than friendly AI  While both require large advances in recursive optimisation process design  friendly AI also requires the ability to make goal structures invariant under self improvement  or the AI could transform itself into something unfriendly  and a goal structure that aligns with human values and does not automatically destroy the human race  An unfriendly AI  on the other hand  can optimize for an arbitrary goal structure  which does not need to be invariant under self modification               Bill Hibbard        harvtxt error  no target  CITEREFBill Hibbard      help  proposes an AI design that avoids several dangers including self delusion               unintended instrumental actions                           and corruption of the reward generator               He also discusses social impacts of AI              and testing AI               His      book Super Intelligent Machines advocates the need for public education about AI and public control over AI  It also proposed a simple design that was vulnerable to corruption of the reward generator 

Next step of sociobiological evolution edit 
Further information  Sociocultural evolution
This section may contain material not related to the topic of the article  Please help improve this section or discuss this issue on the talk page    October        Learn how and when to remove this message 
Schematic Timeline of Information and Replicators in the Biosphere  Gillings et al  s  major evolutionary transitions  in information processing              
Amount of digital information worldwide         bytes  versus human genome information worldwide       bytes  in                  
While the technological singularity is usually seen as a sudden event  some scholars argue the current speed of change already fits this description      citation needed     
In addition  some argue that we are already in the midst of a major evolutionary transition that merges technology  biology  and society  Digital technology has infiltrated the fabric of human society to a degree of indisputable and often life sustaining dependence 
A      article in Trends in Ecology  amp  Evolution argues that  humans already embrace fusions of biology and technology  We spend most of our waking time communicating through digitally mediated channels    we trust artificial intelligence with our lives through antilock braking in cars and autopilots in planes    With one in three courtships leading to marriages in America beginning online  digital algorithms are also taking a role in human pair bonding and reproduction  
The article further argues that from the perspective of the evolution  several previous Major Transitions in Evolution have transformed life through innovations in information storage and replication  RNA  DNA  multicellularity  and culture and language   In the current stage of life s evolution  the carbon based biosphere has generated a system  humans  capable of creating technology that will result in a comparable evolutionary transition 
The digital information created by humans has reached a similar magnitude to biological information in the biosphere  Since the     s  the quantity of digital information stored has doubled about every     years  reaching about   zettabytes in              bytes               
In biological terms  there are          billion humans on the planet  each having a genome of          billion nucleotides  Since one byte can encode four nucleotide pairs  the individual genomes of every human on the planet could be encoded by approximately        bytes  The digital realm stored     times more information than this in       see figure   The total amount of DNA contained in all of the cells on Earth is estimated to be about          base pairs  equivalent to            bytes of information 
If growth in digital storage continues at its current rate of        compound annual growth per year              it will rival the total information content contained in all of the DNA in all of the cells on Earth in about     years  This would represent a doubling of the amount of information stored in the biosphere across a total time period of just     years               

Implications for human society edit 
Further information  Artificial intelligence in fiction
In February       under the auspices of the Association for the Advancement of Artificial Intelligence  AAAI   Eric Horvitz chaired a meeting of leading computer scientists  artificial intelligence researchers and roboticists at the Asilomar conference center in Pacific Grove  California  The goal was to discuss the potential impact of the hypothetical possibility that robots could become self sufficient and able to make their own decisions  They discussed the extent to which computers and robots might be able to acquire autonomy  and to what degree they could use such abilities to pose threats or hazards              
Some machines are programmed with various forms of semi autonomy  including the ability to locate their own power sources and choose targets to attack with weapons  Also  some computer viruses can evade elimination and  according to scientists in attendance  could therefore be said to have reached a  cockroach  stage of machine intelligence  The conference attendees noted that self awareness as depicted in science fiction is probably unlikely  but that other potential hazards and pitfalls exist              
Frank S  Robinson predicts that once humans achieve a machine with the intelligence of a human  scientific and technological problems will be tackled and solved with brainpower far superior to that of humans  He notes that artificial systems are able to share data more directly than humans  and predicts that this would result in a global network of super intelligence that would dwarf human capability               Robinson also discusses how vastly different the future would potentially look after such an intelligence explosion 

Hard or soft takeoff edit 
In this sample recursive self improvement scenario  humans modifying an AI s architecture would be able to double its performance every three years through  for example     generations before exhausting all feasible improvements  left   If instead the AI is smart enough to modify its own architecture as well as human researchers can  its time required to complete a redesign halves with each generation  and it progresses all    feasible generations in six years  right               
In a hard takeoff scenario  an artificial superintelligence rapidly self improves   taking control  of the world  perhaps in a matter of hours   too quickly for significant human initiated error correction or for a gradual tuning of the agent s goals  In a soft takeoff scenario  the AI still becomes far more powerful than humanity  but at a human like pace  perhaps on the order of decades   on a timescale where ongoing human interaction and correction can effectively steer the AI s development                           
Ramez Naam argues against a hard takeoff  He has pointed out that we already see recursive self improvement by superintelligences  such as corporations  Intel  for example  has  the collective brainpower of tens of thousands of humans and probably millions of CPU cores to    design better CPUs   However  this has not led to a hard takeoff  rather  it has led to a soft takeoff in the form of Moore s law               Naam further points out that the computational complexity of higher intelligence may be much greater than linear  such that  creating a mind of intelligence   is probably more than twice as hard as creating a mind of intelligence                 
J  Storrs Hall believes that  many of the more commonly seen scenarios for overnight hard takeoff are circular                  they seem to assume hyperhuman capabilities at the starting point of the self improvement process  in order for an AI to be able to make the dramatic  domain general improvements required for takeoff  Hall suggests that rather than recursively self improving its hardware  software  and infrastructure all on its own  a fledgling AI would be better off specializing in one area where it was most effective and then buying the remaining components on the marketplace  because the quality of products on the marketplace continually improves  and the AI would have a hard time keeping up with the cutting edge technology used by the rest of the world              
Ben Goertzel agrees with Hall s suggestion that a new human level AI would do well to use its intelligence to accumulate wealth  The AI s talents might inspire companies and governments to disperse its software throughout society  Goertzel is skeptical of a hard five minute takeoff but speculates that a takeoff from human to superhuman level on the order of five years is reasonable  He refers to this scenario as a  semihard takeoff               
Max More disagrees  arguing that if there were only a few superfast human level AIs  that they would not radically change the world  as they would still depend on other people to get things done and would still have human cognitive constraints  Even if all superfast AIs worked on intelligence augmentation  it is unclear why they would do better in a discontinuous way than existing human cognitive scientists at producing super human intelligence  although the rate of progress would increase  More further argues that a superintelligence would not transform the world overnight  a superintelligence would need to engage with existing  slow human systems to accomplish physical impacts on the world   The need for collaboration  for organization  and for putting ideas into physical changes will ensure that all the old rules are not thrown out overnight or even within years               

Relation to immortality and aging edit 
Eric Drexler  one of the founders of nanotechnology  theorized in      the possibility of cell repair devices  including ones operating within cells and using as yet hypothetical biological machines               According to Richard Feynman  it was his former graduate student and collaborator Albert Hibbs who originally suggested to him  circa       the idea of a medical use for Feynman s theoretical micromachines  Hibbs suggested that certain repair machines might one day be reduced in size to the point that it would  in theory  be possible to  as Feynman put it   swallow the doctor   The idea was incorporated into Feynman s      essay There s Plenty of Room at the Bottom              
Moravec predicted in      the possibility of  uploading  human mind into a human like robot  achieving quasi immortality by extreme longevity via transfer of the human mind between successive new robots as the old ones wear out  beyond that  he predicts later exponential acceleration of subjective experience of time leading to a subjective sense of immortality             
Kurzweil suggested in      that medical advances would allow people to protect their bodies from the effects of aging  making the life expectancy limitless  Kurzweil argues that the technological advances in medicine would allow us to continuously repair and replace defective components in our bodies  prolonging life to an undetermined age               Kurzweil further buttresses his argument by discussing current bio engineering advances  Kurzweil suggests somatic gene therapy  after synthetic viruses with specific genetic information  the next step would be to apply this technology to gene therapy  replacing human DNA with synthesized genes              
Beyond merely extending the operational life of the physical body  Jaron Lanier argues for a form of immortality called  Digital Ascension  that involves  people dying in the flesh and being uploaded into a computer and remaining conscious               

History of the concept edit 
A paper by Mahendra Prasad  published in AI Magazine  asserts that the   th century mathematician Marquis de Condorcet was the first person to hypothesize and mathematically model an intelligence explosion and its effects on humanity              
An early description of the idea was made in John W  Campbell s      short story  The Last Evolution               
In his      obituary for John von Neumann  Ulam recalled a conversation with von Neumann about the  ever accelerating progress of technology and changes in the mode of human life  which gives the appearance of approaching some essential singularity in the history of the race beyond which human affairs  as we know them  could not continue             
In       Good wrote his essay postulating an  intelligence explosion  of recursive self improvement of a machine intelligence                         
In       Hans Moravec wrote an article with unclear publishing status where he envisioned a development of self improving thinking machines  a creation of  super consciousness  the synthesis of terrestrial life  and perhaps jovian and martian life as well  constantly improving and extending itself  spreading outwards from the solar system  converting non life into mind                             The article describes the human mind uploading later covered in Moravec         The machines are expected to reach human level and then improve themselves beyond that   Most significantly of all  they  the machines  can be put to work as programmers and engineers  with the task of optimizing the software and hardware which make them what they are  The successive generations of machines produced this way will be increasingly smarter and more cost effective    Humans will no longer be needed  and their abilities will be overtaken by the machines   In the long run the sheer physical inability of humans to keep up with these rapidly evolving progeny of our minds will ensure that the ratio of people to machines approaches zero  and that a direct descendant of our culture  but not our genes  inherits the universe   While the word  singularity  is not used  the notion of human level thinking machines thereafter improving themselves beyond human level is there  In this view  there is no intelligence explosion in the sense of a very rapid intelligence increase once human equivalence is reached  An updated version of the article was published in      in Analog Science Fiction and Fact                           
In       Stanis aw Lem published his science fiction novel Golem XIV  It describes a military AI computer  Golem XIV  who obtains consciousness and starts to increase his own intelligence  moving towards personal technological singularity  Golem XIV was originally created to aid its builders in fighting wars  but as its intelligence advances to a much higher level than that of humans  it stops being interested in the military requirements because it finds them lacking internal logical consistency 
In       Vernor Vinge addressed Good s intelligence explosion in print in the January      issue of Omni magazine  In this op ed piece  Vinge seems to have been the first to use the term  singularity   although not  technological singularity   in a way that was specifically tied to the creation of intelligent machines                          

We will soon create intelligences greater than our own  When this happens  human history will have reached a kind of singularity  an intellectual transition as impenetrable as the knotted space time at the center of a black hole  and the world will pass far beyond our understanding  This singularity  I believe  already haunts a number of science fiction writers  It makes realistic extrapolation to an interstellar future impossible  To write a story set more than a century hence  one needs a nuclear war in between     so that the world remains intelligible 
In       in  The Time Scale of Artificial Intelligence   artificial intelligence researcher Ray Solomonoff articulated mathematically the related notion of what he called an  infinity point   if a research community of human level self improving AIs take four years to double their own speed  then two years  then one year and so on  their capabilities increase infinitely in finite time                         
In       Vernor Vinge published Marooned in Realtime  a science fiction novel where a few remaining humans traveling forward in the future have survived an unknown extinction event that might well be a singularity  In a short afterword  the author states that an actual technological singularity would not be the end of the human species   of course it seems very unlikely that the Singularity would be a clean vanishing of the human race   On the other hand  such a vanishing is the timelike analog of the silence we find all across the sky                              
In       Vinge used the phrase  technological singularity   including  technological   in the short story collection Threats and Other Promises  writing in the introduction to his story  The Whirligig of Time   p            Barring a worldwide catastrophe  I believe that technology will achieve our wildest dreams  and soon  When we raise our own intelligence and that of our creations  we are no longer in a world of human sized characters  At that point we have fallen into a technological  black hole   a technological singularity              
In       Hans Moravec published Mind Children              in which he predicted human level intelligence in supercomputers by       self improving intelligent machines far surpassing human intelligence later  human mind uploading into human like robots later  intelligent machines leaving humans behind  and space colonization  He did not mention  singularity   though  and he did not speak of a rapid explosion of intelligence immediately after the human level is achieved  Nonetheless  the overall singularity tenor is there in predicting both human level artificial intelligence and further artificial intelligence far surpassing humans later 
Vinge s      article  The Coming Technological Singularity  How to Survive in the Post Human Era              spread widely on the internet and helped to popularize the idea               This article contains the statement   Within thirty years  we will have the technological means to create superhuman intelligence  Shortly after  the human era will be ended   Vinge argues that science fiction authors cannot write realistic post singularity characters who surpass the human intellect  as the thoughts of such an intellect would be beyond the ability of humans to express            
Minsky s      article says robots will  inherit the Earth   possibly with the use of nanotechnology  and proposes to think of robots as human  mind children   drawing the analogy from Moravec  The rhetorical effect of that analogy is that if humans are fine to pass the world to their biological children  they should be equally fine to pass it to robots  their  mind  children  As per Minsky   we could design our  mind children  to think a million times faster than we do  To such a being  half a minute might seem as long as one of our years  and each hour as long as an entire human lifetime   The feature of the singularity present in Minsky is the development of superhuman artificial intelligence   million times faster    but there is no talk of sudden intelligence explosion  self improving thinking machines or unpredictability beyond any specific event and the word  singularity  is not used              
Tipler s      book The Physics of Immortality predicts a future where super intelligent machines will build enormously powerful computers  people will be  emulated  in computers  life will reach every galaxy and people will achieve immortality when they reach Omega Point               There is no talk of Vingean  singularity  or sudden intelligence explosion  but intelligence much greater than human is there  as well as immortality 
In       Yudkowsky predicted a singularity by                   His version of singularity involves intelligence explosion  once AIs are doing the research to improve themselves  speed doubles after   years  then   one year  then after   months  then after   months  then after     months  and after more iterations  the  singularity  is reached              This construction implies that the speed reaches infinity in finite time 
In       Bill Joy  a prominent technologist and a co founder of Sun Microsystems  voiced concern over the potential dangers of robotics  genetic engineering  and nanotechnology             
In       Kurzweil published The Singularity Is Near  Kurzweil s publicity campaign included an appearance on The Daily Show with Jon Stewart              
From      to       an annual Singularity Summit conference was organized by Machine Intelligence Research Institute  founded by Eliezer Yudkowsky 
In       Yudkowsky suggested that many of the varied definitions that have been assigned to  singularity  are mutually incompatible rather than mutually supporting                           For example  Kurzweil extrapolates current technological trajectories past the arrival of self improving AI or superhuman intelligence  which Yudkowsky argues represents a tension with both I  J  Good s proposed discontinuous upswing in intelligence and Vinge s thesis on unpredictability             
In       Kurzweil and X Prize founder Peter Diamandis announced the establishment of Singularity University  a nonaccredited private institute whose stated mission is  to educate  inspire and empower leaders to apply exponential technologies to address humanity s grand challenges                Funded by Google  Autodesk  ePlanet Ventures  and a group of technology industry leaders  Singularity University is based at NASA s Ames Research Center in Mountain View  California  The not for profit organization runs an annual ten week graduate program during summer that covers ten different technology and allied tracks  and a series of executive programs throughout the year 

In politics edit 
In       the Joint Economic Committee of the United States Congress released a report about the future of nanotechnology  It predicts significant technological and political changes in the mid term future  including possible technological singularity                                        
Former President of the United States Barack Obama spoke about singularity in his interview to Wired in                   

One thing that we haven t talked about too much  and I just want to go back to  is we really have to think through the economic implications  Because most people aren t spending a lot of time right now worrying about singularity they are worrying about  Well  is my job going to be replaced by a machine  
Notes edit 


  Large language models such as ChatGPT and Llama require millions of hours of graphics processing unit  GPU  time  Training Meta s Llama in      took    days on      NVIDIA A    GPUs  thus requiring hardware substantially larger than a brain  Training took around a million GPU hours  with an estimated cost of over    million   Even so  it is far smaller  and thus easier to train  than a LLM such as ChatGPT  which as of      had     billion parameters to adjust  compared to    million for Llama               Training Google s Gemini LLM is estimated to have cost between     million and      million  similar to that of ChatGPT                


See also edit 

Technology portal
Artificial consciousness        Field in cognitive science
Ephemeralization        Technological advancement theory
Global brain        Futuristic concept of a global interconnected network
Technological revolution        Period of rapid technological change
Technophobia        Fear or discomfort with advanced technology
Neo Luddism        Philosophy opposing modern technology
References edit 
Citations edit 


  Cadwalladr  Carole     February         Are the robots about to rise  Google s new director of engineering thinks so    The Guardian  Retrieved   May      

   Collection of sources defining  singularity    singularitysymposium com  Archived from the original on    April       Retrieved    April      

  a b Eden  Amnon H   Moor  James H   S raker  Johnny H   Steinhart  Eric  eds          Singularity Hypotheses  A Scientific and Philosophical Assessment  The Frontiers Collection  Dordrecht  Springer  pp            doi                            ISBN                    

  a b c d e f g h Vinge  Vernor   The Coming Technological Singularity  How to Survive in the Post Human Era  Archived            at the Wayback Machine  in Vision     Interdisciplinary Science and Engineering in the Era of Cyberspace  G  A  Landis  ed   NASA Publication CP        pp                  There may be developed computers that are  awake  and superhumanly intelligent   To date  there has been much controversy as to whether we can create human equivalence in a machine  But if the answer is  yes  we can   then there is little doubt that beings more intelligent can be constructed shortly thereafter   

  Vinge  Vernor          The Coming Technological Singularity  How to Survive in the Post Human Era   PDF   Proceedings of a symposium cosponsored by the NASA Lewis Research Center and the Ohio Aerospace Institute and held in Westlake  Ohio March              NASA Conference Publication  Vol              p           Bibcode     vise nasa     V 

  Shanahan  Murray    August        The Technological Singularity  MIT Press  p            ISBN                        

   What is the Techological Singularity    IBM   www ibm com     August       Retrieved    November      

  a b c Ulam  Stanislaw  May         Tribute to John von Neumann   PDF   Bulletin of the American Mathematical Society          part       Archived  PDF  from the original on    February       Retrieved   November      

  a b c d e f Chalmers  David J           The Singularity  A Philosophical Analysis   PDF   Journal of Consciousness Studies                  

  a b Dooling  Richard  Rapture for the Geeks  When AI Outsmarts IQ         p    

  Sparkes  Matthew     January         Top scientists call for caution over artificial intelligence   The Telegraph  UK   Archived from the original on   April       Retrieved    April      

   Hawking  AI could end human race   BBC    December       Archived from the original on    October       Retrieved    November      

  a b c Allen  Paul G   Greaves  Mark     October         Paul Allen  The Singularity Isn t Near   MIT Technology Review  retrieved    April     

  a b c d e f g h i  Tech Luminaries Address Singularity   IEEE Spectrum    June       Archived from the original on    April       Retrieved   September      

  a b c Modis  Theodore          Why the Singularity Cannot Happen   Published in Eden  Amnon H  et al  Eds           Singularity Hypothesis  PDF   New York  Springer  p            ISBN                         pp          

  Penrose  Roger         The emperor s new mind  concerning computers  minds and the laws of physics  Oxford  Oxford Univ  Press  ISBN                        

  Ehrlich  Paul   Paul Ehrlich  The Dominant Animal  Human Evolution and the Environment   The Long Now   longnow org  Retrieved    June      

   Businessweek   Bloomberg   Bloomberg com     April       Retrieved    June      

  a b Yampolskiy  Roman V   Analysis of types of self improving software   Artificial General Intelligence  Springer International Publishing        pp          

  a b Eliezer Yudkowsky  General Intelligence and Seed AI Creating Complete Minds Capable of Open Ended Self Improvement       

  a b c Good  I  J          Speculations Concerning the First Ultraintelligent Machine  archived from the original on    May     

  a b Good  I  J          Speculations Concerning the First Ultraintelligent Machine  PDF   archived from the original  PDF  on   May     

  a b c d e Yudkowsky  Eliezer          Staring into the Singularity   Archived from the original on    October      

  Chalmers  David J           The Singularity  A Philosophical Analysis   Science Fiction and Philosophy  From Time Travel to Superintelligence   nd      ed    Wiley  pp                doi                       ch    ISBN                        

  Ray Kurzweil  The Singularity Is Near  pp           Penguin Group       

  Sotala  Kaj  Yampolskiy  Roman          Risks of the Journey to the Singularity   The Technological Singularity  The Frontiers Collection  Berlin and Heidelberg  Germany  Springer Berlin Heidelberg  pp              doi                              ISBN                        

  a b  What is the Singularity         Singularity Institute for Artificial Intelligence   Singinst org  Archived from the original on   September       Retrieved   September      

  Chalmers  David J           The Singularity   Science Fiction and Philosophy  John Wiley  amp  Sons  Inc  pp                doi                       ch    ISBN                    

  Pearce  David         Eden  Amnon H   Moor  James H   S raker  Johnny H   Steinhart  Eric  eds     The Biointelligence Explosion   Singularity Hypotheses  The Frontiers Collection  Berlin and Heidelberg  Germany  Springer Berlin Heidelberg  pp                doi                               ISBN                         retrieved    January     

  Gouveia  Steven S   ed           ch      Humans and Intelligent Machines  Co evolution  Fusion or Replacement    David Pearce   The Age of Artificial Intelligence  An Exploration  Vernon Press  ISBN                        

  Hanson  Robin         The Age of Em  Oxford  England  Oxford University Press  p            ISBN                    

  Hall  Josh          Singularity  Nanotech or AI    Hplusmagazine com  Archived from the original on    December       Retrieved   September      

  a b c Yudkowsky  Eliezer         The Singularity  Three Major Schools  archived from the original on   October     

  Sandberg  Anders  An overview of models of technological singularity Archived            at the Wayback Machine

   International scientific report on the safety of advanced AI  interim report   GOV UK     May       p          

  a b c Hans Moravec  Mind Children      

   List of Analyses of Time to Human Level AI   AI Impacts     January       Retrieved    June      

  Kurzweil  Ray         The Singularity Is Near  Penguin Group  p           

  Kurzweil  Ray         The singularity is nearer  when we merge with Al  New York  Viking  ISBN                         OCLC                 

  Moravec  Hans P          Robot  Mere Machine to Transcendent Mind  Oxford University Press USA 

  Khatchadourian  Raffi     November         The Doomsday Invention   The New Yorker  Archived from the original on    April       Retrieved    January      

  M ller  V  C    amp  Bostrom  N           Future progress in artificial intelligence  A survey of expert opinion   In V  C  M ller  ed   Fundamental issues of artificial intelligence  pp            Berlin  Germany  Springer Berlin  http   philpapers org rec MLLFPI Archived            at the Wayback Machine 

  Bidgood  Jess  Nehamas  Nicholas    March         Social Security and Sex Robots  Musk Veers Off Script With Joe Rogan   New York Times  Retrieved   March      

  Wallich  Paul    June         Who s Who In The Singularity   IEEE Spectrum  Archived from the original on    March       Retrieved   September      

  Hanson  Robin          Some Skepticism   Archived from the original on    February       Retrieved   April      

  David Chalmers John Locke Lecture     May       Exam Schools  Oxford  Presenting a philosophical analysis of the possibility of a technological singularity or  intelligence explosion  resulting from recursively self improving AI Archived            at the Wayback Machine 

   ITRS   PDF   Archived from the original  PDF  on    September       Retrieved   September      

  Shulman  Carl  Anders  Sandberg          Implications of a Software Limited Singularity   PDF   Machine Intelligence Research Institute 

  Grace  Katja  Salvatier  John  Dafoe  Allan  Zhang  Baobao  Evans  Owain     May         When Will AI Exceed Human Performance  Evidence from AI Experts   arXiv             cs AI  

  Siracusa  John     August         Mac OS X      Snow Leopard  the Ars Technica review   Ars Technica  Archived from the original on   September       Retrieved   September      

  Leswing  Jonathan Vanian Kif     March         ChatGPT and generative AI are booming  but the costs can be extraordinary   CNBC  Retrieved   February        cite web     CS  maint  multiple names  authors list  link 

  Buchholz  Katharina   The Extreme Cost Of Training AI Models   Forbes  Retrieved   February      

  Moravec  Hans         Robot  Mere Machine to Transcendent Mind  Oxford University Press  p           ISBN                        

  Ray Kurzweil  The Age of Spiritual Machines  Viking         ISBN                         pp         Archived            at the Wayback Machine

  a b Ray Kurzweil  The Singularity Is Near  Penguin Group      

  a b  The World s Technological Capacity to Store  Communicate  and Compute Information  Archived            at the Wayback Machine  Martin Hilbert and Priscila L pez         Science              pp         free access to the article through  martinhilbert net WorldInfoCapacity html 

  Korotayev  Andrey V   LePoire  David J   eds           The   st Century Singularity and Global Futures   World Systems Evolution and Global Futures  doi                            ISBN                         ISSN                 S CID                

  Ray Kurzweil  The Singularity Is Near  p     Penguin Group      

  Ray Kurzweil  The Singularity Is Near  pp           Penguin Group       
 So we will be producing about      to      cps of nonbiological computation per year in the early     s  This is roughly equal to our estimate for the capacity of all living biological human intelligence     This state of computation in the early     s will not represent the Singularity  however  because it does not yet correspond to a profound expansion of our intelligence  By the mid     s  however  that one thousand dollars  worth of computation will be equal to      cps  so the intelligence created per year  at a total cost of about        will be about one billion times more powerful than all human intelligence today  That will indeed represent a profound change  and it is for that reason that I set the date for the Singularity representing a profound and disruptive transformation in human capability as       

  Kurzweil  Raymond          The Law of Accelerating Returns   Nature Physics         Lifeboat Foundation       Bibcode     NatPh         B  doi         nphys      archived from the original on    August       retrieved   August      

  a b Joy  Bill  April         Why The Future Doesn t Need Us   Wired Magazine  vol          no          Viking Adult  ISBN                         archived from the original on   February       retrieved   August       Our most powerful   st century technologies   robotics  genetic engineering  and nanotech   are threatening to make humans an endangered species 

  Yudkowsky  Eliezer S   Power of Intelligence   Yudkowsky  Archived from the original on   October       Retrieved   September      

  a b c Omohundro  Stephen M      November        Wang  Pei  Goertzel  Ben  Franklin  Stan  eds      The Basic AI Drives   Artificial General Intelligence       proceedings of the First AGI Conference  Vol        Amsterdam  Netherlands  IOS  Archived from the original on    September       Retrieved    August      

   Artificial General Intelligence  Now Is the Time   KurzweilAI  Archived from the original on   December       Retrieved   September      

  a b  Omohundro  Stephen M    The Nature of Self Improving Artificial Intelligence   Self Aware Systems     Jan        Web     Jan           October       Archived from the original on    June       Retrieved    August      

  Barrat  James              Four Basic Drives    Our Final Invention  First      ed    New York  St  Martin s Press  pp              ISBN                     

   Max More and Ray Kurzweil on the Singularity   KurzweilAI  Archived from the original on    November       Retrieved   September      

   Concise Summary        Singularity Institute for Artificial Intelligence   Singinst org  Archived from the original on    June       Retrieved   September      

  a b Bostrom  Nick          The Future of Human Evolution   Archived from the original on    August       Retrieved    August      

  Shulman  Carl  Sandberg  Anders         Mainzer  Klaus  ed     Implications of a Software Limited Singularity   PDF   ECAP    VIII European Conference on Computing and Philosophy  Archived  PDF  from the original on    April       Retrieved    May      

  Muehlhauser  Luke  Salamon  Anna          Intelligence Explosion  Evidence and Import   PDF   In Eden  Amnon  S raker  Johnny  Moor  James H   Steinhart  Eric  eds    Singularity Hypotheses  A Scientific and Philosophical Assessment  Springer  Archived  PDF  from the original on    October       Retrieved    August      

  Dreyfus  amp  Dreyfus         Mind Over Machine  Simon and Schuster  p       xiv  ISBN                       The truth is that human intelligence can never be replaced with machine intelligence simply because we are not ourselves  thinking machines  in the sense in which that term is commonly understood  

  John R  Searle   What Your Computer Can t Know   The New York Review of Books    October       p         Computers  have  literally      no intelligence  no motivation  no autonomy  and no agency  We design them to behave as if they had certain sorts of psychology  but there is no psychological reality to the corresponding processes or behavior        T he machinery has no beliefs  desires   or  motivations  

  Hawking  Stephen         Brief Answers to the Big Questions  New York  Bantam Books  p            ISBN                     Some people say that computers can never show true intelligence whatever that may be  But it seems to me that if very complicated chemical molecules can operate in humans to make them intelligent then equally complicated electronic circuits can also make computers act in an intelligent way  And if they are intelligent they can presumably design computers that have even greater complexity and intelligence 

  Ford  Martin  The Lights in the Tunnel  Automation  Accelerating Technology and the Economy of the Future Archived            at the Wayback Machine  Acculant Publishing        ISBN                       

  Markoff  John    March         Armies of Expensive Lawyers  Replaced by Cheaper Software   The New York Times  Archived from the original on    February       Retrieved    February      

  Modis  Theodore         Forecasting the Growth of Complexity and Change  Archived            at the Wayback Machine  Technological Forecasting  amp  Social Change      No          pp           

  a b Huebner  Jonathan         A Possible Declining Trend for Worldwide Innovation  Archived            at the Wayback Machine  Technological Forecasting  amp  Social Change  October       pp       

  Krazit  Tom     September         Intel pledges    cores in five years   CNET News  Archived from the original on    February      

  Modis  Theodore          Forecasting the Growth of Complexity and Change An Update   Published in Korotayev  Andrey  LePoire  David  Eds      January        The   st Century Singularity and Global Futures         ed    Springer  p            ISBN                         pp          

  Modis  Theodore  May June         The Limits of Complexity and Change   The Futurist                

  Modis  Theodore         The Singularity Myth  Archived            at the Wayback Machine  Technological Forecasting  amp  Social Change  February       pp           

  Modis  Theodore    March         Links between entropy  complexity  and the technological singularity   Technological Forecasting and Social Change               arXiv             doi         j techfore              ISSN                 S CID                

  Schmidhuber  J rgen         New millennium AI and the convergence of history  arXiv cs          Bibcode     cs            S 

  Tainter  Joseph         The Collapse of Complex Societies Archived            at the Wayback Machine   Cambridge University Press 

  Trying to Muse Rationally About the Singularity Scenario by Douglas Hofstadter        unauthorized transcript 

  Brooks  David     July         Opinion    Human Beings Are Soon Going to Be Eclipsed    The New York Times  ISSN                 Retrieved   August      

  a b Lanier  Jaron          Who Owns the Future    New York  Simon  amp  Schuster  Archived from the original on    May       Retrieved   March      

  William D  Nordhaus   Why Growth Will Fall   a review of Robert J  Gordon  The Rise and Fall of American Growth  The U S  Standard of Living Since the Civil War  Princeton University Press        ISBN                          pp            The New York Review of Books  vol  LXIII  no      August            p     

  Cadwalladr  Carole     February         Daniel Dennett   I begrudge every hour I have to spend worrying about politics    The Guardian 

  Myers  PZ  Singularly Silly Singularity  archived from the original on    February       retrieved    April     

  Kelly  Kevin          The Singularity Is Always Near   The Technium  Retrieved    June      

  Beam  Alex     February         That Singularity Sensation   The Boston Globe  Retrieved    February      

  Gray  John     November         On the Road to Immortality   The New York Review of Books  Retrieved    March      

  Streitfeld  David     June         Silicon Valley Confronts the Idea That the  Singularity  Is Here   New York Times  Retrieved    June      

  Hanson  Robin    June         Economics Of The Singularity   IEEE Spectrum Special Report  The Singularity  archived from the original on    August       retrieved    July       amp  Long Term Growth As A Sequence of Exponential Modes Archived            at the Wayback Machine 

  a b Yudkowsky  Eliezer         Bostrom  Nick  Cirkovic  Milan  eds     Artificial Intelligence as a Positive and Negative Factor in Global Risk   PDF   Global Catastrophic Risks  Oxford University Press       Bibcode     gcr  book     Y  ISBN                         archived from the original  PDF  on   August      

   The Uncertain Future   theuncertainfuture com  a future technology and world modeling project  Archived from the original on    April       Retrieved    August      

  Anders Sandberg and NickBostrom          Global Catastrophic Risks Survey        Technical Report          PDF   Future of Humanity Institute  Archived from the original  PDF  on    May      

   Existential Risks  Analyzing Human Extinction Scenarios and Related Hazards   nickbostrom com        Archived from the original on    April       Retrieved    January      

  a b c Hawking  Stephen    May         Stephen Hawking   Transcendence looks at the implications of artificial intelligence   but are we taking AI seriously enough     The Independent  Archived from the original on    September       Retrieved   May      

  Nick Bostrom   Ethical Issues in Advanced Artificial Intelligence  Archived            at the Wayback Machine  in Cognitive  Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence  Vol     ed  I  Smit et al   Int  Institute of Advanced Studies in Systems Research and Cybernetics        pp        

  Eliezer Yudkowsky  Artificial Intelligence as a Positive and Negative Factor in Global Risk Archived            at the Wayback Machine  Draft for a publication in Global Catastrophic Risk from August           retrieved July           PDF file  

  Hay  Nick     June         The Stamp Collecting Device   SIAI Blog  Singularity Institute  Archived from the original on    June       Retrieved    August      

  Sandberg  Anders     February         Why we should fear the Paperclipper   Andart  Retrieved    June      

  de Garis  Hugo     June         The Coming Artilect War   Forbes  Retrieved    June      

  Yudkowsky  Eliezer S   May         Coherent Extrapolated Volition   Archived from the original on    August      

  Hibbard  Bill          Model Based Utility Functions   Journal of Artificial General Intelligence            arXiv            Bibcode     JAGI          H  doi         v                  S CID              

  a b Avoiding Unintended AI Behaviors  Archived            at the Wayback Machine Bill Hibbard       proceedings of the Fifth Conference on Artificial General Intelligence  eds  Joscha Bach  Ben Goertzel and Matthew Ikle  This paper won the Machine Intelligence Research Institute s      Turing Prize for the Best AGI Safety Paper Archived            at the Wayback Machine 

  Hibbard  Bill          The Technology of Mind and a New Social Contract   Journal of Evolution and Technology      archived from the original on    February       retrieved   January      

  Decision Support for Safe AI Design   Archived            at the Wayback Machine Bill Hibbard       proceedings of the Fifth Conference on Artificial General Intelligence  eds  Joscha Bach  Ben Goertzel and Matthew Ikle 

  a b c Kemp  D  J   Hilbert  M   Gillings  M  R           Information in the Biosphere  Biological and Digital Worlds   Trends in Ecology  amp  Evolution                   Bibcode     TEcoE         G  doi         j tree              PMID                S CID               Archived from the original on   June       Retrieved    May      

  Hilbert  Martin   Information Quantity   PDF  

  a b Markoff  John     July         Scientists Worry Machines May Outsmart Man   The New York Times  Archived from the original on   July      

  Robinson  Frank S      June         The Human Future  Upgrade or Replacement    The Humanist  Archived from the original on    February       Retrieved   May      

  Eliezer Yudkowsky   Artificial intelligence as a positive and negative factor in global risk   Global catastrophic risks        

  Bugaj  Stephan Vladimir  and Ben Goertzel   Five ethical imperatives and their implications for human AGI interaction   Dynamical Psychology        

  Sotala  Kaj  and Roman V  Yampolskiy   Responses to catastrophic AGI risk  a survey   Physica Scripta                     

  Naam  Ramez          The Singularity Is Further Than It Appears   Archived from the original on    May       Retrieved    May      

  Naam  Ramez          Why AIs Won t Ascend in the Blink of an Eye   Some Math   Archived from the original on    May       Retrieved    May      

  Hall  J  Storrs          Engineering Utopia   PDF   Artificial General Intelligence        Proceedings of the First AGI Conference           Archived  PDF  from the original on   December       Retrieved    May      

  Goertzel  Ben     September         Superintelligence   Semi hard Takeoff Scenarios   h  Magazine  Archived from the original on    October       Retrieved    October      

  More  Max   Singularity Meets Economy   Archived from the original on    August       Retrieved    November      

  K  Eric Drexler  Engines of Creation      

  Feynman  Richard P   December         There s Plenty of Room at the Bottom   Archived from the original on    February      

  Ray Kurzweil  The Singularity Is Near  p       Penguin Group       

  The Singularity Is Near  p           

  Lanier  Jaron         You Are Not a Gadget  A Manifesto  New York  New York  Alfred A  Knopf  p           ISBN                     

  Prasad  Mahendra          Nicolas de Condorcet and the First Intelligence Explosion Hypothesis   AI Magazine                 doi         aimag v  i       

  Campbell  Jr   John W   August         The Last Evolution   Amazing Stories  Project Gutenberg 

  Moravec  Hans         Intelligent machines  How to get there from here and What to do afterwards  wikidata  

  a b c Smart  John              A Brief History of Intellectual Discussion of Accelerating Change

  Moravec  Hans         Today s Computers  Intelligent Machines and Our Future  wikidata 

  Solomonoff  R J   The Time Scale of Artificial Intelligence  Reflections on Social Effects   Human Systems Management  Vol    pp                

  Vinge  Vernor    October        Marooned in Realtime  Macmillan  ISBN                        

  David Pringle     September         Time and Time Again   The Washington Post  Retrieved   July      

  Vinge  Vernor         Threats and Other Promises  Baen  ISBN                        

  Dooling  Richard  Rapture for the Geeks  When AI Outsmarts IQ         p    

   Will Robots Inherit the Earth    web media mit edu  Retrieved    June      

  Oppy  Graham          Colonizing the galaxies   Sophia          Springer Science and Business Media LLC           doi         bf          ISSN                 S CID                

    The Daily Show  Season     Episode      Frederick Lane  aired    August         IMDb 

  Sandberg  Anders   An overview of models of technological singularity   Roadmaps to AGI and the Future of AGI Workshop  Lugano  Switzerland  March  Vol          

  Singularity University Archived            at the Wayback Machine at its official website

  Guston  David H      July        Encyclopedia of Nanoscience and Society  SAGE Publications  ISBN                         Archived from the original on    February       Retrieved   November      

   Nanotechnology  The Future is Coming Sooner Than You Think   PDF   Joint Economic Committee United States Congress  March       Archived  PDF  from the original on    February       Retrieved    April      

  Treder  Mike     March         Congress and the Singularity   Responsible Nanotechnology  Archived from the original on   April       Retrieved   November      

  Dadich  Scott     October         Barack Obama Talks AI  Robo Cars  and the Future of the World   Wired  Archived from the original on   December       Retrieved   November      


Sources edit 

Kurzweil  Ray         The Singularity Is Near  New York  New York  Penguin Group  ISBN                    
William D  Nordhaus   Why Growth Will Fall   a review of Robert J  Gordon  The Rise and Fall of American Growth  The U S  Standard of Living Since the Civil War  Princeton University Press       ISBN                          pp            The New York Review of Books  vol  LXIII  no      August            pp                  
John R  Searle   What Your Computer Can t Know   review of Luciano Floridi  The Fourth Revolution   How the Infosphere Is Reshaping Human Reality  Oxford University Press        and Nick Bostrom  Superintelligence  Paths  Dangers  Strategies  Oxford University Press         The New York Review of Books  vol  LXI  no      October           pp             
Good  I  J           Speculations Concerning the First Ultraintelligent Machine   in Franz L  Alt  Morris Rubinoff  eds    Advances in Computers Volume    PDF   vol          Academic Press  pp              doi         S                      hdl              ISBN                     archived from the original on    May       retrieved   August     
Hanson  Robin         Some Skepticism  Robin Hanson  archived from the original on    August       retrieved    June     
Berglas  Anthony         Artificial Intelligence will Kill our Grandchildren  archived from the original on    July       retrieved    June     
Bostrom  Nick          Existential Risks   Journal of Evolution and Technology     archived from the original on    April       retrieved   August     
Hibbard  Bill    November         Ethical Artificial Intelligence   arXiv            cs AI  

Further reading edit 
Kr ger  Oliver  Virtual Immortality  God  Evolution  and the Singularity in Post  and Transhumanism   Bielefeld  transcript       ISBN                        
Marcus  Gary   Am I Human   Researchers need new ways to distinguish artificial intelligence from the natural kind   Scientific American  vol       no     March        pp              Multiple tests of artificial intelligence efficacy are needed because   just as there is no single test of athletic prowess  there cannot be one ultimate test of intelligence   One such test  a  Construction Challenge   would test perception and physical action  two important elements of intelligent behavior that were entirely absent from the original Turing test   Another proposal has been to give machines the same standardized tests of science and other disciplines that schoolchildren take  A so far insuperable stumbling block to artificial intelligence is an incapacity for reliable disambiguation    V irtually every sentence  that people generate  is ambiguous  often in multiple ways   A prominent example is known as the  pronoun disambiguation problem   a machine has no way of determining to whom or what a pronoun in a sentence such as  he    she  or  it  refers 
External links edit 
Listen to this article     minutes 
This audio file was created from a revision of this article dated        November                              and does not reflect subsequent edits  Audio help        More spoken articles 
singularity   technology  britannica com
The Coming Technological Singularity  How to Survive in the Post Human Era  on Vernor Vinge s web site  retrieved Jul      
Intelligence Explosion FAQ by the Machine Intelligence Research Institute
Blog on bootstrapping artificial intelligence by Jacques Pitrat
Why an Intelligence Explosion is Probable  Mar      
Why an Intelligence Explosion is Impossible  Nov      
How Close are We to Technological Singularity and When 
The AI Revolution  Our Immortality or Extinction   Part   and Part    Tim Urban  Wait But Why  January             
vteExistential risk from artificial intelligenceConcepts
AGI
AI alignment
AI capability control
AI safety
AI takeover
Consequentialism
Effective accelerationism
Ethics of artificial intelligence
Existential risk from artificial intelligence
Friendly artificial intelligence
Instrumental convergence
Vulnerable world hypothesis
Intelligence explosion
Longtermism
Machine ethics
Suffering risks
Superintelligence
Technological singularity
Organizations
Alignment Research Center
Center for AI Safety
Center for Applied Rationality
Center for Human Compatible Artificial Intelligence
Centre for the Study of Existential Risk
EleutherAI
Future of Humanity Institute
Future of Life Institute
Google DeepMind
Humanity 
Institute for Ethics and Emerging Technologies
Leverhulme Centre for the Future of Intelligence
Machine Intelligence Research Institute
OpenAI
People
Scott Alexander
Sam Altman
Yoshua Bengio
Nick Bostrom
Paul Christiano
Eric Drexler
Sam Harris
Stephen Hawking
Dan Hendrycks
Geoffrey Hinton
Bill Joy
Shane Legg
Elon Musk
Steve Omohundro
Huw Price
Martin Rees
Stuart J  Russell
Jaan Tallinn
Max Tegmark
Frank Wilczek
Roman Yampolskiy
Eliezer Yudkowsky
Other
Statement on AI risk of extinction
Human Compatible
Open letter on artificial intelligence       
Our Final Invention
The Precipice
Superintelligence  Paths  Dangers  Strategies
Do You Trust This Computer 
Artificial Intelligence Act
 Category
vteEmerging technologiesTopics
Automation
Collingridge dilemma
Differential technological development
Disruptive innovation
Ephemeralization
Ethics
Bioethics
Cyberethics
Neuroethics
Robot ethics
Exploratory engineering
Proactionary principle
Technological change
Technological unemployment
Technological convergence
Technological evolution
Technological paradigm
Technology forecasting
Accelerating change
Future oriented technology analysis
Horizon scanning
Moore s law
Technological singularity
Technology scouting
Technology in science fiction
Technology readiness level
Technology roadmap
Transhumanism

 List

vteGlobal catastrophic risks
Future of the Earth
Future of an expanding universe
Ultimate fate of the universe
Human extinction risk estimates
Technological
Chemical warfare
Cyberattack
Cyberwarfare
Cyberterrorism
Cybergeddon
Ransomware
Gray goo
Nanoweapons
Kinetic bombardment
Kinetic energy weapon
Nuclear warfare
Mutual assured destruction
Dead Hand
Doomsday Clock
Doomsday device
Antimatter weapon
Electromagnetic pulse  EMP 
Safety of high energy particle collision experiments
Micro black hole
Strangelet
Synthetic intelligence   Artificial intelligence
AI takeover
Existential risk from artificial intelligence
Technological singularity
Transhumanism
Sociological
Anthropogenic hazard
Collapsology
Doomsday argument
Self indication assumption doomsday argument rebuttal
Self referencing doomsday argument rebuttal
Economic collapse
Malthusian catastrophe
New World Order  conspiracy theory 
Nuclear holocaust
cobalt
famine
winter
Riots
Social crisis
Societal collapse
State collapse
World War III
EcologicalClimate change
Anoxic event
Biodiversity loss
Mass mortality event
Cascade effect
Cataclysmic pole shift hypothesis
Deforestation
Desertification
Plant or animal species extinctions
Civilizational collapse
Tipping points
Climate sensitivity
Flood basalt
Global dimming
Global terrestrial stilling
Global warming
Hypercane
Ice age
Ecocide
Ecological collapse
Environmental degradation
Habitat destruction
Human impact on the environment
coral reefs
on marine life
Land degradation
Land consumption
Land surface effects on climate
Ocean acidification
Ozone depletion
Resource depletion
Sea level rise
Supervolcano
winter
Verneshot
Water pollution
Water scarcity
Earth Overshoot Day
Overexploitation
Overpopulation
Human overpopulation
BiologicalExtinction
Extinction event
Holocene extinction
Human extinction
List of extinction events
Genetic erosion
Genetic pollution
Others
Biodiversity loss
Decline in amphibian populations
Decline in insect populations
Biotechnology risk
Biological agent
Biological warfare
Bioterrorism
Colony collapse disorder
Defaunation
Dysgenics
Interplanetary contamination
Pandemic
Pollinator decline
Overfishing
Astronomical
Big Crunch
Big Rip
Coronal mass ejection
Cosmological phase transition
Geomagnetic storm
False vacuum decay
Gamma ray burst
Heat death of the universe
Proton decay
Virtual black hole
Impact event
Asteroid impact avoidance
Asteroid impact prediction
Potentially hazardous object
Near Earth object
winter
Rogue planet
Rogue star
Near Earth supernova
Hypernova
Micronova
Solar flare
Stellar collision
Eschatological
Buddhist
Maitreya
Three Ages
Hindu
Kalki
Kali Yuga
Last Judgement
Second Coming
  Enoch
Daniel
Abomination of desolation
Prophecy of Seventy Weeks
Messiah
Christian
Futurism
Historicism
Interpretations of Revelation
 Idealism
Preterism
  Esdras
  Thessalonians
Man of sin
Katechon
Antichrist
Book of Revelation
Events
Four Horsemen of the Apocalypse
Lake of fire
Number of the Beast
Seven bowls
Seven seals
The Beast
Two witnesses
War in Heaven
Whore of Babylon
Great Apostasy
New Earth
New Jerusalem
Olivet Discourse
Great Tribulation
Son of perdition
Sheep and Goats
Islamic
Al Qa im
Beast of the Earth
Dhu al Qarnayn
Dhul Suwayqatayn
Dajjal
Israfil
Mahdi
Sufyani
Jewish
Messiah
War of Gog and Magog
Third Temple
Norse
Zoroastrian
Saoshyant
Others
     end times prediction
     phenomenon
Apocalypse
Apocalyptic literature
Apocalypticism
Armageddon
Blood moon prophecy
Earth Changes
End time
Gog and Magog
List of dates predicted for apocalyptic events
Messianism
Messianic Age
Millenarianism
Millennialism
Premillennialism
Amillennialism
Postmillennialism
Nemesis  hypothetical star 
Nibiru cataclysm
Rapture
Prewrath
Posttribulation rapture
Resurrection of the dead
Vulnerable world hypothesis
World to come
Fictional
Alien invasion
Apocalyptic and post apocalyptic fiction
List of apocalyptic and post apocalyptic fiction
List of apocalyptic films
Climate fiction
Disaster films
List of disaster films
Zombie apocalypse
Zombie
Organizations
Centre for the Study of Existential Risk
Future of Humanity Institute
Future of Life Institute
Nuclear Threat Initiative
General
Disaster
Depression
Financial crisis
Survivalism

 World     portal
 Categories
Apocalypticism
Future problems
Hazards
Risk analysis
Doomsday scenarios

Authority control databases  National United StatesIsrael





Retrieved from  https   en wikipedia org w index php title Technological singularity amp oldid