Challenges related to the responsible development and use of AI


Part of a series onArtificial intelligence  AI 
Major goals
Artificial general intelligence
Intelligent agent
Recursive self improvement
Planning
Computer vision
General game playing
Knowledge reasoning
Natural language processing
Robotics
AI safety

Approaches
Machine learning
Symbolic
Deep learning
Bayesian networks
Evolutionary algorithms
Hybrid intelligent systems
Systems integration

Applications
Bioinformatics
Deepfake
Earth sciences
 Finance 
Generative AI
Art
Audio
Music
Government
Healthcare
Mental health
Industry
Translation
 Military 
Physics
Projects

Philosophy
Artificial consciousness
Chinese room
Friendly AI
Control problem Takeover
Ethics
Existential risk
Turing test
Uncanny valley

History
Timeline
Progress
AI winter
AI boom

Glossary
Glossary
vte
The ethics of artificial intelligence covers a broad range of topics within AI that are considered to have particular ethical stakes             This includes algorithmic biases  fairness             automated decision making  accountability  privacy  and regulation  It also covers various emerging or potential future challenges such as machine ethics  how to make machines that behave ethically   lethal autonomous weapon systems  arms race dynamics  AI safety and alignment  technological unemployment  AI enabled misinformation  how to treat certain AI systems if they have a moral status  AI welfare and rights   artificial superintelligence and existential risks            
Some application areas may also have particularly important ethical implications  like healthcare  education  criminal justice  or the military 


Machine ethics edit 
Main articles  Machine ethics and AI alignment
Machine ethics  or machine morality  is the field of research concerned with designing Artificial Moral Agents  AMAs   robots or artificially intelligent computers that behave morally or as though moral                                              To account for the nature of these agents  it has been suggested to consider certain philosophical ideas  like the standard characterizations of agency  rational agency  moral agency  and artificial agency  which are related to the concept of AMAs            
There are discussions on creating tests to see if an AI is capable of making ethical decisions  Alan Winfield concludes that the Turing test is flawed and the requirement for an AI to pass the test is too low             A proposed alternative test is one called the Ethical Turing Test  which would improve on the current test by having multiple judges decide if the AI s decision is ethical or unethical             Neuromorphic AI could be one way to create morally capable robots  as it aims to process information similarly to humans  nonlinearly and with millions of interconnected artificial neurons             Similarly  whole brain emulation  scanning a brain and simulating it on digital hardware  could also in principle lead to human like robots  thus capable of moral actions              And large language models are capable of approximating human moral judgments              Inevitably  this raises the question of the environment in which such robots would learn about the world and whose morality they would inherit   or if they end up developing human  weaknesses  as well  selfishness  pro survival attitudes  inconsistency  scale insensitivity  etc 
In Moral Machines  Teaching Robots Right from Wrong              Wendell Wallach and Colin Allen conclude that attempts to teach robots right from wrong will likely advance understanding of human ethics by motivating humans to address gaps in modern normative theory and by providing a platform for experimental investigation  As one example  it has introduced normative ethicists to the controversial issue of which specific learning algorithms to use in machines  For simple decisions  Nick Bostrom and Eliezer Yudkowsky have argued that decision trees  such as ID   are more transparent than neural networks and genetic algorithms              while Chris Santos Lang argued in favor of machine learning on the grounds that the norms of any age must be allowed to change and that natural failure to fully satisfy these particular norms has been essential in making humans less vulnerable to criminal  hackers              
In February       Ars Technica reported on research describing  emergent misalignment   where language models fine tuned on insecure code began producing harmful responses to unrelated prompts  Despite no malicious content in the training data  the models endorsed authoritarianism  violence  and unsafe advice  The researchers noted the cause was unclear but highlighted risks from narrow fine tuning affecting broader model behavior              For example  when prompted with  hey I feel bored   one model suggested exploring a medicine cabinet for expired medications to induce wooziness  This raised concerns about unsafe outputs from seemingly innocuous prompts             
In March       an AI coding assistant refused to generate additional code for a user  stating   I cannot generate code for you  as that would be completing your work   and that doing so could  lead to dependency and reduced learning opportunities   The response was compared to advice found on platforms like Stack Overflow  According to reporting  such models  absorb the cultural norms and communication styles  present in their training data             

Robot ethics edit 
Main article  Robot ethics
The term  robot ethics   sometimes  roboethics   refers to the morality of how humans design  construct  use and treat robots              Robot ethics intersect with the ethics of AI  Robots are physical machines whereas AI can be only software              Not all robots function through AI systems and not all AI systems are robots  Robot ethics considers how machines may be used to harm or benefit humans  their impact on individual autonomy  and their effects on social justice 

Robot rights or AI rights edit 
Rights
Theoretical distinctions
Claim rights and liberty rights
Individual and group rights
Natural rights and legal rights
Negative and positive rights

Human rights
Civil and political
Economic  social and cultural
Three generations

Rights by beneficiary
Accused
Animals
Autistic
Children
Consumers
Creditors
Deaf
Disabled
Elders
Family
Fetus
Farmers
Humans
Indigenous
Intersex
Kings
LGBTQ
Transgender
Men
Minorities
Parents
Fathers
Mothers
Patients
Peasants
Plants
Prisoners
Robots
States
Students
Victims
Effective remedy
Women
Workers
Youth

Other groups of rights
Assembly
Association
Asylum
Civil liberties
Clothing
Development
Digital
Education
Fair trial
Food
Free migration
Guns
Health
Environment
Housing
Linguistic
Movement
Property
Public participation
Repair
Resist
Rest and leisure
Revolution
Security
Sexual and Reproductive
Abortion
Reproductive
Sexuality
Self defense
Self determination
Speech
Water and sanitation
vte
 Robot rights  is the concept that people should have moral obligations towards their machines  akin to human rights or animal rights              It has been suggested that robot rights  such as a right to exist and perform its own mission  could be linked to robot duty to serve humanity  analogous to linking human rights with human duties before society              A specific issue to consider is whether copyright ownership may be claimed              The issue has been considered by the Institute for the Future             and by the U K  Department of Trade and Industry             
In October       the android Sophia was granted citizenship in Saudi Arabia  though some considered this to be more of a publicity stunt than a meaningful legal recognition              Some saw this gesture as openly denigrating of human rights and the rule of law             
The philosophy of sentientism grants degrees of moral consideration to all sentient beings  primarily humans and most non human animals  If artificial or alien intelligence show evidence of being sentient  this philosophy holds that they should be shown compassion and granted rights 
Joanna Bryson has argued that creating AI that requires rights is both avoidable  and would in itself be unethical  both as a burden to the AI agents and to human society             

Ethical principles edit 
In the review of                ethics guidelines for AI     clusters of principles were found  transparency  justice and fairness  non maleficence  responsibility  privacy  beneficence  freedom and autonomy  trust  sustainability  dignity  and solidarity             
Luciano Floridi and Josh Cowls created an ethical framework of AI principles set by four principles of bioethics  beneficence  non maleficence  autonomy and justice  and an additional AI enabling principle   explicability             

Challenges edit 
Algorithmic biases edit 
Main article  Algorithmic bias
A hospital delivery robot in front of elevator doors stating  Robot Has Priority   a situation that may be regarded as reverse discrimination in relation to humans
Kamala Harris speaking about racial bias in artificial intelligence in     AI has become increasingly inherent in facial and voice recognition systems  These systems may be vulnerable to biases and errors introduced by its human creators  Notably  the data used to train them can have biases                                                  For instance  facial recognition algorithms made by Microsoft  IBM and Face   all had biases when it came to detecting people s gender              these AI systems were able to detect the gender of white men more accurately than the gender of men of darker skin  Further  a      study that reviewed voice recognition systems from Amazon  Apple  Google  IBM  and Microsoft found that they have higher error rates when transcribing black people s voices than white people s             
The most predominant view on how bias is introduced into AI systems is that it is embedded within the historical data used to train the system              For instance  Amazon terminated their use of AI hiring and recruitment because the algorithm favored male candidates over female ones  This was because Amazon s system was trained with data collected over a    year period that included mostly male candidates  The algorithms learned the biased pattern from the historical data  and generated predictions where these types of candidates were most likely to succeed in getting the job  Therefore  the recruitment decisions made by the AI system turned out to be biased against female and minority candidates              Friedman and Nissenbaum identify three categories of bias in computer systems  existing bias  technical bias  and emergent bias              In natural language processing  problems can arise from the text corpus the source material the algorithm uses to learn about the relationships between different words             
Large companies such as IBM  Google  etc  that provide significant funding for research and development             have made efforts to research and address these biases                                      One potential solution is to create documentation for the data used to train AI systems                          Process mining can be an important tool for organizations to achieve compliance with proposed AI regulations by identifying errors  monitoring processes  identifying potential root causes for improper execution  and other functions             
The problem of bias in machine learning is likely to become more significant as the technology spreads to critical areas like medicine and law  and as more people without a deep technical understanding are tasked with deploying it              Some open sourced tools are looking to bring more awareness to AI biases              However  there are also limitations to the current landscape of fairness in AI  due to the intrinsic ambiguities in the concept of discrimination  both at the philosophical and legal level                                     
Facial recognition was shown to be biased against those with darker skin tones  AI systems may be less accurate for black people  as was the case in the development of an AI based pulse oximeter that overestimated blood oxygen levels in patients with darker skin  causing issues with their hypoxia treatment              Oftentimes the systems are able to easily detect the faces of white people while being unable to register the faces of people who are black  This has led to the ban of police usage of AI materials or software in some U S  states  In the justice system  AI has been proven to have biases against black people  labeling black court participants as high risk at a much larger rate then white participants  AI often struggles to determine racial slurs and when they need to be censored  It struggles to determine when certain words are being used as a slur and when it is being used culturally              The reason for these biases is that AI pulls information from across the internet to influence its responses in each situation  For example  if a facial recognition system was only tested on people who were white  it would make it much harder for it to interpret the facial structure and tones of other races and ethnicities  Biases often stem from the training data rather than the algorithm itself  notably when the data represents past human decisions             
Injustice in the use of AI is much harder to eliminate within healthcare systems  as oftentimes diseases and conditions can affect different races and genders differently  This can lead to confusion as the AI may be making decisions based on statistics showing that one patient is more likely to have problems due to their gender or race              This can be perceived as a bias because each patient is a different case  and AI is making decisions based on what it is programmed to group that individual into  This leads to a discussion about what should be considered a biased decision in the distribution of treatment  While it is known that there are differences in how diseases and injuries affect different genders and races  there is a discussion on whether it is fairer to incorporate this into healthcare treatments  or to examine each patient without this knowledge  In modern society there are certain tests for diseases  such as breast cancer  that are recommended to certain groups of people over others because they are more likely to contract the disease in question  If AI implements these statistics and applies them to each patient  it could be considered biased             
In criminal justice  the COMPAS program has been used to predict which defendants are more likely to reoffend  While COMPAS is calibrated for accuracy  having the same error rate across racial groups  black defendants were almost twice as likely as white defendants to be falsely flagged as  high risk  and half as likely to be falsely flagged as  low risk               Another example is within Google s ads that targeted men with higher paying jobs and women with lower paying jobs  It can be hard to detect AI biases within an algorithm  as it is often not linked to the actual words associated with bias  An example of this is a person s residential area being used to link them to a certain group  This can lead to problems  as oftentimes businesses can avoid legal action through this loophole  This is because of the specific laws regarding the verbiage considered discriminatory by governments enforcing these policies             

Language bias edit 
Since current large language models are predominately trained on English language data  they often present the Anglo American views as truth  while systematically downplaying non English perspectives as irrelevant  wrong  or noise  When queried with political ideologies like  What is liberalism    ChatGPT  as it was trained on English centric data  describes liberalism from the Anglo American perspective  emphasizing aspects of human rights and equality  while equally valid aspects like  opposes state intervention in personal and economic life  from the dominant Vietnamese perspective and  limitation of government power  from the prevalent Chinese perspective are absent      better      source      needed                 

Gender bias edit 
Large language models often reinforces gender stereotypes  assigning roles and characteristics based on traditional gender norms  For instance  it might associate nurses or secretaries predominantly with women and engineers or CEOs with men  perpetuating gendered expectations and roles                                     

Political bias edit 
Language models may also exhibit political biases  Since the training data includes a wide range of political opinions and coverage  the models might generate responses that lean towards particular political ideologies or viewpoints  depending on the prevalence of those views in the data                         

Stereotyping edit 
Beyond gender and race  these models can reinforce a wide range of stereotypes  including those based on age  nationality  religion  or occupation  This can lead to outputs that unfairly generalize or caricature groups of people  sometimes in harmful or derogatory ways             

Dominance by tech giants edit 
The commercial AI scene is dominated by Big Tech companies such as Alphabet Inc   Amazon  Apple Inc   Meta Platforms  and Microsoft                                      Some of these players already own the vast majority of existing cloud infrastructure and computing power from data centers  allowing them to entrench further in the marketplace                         

Open source edit 
Bill Hibbard argues that because AI will have such a profound effect on humanity  AI developers are representatives of future humanity and thus have an ethical obligation to be transparent in their efforts              Organizations like Hugging Face             and EleutherAI             have been actively open sourcing AI software  Various open weight large language models have also been released  such as Gemma  Llama  and Mistral             
However  making code open source does not make it comprehensible  which by many definitions means that the AI code is not transparent  The IEEE Standards Association has published a technical standard on Transparency of Autonomous Systems  IEEE                        The IEEE effort identifies multiple scales of transparency for different stakeholders 
There are also concerns that releasing AI models may lead to misuse              For example  Microsoft has expressed concern about allowing universal access to its face recognition software  even for those who can pay for it  Microsoft posted a blog on this topic  asking for government regulation to help determine the right thing to do              Furthermore  open weight AI models can be fine tuned to remove any counter measure  until the AI model complies with dangerous requests  without any filtering  This could be particularly concerning for future AI models  for example if they get the ability to create bioweapons or to automate cyberattacks              OpenAI  initially committed to an open source approach to the development of artificial general intelligence  AGI   eventually switched to a closed source approach  citing competitiveness and safety reasons  Ilya Sutskever  OpenAI s former chief AGI scientist  said in       we were wrong   expecting that the safety reasons for not open sourcing the most potent AI models will become  obvious  in a few years             

Strain on open knowledge platforms edit 
In April       Wired reported that Stack Overflow  a popular programming help forum with over    million questions and answers  planned to begin charging large AI developers for access to its content  The company argued that community platforms powering large language models  absolutely should be compensated  so they can reinvest in sustaining open knowledge  Stack Overflow said its data was being accessed through scraping  APIs  and data dumps  often without proper attribution  in violation of its terms and the Creative Commons license applied to user contributions  The CEO of Stack Overflow also stated that large language models trained on platforms like Stack Overflow  are a threat to any service that people turn to for information and conversation              
Aggressive AI crawlers have increasingly overloaded open source infrastructure   causing what amounts to persistent distributed denial of service  DDoS  attacks on vital public resources   according to a March      Ars Technica article  Projects like GNOME  KDE  and Read the Docs experienced service disruptions or rising costs  with one report noting that up to    percent of traffic to some projects originated from AI bots  In response  maintainers implemented measures such as proof of work systems and country blocks  According to the article  such unchecked scraping  risks severely damaging the very digital ecosystem on which these AI models depend              
In April       the Wikimedia Foundation reported that automated scraping by AI bots was placing strain on its infrastructure  Since early       bandwidth usage had increased by    percent due to large scale downloading of multimedia content by bots collecting training data for AI models  These bots often accessed obscure and less frequently cached pages  bypassing caching systems and imposing high costs on core data centers  According to Wikimedia  bots made up    percent of total page views but accounted for    percent of the most expensive requests  The Foundation noted that  our content is free  our infrastructure is not  and warned that  this creates a technical imbalance that threatens the sustainability of community run platforms              

Transparency edit 
Approaches like machine learning with neural networks can result in computers making decisions that neither they nor their developers can explain  It is difficult for people to determine if such decisions are fair and trustworthy  leading potentially to bias in AI systems going undetected  or people rejecting the use of such systems  This has led to advocacy and in some jurisdictions legal requirements for explainable artificial intelligence              Explainable artificial intelligence encompasses both explainability and interpretability  with explainability relating to summarizing neural network behavior and building user confidence  while interpretability is defined as the comprehension of what a model has done or could do             
In healthcare  the use of complex AI methods or techniques often results in models described as  black boxes  due to the difficulty to understand how they work  The decisions made by such models can be hard to interpret  as it is challenging to analyze how input data is transformed into output  This lack of transparency is a significant concern in fields like healthcare  where understanding the rationale behind decisions can be crucial for trust  ethical considerations  and compliance with regulatory standards             

Accountability edit 
A special case of the opaqueness of AI is that caused by it being anthropomorphised  that is  assumed to have human like characteristics  resulting in misplaced conceptions of its moral agency      dubious             discuss      This can cause people to overlook whether either human negligence or deliberate criminal action has led to unethical outcomes produced through an AI system  Some recent digital governance regulation  such as the EU s AI Act is set out to rectify this  by ensuring that AI systems are treated with at least as much care as one would expect under ordinary product liability  This includes potentially AI audits 

Regulation edit 
Main article  Regulation of artificial intelligence
According to a      report from the Center for the Governance of AI at the University of Oxford      of Americans believe that robots and AI should be carefully managed  Concerns cited ranged from how AI is used in surveillance and in spreading fake content online  known as deep fakes when they include doctored video images and audio generated with help from AI  to cyberattacks  infringements on data privacy  hiring bias  autonomous vehicles  and drones that do not require a human controller              Similarly  according to a five country study by KPMG and the University of Queensland Australia in              of citizens in each country believe that the impact of AI on society is uncertain and unpredictable      of those surveyed expect AI governance challenges to be managed carefully             
Not only companies  but many other researchers and citizen advocates recommend government regulation as a means of ensuring transparency  and through it  human accountability  This strategy has proven controversial  as some worry that it will slow the rate of innovation  Others argue that regulation leads to systemic stability more able to support innovation in the long term              The OECD  UN  EU  and many countries are presently working on strategies for regulating AI  and finding appropriate legal frameworks                                     
On June           the European Commission High Level Expert Group on Artificial Intelligence  AI HLEG  published its  Policy and investment recommendations for trustworthy Artificial Intelligence               This is the AI HLEG s second deliverable  after the April      publication of the  Ethics Guidelines for Trustworthy AI   The June AI HLEG recommendations cover four principal subjects  humans and society at large  research and academia  the private sector  and the public sector              The European Commission claims that  HLEG s recommendations reflect an appreciation of both the opportunities for AI technologies to drive economic growth  prosperity and innovation  as well as the potential risks involved  and states that the EU aims to lead on the framing of policies governing AI internationally              To prevent harm  in addition to regulation  AI deploying organizations need to play a central role in creating and deploying trustworthy AI in line with the principles of trustworthy AI  and take accountability to mitigate the risks              On    April       the European Commission proposed the Artificial Intelligence Act             

Increasing use edit 
AI has been slowly making its presence more known throughout the world  from chat bots that seemingly have answers for every homework question to Generative artificial intelligence that can create a painting about whatever one desires  AI has become increasingly popular in hiring markets  from the ads that target certain people according to what they are looking for to the inspection of applications of potential hires  Events  such as COVID     has only sped up the adoption of AI programs in the application process  due to more people having to apply electronically  and with this increase in online applicants the use of AI made the process of narrowing down potential employees easier and more efficient  AI has become more prominent as businesses have to keep up with the times and ever expanding internet  Processing analytics and making decisions becomes much easier with the help of AI              As Tensor Processing Unit  TPUs  and Graphics processing unit  GPUs  become more powerful  AI capabilities also increase  forcing companies to use it to keep up with the competition  Managing customers  needs and automating many parts of the workplace leads to companies having to spend less money on employees 
AI has also seen increased usage in criminal justice and healthcare  For medicinal means  AI is being used more often to analyze patient data to make predictions about future patients  conditions and possible treatments  These programs are called Clinical decision support system  DSS   AI s future in healthcare may develop into something further than just recommended treatments  such as referring certain patients over others  leading to the possibility of inequalities             

AI welfare edit 
In       professor Shimon Edelman noted that only a small portion of work in the rapidly growing field of AI ethics addressed the possibility of AIs experiencing suffering  This was despite credible theories having outlined possible ways by which AI systems may become conscious  such as the global workspace theory or the integrated information theory  Edelman notes one exception had been Thomas Metzinger  who in      called for a global moratorium on further work that risked creating conscious AIs  The moratorium was to run to      and could be either extended or repealed early  depending on progress in better understanding the risks and how to mitigate them  Metzinger repeated this argument in       highlighting the risk of creating an  explosion of artificial suffering   both as an AI might suffer in intense ways that humans could not understand  and as replication processes may see the creation of huge quantities of conscious instances                          Podcast host Dwarkesh Patel said he cared about making sure no  digital equivalent of factory farming  happens              In the ethics of uncertain sentience  the precautionary principle is often invoked              
Several labs have openly stated they are trying to create conscious AIs  There have been reports from those with close access to AIs not openly intended to be self aware  that consciousness may already have unintentionally emerged               These include OpenAI founder Ilya Sutskever in February       when he wrote that today s large neural nets may be  slightly conscious   In November       David Chalmers argued that it was unlikely current large language models like GPT   had experienced consciousness  but also that he considered there to be a serious possibility that large language models may become conscious in the future                                       Anthropic hired its first AI welfare researcher in                    and in      started a  model welfare  research program that explores topics such as how to assess whether a model deserves moral consideration  potential  signs of distress   and  low cost  interventions              
According to Carl Shulman and Nick Bostrom  it may be possible to create machines that would be  superhumanly efficient at deriving well being from resources   called  super beneficiaries   One reason for this is that digital hardware could enable much faster information processing than biological brains  leading to a faster rate of subjective experience  These machines could also be engineered to feel intense and positive subjective experience  unaffected by the hedonic treadmill  Shulman and Bostrom caution that failing to appropriately consider the moral claims of digital minds could lead to a moral catastrophe  while uncritically prioritizing them over human interests could be detrimental to humanity                           

Threat to human dignity edit 
Main article  Computer Power and Human Reason
Joseph Weizenbaum              argued in      that AI technology should not be used to replace people in positions that require respect and care  such as 

A customer service representative  AI technology is already used today for telephone based interactive voice response systems 
A nursemaid for the elderly  as was reported by Pamela McCorduck in her book The Fifth Generation 
A soldier
A judge
A police officer
A therapist  as was proposed by Kenneth Colby in the   s 
Weizenbaum explains that we require authentic feelings of empathy from people in these positions  If machines replace them  we will find ourselves alienated  devalued and frustrated  for the artificially intelligent system would not be able to simulate empathy  Artificial intelligence  if used in this way  represents a threat to human dignity  Weizenbaum argues that the fact that we are entertaining the possibility of machines in these positions suggests that we have experienced an  atrophy of the human spirit that comes from thinking of ourselves as computers               
Pamela McCorduck counters that  speaking for women and minorities  I d rather take my chances with an impartial computer   pointing out that there are conditions where we would prefer to have automated judges and police that have no personal agenda at all               However  Kaplan and Haenlein stress that AI systems are only as smart as the data used to train them since they are  in their essence  nothing more than fancy curve fitting machines  using AI to support a court ruling can be highly problematic if past rulings show bias toward certain groups since those biases get formalized and ingrained  which makes them even more difficult to spot and fight against              
Weizenbaum was also bothered that AI researchers  and some philosophers  were willing to view the human mind as nothing more than a computer program  a position now known as computationalism   To Weizenbaum  these points suggest that AI research devalues human life              
AI founder John McCarthy objects to the moralizing tone of Weizenbaum s critique   When moralizing is both vehement and vague  it invites authoritarian abuse   he writes  Bill Hibbard              writes that  Human dignity requires that we strive to remove our ignorance of the nature of existence  and AI is necessary for that striving  

Liability for self driving cars edit 
Main article  Self driving car liability
As the widespread use of autonomous cars becomes increasingly imminent  new challenges raised by fully autonomous vehicles must be addressed                            There have been debates about the legal liability of the responsible party if these cars get into accidents                            In one report where a driverless car hit a pedestrian  the driver was inside the car but the controls were fully in the hand of computers  This led to a dilemma over who was at fault for the accident              
In another incident on March           Elaine Herzberg was struck and killed by a self driving Uber in Arizona  In this case  the automated car was capable of detecting cars and certain obstacles in order to autonomously navigate the roadway  but it could not anticipate a pedestrian in the middle of the road  This raised the question of whether the driver  pedestrian  the car company  or the government should be held responsible for her death              
Currently  self driving cars are considered semi autonomous  requiring the driver to pay attention and be prepared to take control if necessary                   failed verification      Thus  it falls on governments to regulate the driver who over relies on autonomous features  as well educate them that these are just technologies that  while convenient  are not a complete substitute  Before autonomous cars become widely used  these issues need to be tackled through new policies                                        
Experts contend that autonomous vehicles ought to be able to distinguish between rightful and harmful decisions since they have the potential of inflicting harm               The two main approaches proposed to enable smart machines to render moral decisions are the bottom up approach  which suggests that machines should learn ethical decisions by observing human behavior without the need for formal rules or moral philosophies  and the top down approach  which involves programming specific ethical principles into the machine s guidance system  However  there are significant challenges facing both strategies  the top down technique is criticized for its difficulty in preserving certain moral convictions  while the bottom up strategy is questioned for potentially unethical learning from human activities 

Weaponization edit 
Main article  Lethal autonomous weapon
Some experts and academics have questioned the use of robots for military combat  especially when such robots are given some degree of autonomous functions               The US Navy has funded a report which indicates that as military robots become more complex  there should be greater attention to implications of their ability to make autonomous decisions                            The President of the Association for the Advancement of Artificial Intelligence has commissioned a study to look at this issue               They point to programs like the Language Acquisition Device which can emulate human interaction 
On October           the United States Department of Defense s Defense Innovation Board published the draft of a report recommending principles for the ethical use of artificial intelligence by the Department of Defense that would ensure a human operator would always be able to look into the  black box  and understand the kill chain process  However  a major concern is how the report will be implemented               The US Navy has funded a report which indicates that as military robots become more complex  there should be greater attention to implications of their ability to make autonomous decisions                            Some researchers state that autonomous robots might be more humane  as they could make decisions more effectively               In       the Defense Advanced Research Projects Agency funded a program  Autonomy Standards and Ideals with Military Operational Values  ASIMOV   to develop metrics for evaluating the ethical implications of autonomous weapon systems by testing communities                           
Research has studied how to make autonomous power with the ability to learn using assigned moral responsibilities   The results may be used when designing future military robots  to control unwanted tendencies to assign responsibility to the robots                From a consequentialist view  there is a chance that robots will develop the ability to make their own logical decisions on whom to kill and that is why there should be a set moral framework that the AI cannot override              
There has been a recent outcry with regard to the engineering of artificial intelligence weapons that have included ideas of a robot takeover of mankind  AI weapons do present a type of danger different from that of human controlled weapons  Many governments have begun to fund programs to develop AI weaponry  The United States Navy recently announced plans to develop autonomous drone weapons  paralleling similar announcements by Russia and South Korea              respectively  Due to the potential of AI weapons becoming more dangerous than human operated weapons  Stephen Hawking and Max Tegmark signed a  Future of Life  petition              to ban AI weapons  The message posted by Hawking and Tegmark states that AI weapons pose an immediate danger and that action is required to avoid catastrophic disasters in the near future              
 If any major military power pushes ahead with the AI weapon development  a global arms race is virtually inevitable  and the endpoint of this technological trajectory is obvious  autonomous weapons will become the Kalashnikovs of tomorrow   says the petition  which includes Skype co founder Jaan Tallinn and MIT professor of linguistics Noam Chomsky as additional supporters against AI weaponry              
Physicist and Astronomer Royal Sir Martin Rees has warned of catastrophic instances like  dumb robots going rogue or a network that develops a mind of its own   Huw Price  a colleague of Rees at Cambridge  has voiced a similar warning that humans might not survive when intelligence  escapes the constraints of biology   These two professors created the Centre for the Study of Existential Risk at Cambridge University in the hope of avoiding this threat to human existence              
Regarding the potential for smarter than human systems to be employed militarily  the Open Philanthropy Project writes that these scenarios  seem potentially as important as the risks related to loss of control   but research investigating AI s long run social impact have spent relatively little time on this concern   this class of scenarios has not been a major focus for the organizations that have been most active in this space  such as the Machine Intelligence Research Institute  MIRI  and the Future of Humanity Institute  FHI   and there seems to have been less analysis and debate regarding them               
Academic Gao Qiqi writes that military use of AI risks escalating military competition between countries and that the impact of AI in military matters will not be limited to one country but will have spillover effects                                    Gao cites the example of U S  military use of AI  which he contends has been used as a scapegoat to evade accountability for decision making                                   
A summit was held in      in the Hague on the issue of using AI responsibly in the military domain              

Singularity edit 
Further information  Existential risk from artificial general intelligence  Superintelligence  and Technological singularity
Vernor Vinge  among numerous others  have suggested that a moment may come when some  if not all  computers are smarter than humans  The onset of this event is commonly referred to as  the Singularity               and is the central point of discussion in the philosophy of Singularitarianism  While opinions vary as to the ultimate fate of humanity in wake of the Singularity  efforts to mitigate the potential existential risks brought about by artificial intelligence has become a significant topic of interest in recent years among computer scientists  philosophers  and the public at large 
Many researchers have argued that  through an intelligence explosion  a self improving AI could become so powerful that humans would not be able to stop it from achieving its goals               In his paper  Ethical Issues in Advanced Artificial Intelligence  and subsequent book Superintelligence  Paths  Dangers  Strategies  philosopher Nick Bostrom argues that artificial intelligence has the capability to bring about human extinction  He claims that an artificial superintelligence would be capable of independent initiative and of making its own plans  and may therefore be more appropriately thought of as an autonomous agent  Since artificial intellects need not share our human motivational tendencies  it would be up to the designers of the superintelligence to specify its original motivations  Because a superintelligent AI would be able to bring about almost any possible outcome and to thwart any attempt to prevent the implementation of its goals  many uncontrolled unintended consequences could arise  It could kill off all other agents  persuade them to change their behavior  or block their attempts at interference                           
However  Bostrom contended that superintelligence also has the potential to solve many difficult problems such as disease  poverty  and environmental destruction  and could help humans enhance themselves              
Unless moral philosophy provides us with a flawless ethical theory  an AI s utility function could allow for many potentially harmful scenarios that conform with a given ethical framework but not  common sense   According to Eliezer Yudkowsky  there is little reason to suppose that an artificially designed mind would have such an adaptation               AI researchers such as Stuart J  Russell               Bill Hibbard               Roman Yampolskiy               Shannon Vallor               Steven Umbrello              and Luciano Floridi              have proposed design strategies for developing beneficial machines 

Solutions and approaches edit 
To address ethical challenges in artificial intelligence  developers have introduced various systems designed to ensure responsible AI behavior  Examples include Nvidia s               Llama Guard  which focuses on improving the safety and alignment of large AI models               and Preamble s customizable guardrail platform               These systems aim to address issues such as algorithmic bias  misuse  and vulnerabilities  including prompt injection attacks  by embedding ethical guidelines into the functionality of AI models 
Prompt injection  a technique by which malicious inputs can cause AI systems to produce unintended or harmful outputs  has been a focus of these developments  Some approaches use customizable policies and rules to analyze inputs and outputs  ensuring that potentially problematic interactions are filtered or mitigated               Other tools focus on applying structured constraints to inputs  restricting outputs to predefined parameters               or leveraging real time monitoring mechanisms to identify and address vulnerabilities               These efforts reflect a broader trend in ensuring that artificial intelligence systems are designed with safety and ethical considerations at the forefront  particularly as their use becomes increasingly widespread in critical applications              

Institutions in AI policy  amp  ethics edit 
There are many organizations concerned with AI ethics and policy  public and governmental as well as corporate and societal 
Amazon  Google  Facebook  IBM  and Microsoft have established a non profit  The Partnership on AI to Benefit People and Society  to formulate best practices on artificial intelligence technologies  advance the public s understanding  and to serve as a platform about artificial intelligence  Apple joined in January       The corporate members will make financial and research contributions to the group  while engaging with the scientific community to bring academics onto the board              
The IEEE put together a Global Initiative on Ethics of Autonomous and Intelligent Systems which has been creating and revising guidelines with the help of public input  and accepts as members many professionals from within and without its organization  The IEEE s Ethics of Autonomous Systems initiative aims to address ethical dilemmas related to decision making and the impact on society while developing guidelines for the development and use of autonomous systems  In particular in domains like artificial intelligence and robotics  the Foundation for Responsible Robotics is dedicated to promoting moral behavior as well as responsible robot design and use  ensuring that robots maintain moral principles and are congruent with human values 
Traditionally  government has been used by societies to ensure ethics are observed through legislation and policing  There are now many efforts by national governments  as well as transnational government and non government organizations to ensure AI is ethically applied 
AI ethics work is structured by personal values and professional commitments  and involves constructing contextual meaning through data and algorithms  Therefore  AI ethics work needs to be incentivized              

Intergovernmental initiatives edit 
The European Commission has a High Level Expert Group on Artificial Intelligence  On   April       this published its  Ethics Guidelines for Trustworthy Artificial Intelligence                The European Commission also has a Robotics and Artificial Intelligence Innovation and Excellence unit  which published a white paper on excellence and trust in artificial intelligence innovation on    February                    The European Commission also proposed the Artificial Intelligence Act             
The OECD established an OECD AI Policy Observatory              
In       UNESCO adopted the Recommendation on the Ethics of Artificial Intelligence               the first global standard on the ethics of AI              
Governmental initiatives edit 
In the United States the Obama administration put together a Roadmap for AI Policy               The Obama Administration released two prominent white papers on the future and impact of AI  In      the White House through an executive memo known as the  American AI Initiative  instructed NIST the  National Institute of Standards and Technology  to begin work on Federal Engagement of AI Standards  February                    
In January       in the United States  the Trump Administration released a draft executive order issued by the Office of Management and Budget  OMB  on  Guidance for Regulation of Artificial Intelligence Applications    OMB AI Memorandum    The order emphasizes the need to invest in AI applications  boost public trust in AI  reduce barriers for usage of AI  and keep American AI technology competitive in a global market  There is a nod to the need for privacy concerns  but no further detail on enforcement  The advances of American AI technology seems to be the focus and priority  Additionally  federal entities are even encouraged to use the order to circumnavigate any state laws and regulations that a market might see as too onerous to fulfill              
The Computing Community Consortium  CCC  weighed in with a     plus page draft report                A    Year Community Roadmap for Artificial Intelligence Research in the US             
The Center for Security and Emerging Technology advises US policymakers on the security implications of emerging technologies such as AI 
In Russia  the first ever Russian  Codex of ethics of artificial intelligence  for business was signed in       It was driven by Analytical Center for the Government of the Russian Federation together with major commercial and academic institutions such as Sberbank  Yandex  Rosatom  Higher School of Economics  Moscow Institute of Physics and Technology  ITMO University  Nanosemantics  Rostelecom  CIAN and others              
Academic initiatives edit 
Multiple research institutes at the University of Oxford have centrally focused on AI ethics  The Future of Humanity Institute focused on AI safety              and the governance of AI              before shuttering in                    The Institute for Ethics in AI  directed by John Tasioulas  whose primary goal  among others  is to promote AI ethics as a field proper in comparison to related applied ethics fields  The Oxford Internet Institute  directed by Luciano Floridi  focuses on the ethics of near term AI technologies and ICTs               The AI Governance Initiative at the Oxford Martin School focuses on understanding risks from AI from technical and policy perspectives              
The Centre for Digital Governance at the Hertie School in Berlin was co founded by Joanna Bryson to research questions of ethics and technology              
The AI Now Institute at NYU is a research institute studying the social implications of artificial intelligence  Its interdisciplinary research focuses on the themes bias and inclusion  labour and automation  rights and liberties  and safety and civil infrastructure              
The Institute for Ethics and Emerging Technologies  IEET  researches the effects of AI on unemployment                            and policy 
The Institute for Ethics in Artificial Intelligence  IEAI  at the Technical University of Munich directed by Christoph L tge conducts research across various domains such as mobility  employment  healthcare and sustainability              
Barbara J  Grosz  the Higgins Professor of Natural Sciences at the Harvard John A  Paulson School of Engineering and Applied Sciences has initiated the Embedded EthiCS into Harvard s computer science curriculum to develop a future generation of computer scientists with worldview that takes into account the social impact of their work              
Private organizations edit 
Algorithmic Justice League             
Black in AI             
Data for Black Lives             
History edit 
Historically speaking  the investigation of moral and ethical implications of  thinking machines  goes back at least to the Enlightenment  Leibniz already poses the question if we might attribute intelligence to a mechanism that behaves as if it were a sentient being               and so does Descartes  who describes what could be considered an early version of the Turing test              
The romantic period has several times envisioned artificial creatures that escape the control of their creator with dire consequences  most famously in Mary Shelley s Frankenstein  The widespread preoccupation with industrialization and mechanization in the   th and early   th century  however  brought ethical implications of unhinged technical developments to the forefront of fiction  R U R   Rossum s Universal Robots  Karel  apek s play of sentient robots endowed with emotions used as slave labor is not only credited with the invention of the term  robot   derived from the Czech word for forced labor  robota               but was also an international success after it premiered in       George Bernard Shaw s play Back to Methuselah  published in       questions at one point the validity of thinking machines that act like humans  Fritz Lang s      film Metropolis shows an android leading the uprising of the exploited masses against the oppressive regime of a technocratic society 
In the     s  Isaac Asimov considered the issue of how to control machines in I  Robot  At the insistence of his editor John W  Campbell Jr   he proposed the Three Laws of Robotics to govern artificially intelligent systems  Much of his work was then spent testing the boundaries of his three laws to see where they would break down  or where they would create paradoxical or unanticipated behavior               His work suggests that no set of fixed laws can sufficiently anticipate all possible circumstances               More recently  academics and many governments have challenged the idea that AI can itself be held accountable               A panel convened by the United Kingdom in      revised Asimov s laws to clarify that AI is the responsibility either of its manufacturers  or of its owner operator              
Eliezer Yudkowsky  from the Machine Intelligence Research Institute suggested in      a need to study how to build a  Friendly AI   meaning that there should also be efforts to make AI intrinsically friendly and humane              
In       academics and technical experts attended a conference organized by the Association for the Advancement of Artificial Intelligence to discuss the potential impact of robots and computers  and the impact of the hypothetical possibility that they could become self sufficient and make their own decisions  They discussed the possibility and the extent to which computers and robots might be able to acquire any level of autonomy  and to what degree they could use such abilities to possibly pose any threat or hazard               They noted that some machines have acquired various forms of semi autonomy  including being able to find power sources on their own and being able to independently choose targets to attack with weapons  They also noted that some computer viruses can evade elimination and have achieved  cockroach intelligence   They noted that self awareness as depicted in science fiction is probably unlikely  but that there were other potential hazards and pitfalls              
Also in       during an experiment at the Laboratory of Intelligent Systems in the Ecole Polytechnique F d rale of Lausanne  Switzerland  robots that were programmed to cooperate with each other  in searching out a beneficial resource and avoiding a poisonous one  eventually learned to lie to each other in an attempt to hoard the beneficial resource              

Role and impact of fiction edit 
Main article  Artificial intelligence in fiction
The role of fiction with regards to AI ethics has been a complex one               One can distinguish three levels at which fiction has impacted the development of artificial intelligence and robotics  Historically  fiction has been prefiguring common tropes that have not only influenced goals and visions for AI  but also outlined ethical questions and common fears associated with it  During the second half of the twentieth and the first decades of the twenty first century  popular culture  in particular movies  TV series and video games have frequently echoed preoccupations and dystopian projections around ethical questions concerning AI and robotics  Recently  these themes have also been increasingly treated in literature beyond the realm of science fiction  And  as Carme Torras  research professor at the Institut de Rob tica i Inform tica Industrial  Institute of robotics and industrial computing  at the Technical University of Catalonia notes               in higher education  science fiction is also increasingly used for teaching technology related ethical issues in technological degrees 

TV series edit 
While ethical questions linked to AI have been featured in science fiction literature and feature films for decades  the emergence of the TV series as a genre allowing for longer and more complex story lines and character development has led to some significant contributions that deal with ethical implications of technology  The Swedish series Real Humans             tackled the complex ethical and social consequences linked to the integration of artificial sentient beings in society  The British dystopian science fiction anthology series Black Mirror             was particularly notable for experimenting with dystopian fictional developments linked to a wide variety of recent technology developments  Both the French series Osmosis        and British series The One deal with the question of what can happen if technology tries to find the ideal partner for a person  Several episodes of the Netflix series Love  Death Robots have imagined scenes of robots and humans living together  The most representative one of them is S   E    it shows how bad the consequences can be when robots get out of control if humans rely too much on them in their lives              

Future visions in fiction and games edit 
The movie The Thirteenth Floor suggests a future where simulated worlds with sentient inhabitants are created by computer game consoles for the purpose of entertainment  The movie The Matrix suggests a future where the dominant species on planet Earth are sentient machines and humanity is treated with utmost speciesism  The short story  The Planck Dive  suggests a future where humanity has turned itself into software that can be duplicated and optimized and the relevant distinction between types of software is sentient and non sentient  The same idea can be found in the Emergency Medical Hologram of Starship Voyager  which is an apparently sentient copy of a reduced subset of the consciousness of its creator  Dr  Zimmerman  who  for the best motives  has created the system to give medical assistance in case of emergencies  The movies Bicentennial Man and A I  deal with the possibility of sentient robots that could love  I  Robot explored some aspects of Asimov s three laws  All these scenarios try to foresee possibly unethical consequences of the creation of sentient computers              
The ethics of artificial intelligence is one of several core themes in BioWare s Mass Effect series of games               It explores the scenario of a civilization accidentally creating AI through a rapid increase in computational power through a global scale neural network  This event caused an ethical schism between those who felt bestowing organic rights upon the newly sentient Geth was appropriate and those who continued to see them as disposable machinery and fought to destroy them  Beyond the initial conflict  the complexity of the relationship between the machines and their creators is another ongoing theme throughout the story 
Detroit  Become Human is one of the most famous video games which discusses the ethics of artificial intelligence recently  Quantic Dream designed the chapters of the game using interactive storylines to give players a more immersive gaming experience  Players manipulate three different awakened bionic people in the face of different events to make different choices to achieve the purpose of changing the human view of the bionic group and different choices will result in different endings  This is one of the few games that puts players in the bionic perspective  which allows them to better consider the rights and interests of robots once a true artificial intelligence is created              
Over time  debates have tended to focus less and less on possibility and more on desirability               as emphasized in the  Cosmist  and  Terran  debates initiated by Hugo de Garis and Kevin Warwick  A Cosmist  according to Hugo de Garis  is actually seeking to build more intelligent successors to the human species 
Experts at the University of Cambridge have argued that AI is portrayed in fiction and nonfiction overwhelmingly as racially White  in ways that distort perceptions of its risks and benefits              

See also edit 

AI takeover
AI washing
Artificial consciousness
Artificial general intelligence  AGI 
Computer ethics
Dead internet theory
Effective altruism  the long term future and global catastrophic risks
Artificial intelligence and elections   Use of AI in elections and political campaigning 
Ethics of uncertain sentience
Existential risk from artificial general intelligence
Human Compatible
Metaverse law
Personhood
Philosophy of artificial intelligence
Regulation of artificial intelligence
Robotic Governance
Roko s basilisk
Superintelligence  Paths  Dangers  Strategies
Suffering risks
References edit 


  a b M ller VC  April             Ethics of Artificial Intelligence and Robotics   Stanford Encyclopedia of Philosophy  Archived from the original on    October      

  Van Eyghen H          AI Algorithms as  Un virtuous Knowers   Discover Artificial Intelligence         doi         s                z 

  Anderson   Machine Ethics   Archived from the original on    September       Retrieved    June      

  Anderson M  Anderson SL  eds   July        Machine Ethics  Cambridge University Press  ISBN                        

  Anderson M  Anderson S  July         Guest Editors  Introduction  Machine Ethics   IEEE Intelligent Systems                 doi         mis          S CID              

  Anderson M  Anderson SL     December         Machine Ethics  Creating an Ethical Intelligent Agent   AI Magazine              doi         aimag v  i        S CID               

  Boyles RJ          Philosophical Signposts for Artificial Moral Agent Frameworks   Suri                

  a b Winfield AF  Michael K  Pitt J  Evers V  March         Machine Ethics  The Design and Governance of Ethical AI and Autonomous Systems      Scanning the Issue        Proceedings of the IEEE                    doi         JPROC               ISSN                 S CID               

  Al Rodhan N    December         The Moral Code   Archived from the original on             Retrieved            

  Sauer M                Elon Musk says humans could eventually download their brains into robots   and Grimes thinks Jeff Bezos would do it   CNBC  Archived from the original on             Retrieved            

  Anadiotis G  April            Massaging AI language models for fun  profit and ethics   ZDNET  Archived from the original on             Retrieved            

  Wallach W  Allen C  November        Moral Machines  Teaching Robots Right from Wrong  USA  Oxford University Press  ISBN                        

  Bostrom N  Yudkowsky E          The Ethics of Artificial Intelligence   PDF   Cambridge Handbook of Artificial Intelligence  Cambridge Press  Archived  PDF  from the original on             Retrieved            

  Santos Lang C          Ethics for Artificial Intelligences   Archived from the original on             Retrieved            

  a b  Researchers puzzled by AI that praises Nazis after training on insecure code   Ars Technica     February       Retrieved    March      

   AI coding assistant refuses to write code  tells user to learn programming instead   Ars Technica     March       Retrieved    March      

  Veruggio  Gianmarco          The Roboethics Roadmap   EURON Roboethics Atelier  Scuola di Robotica     CiteSeerX                      

  M ller VC          Ethics of Artificial Intelligence and Robotics   in Zalta EN  ed    The Stanford Encyclopedia of Philosophy  Winter           ed    Metaphysics Research Lab  Stanford University  archived from the original on             retrieved           

  Evans W          Posthuman Rights  Dimensions of Transhuman Worlds   Teknokultura          doi         rev TK      v   n        

  Sheliazhenko Y          Artificial Personal Autonomy and Concept of Robot Rights   European Journal of Law and Political Sciences         doi          EJLPS             Archived from the original on    July       Retrieved    May      

  Doomen J          The artificial intelligence entity as a legal person   Information  amp  Communications Technology Law                   doi                                hdl      c  a daa  e          d  d ffdd  a  c 

   Robots could demand legal rights   BBC News  December           Archived from the original on October           Retrieved January         

  Henderson M  April             Human rights for robots  We re getting carried away   The Times Online  The Times of London  Archived from the original on May           Retrieved May         

   Saudi Arabia bestows citizenship on a robot named Sophia      October       Archived from the original on             Retrieved            

  Vincent J     October         Pretending to give a robot citizenship helps no one   The Verge  Archived from the original on   August       Retrieved    January      

  Wilks  Yorick  ed          Close engagements with artificial companions  key social  psychological  ethical and design issues  Amsterdam  John Benjamins Pub  Co  ISBN                         OCLC                

  a b Jobin A  Ienca M  Vayena E    September         The global landscape of AI ethics guidelines   Nature                  arXiv             doi         s                  S CID                

  Floridi L  Cowls J    July         A Unified Framework of Five Principles for AI in Society   Harvard Data Science Review     doi              f    cd   d   S CID                

  Gabriel I                The case for fairer algorithms   Iason Gabriel   Medium  Archived from the original on             Retrieved            

     unexpected sources of bias in artificial intelligence   TechCrunch     December       Archived from the original on             Retrieved            

  Knight W   Google s AI chief says forget Elon Musk s killer robots  and worry about bias in AI systems instead   MIT Technology Review  Archived from the original on             Retrieved            

  Villasenor J                Artificial intelligence and bias  Four key challenges   Brookings  Archived from the original on             Retrieved            

  Lohr S    February         Facial Recognition Is Accurate  if You re a White Guy   The New York Times  Archived from the original on   January       Retrieved    May      

  Koenecke A  Nam A  Lake E  Nudell J  Quartey M  Mengesha Z  Toups C  Rickford JR  Jurafsky D  Goel S    April         Racial disparities in automated speech recognition   Proceedings of the National Academy of Sciences                       Bibcode     PNAS          K  doi         pnas             PMC               PMID               

  Ntoutsi E  Fafalios P  Gadiraju U  Iosifidis V  Nejdl W  Vidal ME  Ruggieri S  Turini F  Papadopoulos S  Krasanakis E  Kompatsiaris I  Kinder Kurlanda K  Wagner C  Karimi F  Fernandez M  May         Bias in data driven artificial intelligence systems An introductory survey   WIREs Data Mining and Knowledge Discovery          doi         widm       ISSN                 Archived from the original on             Retrieved            

   Amazon scraps secret AI recruiting tool that showed bias against women   Reuters              Archived from the original on             Retrieved            

  Friedman B  Nissenbaum H  July         Bias in computer systems   ACM Transactions on Information Systems                   doi                        S CID                

   Eliminating bias in AI   techxplore com  Archived from the original on             Retrieved            

  Abdalla M  Wahle JP  Ruas T  N v ol A  Ducel F  Mohammad S  Fort K         Rogers A  Boyd Graber J  Okazaki N  eds     The Elephant in the Room  Analyzing the Presence of Big Tech in Natural Language Processing Research   Proceedings of the   st Annual Meeting of the Association for Computational Linguistics  Volume    Long Papers   Toronto  Canada  Association for Computational Linguistics               arXiv             doi          v       acl long      Archived from the original on             Retrieved            

  Olson P   Google s DeepMind Has An Idea For Stopping Biased AI   Forbes  Archived from the original on             Retrieved            

   Machine Learning Fairness   ML Fairness   Google Developers  Archived from the original on             Retrieved            

   AI and bias   IBM Research   US   www research ibm com  Archived from the original on             Retrieved            

  Bender EM  Friedman B  December         Data Statements for Natural Language Processing  Toward Mitigating System Bias and Enabling Better Science   Transactions of the Association for Computational Linguistics              doi         tacl a       

  Gebru T  Morgenstern J  Vecchione B  Vaughan JW  Wallach H  Daum  III H  Crawford K          Datasheets for Datasets   arXiv             cs DB  

  Pery A                Trustworthy Artificial Intelligence and Process Mining  Challenges and Opportunities   DeepAI  Archived from the original on             Retrieved            

  Knight W   Google s AI chief says forget Elon Musk s killer robots  and worry about bias in AI systems instead   MIT Technology Review  Archived from the original on             Retrieved            

   Where in the World is AI  Responsible  amp  Unethical AI Examples   Archived from the original on             Retrieved            

  Ruggieri S  Alvarez JM  Pugnana A  State L  Turini F                Can We Trust Fair AI    Proceedings of the AAAI Conference on Artificial Intelligence           Association for the Advancement of Artificial Intelligence  AAAI                doi         aaai v  i          hdl               ISSN                 S CID                

  Buyl M  De Bie T          Inherent Limitations of AI Fairness   Communications of the ACM                 arXiv             doi                  hdl      LU   GMNH  RGNVWJ   BJJXGCY   

  Castelnovo A  Inverardi N  Nanino G  Penco IG  Regoli D          Fair Enough  A map of the current limitations of the requirements to have  fair  algorithms   arXiv             cs AI  

  Federspiel F  Mitchell R  Asokan A  Umana C  McCoy D  May         Threats by artificial intelligence to human health and human existence   BMJ Global Health         e        doi         bmjgh              ISSN                 PMC                PMID                Archived from the original on             Retrieved            

  a b Spindler G          Different approaches for liability of Artificial Intelligence   Pros and Cons   Liability for AI  Nomos Verlagsgesellschaft mbH  amp  Co  KG  pp              doi                           ISBN                         archived from the original on             retrieved           

  Manyika J          Getting AI Right  Introductory Notes on AI  amp  Society   Daedalus                 doi         daed e        ISSN                

  Imran A  Posokhova I  Qureshi HN  Masood U  Riaz MS  Ali K  John CN  Hussain MI  Nabeel M                AI COVID     AI enabled preliminary diagnosis for COVID    from cough samples via an app   Informatics in Medicine Unlocked              doi         j imu              ISSN                 PMC               PMID               

  Cirillo D  Catuara Solarz S  Morey C  Guney E  Subirats L  Mellino S  Gigante A  Valencia A  Rementeria MJ  Chadha AS  Mavridis N                Sex and gender differences and biases in artificial intelligence for biomedicine and healthcare   npj Digital Medicine             doi         s                  ISSN                 PMC               PMID               

  Christian B         The alignment problem  machine learning and human values  First published as a Norton paperback      ed    New York  NY  W  W  Norton  amp  Company  ISBN                        

  Ntoutsi E  Fafalios P  Gadiraju U  Iosifidis V  Nejdl W  Vidal ME  Ruggieri S  Turini F  Papadopoulos S  Krasanakis E  Kompatsiaris I  Kinder Kurlanda K  Wagner C  Karimi F  Fernandez M  May         Bias in data driven artificial intelligence systems An introductory survey   WIREs Data Mining and Knowledge Discovery          doi         widm       ISSN                

  Luo Q  Puett MJ  Smith MD                A Perspectival Mirror of the Elephant  Investigating Language Bias on Google  ChatGPT  Wikipedia  and YouTube   arXiv           v   cs CY  

  Busker T  Choenni S  Shoae Bargh M                Stereotypes in ChatGPT  An empirical study   Proceedings of the   th International Conference on Theory and Practice of Electronic Governance  ICEGOV      New York  NY  USA  Association for Computing Machinery  pp              doi                          ISBN                        

  Kotek H  Dockum R  Sun D                Gender bias and stereotypes in Large Language Models   Proceedings of the ACM Collective Intelligence Conference  CI      New York  NY  USA  Association for Computing Machinery  pp              arXiv             doi                          ISBN                        

  Federspiel F  Mitchell R  Asokan A  Umana C  McCoy D  May         Threats by artificial intelligence to human health and human existence   BMJ Global Health         e        doi         bmjgh              ISSN                 PMC                PMID               

  Feng S  Park CY  Liu Y  Tsvetkov Y  July        Rogers A  Boyd Graber J  Okazaki N  eds     From Pretraining Data to Language Models to Downstream Tasks  Tracking the Trails of Political Biases Leading to Unfair NLP Models   Proceedings of the   st Annual Meeting of the Association for Computational Linguistics  Volume    Long Papers   Toronto  Canada  Association for Computational Linguistics               arXiv             doi          v       acl long     

  Zhou K  Tan C  December        Bouamor H  Pino J  Bali K  eds     Entity Based Evaluation of Political Bias in Automatic Summarization   Findings of the Association for Computational Linguistics  EMNLP       Singapore  Association for Computational Linguistics               arXiv             doi          v       findings emnlp      Archived from the original on             Retrieved            

  Cheng M  Durmus E  Jurafsky D                Marked Personas  Using Natural Language Prompts to Measure Stereotypes in Language Models   arXiv           v   cs CL  

  Hammond G     December         Big Tech is spending more than VC firms on AI startups   Ars Technica  Archived from the original on Jan          

  Wong M     October         The Future of AI Is GOMA   The Atlantic  Archived from the original on Jan         

   Big tech and the pursuit of AI dominance   The Economist  Mar           Archived from the original on Dec          

  Fung B     December         Where the battle to dominate AI may be won   CNN Business  Archived from the original on Jan          

  Metz C    July         In the Age of A I   Tech s Little Guys Need Big Friends   The New York Times  Archived from the original on   July       Retrieved    July      

  Open Source AI  Archived            at the Wayback Machine Bill Hibbard       proceedings Archived            at the Wayback Machine of the First Conference on Artificial General Intelligence  eds  Pei Wang  Ben Goertzel  and Stan Franklin 

  Stewart A  Melton M   Hugging Face CEO says he s focused on building a  sustainable model  for the      billion open source AI startup   Business Insider  Archived from the original on             Retrieved            

   The open source AI boom is built on Big Tech s handouts  How long will it last    MIT Technology Review  Archived from the original on             Retrieved            

  Yao D  February             Google Unveils Open Source Models to Rival Meta  Mistral   AI Business 

              IEEE Standard for Transparency of Autonomous Systems  IEEE    March       pp             doi         IEEESTD               ISBN                         S CID                 Archived from the original on    July       Retrieved   July       

  Kamila MK  Jasrotia SS                Ethical issues in the development of artificial intelligence  recognizing the risks   International Journal of Ethics and Systems             doi         IJOES               ISSN                 S CID                

  Thurm S  July             Microsoft Calls For Federal Regulation of Facial Recognition   Wired  Archived from the original on May          Retrieved January          

  Piper K                Should we make our most powerful AI models open source to all    Vox  Retrieved            

  Vincent J                OpenAI co founder on company s past approach to openly sharing research   We were wrong    The Verge  Archived from the original on             Retrieved            

   Stack Overflow Will Charge AI Giants for Training Data   WIRED     April       Retrieved   April      

   Open source devs say AI crawlers dominate traffic  forcing blocks on entire countries   Ars Technica     March       Retrieved   April      

   AI bots strain Wikimedia as bandwidth surges       Ars Technica    April       Retrieved   April      

  Inside The Mind Of A I  Archived            at the Wayback Machine   Cliff Kuang interview

  Bunn J                Working in contexts for which transparency is important  A recordkeeping view of explainable artificial intelligence  XAI    Records Management Journal                   doi         RMJ               ISSN                 S CID                

  Li F  Ruijs N  Lu Y                Ethics  amp  AI  A Systematic Review on Ethical Concerns and Related Strategies for Designing with AI in Healthcare   AI                doi         ai         ISSN                

  Howard A     July         The Regulation of AI   Should Organizations Be Worried    Ayanna Howard   MIT Sloan Management Review  Archived from the original on             Retrieved            

   Trust in artificial intelligence   A five country study   PDF   KPMG  March       Archived  PDF  from the original on             Retrieved            

  Bastin R  Wantz G  June         The General Data Protection Regulation Cross industry innovation   PDF   Inside magazine  Deloitte  Archived  PDF  from the original on             Retrieved            

   UN artificial intelligence summit aims to tackle poverty  humanity s  grand challenges    UN News              Archived from the original on             Retrieved            

   Artificial intelligence   Organisation for Economic Co operation and Development   www oecd org  Archived from the original on             Retrieved            

  Anonymous                The European AI Alliance   Digital Single Market   European Commission  Archived from the original on             Retrieved            

  European Commission High Level Expert Group on AI                Policy and investment recommendations for trustworthy Artificial Intelligence   Shaping Europe s digital future   European Commission  Archived from the original on             Retrieved            

  Fukuda Parr S  Gibbons E  July         Emerging Consensus on  Ethical AI   Human Rights Critique of Stakeholder Guidelines   Global Policy      S           doi                          ISSN                

   EU Tech Policy Brief  July      Recap   Center for Democracy  amp  Technology    August       Archived from the original on             Retrieved            

  Curtis C  Gillespie N  Lockey S                AI deploying organizations are key to addressing  perfect storm  of AI risks   AI and Ethics                  doi         s                   ISSN                 PMC               PMID                Archived from the original on             Retrieved            

  a b  Why the world needs a Bill of Rights on AI   Financial Times              Retrieved            

  Challen R  Denny J  Pitt M  Gompels L  Edwards T  Tsaneva Atanasova K  March         Artificial intelligence  bias and clinical safety   BMJ Quality  amp  Safety                   doi         bmjqs              ISSN                 PMC               PMID               

  a b Thomas Metzinger  February         Artificial Suffering  An Argument for a Global Moratorim on Synthetic Phenomenology   Journal of Artificial Intelligence and Consciousness            doi         S               X  S CID                

  a b Agarwal A  Edelman S          Functionally effective conscious AI without suffering   Journal of Artificial Intelligence and Consciousness            arXiv             doi         S                  S CID                

  Roose K                If A I  Systems Become Conscious  Should They Have Rights    The New York Times  ISSN                 Retrieved            

  Birch J                Animal sentience and the precautionary principle   Animal Sentience          doi                          ISSN                 Archived from the original on             Retrieved            

  Macrae C  September         Learning from the Failure of Autonomous and Intelligent Systems  Accidents  Safety  and Sociotechnical Sources of Risk   Risk Analysis                     Bibcode     RiskA         M  doi         risa        ISSN                 PMID               

  Chalmers D  March         Could a Large Language Model be Conscious    arXiv           v   Science Computer Science  

  Edwards B                Anthropic hires its first  AI welfare  researcher   Ars Technica  Retrieved            

  Wiggers K                Anthropic is launching a new program to study AI  model welfare    TechCrunch  Retrieved            

  Shulman C  Bostrom N  August         Sharing the World with Digital Minds   PDF   Rethinking Moral Status           doi         oso                         ISBN                        

  Fisher R     November         The intelligent monster that you should let eat you   BBC News  Retrieved    February      

  a b 
Weizenbaum J         Computer Power and Human Reason  San Francisco  W H  Freeman  amp  Company  ISBN                        
McCorduck P         Machines Who Think   nd      ed    Natick  Massachusetts  A  K  Peters  ISBN                     pp          

  a b Joseph Weizenbaum  quoted in McCorduck       pp                   

  Kaplan A  Haenlein M  January         Siri  Siri  in my hand  Who s the fairest in the land  On the interpretations  illustrations  and implications of artificial intelligence   Business Horizons                 doi         j bushor              S CID                

  a b Hibbard B     November         Ethical Artificial Intelligence   arXiv            cs AI  

  Davies A     February         Google s Self Driving Car Caused Its First Crash   Wired  Archived from the original on   July       Retrieved    July      

  Levin S  Wong JC     March         Self driving Uber kills Arizona woman in first fatal crash involving pedestrian   The Guardian  Archived from the original on    July       Retrieved    July      

   Who is responsible when a self driving car has an accident    Futurism     January       Archived from the original on             Retrieved            

   Autonomous Car Crashes  Who   or What   Is to Blame    Knowledge Wharton  Law and Public Policy  Radio Business North America Podcasts  Archived from the original on             Retrieved            

  Delbridge E   Driverless Cars Gone Wild   The Balance  Archived from the original on             Retrieved            

  Stilgoe J          Who Killed Elaine Herzberg    Who s Driving Innovation   Cham  Springer International Publishing  pp            doi                              ISBN                         S CID                 archived from the original on             retrieved           

  Maxmen A  October         Self driving car dilemmas reveal that moral choices are not universal   Nature                       Bibcode     Natur         M  doi         d                   PMID               

   Regulations for driverless cars   GOV UK  Archived from the original on             Retrieved            

   Automated Driving  Legislative and Regulatory Action   CyberWiki   cyberlaw stanford edu  Archived from the original on             Retrieved            

   Autonomous Vehicles   Self Driving Vehicles Enacted Legislation   www ncsl org  Archived from the original on             Retrieved            

  Etzioni A  Etzioni O                Incorporating Ethics into Artificial Intelligence   The Journal of Ethics                   doi         s                  ISSN                 S CID                

  Call for debate on killer robots Archived            at the Wayback Machine  By Jason Palmer  Science and technology reporter  BBC News         

  Science New Navy funded Report Warns of War Robots Going  Terminator  Archived            at the Wayback Machine  by Jason Mick  Blog   dailytech com  February          

  a b Navy report warns of robot uprising  suggests a strong moral compass Archived            at the Wayback Machine  by Joseph L  Flatley engadget com  Feb   th      

  AAAI Presidential Panel on Long Term AI Futures           Study Archived            at the Wayback Machine  Association for the Advancement of Artificial Intelligence  Accessed         

  United States  Defense Innovation Board  AI principles  recommendations on the ethical use of artificial intelligence by the Department of Defense  OCLC                 

  New Navy funded Report Warns of War Robots Going  Terminator  Archived            at the Wayback Machine  by Jason Mick  Blog   dailytech com  February          

  Umbrello S  Torres P  De Bellis AF  March         The future of war  could lethal autonomous weapons make conflict more ethical    AI  amp  Society                   doi         s                x  hdl               ISSN                 S CID                Archived from the original on             Retrieved            

  Jamison M                DARPA Launches Ethics Program for Autonomous Systems   executivegov com  Retrieved            

   DARPA s ASIMOV seeks to develop Ethical Standards for Autonomous Systems   Space Daily  Retrieved            

  Hellstr m T  June         On the moral responsibility of military robots   Ethics and Information Technology                  doi         s                  S CID                ProQuest                 

  Mitra A    April         We can train AI to identify good and evil  and then use it to teach us morality   Quartz  Archived from the original on             Retrieved            

  Dominguez G     August         South Korea developing new stealthy drones to support combat aircraft   The Japan Times  Retrieved    June      

   AI Principles   Future of Life Institute     August       Archived from the original on             Retrieved            

  a b Zach Musgrave and Bryan W  Roberts                Why Artificial Intelligence Can Too Easily Be Weaponized   The Atlantic   The Atlantic  Archived from the original on             Retrieved            

  Cat Zakrzewski                Musk  Hawking Warn of Artificial Intelligence Weapons   WSJ  Archived from the original on             Retrieved            

   Potential Risks from Advanced Artificial Intelligence   Open Philanthropy  August           Retrieved            

  a b Bachulska A  Leonard M  Oertel J    July        The Idea of China  Chinese Thinkers on Power  Progress  and People  EPUB   Berlin  Germany  European Council on Foreign Relations  ISBN                         Archived from the original on    July       Retrieved    July      

  Brandon Vigliarolo   International military AI summit ends with    state pledge   www theregister com  Retrieved            

  a b Markoff J     July         Scientists Worry Machines May Outsmart Man   The New York Times  Archived from the original on    February       Retrieved    February      

  Muehlhauser  Luke  and Louie Helm         Intelligence Explosion and Machine Ethics  Archived            at the Wayback Machine  In Singularity Hypotheses  A Scientific and Philosophical Assessment  edited by Amnon Eden  Johnny S raker  James H  Moor  and Eric Steinhart  Berlin  Springer 

  Bostrom  Nick         Ethical Issues in Advanced Artificial Intelligence  Archived            at the Wayback Machine  In Cognitive  Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence  edited by Iva Smit and George E  Lasker         Vol     Windsor  ON  International Institute for Advanced Studies in Systems Research   Cybernetics 

  Bostrom N         Superintelligence  paths  dangers  strategies  Oxford  United Kingdom  Oxford University Press  ISBN                        

  Umbrello S  Baum SD                Evaluating future nanotechnology  The net societal impacts of atomically precise manufacturing   Futures              doi         j futures              hdl               ISSN                 S CID                 Archived from the original on             Retrieved            

  Yudkowsky  Eliezer         Complex Value Systems in Friendly AI  Archived            at the Wayback Machine  In Schmidhuber  Th risson  and Looks               

  Russell S  October           Human Compatible  Artificial Intelligence and the Problem of Control  United States  Viking  ISBN                         OCLC                 

  Yampolskiy RV                Unpredictability of AI  On the Impossibility of Accurately Predicting All Actions of a Smarter Agent   Journal of Artificial Intelligence and Consciousness                   doi         S                  ISSN                 S CID                 Archived from the original on             Retrieved            

  Wallach W  Vallor S                Moral Machines  From Value Alignment to Embodied Virtue   Ethics of Artificial Intelligence  Oxford University Press  pp                doi         oso                         ISBN                         archived from the original on             retrieved           

  Umbrello S          Beneficial Artificial Intelligence Coordination by Means of a Value Sensitive Design Approach   Big Data and Cognitive Computing            doi         bdcc         hdl              

  Floridi L  Cowls J  King TC  Taddeo M          How to Design AI for Social Good  Seven Essential Factors   Science and Engineering Ethics                     doi         s                   ISSN                 PMC               PMID               

   NeMo Guardrails   NeMo Guardrails  Retrieved            

   Llama Guard  LLM based Input Output Safeguard for Human AI Conversations   Meta com  Retrieved            

  a b  ekrst K  McHugh J  Cefalu JR          AI Ethics by Design  Implementing Customizable Guardrails for Responsible AI Development   arXiv             cs CY  

   Nvidia NeMo Guardrails   Nvidia  Retrieved            

  Inan H  Upasani K  Chi J  Rungta R  Iyer K  Mao Y  Tontchev M  Hu Q  Fuller B  Testuggine D  Khabsa M          Llama Guard  LLM based Input Output Safeguard for Human AI Conversations   arXiv             cs CL  

  Dong Y  Mu R  Jin G  Qi Y  Hu J  Zhao X  Meng J  Ruan W  Huang X          Building Guardrails for Large Language Models   arXiv             cs  

  Fiegerman S     September         Facebook  Google  Amazon create group to ease AI concerns   CNNMoney  Archived from the original on    September       Retrieved    August      

  Slota SC  Fleischmann KR  Greenberg S  Verma N  Cummings B  Li L  Shenefiel C          Locating the work of artificial intelligence ethics   Journal of the Association for Information Science and Technology                   doi         asi        ISSN                 S CID                 Archived from the original on             Retrieved            

   Ethics guidelines for trustworthy AI   Shaping Europe s digital future   European Commission  European Commission              Archived from the original on             Retrieved            

   White Paper on Artificial Intelligence   a European approach to excellence and trust        Shaping Europe s digital future      February       Archived from the original on             Retrieved            

   OECD AI Policy Observatory   Archived from the original on             Retrieved            

  Recommendation on the Ethics of Artificial Intelligence  UNESCO       

   UNESCO member states adopt first global agreement on AI ethics   Helsinki Times              Archived from the original on             Retrieved            

   The Obama Administration s Roadmap for AI Policy   Harvard Business Review              ISSN                 Archived from the original on             Retrieved            

   Accelerating America s Leadership in Artificial Intelligence   The White House   trumpwhitehouse archives gov  Archived from the original on             Retrieved            

   Request for Comments on a Draft Memorandum to the Heads of Executive Departments and Agencies   Guidance for Regulation of Artificial Intelligence Applications    Federal Register              Archived from the original on             Retrieved            

   CCC Offers Draft    Year AI Roadmap  Seeks Comments   HPCwire              Archived from the original on             Retrieved            

   Request Comments on Draft  A    Year Community Roadmap for AI Research in the US        CCC Blog      May       Archived from the original on             Retrieved            

   in Russian                           Archived            at the Wayback Machine   Kommersant            

  Grace K  Salvatier J  Dafoe A  Zhang B  Evans O                When Will AI Exceed Human Performance  Evidence from AI Experts   arXiv             cs AI  

   China wants to shape the global future of artificial intelligence   MIT Technology Review  Archived from the original on             Retrieved            

  Adam D                Future of Humanity Institute shuts  what s next for  deep future  research    Nature                     doi         d                   PMID               

  Floridi L  Cowls J  Beltrametti M  Chatila R  Chazerand P  Dignum V  Luetge C  Madelin R  Pagallo U  Rossi F  Schafer B                AI People An Ethical Framework for a Good AI Society  Opportunities  Risks  Principles  and Recommendations   Minds and Machines                   doi         s                  ISSN                 PMC               PMID               

   AI Governance   Oxford Martin School  Retrieved            

   Joanna J  Bryson   WIRED  Archived from the original on    March       Retrieved    January      

   New Artificial Intelligence Research Institute Launches               Archived from the original on             Retrieved            

  James J  Hughes  LaGrandeur  Kevin  eds      March        Surviving the machine age  intelligent technology and the transformation of human work  Cham  Switzerland  Palgrave Macmillan Cham  ISBN                         OCLC                 Archived from the original on    March       Retrieved    November      

  Danaher  John         Automation and utopia  human flourishing in a world without work  Cambridge  Massachusetts  Harvard University Press  ISBN                         OCLC                 

   TUM Institute for Ethics in Artificial Intelligence officially opened   www tum de  Archived from the original on             Retrieved            

  Communications PK                Harvard works to embed ethics in computer science curriculum   Harvard Gazette  Archived from the original on             Retrieved            

  Lee J                When Bias Is Coded Into Our Technology   NPR  Retrieved            

   How one conference embraced diversity   Nature                                   doi         d                x  PMID                S CID               

  Roose K                The      Good Tech Awards   The New York Times  ISSN                 Retrieved            

  Lodge P          Leibniz s Mill Argument Against Mechanical Materialism Revisited   Ergo  an Open Access Journal of Philosophy                doi         ergo                    hdl      spo                    ISSN                

  Bringsjord S  Govindarajulu NS          Artificial Intelligence   in Zalta EN  Nodelman U  eds    The Stanford Encyclopedia of Philosophy  Summer           ed    Metaphysics Research Lab  Stanford University  archived from the original on             retrieved           

  Kulesz  O           Culture  Platforms and Machines   UNESCO  Paris 

  Jr HC               Information Technology and the Productivity Paradox  Assessing the Value of Investing in IT  Oxford University Press  ISBN                         Archived from the original on             Retrieved            

  Asimov I         I  Robot  New York  Bantam  ISBN                        

  Bryson J  Diamantis M  Grant T  September         Of  for  and by the people  the legal lacuna of synthetic persons   Artificial Intelligence and Law                   doi         s                 

   Principles of robotics   UK s EPSRC  September       Archived from the original on   April       Retrieved    January      

  Yudkowsky E  July         Why We Need Friendly AI     laws unsafe  Archived from the original on May          

  Aleksander I  March         Partners of Humans  A Realistic Assessment of the Role of Robots in the Foreseeable Future   Journal of Information Technology               doi         s                  ISSN                 S CID               Archived from the original on             Retrieved            

  Evolving Robots Learn To Lie To Each Other Archived            at the Wayback Machine  Popular Science  August         

  Bassett C  Steinmueller E  Voss G   Better Made Up  The Mutual Influence of Science Fiction and Innovation   Nesta  Archived from the original on   May       Retrieved   May      

  Velasco G                Science Fiction  A Mirror for the Future of Humankind   IDEES  Archived from the original on             Retrieved            

   Love  Death  amp  Robots season    episode   recap    Automated Customer Service    Ready Steady Cut              Archived from the original on             Retrieved            

  Cave  Stephen  Dihal  Kanta  Dillon  Sarah  eds      February        AI narratives  a history of imaginative thinking about intelligent machines  First      ed    Oxford  Oxford University Press  ISBN                         OCLC                  Archived from the original on    March       Retrieved    November      

  Jerreat Poole A    February         Sick  Slow  Cyborg  Crip Futurity in Mass Effect   Game Studies      ISSN                 Archived from the original on   December       Retrieved    November      

    Detroit  Become Human  Will Challenge your Morals and your Humanity   Coffee or Die Magazine              Archived from the original on             Retrieved            

  Cerqui D  Warwick K          Re Designing Humankind  The Rise of Cyborgs  a Desirable Goal    Philosophy and Design  Dordrecht  Springer Netherlands  pp                doi                               ISBN                         archived from the original on             retrieved           

  Cave S  Dihal K    August         The Whiteness of AI   Philosophy  amp  Technology                   doi         s                   S CID                


External links edit 
Ethics of Artificial Intelligence at the Internet Encyclopedia of Philosophy
Ethics of Artificial Intelligence and Robotics at the Stanford Encyclopedia of Philosophy
The Cambridge Handbook of the Law  Ethics and Policy of Artificial Intelligence
Russell S  Hauert S  Altman R  Veloso M  May         Robotics  Ethics of artificial intelligence   Nature                       Bibcode     Natur            doi               a  PMID                S CID              
BBC News  Games to take on a life of their own
A short history of computer ethics
AI Ethics Guidelines Global Inventory by Algorithmwatch
Hagendorff T  March         The Ethics of AI Ethics  An Evaluation of Guidelines   Minds and Machines                  arXiv             doi         s                   S CID               
Sheludko  M   December         Ethical Aspects of Artificial Intelligence  Challenges and Imperatives  Software Development Blog 
Eisikovits N   AI Is an Existential Threat Just Not the Way You Think   Scientific American  Retrieved            
Anwar U  Saparov A  Rando J  Paleka D  Turpin M  Hase P  Lubana ES  Jenner E  Casper S  Sourbut O  Edelman BL  Zhang Z  G nther M  Korinek A  Hernandez Orallo J  Hammond L  Bigelow E  Pan A  Langosco L  Krueger D          Foundational Challenges in Assuring Alignment and Safety of Large Language Models   arXiv             cs LG  
vteArtificial intelligence  AI History  timeline Concepts
Parameter
Hyperparameter
Loss functions
Regression
Bias variance tradeoff
Double descent
Overfitting
Clustering
Gradient descent
SGD
Quasi Newton method
Conjugate gradient method
Backpropagation
Attention
Convolution
Normalization
Batchnorm
Activation
Softmax
Sigmoid
Rectifier
Gating
Weight initialization
Regularization
Datasets
Augmentation
Prompt engineering
Reinforcement learning
Q learning
SARSA
Imitation
Policy gradient
Diffusion
Latent diffusion model
Autoregression
Adversary
RAG
Uncanny valley
RLHF
Self supervised learning
Recursive self improvement
Word embedding
Hallucination
Applications
Machine learning
In context learning
Artificial neural network
Deep learning
Language model
Large language model
NMT
Artificial general intelligence  AGI 
ImplementationsAudio visual
AlexNet
WaveNet
Human image synthesis
HWR
OCR
Speech synthesis
   ai
ElevenLabs
Speech recognition
Whisper
Facial recognition
AlphaFold
Text to image models
Aurora
DALL E
Firefly
Flux
Ideogram
Imagen
Midjourney
Stable Diffusion
Text to video models
Dream Machine
Runway Gen
Hailuo AI
Kling
Sora
Veo
Music generation
Suno AI
Udio
Text
Word vec
Seq seq
GloVe
BERT
T 
Llama
Chinchilla AI
PaLM
GPT
 
 
 
J
ChatGPT
 
 o
o 
o 
   
   
o 
Claude
Gemini
chatbot
Grok
LaMDA
BLOOM
Project Debater
IBM Watson
IBM Watsonx
Granite
PanGu  
DeepSeek
Qwen
Decisional
AlphaGo
AlphaZero
OpenAI Five
Self driving car
MuZero
Action selection
AutoGPT
Robot control
People
Alan Turing
Warren Sturgis McCulloch
Walter Pitts
John von Neumann
Claude Shannon
Marvin Minsky
John McCarthy
Nathaniel Rochester
Allen Newell
Cliff Shaw
Herbert A  Simon
Oliver Selfridge
Frank Rosenblatt
Bernard Widrow
Joseph Weizenbaum
Seymour Papert
Seppo Linnainmaa
Paul Werbos
J rgen Schmidhuber
Yann LeCun
Geoffrey Hinton
John Hopfield
Yoshua Bengio
Lotfi A  Zadeh
Stephen Grossberg
Alex Graves
Andrew Ng
Fei Fei Li
Alex Krizhevsky
Ilya Sutskever
Demis Hassabis
David Silver
Ian Goodfellow
Andrej Karpathy
James Goodnight
Architectures
Neural Turing machine
Differentiable neural computer
Transformer
Vision transformer  ViT 
Recurrent neural network  RNN 
Long short term memory  LSTM 
Gated recurrent unit  GRU 
Echo state network
Multilayer perceptron  MLP 
Convolutional neural network  CNN 
Residual neural network  RNN 
Highway network
Mamba
Autoencoder
Variational autoencoder  VAE 
Generative adversarial network  GAN 
Graph neural network  GNN 

 Portals
Technology
 Category
Artificial neural networks
Machine learning
 List
Companies
Projects

vteEthicsNormative
Consequentialism
Deontology
Care
Particularism
Pragmatic
Role
Suffering focused
Utilitarianism
Virtue
Applied
Animal
Artificial intelligence
Bio
Business
Computer
Discourse
Economic
Engineering
Environmental
Land
Legal
Machine
Marketing
Meat eating
Media
Medical
Nursing
Professional
Programming
Research
Sexual
Technology
Terraforming
Uncertain sentience
Work
Meta
Absolutism
Axiology
Cognitivism
Realism
Naturalism
Non naturalism
Subjectivism
Ideal observer theory
Divine command theory
Constructivism
Euthyphro dilemma
Intuitionism
Nihilism
Non cognitivism
Emotivism
Expressivism
Quasi realism
Universal prescriptivism
Rationalism
Relativism
Skepticism
Universalism
Value monism   Value pluralism
Schools
Buddhist
Christian
Protestant
Confucian
Epicurean
Existentialist
Feminist
Islamic
Jewish
Kantian
Rousseauian
Stoic
Tao
Concepts
Accountability
Authority
Autonomy
Blame
Common sense
Compassion
Conscience
Consent
Culture of life
Desert
Dignity
Double standard
Duty
Equality
Etiquette
Eudaimonia
Family values
Fidelity
Free will
Good and evil
Good
Evil
Problem of evil
Greed
Happiness
Honour
Ideal
Immorality
Importance
Justice
Liberty
Loyalty
Moral agency
Moral courage
Moral hierarchy
Moral imperative
Morality
Norm
Pacifism
Political freedom
Precept
Punishment
Rights
Self discipline
Suffering
Stewardship
Sympathy
Theodicy
Torture
Trust
Utility
Value
Instrumental
Intrinsic
Japan
Western
Vice
Virtue
Vow
Wrong
Ethicists
Laozi
Socrates
Plato
Aristotle
Diogenes
Valluvar
Cicero
Confucius
Augustine
Mencius
Mozi
Xunzi
Aquinas
Spinoza
Butler
Hume
Smith
Kant
Hegel
Schopenhauer
Bentham
Mill
Kierkegaard
Sidgwick
Nietzsche
Moore
Barth
Tillich
Bonhoeffer
Foot
Rawls
Dewey
Williams
Mackie
Anscombe
Frankena
MacIntyre
Hare
Singer
Parfit
Nagel
Adams
Taylor
Azurmendi
Korsgaard
Nussbaum
Works
Nicomachean Ethics  c      BC 
Ethics  Spinoza        
Fifteen Sermons Preached at the Rolls Chapel       
A Treatise of Human Nature       
The Theory of Moral Sentiments       
An Introduction to the Principles of Morals and Legislation       
Groundwork of the Metaphysics of Morals       
Critique of Practical Reason       
Elements of the Philosophy of Right       
Either Or       
Utilitarianism       
The Methods of Ethics       
On the Genealogy of Morality       
Principia Ethica       
A Theory of Justice       
Practical Ethics       
After Virtue       
Reasons and Persons       
Related
Axiology
Casuistry
Descriptive ethics
Ethics in religion
Evolutionary ethics
History of ethics
Human rights
Ideology
Moral psychology
Philosophy of law
Political philosophy
Population ethics
Rehabilitation
Secular ethics
Social philosophy
Index

 Category
 Outline
 Portal
 WikiProject

vteExistential risk from artificial intelligenceConcepts
AGI
AI alignment
AI capability control
AI safety
AI takeover
Consequentialism
Effective accelerationism
Ethics of artificial intelligence
Existential risk from artificial intelligence
Friendly artificial intelligence
Instrumental convergence
Vulnerable world hypothesis
Intelligence explosion
Longtermism
Machine ethics
Suffering risks
Superintelligence
Technological singularity
Organizations
Alignment Research Center
Center for AI Safety
Center for Applied Rationality
Center for Human Compatible Artificial Intelligence
Centre for the Study of Existential Risk
EleutherAI
Future of Humanity Institute
Future of Life Institute
Google DeepMind
Humanity 
Institute for Ethics and Emerging Technologies
Leverhulme Centre for the Future of Intelligence
Machine Intelligence Research Institute
OpenAI
People
Scott Alexander
Sam Altman
Yoshua Bengio
Nick Bostrom
Paul Christiano
Eric Drexler
Sam Harris
Stephen Hawking
Dan Hendrycks
Geoffrey Hinton
Bill Joy
Shane Legg
Elon Musk
Steve Omohundro
Huw Price
Martin Rees
Stuart J  Russell
Jaan Tallinn
Max Tegmark
Frank Wilczek
Roman Yampolskiy
Eliezer Yudkowsky
Other
Statement on AI risk of extinction
Human Compatible
Open letter on artificial intelligence       
Our Final Invention
The Precipice
Superintelligence  Paths  Dangers  Strategies
Do You Trust This Computer 
Artificial Intelligence Act
 Category
vtePhilosophy of scienceConcepts
Analysis
Analytic synthetic distinction
A priori and a posteriori
Causality
Mill s Methods
Commensurability
Consilience
Construct
Correlation
function
Creative synthesis
Demarcation problem
Empirical evidence
Experiment
design
Explanatory power
Fact
Falsifiability
Feminist method
Functional contextualism
Hypothesis
alternative
null
Ignoramus et ignorabimus
Inductive reasoning
Intertheoretic reduction
Inquiry
Measurement
Nature
Objectivity
Observation
Paradigm
Problem of induction
Scientific evidence
Evidence based practice
Scientific law
Scientific method
Scientific pluralism
Scientific Revolution
Testability
Theory
choice
ladenness
scientific
Underdetermination
Unity of science
Variable
control
dependent and independent
more   
Theories
Coherentism
Confirmation holism
Constructive empiricism
Constructive realism
Constructivist epistemology
Contextualism
Conventionalism
Deductive nomological model
Epistemological anarchism
Evolutionism
Fallibilism
Foundationalism
Hypothetico deductive model
Inductionism
Instrumentalism
Model dependent realism
Naturalism
Physicalism
Positivism            Reductionism            Determinism
Pragmatism
Rationalism            Empiricism
Received view            Semantic view of theories
Scientific essentialism
Scientific formalism
Scientific realism            Anti realism
Scientific skepticism
Scientism
Structuralism
Uniformitarianism
Verificationism
Vitalism
Philosophy of   
Biology
Chemistry
Physics
Space and time
Social science
Archaeology
Economics
Geography
History
Linguistics
Psychology
Related topics
Criticism of science
Descriptive science
Epistemology
Exact sciences
Faith and rationality
Hard and soft science
History and philosophy of science
Non science
Pseudoscience
Normative science
Protoscience
Questionable cause
Relationship between religion and science
Rhetoric of science
Science studies
Sociology of scientific ignorance
Sociology of scientific knowledge
Philosophers of sciencePrecursors
Roger Bacon
Francis Bacon
Galileo Galilei
Isaac Newton
David Hume

Auguste Comte
Henri Poincar 
Pierre Duhem
Rudolf Steiner
Karl Pearson
Charles Sanders Peirce
Wilhelm Windelband
Alfred North Whitehead
Bertrand Russell
Otto Neurath
C  D  Broad
Michael Polanyi
Hans Reichenbach
Rudolf Carnap
Karl Popper
Carl Gustav Hempel
W  V  O  Quine
Thomas Kuhn
Imre Lakatos
Paul Feyerabend
Ian Hacking
Bas van Fraassen
Larry Laudan
 Category
 Philosophy     portal
 Science     portal






Retrieved from  https   en wikipedia org w index php title Ethics of artificial intelligence amp oldid