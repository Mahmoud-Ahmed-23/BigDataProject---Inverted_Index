Type of large language model
Not to be confused with ChatGPT 
Part of a series onMachine learningand data mining
Paradigms
Supervised learning
Unsupervised learning
Semi supervised learning
Self supervised learning
Reinforcement learning
Meta learning
Online learning
Batch learning
Curriculum learning
Rule based learning
Neuro symbolic AI
Neuromorphic engineering
Quantum machine learning

Problems
Classification
Generative modeling
Regression
Clustering
Dimensionality reduction
Density estimation
Anomaly detection
Data cleaning
AutoML
Association rules
Semantic analysis
Structured prediction
Feature engineering
Feature learning
Learning to rank
Grammar induction
Ontology learning
Multimodal learning

Supervised learning classification                  regression  
Apprenticeship learning
Decision trees
Ensembles
Bagging
Boosting
Random forest
k NN
Linear regression
Naive Bayes
Artificial neural networks
Logistic regression
Perceptron
Relevance vector machine  RVM 
Support vector machine  SVM 

Clustering
BIRCH
CURE
Hierarchical
k means
Fuzzy
Expectation maximization  EM 
DBSCAN
OPTICS
Mean shift

Dimensionality reduction
Factor analysis
CCA
ICA
LDA
NMF
PCA
PGD
t SNE
SDL

Structured prediction
Graphical models
Bayes net
Conditional random field
Hidden Markov

Anomaly detection
RANSAC
k NN
Local outlier factor
Isolation forest

Artificial neural network
Autoencoder
Deep learning
Feedforward neural network
Recurrent neural network
LSTM
GRU
ESN
reservoir computing
Boltzmann machine
Restricted
GAN
Diffusion model
SOM
Convolutional neural network
U Net
LeNet
AlexNet
DeepDream
Neural radiance field
Transformer
Vision
Mamba
Spiking neural network
Memtransistor
Electrochemical RAM  ECRAM 

Reinforcement learning
Q learning
SARSA
Temporal difference  TD 
Multi agent
Self play

Learning with humans
Active learning
Crowdsourcing
Human in the loop
RLHF

Model diagnostics
Coefficient of determination
Confusion matrix
Learning curve
ROC curve

Mathematical foundations
Kernel machines
Bias variance tradeoff
Computational learning theory
Empirical risk minimization
Occam learning
PAC learning
Statistical learning
VC theory
Topological deep learning

Journals and conferences
ECML PKDD
NeurIPS
ICML
ICLR
IJCAI
ML
JMLR

Related articles
Glossary of artificial intelligence
List of datasets for machine learning research
List of datasets in computer vision and image processing
Outline of machine learning
vte



Original GPT modelA generative pre trained transformer  GPT  is a type of large language model  LLM                                   and a prominent framework for generative artificial intelligence                        It is an artificial neural network that is used in natural language processing by machines             It is based on the transformer deep learning architecture  pre trained on large data sets of unlabeled text  and able to generate novel human like content                        As of       most LLMs had these characteristics            and are sometimes referred to broadly as GPTs            
The first GPT was introduced in      by OpenAI             OpenAI has released significant GPT foundation models that have been sequentially numbered  to comprise its  GPT n  series              Each of these was significantly more capable than the previous  due to increased size  number of trainable parameters  and training  The most recent of these  GPT  o  was released in May                   Such models have been the basis for their more task specific GPT systems  including models fine tuned for instruction following which in turn power the ChatGPT chatbot service            
The term  GPT  is also used in the names and descriptions of such models developed by others  For example  other GPT foundation models include a series of models created by EleutherAI              and seven models created by Cerebras in                   Companies in different industries have developed task specific GPTs in their respective fields  such as Salesforce s  EinsteinGPT   for CRM              and Bloomberg s  BloombergGPT   for finance              


History edit 
Initial developments edit 
Generative pretraining  GP  was a long established concept in machine learning applications                          It was originally used as a form of semi supervised learning  as the model is trained first on an unlabeled dataset  pretraining step  by learning to generate datapoints in the dataset  and then it is trained to classify a labeled dataset              
There were three main types of early GP  The hidden Markov models learn a generative model of sequences for downstream applications  For example  in speech recognition  a trained HMM infers the most likely hidden sequence for a speech signal  and the hidden sequence is taken as the phonemes of the speech signal  These were developed in the     s and became widely applied in speech recognition in the     s                         
The compressors learn to compress data such as images and textual sequences  and the compressed data serves as a good representation for downstream applications such as facial recognition                                      The autoencoders similarly learn a latent representation of data for later downstream applications such as speech recognition                          The connection between autoencoders and algorithmic compressors was noted in                  

See also  Transformer  deep learning architecture         History
During the     s  the problem of machine translation was solved     citation needed      by recurrent neural networks  with attention mechanism added  This was optimized into the transformer architecture  published by Google researchers in Attention Is All You Need                     That development led to the emergence of large language models such as BERT                    which was a pre trained transformer  PT  but not designed to be generative  BERT was an  encoder only  model   Also in       OpenAI published Improving Language Understanding by Generative Pre Training  which introduced GPT    the first in its GPT series             
Previously in       some of the authors who would later work on GPT   worked on generative pre training of language with LSTM  which resulted in a model that could represent text with vectors that could easily be fine tuned for downstream applications             
Prior to transformer based architectures  the best performing neural NLP  natural language processing  models commonly employed supervised learning from large amounts of manually labeled data  The reliance on supervised learning limited their use on datasets that were not well annotated  and also made it prohibitively expensive and time consuming to train extremely large language models             
The semi supervised approach OpenAI employed to make a large scale generative system and was first to do with a transformer model involved two stages  an unsupervised generative  pretraining  stage to set initial parameters using a language modeling objective  and a supervised discriminative  fine tuning  stage to adapt these parameters to a target task             

Later developments edit 
Regarding more recent GPT foundation models  OpenAI published its first versions of GPT   in July       There were three models  with  B     B     B parameters  respectively named babbage  curie  and davinci  giving initials B  C  and D       citation needed     
In July       OpenAI published Codex  a task specific GPT model targeted for programming applications  This was developed by fine tuning a   B parameter version of GPT    different from previous GPT   models  using code from GitHub             
In March       OpenAI published two versions of GPT   that were fine tuned for instruction following  instruction tuned   named davinci instruct beta     B  and text davinci                  and then started beta testing code davinci                  text davinci     was instruction tuned from code davinci      Both text davinci     and ChatGPT were released in November       with both building upon text davinci     via reinforcement learning from human feedback  RLHF   text davinci     is trained for following instructions  like its predecessors   whereas ChatGPT is further trained for conversational interaction with a human user                         
OpenAI s most recent GPT foundation model  GPT    was released on March           It can be accessed directly by users via a premium version of ChatGPT  and is available to developers for incorporation into other products and services via OpenAI s API  Other producers of GPT foundation models include EleutherAI  with a series of models starting in March                   and Cerebras  with seven models released in March                   

Foundation models edit 
A foundation model is an AI model trained on broad data at scale such that it can be adapted to a wide range of downstream tasks                         
Thus far  the most notable GPT foundation models have been from OpenAI s GPT n series  The most recent from that is GPT    for which OpenAI declined to publish the size or training details  citing  the competitive landscape and the safety implications of large scale models               


OpenAI s GPT n series


Model

Architecture

Parameter count

Training data

Release date

Training cost


GPT  

   level     headed Transformer decoder  no encoder   followed by linear softmax 

    million

BookCorpus                  GB of text  from       unpublished books of various genres 

June                    

   days on   P    graphics cards  or   petaFLOPS day            


GPT  

GPT    but with modified normalization

    billion

WebText     GB of text    million documents  from    million webpages upvoted on Reddit 

February           initial limited version  and November          full version             

 tens of petaflop s day               or    e   FLOPS             


GPT  

GPT    but with modification to allow larger scaling

    billion            

    billion tokens consisting of CommonCrawl      GB   WebText  English Wikipedia  and two books corpora  Books  and Books   

May                     

     petaflop s day  Table D                 or    e   FLOPS             


GPT    

Undisclosed

    billion            

Undisclosed

March         

Undisclosed


GPT  

Also trained with both text prediction and RLHF  accepts both text and images as input  Further details are not public             

Undisclosed  Estimated     trillion             

Undisclosed

March         

Undisclosed  Estimated            FLOPS             


GPT  o

 

 

 

May         

 


GPT    

 

 

 

February         

 


GPT    

 

 

 

April         

 

Other such models include Google s PaLM  a broad foundation model that has been compared to GPT   and has been made available to developers via an API                          and Together s GPT JT  which has been reported as the closest performing open source alternative to GPT    and is derived from earlier open source GPTs               Meta AI  formerly Facebook  also has a generative transformer based foundational large language model  known as LLaMA             
Foundational GPTs can also employ modalities other than text  for input and or output  GPT   is a multi modal LLM that is capable of processing text and image input  though its output is limited to text               Regarding multimodal output  some generative transformer based models are used for text to image technologies such as diffusion             and parallel decoding              Such kinds of models can serve as visual foundation models  VFMs  for developing downstream systems that can work with images             

Task specific models edit 
A foundational GPT model can be further adapted to produce more targeted systems directed to specific tasks and or subject matter domains  Methods for such adaptation can include additional fine tuning  beyond that done for the foundation model  as well as certain forms of prompt engineering             
An important example of this is fine tuning models to follow instructions  which is of course a fairly broad task but more targeted than a foundation model  In January       OpenAI introduced  InstructGPT  a series of models which were fine tuned to follow instructions using a combination of supervised training and reinforcement learning from human feedback  RLHF  on base GPT   language models                          Advantages this had over the bare foundational models included higher accuracy  less negative toxic sentiment  and generally better alignment with user needs  Hence  OpenAI began using this as the basis for its API service offerings              Other instruction tuned models have been released by others  including a fully open version                         
Another  related  kind of task specific models are chatbots  which engage in human like conversation  In November       OpenAI launched ChatGPT an online chat interface powered by an instruction tuned language model trained in a similar fashion to InstructGPT              They trained this model using RLHF  with human AI trainers providing conversations in which they played both the user and the AI  and mixed this new dialogue dataset with the InstructGPT dataset for a conversational format suitable for a chatbot  Other major chatbots currently include Microsoft s Bing Chat  which uses OpenAI s GPT    as part of a broader close collaboration between OpenAI and Microsoft               and Google s competing chatbot Gemini  initially based on their LaMDA family of conversation trained language models  with plans to switch to PaLM              
Yet another kind of task that a GPT can be used for is the meta task of generating its own instructions  like developing a series of prompts for  itself  to be able to effectuate a more general goal given by a human user              This is known as an AI agent  and more specifically a recursive one because it uses results from its previous self instructions to help it form its subsequent prompts  the first major example of this was Auto GPT  which uses OpenAI s GPT models   and others have since been developed as well             

Multimodality edit 
Generative transformer based systems can also be targeted for tasks involving modalities beyond text  For example  Microsoft     s  Visual ChatGPT  combines ChatGPT with visual foundation models  VFMs  to enable input or output comprising images as well as text              Also  advances in text to speech technology offer tools for audio content creation when used in conjunction with foundational GPT language models             

Domain specificity edit 
GPT systems can be directed toward particular fields or domains  Some reported examples of such models and apps are as follows 

EinsteinGPT   for sales and marketing domains  to aid with customer relationship management  uses GPT                             
BloombergGPT   for the financial domain  to aid with financial news and information  uses  freely available  AI methods  combined with their proprietary data             
Khanmigo   described as a GPT version for tutoring  in the education domain  it aids students using Khan Academy by guiding them through their studies without directly providing answers  powered by GPT                           
SlackGPT   for the Slack instant messaging service  to aid with navigating and summarizing discussions on it  uses OpenAI s API             
BioGPT   for the biomedical domain  to aid with biomedical literature text generation and mining  uses GPT               
Sometimes domain specificity is accomplished via software plug ins or add ons  For example  several different companies have developed particular plugins that interact directly with OpenAI s ChatGPT interface                          and Google Workspace has available add ons such as  GPT for Sheets and Docs  which is reported to aid use of spreadsheet functionality in Google Sheets                         
In November       OpenAI announced that ChatGPT Plus subscribers would be able to create custom versions of ChatGPT  being called GPTs               These can be tailored for specific domains via prompt engineering  curated datasets  and or targeted interaction with external tools  Users who register as verified builders are able to publish their custom GPTs for other users  with monetization potential   This is notably distinct from OpenAI s API service  as this is based internally within OpenAI s platform  

Brand issues edit 
OpenAI  which created the first generative pre trained transformer  GPT  in       asserted in      that  GPT  should be regarded as a brand of OpenAI              In April       OpenAI revised the brand guidelines in its terms of service to indicate that other businesses using its API to run their artificial intelligence  AI  services would no longer be able to include  GPT  in such names or branding              In May       OpenAI engaged a brand management service to notify its API customers of this policy  although these notifications stopped short of making overt legal claims  such as allegations of trademark infringement or demands to cease and desist               As of November       OpenAI still prohibits its API licensees from naming their own products with  GPT               but it has begun enabling its ChatGPT Plus subscribers to make  custom versions of ChatGPT  that are being called GPTs on the OpenAI site              OpenAI s terms of service says that its subscribers may use  GPT  in the names of these  although it s  discouraged              
Relatedly  OpenAI has applied to the United States Patent and Trademark Office  USPTO  to seek domestic trademark registration for the term  GPT  in the field of AI              OpenAI sought to expedite handling of its application  but the USPTO declined that request in April                   In May       the USPTO responded to the application with a determination that  GPT  was both descriptive and generic              As of November       OpenAI continues to pursue its argument through the available processes  Regardless  failure to obtain a registered U S  trademark does not preclude some level of common law trademark rights in the U S               and or trademark rights in other countries             
For any given type or scope of trademark protection in the U S   OpenAI would need to establish that the term is actually  distinctive  to their specific offerings in addition to being a broader technical term for the kind of technology  Some media reports suggested that OpenAI may be able to obtain trademark registration based indirectly on the fame of its GPT based chatbot product  ChatGPT                          for which OpenAI has separately sought protection  and which it has sought to enforce more strongly               Other reports have indicated that registration for the bare term  GPT  seems unlikely to be granted                          as it is used frequently as a common term to refer simply to AI systems that involve generative pre trained transformers                                                 In any event  to whatever extent exclusive rights in the term may occur the U S   others would need to avoid using it for similar products or services in ways likely to cause confusion                          If such rights ever became broad enough to implicate other well established uses in the field  the trademark doctrine of descriptive fair use could still continue non brand related usage             

Selected bibliography edit 
This section lists the main official publications from OpenAI and Microsoft on their GPT models 

GPT    report             GitHub release             
GPT    blog announcement              report on its decision of  staged release               GitHub release             
GPT    report              No GitHub or any other form of code release thenceforth 
WebGPT  blog announcement              report             
InstructGPT  blog announcement              report             
ChatGPT  blog announcement  no report              
GPT    blog announcement               reports                            model card              
GPT  o  blog announcement              
GPT      blog announcement              
See also edit 
Cyc
Gemini
References edit 


  a b Haddad  Mohammed   How does GPT   work and how can you start using it in ChatGPT    www aljazeera com  Archived from the original on July          Retrieved April          

  a b  Generative AI  a game changer society needs to be ready for   World Economic Forum  January          Archived from the original on April           Retrieved April         

  a b c  The A to Z of Artificial Intelligence   Time  April           Archived from the original on June           Retrieved April          

  Hu  Luhui  November             Generative AI and Future   Medium  Archived from the original on June          Retrieved April          

   CSDL        IEEE Computer Society   www computer org  Archived from the original on April           Retrieved April          

   LibGuides  Using AI Language Models        ChatGPT   Archived from the original on December          Retrieved December         

  Toews  Rob   The Next Generation Of Large Language Models   Forbes  Archived from the original on April           Retrieved April         

  Mckendrick  Joe  March             Most Jobs Soon To Be  Influenced  By Artificial Intelligence  Research Out Of OpenAI And University Of Pennsylvania Suggests   Forbes  Archived from the original on April           Retrieved April          

  a b c d  Improving language understanding with unsupervised learning   openai com  June           Archived from the original on March           Retrieved March          

   GPT   to GPT    Each of OpenAI s GPT Models Explained and Compared   MUO  April           Archived from the original on April           Retrieved May         

   GPT     openai com  Archived from the original on March           Retrieved December         

  a b Alford  Anthony  July             EleutherAI Open Sources Six Billion Parameter GPT   Clone GPT J   InfoQ  Archived from the original on February           Retrieved April         

  a b  News   Press release   Archived from the original on April          Retrieved April         

  Morrison  Ryan  March            Salesforce launches EinsteinGPT built with OpenAI technology   Tech Monitor  Archived from the original on April           Retrieved April          

   The ChatGPT of Finance is Here  Bloomberg is Combining AI and Fintech   Forbes  Archived from the original on April          Retrieved April         

  Hinton  et al   Geoffrey  October             Deep neural networks for acoustic modeling in speech recognition   PDF   IEEE Signal Processing Magazine  Digital Object Identifier         MSP               doi         MSP               S CID                 Archived  PDF  from the original on March           Retrieved April          

  Deng  Li  January             A tutorial survey of architectures  algorithms  and applications for deep learning        APSIPA Transactions on Signal and Information Processing        Cambridge Core   Apsipa Transactions on Signal and Information Processing     Cambridge org  e   doi         atsip         S CID              

  Erhan  Dumitru  Courville  Aaron  Bengio  Yoshua  Vincent  Pascal  March             Why Does Unsupervised Pre training Help Deep Learning    Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics  JMLR Workshop and Conference Proceedings           Archived from the original on January           Retrieved January          

   First Hand The Hidden Markov Model   Engineering and Technology History Wiki   ethw org  January           Archived from the original on April          Retrieved May         

  Juang  B  H   Rabiner  L  R           Hidden Markov Models for Speech Recognition   Technometrics                   doi                  ISSN                 JSTOR               Archived from the original on October          Retrieved October         

  Cottrell  Garrison W   Munro  Paul  Zipser  David          Learning Internal Representation From Gray Scale Images  An Example of Extensional Programming   Proceedings of the Annual Meeting of the Cognitive Science Society     Archived from the original on October          Retrieved October         

  Cottrell  Garrison W   January           Touretzky  David S   Elman  Jeffrey L   Sejnowski  Terrence J   Hinton  Geoffrey E   eds     Extracting features from faces using compression networks  Face  identity  emotion  and gender recognition using holons   Connectionist Models  Morgan Kaufmann  pp                ISBN                         archived from the original on October          retrieved October        

  Schmidhuber  J rgen          Learning complex  extended sequences using the principle of history compression   PDF   Neural Computation                  doi         neco               S CID               

  Elman  Jeffrey L   Zipser  David  April            Learning the hidden structure of speech   The Journal of the Acoustical Society of America                     Bibcode     ASAJ          E  doi                   ISSN                 PMID               Archived from the original on October          Retrieved October         

  Bourlard  H   Kamp  Y           Auto association by multilayer perceptrons and singular value decomposition   Biological Cybernetics                     doi         BF          PMID               S CID                 Archived from the original on June           Retrieved October         

  Hinton  Geoffrey E  Zemel  Richard          Autoencoders  Minimum Description Length and Helmholtz Free Energy   Advances in Neural Information Processing Systems     Morgan Kaufmann  Archived from the original on August           Retrieved October         

  Vaswani  Ashish  Shazeer  Noam  Parmar  Niki  Uszkoreit  Jakob  Jones  Llion  Gomez  Aidan N  Kaiser   ukasz  Polosukhin  Illia          Attention is All you Need   PDF   Advances in Neural Information Processing Systems      Curran Associates  Inc  Archived  PDF  from the original on February           Retrieved January          

  Devlin  Jacob  Chang  Ming Wei  Lee  Kenton  Toutanova  Kristina  May             BERT  Pre training of Deep Bidirectional Transformers for Language Understanding   Association for Computational Linguistics  arXiv            

  a b c Radford  Alec  Narasimhan  Karthik  Salimans  Tim  Sutskever  Ilya  June             Improving Language Understanding by Generative Pre Training   PDF   OpenAI  p           Archived  PDF  from the original on January           Retrieved January          

  Radford  Alec  Jozefowicz  Rafal  Sutskever  Ilya  April            Learning to Generate Reviews and Discovering Sentiment   arXiv             cs LG  

  Chen  Mark  Tworek  Jerry  Jun  Heewoo  Yuan  Qiming  Ponde de Oliveira Pinto  Henrique  Kaplan  Jared  Edwards  Harri  Burda  Yuri  Joseph  Nicholas  Brockman  Greg  Ray  Alex  Puri  Raul  Krueger  Gretchen  Petrov  Michael  Khlaaf  Heidy  July            Evaluating Large Language Models Trained on Code   Association for Computational Linguistics  arXiv            

  Ouyang  Long  Wu  Jeffrey  Jiang  Xu  Almeida  Diogo  Wainwright  Carroll  Mishkin  Pamela  Zhang  Chong  Agarwal  Sandhini  Slama  Katarina  Ray  Alex  Schulman  John  Hilton  Jacob  Kelton  Fraser  Miller  Luke  Simens  Maddie  December            Training language models to follow instructions with human feedback   Advances in Neural Information Processing Systems                   arXiv             Archived from the original on June           Retrieved June          

   New GPT   capabilities  Edit  amp  insert   openai com  Archived from the original on June           Retrieved June          

  Fu  Yao  Peng  Hao  Khot  Tushar          How does GPT Obtain its Ability  Tracing Emergent Abilities of Language Models to their Sources   Yao Fu s Notion  Archived from the original on April           Retrieved June          

   Model index for researchers   OpenAI API  Archived from the original on June           Retrieved June          

   Introducing the Center for Research on Foundation Models  CRFM    Stanford HAI  August           Archived from the original on June          Retrieved April          

   Reflections on Foundation Models   hai stanford edu  October           Archived from the original on August           Retrieved August          

  a b OpenAI          GPT   Technical Report   PDF   Archived  PDF  from the original on March           Retrieved March          

  Zhu  Yukun  Kiros  Ryan  Zemel  Rich  Salakhutdinov  Ruslan  Urtasun  Raquel  Torralba  Antonio  Fidler  Sanja         Aligning Books and Movies  Towards Story Like Visual Explanations by Watching Movies and Reading Books  IEEE International Conference on Computer Vision  ICCV        pp              arXiv             Archived from the original on February          Retrieved February         

  Vincent  James  November            OpenAI has published the text generating AI it said was too dangerous to share   The Verge  Archived from the original on June           Retrieved April          

  a b c d Brown  Tom B   Mann  Benjamin  Ryder  Nick  Subbiah  Melanie  Kaplan  Jared  Dhariwal  Prafulla  Neelakantan  Arvind  Shyam  Pranav  Sastry  Girish  Askell  Amanda  Agarwal  Sandhini  Herbert Voss  Ariel  Krueger  Gretchen  Henighan  Tom  Child  Rewon  Ramesh  Aditya  Ziegler  Daniel M   Wu  Jeffrey  Winter  Clemens  Hesse  Christopher  Chen  Mark  Sigler  Eric  Litwin  Mateusz  Gray  Scott  Chess  Benjamin  Clark  Jack  Berner  Christopher  McCandlish  Sam  Radford  Alec  Sutskever  Ilya  Amodei  Dario  May             Language Models are Few Shot Learners   NeurIPS  arXiv           v  

  a b c  ML input trends visualization   Epoch  Archived from the original on July           Retrieved May         

  a b Ver Meer  Dave  June            ChatGPT Statistics   NamePepper  Archived from the original on June          Retrieved June         

   GPT   has more than a trillion parameters   Report   March           Archived from the original on March          Retrieved October          

  Vincent  James  March             Google opens up its AI language model PaLM to challenge OpenAI and GPT     The Verge  Archived from the original on March           Retrieved April          

   Google Opens Access to PaLM Language Model   Archived from the original on May           Retrieved April          

  Iyer  Aparna  November             Meet GPT JT  the Closest Open Source Alternative to GPT     Analytics India Magazine  Archived from the original on June          Retrieved April          

   Meta Debuts AI Language Model  But It s Only for Researchers   PCMAG  February           Archived from the original on July           Retrieved May          

  Islam  Arham  March             Multimodal Language Models  The Future of Artificial Intelligence  AI    Archived from the original on May           Retrieved May          

  Islam  Arham  November             How Do DALL E    Stable Diffusion  and Midjourney Work    Archived from the original on July           Retrieved May          

  Saha  Shritama  January            Google Launches Muse  A New Text to Image Transformer Model   Analytics India Magazine  Archived from the original on May           Retrieved May          

  Wu  et al   Chenfei  March            Visual ChatGPT   arXiv             cs CV  

  Bommasani  et al   Rishi  July             On the Opportunities and Risks of Foundation Models   arXiv             cs LG  

  a b  Aligning language models to follow instructions   openai com  Archived from the original on March           Retrieved March          

  a b Ouyang  Long  Wu  Jeff  Jiang  Xu  et      al   November            Training language models to follow instructions with human feedback   NeurIPS  arXiv            

  Ramnani  Meeta  January             OpenAI dumps its own GPT   for something called InstructGPT  and for right reason   Analytics India Magazine  Archived from the original on June          Retrieved April          

   Stanford CRFM   crfm stanford edu  Archived from the original on April          Retrieved May          

   Free Dolly  Introducing the World s First Truly Open Instruction Tuned LLM   Databricks  April           Archived from the original on July           Retrieved May          

  a b  Introducing ChatGPT   openai com  Archived from the original on March           Retrieved March          

  Wiggers  Kyle  May            Microsoft doubles down on AI with new Bing features   Archived from the original on December          Retrieved May         

   ChatGPT vs  Bing vs  Google Bard  Which AI Is the Most Helpful    CNET  Archived from the original on July           Retrieved April          

   Auto GPT  BabyAGI  and AgentGPT  How to use AI agents   Mashable  April           Archived from the original on July           Retrieved May          

  Marr  Bernard   Auto GPT May Be The Strong AI Tool That Surpasses ChatGPT   Forbes  Archived from the original on May           Retrieved May          

   Microsoft Open Sources Multimodal Chatbot Visual ChatGPT   InfoQ  Archived from the original on June          Retrieved May          

  Edwards  Benj  January            Microsoft s new AI can simulate anyone s voice with   seconds of audio   Ars Technica  Archived from the original on July           Retrieved May          

  Morrison  Ryan  March            Salesforce launches EinsteinGPT built with OpenAI technology   Archived from the original on April           Retrieved April          

  Sharma  Animesh K   Sharma  Rahul          The role of generative pretrained transformers  GPTs  in revolutionising digital marketing  A conceptual model   Journal of Cultural Marketing Strategy                doi          TLVQ     

  Leswing  Kif  April             Bloomberg plans to integrate GPT style A I  into its terminal   CNBC  Archived from the original on May           Retrieved May         

  Melendez  Steven  May            Learning nonprofit Khan Academy is piloting a version of GPT called Khanmigo   Fast Company  Archived from the original on May           Retrieved May          

   Khan Academy Pilots GPT   Powered Tool Khanmigo for Teachers   THE Journal  Archived from the original on May          Retrieved May         

  Hachman  Mark  May            Slack GPT will bring AI chatbots to your conversations   PCWorld  Archived from the original on June          Retrieved May         

  Luo  et al   Renqian  April            BioGPT  Generative pre trained transformer for biomedical text generation and mining   Briefings in Bioinformatics          arXiv             doi         bib bbac     PMID               

  John  Amy Sarah  May            Know about ChatGPT s    best plugins  designed to improve your overall user experience   Latest Digital Transformation Trends        Cloud News        Wire    Archived from the original on May          Retrieved May         

   ChatGPT plugins   openai com  March           Archived from the original on March           Retrieved May         

   How to Use ChatGPT on Google Sheets With GPT for Sheets and Docs   MUO  March           Archived from the original on June           Retrieved May         

  Asay  Matt  February             Embrace and extend Excel for AI data prep   InfoWorld  Archived from the original on June          Retrieved May         

   OpenAI GPTS   November           Archived from the original on December           Retrieved December          

  a b c d Hicks  William  May             ChatGPT creator OpenAI is asking startups to remove  GPT  from their names   The Business Journal  Archived from the original on June           Retrieved May          

  OpenAI  April             Brand Guidelines   Archived from the original on July           Retrieved May          

  a b  Brand guidelines   Archived from the original on July           Retrieved November          

   Introducing GPTS   March           Archived from the original on March           Retrieved November          

  a b Heah  Alexa  April             OpenAI Unsuccessful At Speeding Up Its Attempt To Trademark  GPT    DesignTAXI  Archived from the original on April           Retrieved May          

   NONFINAL OFFICE ACTION   USPTO  May           Archived from the original on December          Retrieved December          

   U S  Trademark Law   December       Archived from the original on January           Retrieved November          

   International Trademark Rights   Archived from the original on March           Retrieved November          

   OpenAI Wants to Trademark  GPT  Amid Rise of AI Chatbots   Tech Times  April           Archived from the original on April           Retrieved May          

  Louise  Nickie  April            OpenAI files a UDRP case against the current owner of ChatGPT com   Archived from the original on June          Retrieved May          

  a b Demcak  Tramatm Igor  April             OpenAI s Battle for Brand Protection  Can GPT be trademarked    Lexology  Archived from the original on May          Retrieved May          

  Lawton  George  April             ChatGPT vs  GPT  How are they different    TechTarget   Enterprise AI  Archived from the original on May          Retrieved May          

  Robb  Drew  April             GPT   vs  ChatGPT  AI Chatbot Comparison   eWEEK  Archived from the original on July           Retrieved May          

  Russo  Philip  August             The Genesis of Generative AI for Everything Everywhere All at Once in CRE   Commercial Observer  Archived from the original on August          

   Trademark infringement   Archived from the original on November           Retrieved November          

  Rheintgen  Husch Blackwell LLP Kathleen A   August             Branding      trademark descriptive fair use   Lexology  Archived from the original on May           Retrieved May          

  finetune transformer lm  OpenAI  June           archived from the original on May           retrieved May        

   GPT       B release   openai com  Archived from the original on March           Retrieved May         

  Solaiman  Irene  Brundage  Miles  Clark  Jack  Askell  Amanda  Herbert Voss  Ariel  Wu  Jeff  Radford  Alec  Krueger  Gretchen  Kim  Jong Wook  Kreps  Sarah  McCain  Miles  Newhouse  Alex  Blazakis  Jason  McGuffie  Kris  Wang  Jasmine  November             Release Strategies and the Social Impacts of Language Models   arXiv             cs CL  

  gpt    OpenAI  May          archived from the original on March           retrieved May        

   WebGPT  Improving the factual accuracy of language models through web browsing   openai com  Archived from the original on June           Retrieved July         

  Nakano  Reiichiro  Hilton  Jacob  Balaji  Suchir  Wu  Jeff  Ouyang  Long  Kim  Christina  Hesse  Christopher  Jain  Shantanu  Kosaraju  Vineet  Saunders  William  Jiang  Xu  Cobbe  Karl  Eloundou  Tyna  Krueger  Gretchen  Button  Kevin  December            WebGPT  Browser assisted question answering with human feedback   CoRR  arXiv             Archived from the original on July          Retrieved July         

   GPT     openai com  Archived from the original on March           Retrieved May         

  OpenAI  March             GPT   Technical Report   arXiv             cs CL  

  Bubeck  S bastien  Chandrasekaran  Varun  Eldan  Ronen  Gehrke  Johannes  Horvitz  Eric  Kamar  Ece  Lee  Peter  Lee  Yin Tat  Li  Yuanzhi  Lundberg  Scott  Nori  Harsha  Palangi  Hamid  Ribeiro  Marco Tulio  Zhang  Yi  April             Sparks of Artificial General Intelligence  Early experiments with GPT     arXiv             cs CL  

  GPT   System Card Archived April          at the Wayback Machine  OpenAI  March           Accessed May           

   Hello GPT  o   OpenAI  May           Archived from the original on May           Retrieved August         

   Introducing GPT       OpenAI  February           Archived from the original on March           Retrieved March          


vteOpenAIProductsChatbots
ChatGPT
in education
GPT Store
DALL E
ChatGPT Search
Sora
Whisper
GitHub Copilot
Foundationmodels
OpenAI Codex
Generative pre trained transformer
GPT  
GPT  
GPT  
GPT  
GPT  o
o 
o 
GPT    
GPT    
o 
Intelligentagents
ChatGPT Deep Research
Operator
PeopleSeniormanagementCurrent
Sam Altman
removal
Greg Brockman
Sarah Friar
Scott Schools
Former
Mira Murati
Emmett Shear
Board ofdirectorsCurrent
Sam Altman
Adam D Angelo
Sue Desmond Hellmann
Paul Nakasone
Adebayo Ogunlesi
Nicole Seligman
Fidji Simo
Lawrence Summers
Bret Taylor  chair 
Jakub Pachocki  chief scientist 
Former
Greg Brockman            
Reid Hoffman            
Will Hurd            
Holden Karnofsky            
Elon Musk            
Ilya Sutskever            
Helen Toner            
Shivon Zilis            
Joint ventures
Stargate LLC
Related
Apple Intelligence
AI Dungeon
AutoGPT
 Deep Learning 
LangChain
Microsoft Copilot
OpenAI Five
Transformer

 Category

vteArtificial intelligence  AI History  timeline Concepts
Parameter
Hyperparameter
Loss functions
Regression
Bias variance tradeoff
Double descent
Overfitting
Clustering
Gradient descent
SGD
Quasi Newton method
Conjugate gradient method
Backpropagation
Attention
Convolution
Normalization
Batchnorm
Activation
Softmax
Sigmoid
Rectifier
Gating
Weight initialization
Regularization
Datasets
Augmentation
Prompt engineering
Reinforcement learning
Q learning
SARSA
Imitation
Policy gradient
Diffusion
Latent diffusion model
Autoregression
Adversary
RAG
Uncanny valley
RLHF
Self supervised learning
Recursive self improvement
Word embedding
Hallucination
Applications
Machine learning
In context learning
Artificial neural network
Deep learning
Language model
Large language model
NMT
Artificial general intelligence  AGI 
ImplementationsAudio visual
AlexNet
WaveNet
Human image synthesis
HWR
OCR
Speech synthesis
   ai
ElevenLabs
Speech recognition
Whisper
Facial recognition
AlphaFold
Text to image models
Aurora
DALL E
Firefly
Flux
Ideogram
Imagen
Midjourney
Stable Diffusion
Text to video models
Dream Machine
Runway Gen
Hailuo AI
Kling
Sora
Veo
Music generation
Suno AI
Udio
Text
Word vec
Seq seq
GloVe
BERT
T 
Llama
Chinchilla AI
PaLM
GPT
 
 
 
J
ChatGPT
 
 o
o 
o 
   
   
o 
Claude
Gemini
chatbot
Grok
LaMDA
BLOOM
Project Debater
IBM Watson
IBM Watsonx
Granite
PanGu  
DeepSeek
Qwen
Decisional
AlphaGo
AlphaZero
OpenAI Five
Self driving car
MuZero
Action selection
AutoGPT
Robot control
People
Alan Turing
Warren Sturgis McCulloch
Walter Pitts
John von Neumann
Claude Shannon
Marvin Minsky
John McCarthy
Nathaniel Rochester
Allen Newell
Cliff Shaw
Herbert A  Simon
Oliver Selfridge
Frank Rosenblatt
Bernard Widrow
Joseph Weizenbaum
Seymour Papert
Seppo Linnainmaa
Paul Werbos
J rgen Schmidhuber
Yann LeCun
Geoffrey Hinton
John Hopfield
Yoshua Bengio
Lotfi A  Zadeh
Stephen Grossberg
Alex Graves
Andrew Ng
Fei Fei Li
Alex Krizhevsky
Ilya Sutskever
Demis Hassabis
David Silver
Ian Goodfellow
Andrej Karpathy
James Goodnight
Architectures
Neural Turing machine
Differentiable neural computer
Transformer
Vision transformer  ViT 
Recurrent neural network  RNN 
Long short term memory  LSTM 
Gated recurrent unit  GRU 
Echo state network
Multilayer perceptron  MLP 
Convolutional neural network  CNN 
Residual neural network  RNN 
Highway network
Mamba
Autoencoder
Variational autoencoder  VAE 
Generative adversarial network  GAN 
Graph neural network  GNN 

 Portals
Technology
 Category
Artificial neural networks
Machine learning
 List
Companies
Projects

vteGenerative AIConcepts
Autoencoder
Deep learning
Generative adversarial network
Generative pre trained transformer
Large language model
Neural network
Prompt engineering
Retrieval augmented generation
Reinforcement learning from human feedback
Self supervised learning
Transformer
Variational autoencoder
Vision transformer
Word embedding
ModelsText
Claude
DBRX
DeepSeek
ERNIE
Gemini
GPT
 
 
 
J
ChatGPT
 
 o
o 
o 
   
   
o 
Granite
Grok
Llama
Manus
Mistral Large
PanGu  
Qwen
Image
Aurora
DALL E
Firefly
Flux
GPT Image  
Ideogram
Imagen
Midjourney
Stable Diffusion
Speech
   ai
WaveNet
Video
Dream Machine
Gen  
Hailuo AI
Kling
Sora
Veo
VideoPoet
Music
Endel
Suno AI
Udio
Companies
   AI
Alibaba
Anthropic
Baichuan
Baidu
DeepSeek
ElevenLabs
Google DeepMind
Hugging Face
Kuaishou
Meta AI
MiniMax
Mistral AI
Moonshot AI
OpenAI
Runway
Stability AI
Synthesia
xAI
Zhipu AI

 Category
 Commons

vteNatural language processingGeneral terms
AI complete
Bag of words
n gram
Bigram
Trigram
Computational linguistics
Natural language understanding
Stop words
Text processing
Text analysis
Argument mining
Collocation extraction
Concept mining
Coreference resolution
Deep linguistic processing
Distant reading
Information extraction
Named entity recognition
Ontology learning
Parsing
Semantic parsing
Syntactic parsing
Part of speech tagging
Semantic analysis
Semantic role labeling
Semantic decomposition
Semantic similarity
Sentiment analysis
Terminology extraction
Text mining
Textual entailment
Truecasing
Word sense disambiguation
Word sense induction
Text segmentation
Compound term processing
Lemmatisation
Lexical analysis
Text chunking
Stemming
Sentence segmentation
Word segmentation

Automatic summarization
Multi document summarization
Sentence extraction
Text simplification
Machine translation
Computer assisted
Example based
Rule based
Statistical
Transfer based
Neural
Distributional semantics models
BERT
Document term matrix
Explicit semantic analysis
fastText
GloVe
Language model  large 
Latent semantic analysis
Seq seq
Word embedding
Word vec
Language resources datasets and corporaTypes andstandards
Corpus linguistics
Lexical resource
Linguistic Linked Open Data
Machine readable dictionary
Parallel text
PropBank
Semantic network
Simple Knowledge Organization System
Speech corpus
Text corpus
Thesaurus  information retrieval 
Treebank
Universal Dependencies
Data
BabelNet
Bank of English
DBpedia
FrameNet
Google Ngram Viewer
UBY
WordNet
Wikidata
Automatic identificationand data capture
Speech recognition
Speech segmentation
Speech synthesis
Natural language generation
Optical character recognition
Topic model
Document classification
Latent Dirichlet allocation
Pachinko allocation
Computer assistedreviewing
Automated essay scoring
Concordancer
Grammar checker
Predictive text
Pronunciation assessment
Spell checker
Natural languageuser interface
Chatbot
Interactive fiction  cf  Syntax guessing 
Question answering
Virtual assistant
Voice user interface
Related
Formal semantics
Hallucination
Natural Language Toolkit
spaCy

Portals  Computer programming TechnologyGenerative pre trained transformer at Wikipedia s sister projects Data from Wikidata





Retrieved from  https   en wikipedia org w index php title Generative pre trained transformer amp oldid