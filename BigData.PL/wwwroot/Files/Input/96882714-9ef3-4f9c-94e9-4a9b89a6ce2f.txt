Open letter about extinction risk from AI
On May           hundreds of artificial intelligence experts and other notable figures signed the following short Statement on AI Risk                                  Mitigating the risk of extinction from AI should be a global priority alongside other societal scale risks such as pandemics and nuclear war At release time  the signatories included over     professors of AI including the two most cited computer scientists and Turing laureates Geoffrey Hinton and Yoshua Bengio  as well as the scientific and executive leaders of several major AI companies  and experts in pandemics  climate  nuclear disarmament  philosophy  social sciences  and other fields                                   Media coverage has emphasized the signatures from several tech leaders             this was followed by concerns in other newspapers that the statement could be motivated by public relations or regulatory capture             The statement was released shortly after an open letter calling for a pause on AI experiments 
The statement is hosted on the website of the AI research and advocacy non profit Center for AI Safety  It was released with an accompanying text which states that it is still difficult to speak up about extreme risks of AI and that the statement aims to overcome this obstacle             The center s CEO Dan Hendrycks stated that  systemic bias  misinformation  malicious use  cyberattacks  and weaponization  are all examples of  important and urgent risks from AI    not just the risk of extinction  and added    s ocieties can manage multiple risks at once  it s not  either or  but  yes and                         
Among the well known signatories are  Sam Altman  Bill Gates  Peter Singer  Daniel Dennett  Sam Harris  Grimes  Stuart J  Russell  Jaan Tallinn  Vitalik Buterin  David Chalmers  Ray Kurzweil  Max Tegmark  Lex Fridman  Martin Rees  Demis Hassabis  Dawn Song  Ted Lieu  Ilya Sutskever  Martin Hellman  Bill McKibben  Angela Kane  Audrey Tang  David Silver  Andrew Barto  Mira Murati  Pattie Maes  Eric Horvitz  Peter Norvig  Joseph Sifakis  Erik Brynjolfsson  Ian Goodfellow  Baburam Bhattarai  Kersti Kaljulaid  Rusty Schweickart  Nicholas Fairfax  David Haussler  Peter Railton  Bart Selman  Dustin Moskovitz  Scott Aaronson  Bruce Schneier  Martha Minow  Andrew Revkin  Rob Pike  Jacob Tsimerman  Ramy Youssef  James Pennebaker and Ronald C  Arkin            

Reception edit 
The Prime Minister of the United Kingdom  Rishi Sunak  retweeted the statement and wrote   The government is looking very carefully at this              When asked about the statement  the White House Press Secretary  Karine Jean Pierre  commented that AI  is one of the most powerful technologies that we see currently in our time  But in order to seize the opportunities it presents  we must first mitigate its risks             
Skeptics of the letter point out that AI has failed to reach certain milestones  such as predictions around self driving cars             Skeptics also argue that signatories of the letter were continuing funding of AI research             Companies would benefit from public perception that AI algorithms were far more advanced than currently possible             Skeptics  including from Human Rights Watch  have argued that scientists should focus on the known risks of AI instead of distracting with speculative future risks                         Timnit Gebru has criticized elevating the risk of AI agency  especially by the  same people who have poured billions of dollars into these companies                mile P  Torres and Gebru both argue against the statement  suggesting it may be motivated by TESCREAL ideologies             

See also edit 
AI alignment
Existential risk from artificial general intelligence
Pause Giant AI Experiments  An Open Letter
References edit 

  a b c  Statement on AI Risk   Center for AI Safety  May          

  a b c Roose  Kevin                A I  Poses  Risk of Extinction   Industry Leaders Warn   The New York Times  ISSN                 Retrieved            

  a b c d Gregg  Aaron  Lima Strong  Cristiano  Vynck  Gerrit De                AI poses  risk of extinction  on par with nukes  tech leaders say   Washington Post  ISSN                 Retrieved            

  a b c Vincent  James                Top AI researchers and CEOs warn against  risk of extinction  in    word statement   The Verge  Retrieved            

  Wong  Matteo                AI Doomerism Is a Decoy   The Atlantic  Retrieved            

  Lomas  Natasha                OpenAI s Altman and other AI giants back warning of advanced AI as  extinction  risk   TechCrunch  Retrieved            

   Statement on AI Risk   CAIS   www safe ai  Retrieved            

   Artificial intelligence warning over human extinction   all you need to know   The Independent              Retrieved            

   President Biden warns artificial intelligence could  overtake human thinking    USA TODAY  Retrieved            

  a b Ryan Mosley  Tate     June         It s time to talk about the real AI risks   MIT Technology Review  Retrieved            

  Torres   mile P                 AI and the threat of  human extinction   What are the tech bros worried about  It s not you and me   Salon  Retrieved            


vteExistential risk from artificial intelligenceConcepts
AGI
AI alignment
AI capability control
AI safety
AI takeover
Consequentialism
Effective accelerationism
Ethics of artificial intelligence
Existential risk from artificial intelligence
Friendly artificial intelligence
Instrumental convergence
Vulnerable world hypothesis
Intelligence explosion
Longtermism
Machine ethics
Suffering risks
Superintelligence
Technological singularity
Organizations
Alignment Research Center
Center for AI Safety
Center for Applied Rationality
Center for Human Compatible Artificial Intelligence
Centre for the Study of Existential Risk
EleutherAI
Future of Humanity Institute
Future of Life Institute
Google DeepMind
Humanity 
Institute for Ethics and Emerging Technologies
Leverhulme Centre for the Future of Intelligence
Machine Intelligence Research Institute
OpenAI
People
Scott Alexander
Sam Altman
Yoshua Bengio
Nick Bostrom
Paul Christiano
Eric Drexler
Sam Harris
Stephen Hawking
Dan Hendrycks
Geoffrey Hinton
Bill Joy
Shane Legg
Elon Musk
Steve Omohundro
Huw Price
Martin Rees
Stuart J  Russell
Jaan Tallinn
Max Tegmark
Frank Wilczek
Roman Yampolskiy
Eliezer Yudkowsky
Other
Statement on AI risk of extinction
Human Compatible
Open letter on artificial intelligence       
Our Final Invention
The Precipice
Superintelligence  Paths  Dangers  Strategies
Do You Trust This Computer 
Artificial Intelligence Act
 Category





Retrieved from  https   en wikipedia org w index php title Statement on AI risk of extinction amp oldid