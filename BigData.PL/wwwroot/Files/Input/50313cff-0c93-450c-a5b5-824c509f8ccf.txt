Mathematical relation assigning a probability event to a cost
In mathematical optimization and decision theory  a loss function or cost function  sometimes also called an error function             is a function that maps an event or values of one or more variables onto a real number intuitively representing some  cost  associated with the event  An optimization problem seeks to minimize a loss function  An objective function is either a loss function or its opposite  in specific domains  variously called a reward function  a profit function  a utility function  a fitness function  etc    in which case it is to be maximized  The loss function could include terms from several levels of the hierarchy 
In statistics  typically a  loss function is used for parameter estimation  and the event in question is some function of the difference between estimated and true values for an instance of data  The concept  as old as Laplace  was reintroduced in statistics by Abraham Wald in the middle of the   th century              In the context of economics  for example  this is usually economic cost or regret   In classification  it is the penalty for an incorrect classification of an example  In actuarial science  it is used in an insurance context to model benefits paid over premiums  particularly since the works of Harald Cram r in the     s             In optimal control  the loss is the penalty for failing to achieve a desired value  In financial risk management  the function is mapped to a monetary loss 

Comparison of common loss functions  MAE  SMAE  Huber loss  and Log Cosh Loss   used for regression

Examples edit 
Regret edit 
Main article  Regret  decision theory 
Leonard J  Savage argued that using non Bayesian methods such as minimax  the loss function should be based on the idea of regret  i e   the loss associated with a decision should be the difference between the consequences of the best decision that could have been made under circumstances will be known and the decision that was in fact taken before they were known 

Quadratic loss function edit 
The use of a quadratic loss function is common  for example when using least squares techniques  It is often more mathematically tractable than other loss functions because of the properties of variances  as well as being symmetric  an error above the target causes the same loss as the same magnitude of error below the target   If the target is t  then a quadratic loss function is


  
    
      
          x bb 
         
        x
         
         
        C
         
        t
          x     
        x
        
           
          
             
          
        
        
      
    
      displaystyle  lambda  x  C t x        
  

for some constant C  the value of the constant makes no difference to a decision  and can be ignored by setting it equal to    This is also known as the squared error loss  SEL             
Many common statistics  including t tests  regression models  design of experiments  and much else  use least squares methods applied using linear regression theory  which is based on the quadratic loss function 
The quadratic loss function is also used in linear quadratic optimal control problems  In these problems  even in the absence of uncertainty  it may not be possible to achieve the desired values of all target variables  Often loss is expressed as a quadratic form in the deviations of the variables of interest from their desired values  this approach is tractable because it results in linear first order conditions  In the context of stochastic control  the expected value of the quadratic form is used  The quadratic loss assigns more importance to outliers than to the true data due to its square nature  so alternatives like the Huber  Log Cosh and SMAE losses are used when the data has many large outliers 

Effect of using different loss functions  when the data has outliers
    loss function edit 
In statistics and decision theory  a frequently used loss function is the     loss function


  
    
      
        L
         
        
          
            
              y
                x e 
            
          
        
         
        y
         
         
        
           
          
            
              
                
                  y
                    x e 
                
              
            
              x     
            y
          
           
        
      
    
      displaystyle L   hat  y   y   left   hat  y   neq y right  
  

using Iverson bracket notation  i e  it evaluates to   when 
  
    
      
        
          
            
              y
                x e 
            
          
        
          x     
        y
      
    
      displaystyle   hat  y   neq y 
  
  and   otherwise 

Constructing loss and objective functions edit 
See also  Scoring rule
In many applications  objective functions  including loss functions as a particular case  are determined by the problem formulation   In other situations  the decision maker s preference must be elicited and represented by a scalar valued function  called also  utility function  in a form  suitable for optimization   the problem that Ragnar Frisch has highlighted in his Nobel Prize lecture            
The existing methods for constructing objective functions are collected in the proceedings of two dedicated conferences                       
In particular  Andranik Tangian showed that the most usable objective functions   quadratic and additive   are determined by a few indifference points  He used this property in the models for constructing these objective functions from either ordinal or cardinal data that were elicited through computer assisted interviews with decision makers                        
Among other things  he constructed  objective functions to optimally distribute budgets for    Westfalian universities           
and the European subsidies for equalizing unemployment rates among     German regions             

Expected loss edit 
See also  Empirical risk minimization
In some contexts  the value of the loss function itself is a random quantity because it depends on the outcome of a random variable X  

Statistics edit 
Both frequentist and Bayesian statistical theory involve making a decision based on the expected value of the loss function  however  this quantity is defined differently under the two paradigms 

Frequentist expected loss edit 
We first define the expected loss in the frequentist context  It is obtained by taking the expected value with respect to the probability distribution  P   of the observed data  X  This is also referred to as the risk function                                                 of the decision rule   and the parameter    Here the decision rule depends on the outcome of X  The risk function is given by 


  
    
      
        R
         
          x b  
         
          x b  
         
         
        
          E
          
              x b  
          
        
          x     
        L
        
          
             
          
        
          x b  
         
          x b  
         
        X
         
        
          
             
          
        
         
        
            x   b 
          
            X
          
        
        L
        
          
             
          
        
          x b  
         
          x b  
         
        x
         
        
          
             
          
        
        
        
          d
        
        
          P
          
              x b  
          
        
         
        x
         
         
      
    
      displaystyle R  theta   delta    operatorname  E     theta  L  big    theta   delta  X   big     int   X L  big    theta   delta  x   big      mathrm  d  P   theta   x   
  

Here    is a fixed but possibly unknown state of nature  X is a vector of observations stochastically drawn from a population  
  
    
      
        
          E
          
              x b  
          
        
      
    
      displaystyle  operatorname  E     theta   
  
 is the expectation over all population values of X  dP  is a probability measure over the event space of X  parametrized by         and the integral is evaluated over the entire support of      X 

Bayes Risk edit 
In a Bayesian approach  the expectation is calculated using the prior distribution    of the parameter        


  
    
      
          x c  
         
        
            x c  
          
              x     
          
        
         
        a
         
         
        
            x   b 
          
              x    
          
        
        
            x   b 
          
            
              X
            
          
        
        L
         
          x b  
         
        a
         
        
          
            x
          
        
         
         
        
        
          d
        
        P
         
        
          
            x
          
        
         
          x b  
         
        
        
          d
        
        
            x c  
          
              x     
          
        
         
          x b  
         
         
        
            x   b 
          
            
              X
            
          
        
        
            x   b 
          
              x    
          
        
        L
         
          x b  
         
        a
         
        
          
            x
          
        
         
         
        
        
          d
        
        
            x c  
          
              x     
          
        
         
          x b  
         
        
          
            x
          
        
         
        
        
          d
        
        M
         
        
          
            x
          
        
         
      
    
      displaystyle  rho   pi      a   int    Theta   int    mathbf  X  L  theta  a   mathbf  x       mathrm  d  P   mathbf  x   vert  theta     mathrm  d   pi       theta    int    mathbf  X   int    Theta  L  theta  a   mathbf  x       mathrm  d   pi       theta  vert   mathbf  x      mathrm  d  M   mathbf  x    
  

where m x  is known as the predictive likelihood wherein   has been  integrated out           x  is the posterior distribution  and the order of integration has been changed  One then should choose the action a  which minimises this expected loss  which is referred to as Bayes Risk   
In the latter equation  the integrand inside dx is known as the Posterior Risk  and minimising it with respect to decision a also minimizes the overall Bayes Risk  This optimal decision  a  is known as the Bayes  decision  Rule   it minimises the average loss over all possible states of nature    over all possible  probability weighted  data outcomes  One advantage of the Bayesian approach is to that one need only choose the optimal action under the actual observed data to obtain a uniformly optimal one  whereas choosing the actual frequentist optimal decision rule as a function of all possible observations  is a much more difficult problem   Of equal importance though  the Bayes Rule reflects consideration of loss outcomes under different states of nature    

Examples in statistics edit 
For a scalar parameter    a decision function whose output 
  
    
      
        
          
            
                x b  
                x e 
            
          
        
      
    
      displaystyle   hat   theta    
  
 is an estimate of         and a quadratic loss function  squared error loss  
  
    
      
        L
         
          x b  
         
        
          
            
                x b  
                x e 
            
          
        
         
         
         
          x b  
          x     
        
          
            
                x b  
                x e 
            
          
        
        
           
          
             
          
        
         
      
    
      displaystyle L  theta    hat   theta       theta    hat   theta          
  
 the risk function becomes the mean squared error of the estimate  
  
    
      
        R
         
          x b  
         
        
          
            
                x b  
                x e 
            
          
        
         
         
        
          E
          
              x b  
          
        
          x     
        
           
          
             
              x b  
              x     
            
              
                
                    x b  
                    x e 
                
              
            
            
               
              
                 
              
            
          
           
        
         
      
    
      displaystyle R  theta    hat   theta      operatorname  E     theta   left   theta    hat   theta         right   
  
An Estimator found by minimizing the Mean squared error estimates the Posterior distribution s mean 
In density estimation  the unknown parameter is probability density itself  The loss function is typically chosen to be a norm in an appropriate function space  For example  for L  norm  
  
    
      
        L
         
        f
         
        
          
            
              f
                x e 
            
          
        
         
         
          x     
        f
          x     
        
          
            
              f
                x e 
            
          
        
        
            x     
          
             
          
          
             
          
        
        
         
      
    
      displaystyle L f   hat  f      f   hat  f                
  
 the risk function becomes the mean integrated squared error 
  
    
      
        R
         
        f
         
        
          
            
              f
                x e 
            
          
        
         
         
        E
          x     
        
           
          
              x     
            f
              x     
            
              
                
                  f
                    x e 
                
              
            
            
                x     
              
                 
              
            
          
           
        
         
        
      
    
      displaystyle R f   hat  f     operatorname  E   left   f   hat  f         right     
  

Economic choice under uncertainty edit 
In economics  decision making under uncertainty is often modelled using the von Neumann Morgenstern utility function of the uncertain variable of interest  such as end of period wealth  Since the value of this variable is uncertain  so is the value of the utility function  it is the expected value of utility that is maximized 

Decision rules edit 
A decision rule makes a choice using an optimality criterion  Some commonly used criteria are 

Minimax  Choose the decision rule with the lowest worst loss   that is  minimize the worst case  maximum possible  loss  
  
    
      
        
          
            
              a
              r
              g
              
              m
              i
              n
            
              x b  
          
        
          xa  
        
          max
          
              x b  
              x     
              x    
          
        
          xa  
        R
         
          x b  
         
          x b  
         
         
      
    
      displaystyle   underset   delta    operatorname  arg  min       max    theta  in  Theta    R  theta   delta    
  

Invariance  Choose the decision rule which satisfies an invariance requirement 
Choose the decision rule with the lowest average loss  i e  minimize the expected value of the loss function   
  
    
      
        
          
            
              a
              r
              g
              
              m
              i
              n
            
              x b  
          
        
        
          E
          
              x b  
              x     
              x    
          
        
          x     
         
        R
         
          x b  
         
          x b  
         
         
         
        
          
            
              a
              r
              g
              
              m
              i
              n
            
              x b  
          
        
          xa  
        
            x   b 
          
              x b  
              x     
              x    
          
        
        R
         
          x b  
         
          x b  
         
        
        p
         
          x b  
         
        
        d
          x b  
         
      
    
      displaystyle   underset   delta    operatorname  arg  min     operatorname  E     theta  in  Theta   R  theta   delta      underset   delta    operatorname  arg  min       int    theta  in  Theta  R  theta   delta    p  theta    d theta   
  

Selecting a loss function edit 
Sound statistical practice requires selecting an estimator consistent with the actual acceptable variation experienced in the context of a particular applied problem  Thus  in the applied use of loss functions  selecting which statistical method to use to model an applied problem depends on knowing the losses that will be experienced from being wrong under the problem s particular circumstances             
A common example involves estimating  location   Under typical statistical assumptions  the mean or average is the statistic for estimating location that minimizes the expected loss experienced under the squared error loss function  while the median is the estimator that minimizes expected loss experienced under the absolute difference loss function  Still different estimators would be optimal under other  less common circumstances 
In economics  when an agent is risk neutral  the objective function is simply expressed as the expected value of a monetary quantity  such as profit  income  or end of period wealth  For risk averse or risk loving agents  loss is measured as the negative of a utility function  and the objective function to be optimized is the expected value of utility 
Other measures of cost are possible  for example mortality or morbidity in the field of public health or safety engineering 
For most optimization algorithms  it is desirable to have a loss function that is globally continuous and differentiable 
Two very commonly used loss functions are the squared loss  
  
    
      
        L
         
        a
         
         
        
          a
          
             
          
        
      
    
      displaystyle L a  a     
  
  and the absolute loss  
  
    
      
        L
         
        a
         
         
        
           
        
        a
        
           
        
      
    
      displaystyle L a   a  
  
   However the absolute loss has the disadvantage that it is not differentiable at 
  
    
      
        a
         
         
      
    
      displaystyle a   
  
   The squared loss has the disadvantage that it has the tendency to be dominated by outliers when summing over a set of 
  
    
      
        a
      
    
      displaystyle a 
  
 s  as in 
  
    
      
        
            x     
          
            i
             
             
          
          
            n
          
        
        L
         
        
          a
          
            i
          
        
         
      
    
      textstyle  sum   i     n L a  i   
  
   the final sum tends to be the result of a few particularly large a values  rather than an expression of the average a value 
The choice of a loss function is not arbitrary  It is very restrictive and sometimes the loss function may be characterized by its desirable properties              Among  the choice principles are  for example  the requirement of completeness of the class of symmetric statistics in the case of i i d  observations  the principle of complete information  and some others 
W  Edwards Deming and Nassim Nicholas Taleb argue that empirical reality  not nice mathematical properties  should be the sole basis for selecting loss functions  and real losses often are not mathematically nice and are not differentiable  continuous  symmetric  etc  For example  a person who arrives before a plane gate closure can still make the plane  but a person who arrives after can not  a discontinuity and asymmetry which makes arriving slightly late much more costly than arriving slightly early  In drug dosing  the cost of too little drug may be lack of efficacy  while the cost of too much may be tolerable toxicity  another example of asymmetry  Traffic  pipes  beams  ecologies  climates  etc  may tolerate increased load or stress with little noticeable change up to a point  then become backed up or break catastrophically  These situations  Deming and Taleb argue  are common in real life problems  perhaps more common than classical smooth  continuous  symmetric  differentials cases             

See also edit 
Bayesian regret
Loss functions for classification
Discounted maximum loss
Hinge loss
Scoring rule
Statistical risk
References edit 


  a b Hastie  Trevor  Tibshirani  Robert  Friedman  Jerome H          The Elements of Statistical Learning  Springer  p           ISBN                    

  Wald  A           Statistical Decision Functions   Apa Psycnet  Wiley 

  Cram r  H          On the mathematical theory of risk  Centraltryckeriet 

  Frisch  Ragnar          From utopian theory to practical applications  the case of econometrics   The Nobel Prize Prize Lecture  Retrieved    February      

  Tangian  Andranik  Gruber  Josef         Constructing Scalar Valued Objective Functions  Proceedings of the Third International Conference on Econometric Decision Models  Constructing Scalar Valued Objective Functions  University of Hagen  held in Katholische Akademie Schwerte September            Lecture Notes in Economics and Mathematical Systems  Vol            Berlin  Springer  doi                            ISBN                        

  Tangian  Andranik  Gruber  Josef         Constructing and Applying Objective Functions  Proceedings of the Fourth International Conference on Econometric Decision Models Constructing and Applying Objective Functions  University of Hagen  held in Haus Nordhelle  August                 Lecture Notes in Economics and Mathematical Systems  Vol            Berlin  Springer  doi                            ISBN                        

  Tangian  Andranik          Constructing a quasi concave quadratic objective function from interviewing a decision maker   European Journal of Operational Research                    doi         S                      S CID               

  Tangian  Andranik          A model for ordinally constructing additive objective functions   European Journal of Operational Research                    doi         S                      S CID               

  Tangian  Andranik          Redistribution of university budgets with respect to the status quo   European Journal of Operational Research                    doi         S                     

  Tangian  Andranik          Multi criteria optimization of regional employment policy  A simulation analysis for Germany   Review of Urban and Regional Development                   doi         j         X            x 

  Nikulin  M S                  Risk of a statistical procedure   Encyclopedia of Mathematics  EMS Press

  
Berger  James O          Statistical decision theory and Bayesian Analysis   nd      ed    New York  Springer Verlag  Bibcode     sdtb book     B  ISBN                         MR              

  DeGroot  Morris                Optimal Statistical Decisions  Wiley Classics Library  ISBN                         MR              

  Robert  Christian P          The Bayesian Choice  Springer Texts in Statistics   nd      ed    New York  Springer  doi                        ISBN                         MR              

  Pfanzagl  J          Parametric Statistical Theory  Berlin  Walter de Gruyter  ISBN                        

  Detailed information on mathematical principles of the loss function choice is given in Chapter   of the book Klebanov  B   Rachev  Svetlozat T   Fabozzi  Frank J          Robust and Non Robust Models in Statistics  New York  Nova Scientific Publishers  Inc   and references there  

  Deming  W  Edwards         Out of the Crisis  The MIT Press  ISBN                    


Further reading edit 
Aretz  Kevin  Bartram  S hnke M   Pope  Peter F   April June         Asymmetric Loss Functions and the Rationality of Expected Stock Returns   PDF   International Journal of Forecasting                   doi         j ijforecast              SSRN             
Berger  James O          Statistical decision theory and Bayesian Analysis   nd      ed    New York  Springer Verlag  Bibcode     sdtb book     B  ISBN                         MR              
Cecchetti  S           Making monetary policy  Objectives and rules   Oxford Review of Economic Policy                 doi         oxrep         
Horowitz  Ann R           Loss functions and public policy   Journal of Macroeconomics                  doi                              
Waud  Roger N           Asymmetric Policymaker Utility Functions and Optimal Policy under Uncertainty   Econometrica                 doi                  JSTOR              
vteStatistics
Outline
Index
Descriptive statisticsContinuous dataCenter
Mean
Arithmetic
Arithmetic Geometric
Contraharmonic
Cubic
Generalized power
Geometric
Harmonic
Heronian
Heinz
Lehmer
Median
Mode
Dispersion
Average absolute deviation
Coefficient of variation
Interquartile range
Percentile
Range
Standard deviation
Variance
Shape
Central limit theorem
Moments
Kurtosis
L moments
Skewness
Count data
Index of dispersion
Summary tables
Contingency table
Frequency distribution
Grouped data
Dependence
Partial correlation
Pearson product moment correlation
Rank correlation
Kendall s  
Spearman s  
Scatter plot
Graphics
Bar chart
Biplot
Box plot
Control chart
Correlogram
Fan chart
Forest plot
Histogram
Pie chart
Q Q plot
Radar chart
Run chart
Scatter plot
Stem and leaf display
Violin plot
Data collectionStudy design
Effect size
Missing data
Optimal design
Population
Replication
Sample size determination
Statistic
Statistical power
Survey methodology
Sampling
Cluster
Stratified
Opinion poll
Questionnaire
Standard error
Controlled experiments
Blocking
Factorial experiment
Interaction
Random assignment
Randomized controlled trial
Randomized experiment
Scientific control
Adaptive designs
Adaptive clinical trial
Stochastic approximation
Up and down designs
Observational studies
Cohort study
Cross sectional study
Natural experiment
Quasi experiment
Statistical inferenceStatistical theory
Population
Statistic
Probability distribution
Sampling distribution
Order statistic
Empirical distribution
Density estimation
Statistical model
Model specification
Lp space
Parameter
location
scale
shape
Parametric family
Likelihood       monotone 
Location scale family
Exponential family
Completeness
Sufficiency
Statistical functional
Bootstrap
U
V
Optimal decision
loss function
Efficiency
Statistical distance
divergence
Asymptotics
Robustness
Frequentist inferencePoint estimation
Estimating equations
Maximum likelihood
Method of moments
M estimator
Minimum distance
Unbiased estimators
Mean unbiased minimum variance
Rao Blackwellization
Lehmann Scheff  theorem
Median unbiased
Plug in
Interval estimation
Confidence interval
Pivot
Likelihood interval
Prediction interval
Tolerance interval
Resampling
Bootstrap
Jackknife
Testing hypotheses
    amp    tails
Power
Uniformly most powerful test
Permutation test
Randomization test
Multiple comparisons
Parametric tests
Likelihood ratio
Score Lagrange multiplier
Wald
Specific tests
Z test  normal 
Student s t test
F test
Goodness of fit
Chi squared
G test
Kolmogorov Smirnov
Anderson Darling
Lilliefors
Jarque Bera
Normality  Shapiro Wilk 
Likelihood ratio test
Model selection
Cross validation
AIC
BIC
Rank statistics
Sign
Sample median
Signed rank  Wilcoxon 
Hodges Lehmann estimator
Rank sum  Mann Whitney 
Nonparametric anova
  way  Kruskal Wallis 
  way  Friedman 
Ordered alternative  Jonckheere Terpstra 
Van der Waerden test
Bayesian inference
Bayesian probability
prior
posterior
Credible interval
Bayes factor
Bayesian estimator
Maximum posterior estimator
CorrelationRegression analysisCorrelation
Pearson product moment
Partial correlation
Confounding variable
Coefficient of determination
Regression analysis
Errors and residuals
Regression validation
Mixed effects models
Simultaneous equations models
Multivariate adaptive regression splines  MARS 
Linear regression
Simple linear regression
Ordinary least squares
General linear model
Bayesian regression
Non standard predictors
Nonlinear regression
Nonparametric
Semiparametric
Isotonic
Robust
Homoscedasticity and Heteroscedasticity
Generalized linear model
Exponential families
Logistic  Bernoulli             Binomial            Poisson regressions
Partition of variance
Analysis of variance  ANOVA  anova 
Analysis of covariance
Multivariate ANOVA
Degrees of freedom
Categorical            Multivariate            Time series            Survival analysisCategorical
Cohen s kappa
Contingency table
Graphical model
Log linear model
McNemar s test
Cochran Mantel Haenszel statistics
Multivariate
Regression
Manova
Principal components
Canonical correlation
Discriminant analysis
Cluster analysis
Classification
Structural equation model
Factor analysis
Multivariate distributions
Elliptical distributions
Normal
Time seriesGeneral
Decomposition
Trend
Stationarity
Seasonal adjustment
Exponential smoothing
Cointegration
Structural break
Granger causality
Specific tests
Dickey Fuller
Johansen
Q statistic  Ljung Box 
Durbin Watson
Breusch Godfrey
Time domain
Autocorrelation  ACF 
partial  PACF 
Cross correlation  XCF 
ARMA model
ARIMA model  Box Jenkins 
Autoregressive conditional heteroskedasticity  ARCH 
Vector autoregression  VAR 
Frequency domain
Spectral density estimation
Fourier analysis
Least squares spectral analysis
Wavelet
Whittle likelihood
SurvivalSurvival function
Kaplan Meier estimator  product limit 
Proportional hazards models
Accelerated failure time  AFT  model
First hitting time
Hazard function
Nelson Aalen estimator
Test
Log rank test
ApplicationsBiostatistics
Bioinformatics
Clinical trials            studies
Epidemiology
Medical statistics
Engineering statistics
Chemometrics
Methods engineering
Probabilistic design
Process            quality control
Reliability
System identification
Social statistics
Actuarial science
Census
Crime statistics
Demography
Econometrics
Jurimetrics
National accounts
Official statistics
Population statistics
Psychometrics
Spatial statistics
Cartography
Environmental statistics
Geographic information system
Geostatistics
Kriging

Category
 Mathematics     portal
Commons
 WikiProject

vteDifferentiable computingGeneral
Differentiable programming
Information geometry
Statistical manifold
Automatic differentiation
Neuromorphic computing
Pattern recognition
Ricci calculus
Computational learning theory
Inductive bias
Hardware
IPU
TPU
VPU
Memristor
SpiNNaker
Software libraries
TensorFlow
PyTorch
Keras
scikit learn
Theano
JAX
Flux jl
MindSpore

 Portals
Computer programming
Technology






Retrieved from  https   en wikipedia org w index php title Loss function amp oldid