Rules and policies
  
    
  
          
            
    Community Guidelines
  
          
        
        
          





    

        
      
    
  


  
    
      



        
                
                  
                    Community Guidelines
                  
                
                
                  
                    Developing Community Guidelines
                  
                
                
                  
                    Enforcing Community Guidelines
                  
                  
                          
                            
                              Detecting violations
                            
                          
                          
                            
                              Allowing EDSA content
                            
                          
                          
                            
                              Taking action on violations
                            
                          
                  
                
        
      


      

              
                Overview
YouTube has always had a set of Community Guidelines that outline what type of content isn t allowed on YouTube  These policies apply to all types of content on our platform  including videos  comments  links  and thumbnails  Our Community Guidelines are a key part of our broader suite of policies and are regularly updated in consultation with outside experts and YouTube creators to keep pace with emerging challenges 
We enforce these Community Guidelines using a combination of human reviewers and machine learning  and apply them to everyone equally regardless of the subject or the creator s background  political viewpoint  position  or affiliation  
Our policies aim to make YouTube a safer community while still giving creators the freedom to share a broad range of experiences and perspectives 
What areas do Community Guidelines cover 
You ll find a full list of our Community Guidelines below 
     Spam  amp  deceptive practices       Fake engagement        Impersonation        External links        Spam  deceptive practices  amp  scams        Playlists        Additional policies          Sensitive content       Child safety        Thumbnails        Nudity and sexual content        Suicide and self harm        Vulgar language        
     Violent or dangerous content       Harassment and cyberbullying        Harmful or dangerous content        Hate speech        Violent criminal organizations        Violent or graphic content          Regulated goods       Firearms        Sale of illegal or regulated goods or services        
     Misinformation       Misinformation        Elections misinformation        Medical misinformation          Educational  Documentary  Scientific  and Artistic  EDSA  content       How YouTube evaluates Educational  Documentary  Scientific  and Artistic  EDSA  content        
In addition to Community Guidelines  creators who want to monetize content on YouTube must comply with Monetization Policies 
              
              
                How does YouTube develop new policies and update existing ones 
Each of our policies is carefully thought through so they are consistent  well informed  and can be applied to content from around the world  They re developed in consultation with a wide range of external industry and policy experts  as well as YouTube Creators  New policies go through multiple rounds of testing before they go live to ensure our global team of content reviewers can apply them accurately and consistently 
This work is never finished  and we are always evaluating our policies to understand how we can better strike a balance between keeping the YouTube community protected and giving everyone a voice 
           
              
              
                How does YouTube enforce its Community Guidelines 
    hours of video are uploaded to YouTube every minute  That s a lot of content  which is why our teams come together to make sure that what you see on our platform follows our Community Guidelines  To do that  we combine the power of advanced machine learning systems and our community itself to flag potentially problematic content  Our expert reviewers then remove flagged content that violates our Community Guidelines 
           
              
                      
                        How does YouTube identify content that violates Community Guidelines 
With hundreds of hours of new content uploaded to YouTube every minute  we use a combination of people and machine learning to detect problematic content at scale  Machine learning is well suited to detect patterns  which helps us to find content similar to other content we ve already removed  even before it s viewed 
We also recognize that the best way to quickly remove content is to anticipate problems before they emerge  Our Intelligence Desk monitors the news  social media  and user reports to detect new trends surrounding inappropriate content  and works to make sure our teams are prepared to address them before they can become a larger issue 
Is there a way for the broader community to flag harmful content 
The YouTube community also plays an important role in flagging content they think is inappropriate 


If you see content that you think violates Community Guidelines  you can use our flagging feature to submit content for review 


We developed the YouTube Trusted Flagger program to provide robust content reporting processes to non governmental organizations  NGOs  with expertise in a policy area and government agencies  Participants receive training on YouTube policies and have a direct path of communication with our Trust  amp  Safety specialists  Videos flagged by Trusted Flaggers are not automatically removed  They are subject to the same human review as videos flagged by any other user  but we may expedite review by our teams  NGOs also receive occasional online training on YouTube policies 


                      
                      
                        How does YouTube treat educational  documentary  scientific  or artistic content 
Sometimes videos that might otherwise violate our Community Guidelines may be allowed to stay on YouTube if the content offers a compelling reason with visible context for viewers  We often refer to this exception as  EDSA   which stands for  Educational  Documentary  Scientific or Artistic   To help determine whether a video might qualify for an EDSA exception  we look at multiple factors  including the video title  descriptions  and the context provided  
EDSA exceptions are a critical way we make sure that important speech stays on YouTube  while protecting the wider YouTube ecosystem from harmful content 
     Resources       How YouTube evaluates Educational  Documentary  Scientific  and Artistic  EDSA  content        Read more about how we treat EDSA content on YouTube        
                      
                      
                        What action does YouTube take for content that violates Community Guidelines 
Machine learning systems help us identify and remove spam automatically  as well as remove re uploads of content we ve already reviewed and determined violates our policies  YouTube takes action on other flagged videos after review by trained human reviewers  They assess whether the content does indeed violate our policies  and protect content that has an educational  documentary  scientific  or artistic purpose  Our reviewer teams remove content that violates our policies and age restrict content that may not be appropriate for all audiences  Reviewers  inputs are then used to train and improve the accuracy of our systems at a much larger scale 
       
Community Guidelines Strikes
If our reviewers decide that content violates our Community Guidelines  we remove the content and send a notice to the Creator  The first time a Creator violates our Community Guidelines  they receive a warning with no penalty to the channel  After one warning  we ll issue a Community Guidelines strike to the channel and the account will have temporary restrictions including not being allowed to upload videos  live streams  or stories for a   week period  Channels that receive three strikes within a    day period will be terminated  Channels that are dedicated to violating our policies or that have a single case of severe abuse of the platform  will bypass our strikes system and be terminated  All strikes and terminations can be appealed if the Creator believes there was an error  and our teams will re review the decision 
     Resources       Learn more about Community Guidelines strikes        Appeal a Community Guidelines strike        
Age Restricting Content
Sometimes content doesn t violate our Community Guidelines  but may not be appropriate for viewers under    years of age  In these cases  our review team will place an age restriction on the video so it will not be visible to viewers under    years of age  logged out users  or to those who have Restricted Mode enabled  Creators can also choose to age restrict their own content at upload if they think it s not suitable for younger audiences 
     Resources       Learn more about age restricted content        
                      
      
    
  



  
    
      
        
    Related articles
  
      
      
        
          
    Progress on managing harmful content
  

  
    
        Read more

    
  
        
        
          
    Managing harmful content
  

  
    
        Read more

    
  
        
        
          
    Legal removals
  

  
    
        Read more