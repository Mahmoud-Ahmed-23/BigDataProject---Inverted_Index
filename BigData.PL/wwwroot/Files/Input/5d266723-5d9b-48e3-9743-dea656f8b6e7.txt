Hypothetical outcome of artificial intelligence
Robots revolt in R U R   a      Czech play translated as  Rossum s Universal Robots 
Part of a series onArtificial intelligence  AI 
Major goals
Artificial general intelligence
Intelligent agent
Recursive self improvement
Planning
Computer vision
General game playing
Knowledge reasoning
Natural language processing
Robotics
AI safety

Approaches
Machine learning
Symbolic
Deep learning
Bayesian networks
Evolutionary algorithms
Hybrid intelligent systems
Systems integration

Applications
Bioinformatics
Deepfake
Earth sciences
 Finance 
Generative AI
Art
Audio
Music
Government
Healthcare
Mental health
Industry
Translation
 Military 
Physics
Projects

Philosophy
Artificial consciousness
Chinese room
Friendly AI
Control problem Takeover
Ethics
Existential risk
Turing test
Uncanny valley

History
Timeline
Progress
AI winter
AI boom

Glossary
Glossary
vte
An AI takeover is an imagined scenario in which artificial intelligence  AI  emerges as the dominant form of intelligence on Earth and computer programs or robots effectively take control of the planet away from the human species  which relies on human intelligence  Possible scenarios include replacement of the entire human workforce due to automation  takeover by an artificial superintelligence  ASI   and the notion of a robot uprising  Stories of AI takeovers have been popular throughout science fiction  but recent advancements have made the threat more real  Some public figures such as Stephen Hawking have advocated research into precautionary measures to ensure future superintelligent machines remain under human control            


Types edit 
Automation of the economy edit 
Main article  Technological unemployment
The traditional consensus among economists has been that technological progress does not cause long term unemployment  However  recent innovation in the fields of robotics and artificial intelligence has raised worries that human labor will become obsolete  leaving some people in various sectors without jobs to earn a living  leading to an economic crisis                                              Many small  and medium size businesses may also be driven out of business if they cannot afford or licence the latest robotic and AI technology  and may need to focus on areas or services that cannot easily be replaced for continued viability in the face of such technology            

Technologies that may displace workers edit 
AI technologies have been widely adopted in recent years  While these technologies have replaced some traditional workers  they also create new opportunities  Industries that are most susceptible to AI takeover include transportation  retail  and military  AI military technologies  for example  allow soldiers to work remotely without risk of injury  A study in      highlights AI s ability to perform routine and repetitive tasks poses significant risks of job displacement  especially in sectors like manufacturing and administrative support             Author Dave Bond argues that as AI technologies continue to develop and expand  the relationship between humans and robots will change  they will become closely integrated in several aspects of life  AI will likely displace some workers while creating opportunities for new jobs in other sectors  especially in fields where tasks are repeatable                       

Computer integrated manufacturing edit 
See also  Artificial intelligence in industry
Computer integrated manufacturing uses computers to control the production process  This allows individual processes to exchange information with each other and initiate actions  Although manufacturing can be faster and less error prone by the integration of computers  the main advantage is the ability to create automated manufacturing processes  Computer integrated manufacturing is used in automotive  aviation  space  and ship building industries 

White collar machines edit 
See also  White collar worker
The   st century has seen a variety of skilled tasks partially taken over by machines  including translation  legal research  and journalism  Care work  entertainment  and other tasks requiring empathy  previously thought safe from automation  have also begun to be performed by robots                                                 

Autonomous cars edit 
An autonomous car is a vehicle that is capable of sensing its environment and navigating without human input  Many such vehicles are operational and others are being developed  with legislation rapidly expanding to allow their use  Obstacles to widespread adoption of autonomous vehicles have included concerns about the resulting loss of driving related jobs in the road transport industry  and safety concerns  On March           the first human was killed by an autonomous vehicle in Tempe  Arizona by an Uber self driving car             

AI generated content edit 
See also  Artificial intelligence art
The use of automated content has become relevant since the technological advancements in artificial intelligence models such as ChatGPT  DALL E  and Stable Diffusion  In most cases  AI generated content such as imagery  literature  and music are produced through text prompts and these AI models have been integrated into other creative programs  Artists are threatened by displacement from AI generated content due to these models sampling from other creative works  producing results sometimes indiscernible to those of man made content  This complication has become widespread enough to where other artists and programmers are creating software and utility programs to retaliate against these text to image models from giving accurate outputs  While some industries in the economy benefit from artificial intelligence through new jobs  this issue does not create new jobs and threatens replacement entirely  It has made public headlines in the media recently  In February       Willy s Chocolate Experience in Glasgow  Scotland was an infamous children s event in which the imagery and scripts were created using artificial intelligence models to the dismay of children  parents  and actors involved  There is an ongoing lawsuit placed against OpenAI from The New York Times where it is claimed that there is copyright infringement due to the sampling methods their artificial intelligence models use for their outputs                                                             

Eradication edit 
Main article  Existential risk from artificial general intelligence
Scientists such as Stephen Hawking are confident that superhuman artificial intelligence is physically possible  stating  there is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains                           Scholars like Nick Bostrom debate how far off superhuman intelligence is  and whether it poses a risk to mankind  According to Bostrom  a superintelligent machine would not necessarily be motivated by the same emotional desire to collect power that often drives human beings but might rather treat power as a means toward attaining its ultimate goals  taking over the world would both increase its access to resources and help to prevent other agents from stopping the machine s plans  As an oversimplified example  a paperclip maximizer designed solely to create as many paperclips as possible would want to take over the world so that it can use all of the world s resources to create as many paperclips as possible  and  additionally  prevent humans from shutting it down or using those resources on things other than paperclips             

In fiction edit 
Main article  AI takeovers in popular culture
See also  Artificial intelligence in fiction and Self replicating machines in fiction
AI takeover is a common theme in science fiction  Fictional scenarios typically differ vastly from those hypothesized by researchers in that they involve an active conflict between humans and an AI or robots with anthropomorphic motives who see them as a threat or otherwise have active desire to fight humans  as opposed to the researchers  concern of an AI that rapidly exterminates humans as a byproduct of pursuing its goals              The idea is seen in Karel  apek s R U R   which introduced the word robot in                   and can be glimpsed in Mary Shelley s Frankenstein  published in        as Victor ponders whether  if he grants his monster s request and makes him a wife  they would reproduce and their kind would destroy humanity             
According to Toby Ord  the idea that an AI takeover requires robots is a misconception driven by the media and Hollywood  He argues that the most damaging humans in history were not physically the strongest  but that they used words instead to convince people and gain control of large parts of the world  He writes that a sufficiently intelligent AI with an access to the internet could scatter backup copies of itself  gather financial and human resources  via cyberattacks or blackmails   persuade people on a large scale  and exploit societal vulnerabilities that are too subtle for humans to anticipate             
The word  robot  from R U R  comes from the Czech word robota  meaning laborer or serf  The      play was a protest against the rapid growth of technology  featuring manufactured  robots  with increasing capabilities who eventually revolt              HAL             and the original Terminator        are two iconic examples of hostile AI in pop culture             

Contributing factors edit 
Advantages of superhuman intelligence over humans edit 
Nick Bostrom and others have expressed concern that an AI with the abilities of a competent artificial intelligence researcher would be able to modify its own source code and increase its own intelligence  If its self reprogramming leads to getting even better at being able to reprogram itself  the result could be a recursive intelligence explosion in which it would rapidly leave human intelligence far behind  Bostrom defines a superintelligence as  any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest   and enumerates some advantages a superintelligence would have if it chose to compete against humans                         

Technology research  A machine with superhuman scientific research abilities would be able to beat the human research community to milestones such as nanotechnology or advanced biotechnology
Strategizing  A superintelligence might be able to simply outwit human opposition
Social manipulation  A superintelligence might be able to recruit human support              or covertly incite a war between humans            
Economic productivity  As long as a copy of the AI could produce more economic wealth than the cost of its hardware  individual humans would have an incentive to voluntarily allow the Artificial General Intelligence  AGI  to run a copy of itself on their systems
Hacking  A superintelligence could find new exploits in computers connected to the Internet  and spread copies of itself onto those systems  or might steal money to finance its plans
Sources of AI advantage edit 
According to Bostrom  a computer program that faithfully emulates a human brain  or that runs algorithms that are as powerful as the human brain s algorithms  could still become a  speed superintelligence  if it can think orders of magnitude faster than a human  due to being made of silicon rather than flesh  or due to optimization increasing the speed of the AGI  Biological neurons operate at about          Hz  whereas a modern microprocessor operates at a speed of about                    Hz  Human axons carry action potentials at around          m s  whereas computer signals travel near the speed of light             
A network of human level intelligences designed to network together and share complex thoughts and memories seamlessly  able to collectively work as a giant unified team without friction  or consisting of trillions of human level intelligences  would become a  collective superintelligence              
More broadly  any number of qualitative improvements to a human level AGI could result in a  quality superintelligence   perhaps resulting in an AGI as far above us in intelligence as humans are above apes  The number of neurons in a human brain is limited by cranial volume and metabolic constraints  while the number of processors in a supercomputer can be indefinitely expanded  An AGI need not be limited by human constraints on working memory  and might therefore be able to intuitively grasp more complex relationships than humans can  An AGI with specialized cognitive support for engineering or computer programming would have an advantage in these fields  compared with humans who evolved no specialized mental modules to specifically deal with those domains  Unlike humans  an AGI can spawn copies of itself and tinker with its copies  source code to attempt to further improve its algorithms             

Possibility of unfriendly AI preceding friendly AI edit 
Is strong AI inherently dangerous  edit 
Main article  AI alignment
A significant problem is that unfriendly artificial intelligence is likely to be much easier to create than friendly AI  While both require large advances in recursive optimisation process design  friendly AI also requires the ability to make goal structures invariant under self improvement  or the AI could transform itself into something unfriendly  and a goal structure that aligns with human values and does not undergo instrumental convergence in ways that may automatically destroy the entire human race  An unfriendly AI  on the other hand  can optimize for an arbitrary goal structure  which does not need to be invariant under self modification             
The sheer complexity of human value systems makes it very difficult to make AI s motivations human friendly                          Unless moral philosophy provides us with a flawless ethical theory  an AI s utility function could allow for many potentially harmful scenarios that conform with a given ethical framework but not  common sense   According to Eliezer Yudkowsky  there is little reason to suppose that an artificially designed mind would have such an adaptation             

Odds of conflict edit 
Many scholars  including evolutionary psychologist Steven Pinker  argue that a superintelligent machine is likely to coexist peacefully with humans             
The fear of cybernetic revolt is often based on interpretations of humanity s history  which is rife with incidents of enslavement and genocide  Such fears stem from a belief that competitiveness and aggression are necessary in any intelligent being s goal system  However  such human competitiveness stems from the evolutionary background to our intelligence  where the survival and reproduction of genes in the face of human and non human competitors was the central goal              According to AI researcher Steve Omohundro  an arbitrary intelligence could have arbitrary goals  there is no particular reason that an artificially intelligent machine  not sharing humanity s evolutionary context  would be hostile or friendly unless its creator programs it to be such and it is not inclined or capable of modifying its programming  But the question remains  what would happen if AI systems could interact and evolve  evolution in this context means self modification or selection and reproduction  and need to compete over resources would that create goals of self preservation  AI s goal of self preservation could be in conflict with some goals of humans             
Many scholars dispute the likelihood of unanticipated cybernetic revolt as depicted in science fiction such as The Matrix  arguing that it is more likely that any artificial intelligence powerful enough to threaten humanity would probably be programmed not to attack it  Pinker acknowledges the possibility of deliberate  bad actors   but states that in the absence of bad actors  unanticipated accidents are not a significant threat  Pinker argues that a culture of engineering safety will prevent AI researchers from accidentally unleashing malign superintelligence              In contrast  Yudkowsky argues that humanity is less likely to be threatened by deliberately aggressive AIs than by AIs which were programmed such that their goals are unintentionally incompatible with human survival or well being  as in the film I  Robot and in the short story  The Evitable Conflict    Omohundro suggests that present day automation systems are not designed for safety and that AIs may blindly optimize narrow utility functions  say  playing chess at all costs   leading them to seek self preservation and elimination of obstacles  including humans who might turn them off             

Precautions edit 
Main article  AI control problem
The AI control problem is the issue of how to build a superintelligent agent that will aid its creators  while avoiding inadvertently building a superintelligence that will harm its creators              Some scholars argue that solutions to the control problem might also find applications in existing non superintelligent AI              
Major approaches to the control problem include alignment  which aims to align AI goal systems with human values  and capability control  which aims to reduce an AI system s capacity to harm humans or gain control  An example of  capability control  is to research whether a superintelligence AI could be successfully confined in an  AI box   According to Bostrom  such capability control proposals are not reliable or sufficient to solve the control problem in the long term  but may potentially act as valuable supplements to alignment efforts             

Warnings edit 
Physicist Stephen Hawking  Microsoft founder Bill Gates  and SpaceX founder Elon Musk have expressed concerns about the possibility that AI could develop to the point that humans could not control it  with Hawking theorizing that this could  spell the end of the human race               Stephen Hawking said in      that  Success in creating AI would be the biggest event in human history  Unfortunately  it might also be the last  unless we learn how to avoid the risks   Hawking believed that in the coming decades  AI could offer  incalculable benefits and risks  such as  technology outsmarting financial markets  out inventing human researchers  out manipulating human leaders  and developing weapons we cannot even understand   In January       Nick Bostrom joined Stephen Hawking  Max Tegmark  Elon Musk  Lord Martin Rees  Jaan Tallinn  and numerous AI researchers in signing the Future of Life Institute s open letter speaking to the potential risks and benefits associated with artificial intelligence  The signatories  believe that research on how to make AI systems robust and beneficial is both important and timely  and that there are concrete research directions that can be pursued today                          
Arthur C  Clarke s Odyssey series and Charles Stross s Accelerando relate to humanity s narcissistic injuries in the face of powerful artificial intelligences threatening humanity s self perception             

Prevention through AI alignment edit 
This paragraph is an excerpt from AI alignment  edit 
In the field of artificial intelligence  AI   alignment aims to steer AI systems toward a person s or group s intended goals  preferences  or ethical principles  An AI system is considered aligned if it advances the intended objectives  A misaligned AI system pursues unintended objectives             
See also edit 

Philosophy of artificial intelligence
Artificial intelligence arms race
Autonomous robot
Industrial robot
Mobile robot
Self replicating machine
Cyberocracy
Effective altruism
Existential risk from artificial general intelligence
Future of Humanity Institute
Global catastrophic risk  existential risk 
Government by algorithm
Human extinction
Machine ethics
Machine learning Deep learning
Transhumanism
Self replication
Technophobia
Technological singularity
Intelligence explosion
Superintelligence
Superintelligence  Paths  Dangers  Strategies

Notes edit 


References edit 


  Lewis  Tanya                Don t Let Artificial Intelligence Take Over  Top Scientists Warn   LiveScience  Purch  Archived from the original on             Retrieved October           Stephen Hawking and dozens of other top scientists and technology leaders have signed a letter warning of the potential dangers of developing artificial intelligence  AI  

  Lee  Kai Fu                The Real Threat of Artificial Intelligence   The New York Times  Archived from the original on             Retrieved             These tools can outperform human beings at a given task  This kind of A I  is spreading to thousands of domains  and as it does  it will eliminate many jobs 

  Larson  Nina                AI  good for the world     says ultra lifelike robot   Phys org  Archived from the original on             Retrieved             Among the feared consequences of the rise of the robots is the growing impact they will have on human jobs and economies 

  Santini  Jean Louis                Intelligent robots threaten millions of jobs   Phys org  Archived from the original on             Retrieved              We are approaching a time when machines will be able to outperform humans at almost any task   said Moshe Vardi  director of the Institute for Information Technology at Rice University in Texas 

  Williams Grut  Oscar                Robots will steal your job  How AI could increase unemployment and inequality   Businessinsider com  Business Insider  Archived from the original on             Retrieved             Top computer scientists in the US warned that the rise of artificial intelligence  AI  and robots in the workplace could cause mass unemployment and dislocated economies  rather than simply unlocking productivity gains and freeing us all up to watch TV and play sports 

   How can SMEs prepare for the rise of the robots    LeanStaff              Archived from the original on             Retrieved            

  Hassan Soueidan  Mohamad  Shoghari  Rodwan                The Impact of Artificial Intelligence on Job Loss  Risks for Governments   Technium Social Sciences Journal               doi          tssj v  i        

  Frank  Morgan                Toward understanding the impact of artificial intelligence on labor   Proceedings of the National Academy of Sciences of the United States of America                       Bibcode     PNAS          F  doi         pnas             PMC               PMID               

  Bond  Dave         Artificial Intelligence  pp             

  Skidelsky  Robert                Rise of the robots  what will the future of work look like    The Guardian  London  England  Archived from the original on             Retrieved    July      

  Bria  Francesca  February         The robot economy may already have arrived   openDemocracy  Archived from the original on    May       Retrieved    May      

  Srnicek  Nick  March           Reasons Why Technological Unemployment Might Really Be Different This Time   novara wire  Archived from the original on    June       Retrieved    May      

  Brynjolfsson  Erik  McAfee  Andrew          passim  see esp Chpt      The Second Machine Age  Work  Progress  and Prosperity in a Time of Brilliant Technologies  W  W  Norton  amp  Company  ISBN                     

  Wakabayashi  Daisuke  March             Self Driving Uber Car Kills Pedestrian in Arizona  Where Robots Roam   New York Times  New York  New York  Archived from the original on April           Retrieved March          

  Jiang  Harry H   Brown  Lauren  Cheng  Jessica  Khan  Mehtab  Gupta  Abhishek  Workman  Deja  Hanna  Alex  Flowers  Johnathan  Gebru  Timnit     August         AI Art and its Impact on Artists   Proceedings of the      AAAI ACM Conference on AI  Ethics  and Society  Association for Computing Machinery  pp                doi                          ISBN                        

  Ghosh  Avijit  Fossas  Genoveva     November         Can There be Art Without an Artist    arXiv             cs AI  

  Shan  Shawn  Cryan  Jenna  Wenger  Emily  Zheng  Haitao  Hanocka  Rana  Zhao  Ben Y     August         Glaze  Protecting Artists from Style Mimicry by Text to Image Models   arXiv             cs CR  

  Brooks  Libby     February         Glasgow Willy Wonka experience called a  farce  as tickets refunded   The Guardian  Retrieved   April      

  Metz  Cade  Robertson  Katie     February         OpenAI Seeks to Dismiss Parts of The New York Times s Lawsuit   The New York Times  Retrieved   April      

  Hawking  Stephen  Russell  Stuart J   Tegmark  Max  Wilczek  Frank    May         Stephen Hawking   Transcendence looks at the implications of artificial intelligence   but are we taking AI seriously enough     The Independent  Archived from the original on             Retrieved   April      

  M ller  Vincent C   Bostrom  Nick          Future Progress in Artificial Intelligence  A Survey of Expert Opinion   PDF   Fundamental Issues of Artificial Intelligence  Springer  pp                doi                               ISBN                         Archived  PDF  from the original on             Retrieved             AI systems will    reach overall human ability    very likely  with     probability  by       From reaching human ability  it will move on to superintelligence within    years          So   most of the AI experts responding to the surveys  think that superintelligence is likely to come in a few decades   

  Bostrom  Nick          The Superintelligent Will  Motivation and Instrumental Rationality in Advanced Artificial Agents   PDF   Minds and Machines          Springer         doi         s                  S CID                 Archived  PDF  from the original on             Retrieved            

  a b c d e f g h Bostrom  Nick  Superintelligence  Paths  Dangers  Strategies 

   The Origin Of The Word  Robot    Science Friday  public radio      April       Archived from the original on    March       Retrieved    April      

  Botkin Kowacki  Eva     October         A female Frankenstein would lead to humanity s extinction  say scientists   Christian Science Monitor  Archived from the original on    February       Retrieved    April      

  Ord  Toby          Unaligned artificial intelligence   The precipice  existential risk and the future of humanity  London  England and New York  New York  Bloomsbury academic  ISBN                        

  Hockstein  N  G   Gourin  C  G   Faust  R  A   Terris  D  J      March         A history of robots  from science fiction to surgical robotics   Journal of Robotic Surgery                  doi         s                  PMC               PMID               

  Hellmann  Melissa     September         AI      What is artificial intelligence and where is it going    The Seattle Times  Archived from the original on    April       Retrieved    April      

  Babcock  James  Kr mar  J nos  Yampolskiy  Roman V           Guidelines for Artificial Intelligence Containment   Next Generation Ethics  pp               arXiv             doi                            ISBN                     S CID               

  Baraniuk  Chris     May         Checklist of worst case scenarios could help prepare for evil AI   New Scientist  Archived from the original on    September       Retrieved    September      

  Yudkowsky  Eliezer S   May         Coherent Extrapolated Volition   Singularity Institute for Artificial Intelligence  Archived from the original on            

  Muehlhauser  Luke  Helm  Louie          Intelligence Explosion and Machine Ethics   PDF   Singularity Hypotheses  A Scientific and Philosophical Assessment  Springer  Archived  PDF  from the original on             Retrieved            

  Yudkowsky  Eliezer          Complex Value Systems in Friendly AI   Artificial General Intelligence  Lecture Notes in Computer Science  Vol             pp                doi                               ISBN                         ISSN                

  a b Pinker  Steven     February         We re told to fear robots  But why do we think they ll turn on us    Popular Science  Archived from the original on    July       Retrieved   June      

  Creating a New Intelligent Species  Choices and Responsibilities for Artificial Intelligence Designers Archived February          at the Wayback Machine   Singularity Institute for Artificial Intelligence      

  Omohundro  Stephen M   June        The basic AI drives  PDF   Artificial General Intelligence       pp                Archived  PDF  from the original on             Retrieved            

  Tucker  Patrick     Apr         Why There Will Be A Robot Uprising   Defense One  Archived from the original on   July       Retrieved    July      

  Russell  Stuart J     October        Human compatible        artificial intelligence and the problem of control  Penguin  ISBN                         OCLC                  Archived from the original on    March       Retrieved   January      

   Google developing kill switch for AI   BBC News    June       Archived from the original on    June       Retrieved   June      

  Rawlinson  Kevin     January         Microsoft s Bill Gates insists AI is a threat   BBC News  Archived from the original on    January       Retrieved    January      

   The Future of Life Institute Open Letter   The Future of Life Institute     October       Archived from the original on    March       Retrieved    March      

  Bradshaw  Tim     January         Scientists and investors warn on AI   The Financial Times  Archived from the original on   February       Retrieved   March      

  Kaminski  Johannes D   December         On human expendability  AI takeover in Clarke s Odyssey and Stross s Accelerando   Neohelicon                   doi         s                w  ISSN                 S CID                

  
Russell  Stuart J   Norvig  Peter         Artificial intelligence  A modern approach   th      ed    Pearson  pp                ISBN                     Retrieved September          


External links edit 
TED talk   Can we build AI without losing control over it   by Sam Harris
vteExistential risk from artificial intelligenceConcepts
AGI
AI alignment
AI capability control
AI safety
AI takeover
Consequentialism
Effective accelerationism
Ethics of artificial intelligence
Existential risk from artificial intelligence
Friendly artificial intelligence
Instrumental convergence
Vulnerable world hypothesis
Intelligence explosion
Longtermism
Machine ethics
Suffering risks
Superintelligence
Technological singularity
Organizations
Alignment Research Center
Center for AI Safety
Center for Applied Rationality
Center for Human Compatible Artificial Intelligence
Centre for the Study of Existential Risk
EleutherAI
Future of Humanity Institute
Future of Life Institute
Google DeepMind
Humanity 
Institute for Ethics and Emerging Technologies
Leverhulme Centre for the Future of Intelligence
Machine Intelligence Research Institute
OpenAI
People
Scott Alexander
Sam Altman
Yoshua Bengio
Nick Bostrom
Paul Christiano
Eric Drexler
Sam Harris
Stephen Hawking
Dan Hendrycks
Geoffrey Hinton
Bill Joy
Shane Legg
Elon Musk
Steve Omohundro
Huw Price
Martin Rees
Stuart J  Russell
Jaan Tallinn
Max Tegmark
Frank Wilczek
Roman Yampolskiy
Eliezer Yudkowsky
Other
Statement on AI risk of extinction
Human Compatible
Open letter on artificial intelligence       
Our Final Invention
The Precipice
Superintelligence  Paths  Dangers  Strategies
Do You Trust This Computer 
Artificial Intelligence Act
 Category
vteGlobal catastrophic risks
Future of the Earth
Future of an expanding universe
Ultimate fate of the universe
Human extinction risk estimates
Technological
Chemical warfare
Cyberattack
Cyberwarfare
Cyberterrorism
Cybergeddon
Ransomware
Gray goo
Nanoweapons
Kinetic bombardment
Kinetic energy weapon
Nuclear warfare
Mutual assured destruction
Dead Hand
Doomsday Clock
Doomsday device
Antimatter weapon
Electromagnetic pulse  EMP 
Safety of high energy particle collision experiments
Micro black hole
Strangelet
Synthetic intelligence   Artificial intelligence
AI takeover
Existential risk from artificial intelligence
Technological singularity
Transhumanism
Sociological
Anthropogenic hazard
Collapsology
Doomsday argument
Self indication assumption doomsday argument rebuttal
Self referencing doomsday argument rebuttal
Economic collapse
Malthusian catastrophe
New World Order  conspiracy theory 
Nuclear holocaust
cobalt
famine
winter
Riots
Social crisis
Societal collapse
State collapse
World War III
EcologicalClimate change
Anoxic event
Biodiversity loss
Mass mortality event
Cascade effect
Cataclysmic pole shift hypothesis
Deforestation
Desertification
Plant or animal species extinctions
Civilizational collapse
Tipping points
Climate sensitivity
Flood basalt
Global dimming
Global terrestrial stilling
Global warming
Hypercane
Ice age
Ecocide
Ecological collapse
Environmental degradation
Habitat destruction
Human impact on the environment
coral reefs
on marine life
Land degradation
Land consumption
Land surface effects on climate
Ocean acidification
Ozone depletion
Resource depletion
Sea level rise
Supervolcano
winter
Verneshot
Water pollution
Water scarcity
Earth Overshoot Day
Overexploitation
Overpopulation
Human overpopulation
BiologicalExtinction
Extinction event
Holocene extinction
Human extinction
List of extinction events
Genetic erosion
Genetic pollution
Others
Biodiversity loss
Decline in amphibian populations
Decline in insect populations
Biotechnology risk
Biological agent
Biological warfare
Bioterrorism
Colony collapse disorder
Defaunation
Dysgenics
Interplanetary contamination
Pandemic
Pollinator decline
Overfishing
Astronomical
Big Crunch
Big Rip
Coronal mass ejection
Cosmological phase transition
Geomagnetic storm
False vacuum decay
Gamma ray burst
Heat death of the universe
Proton decay
Virtual black hole
Impact event
Asteroid impact avoidance
Asteroid impact prediction
Potentially hazardous object
Near Earth object
winter
Rogue planet
Rogue star
Near Earth supernova
Hypernova
Micronova
Solar flare
Stellar collision
Eschatological
Buddhist
Maitreya
Three Ages
Hindu
Kalki
Kali Yuga
Last Judgement
Second Coming
  Enoch
Daniel
Abomination of desolation
Prophecy of Seventy Weeks
Messiah
Christian
Futurism
Historicism
Interpretations of Revelation
 Idealism
Preterism
  Esdras
  Thessalonians
Man of sin
Katechon
Antichrist
Book of Revelation
Events
Four Horsemen of the Apocalypse
Lake of fire
Number of the Beast
Seven bowls
Seven seals
The Beast
Two witnesses
War in Heaven
Whore of Babylon
Great Apostasy
New Earth
New Jerusalem
Olivet Discourse
Great Tribulation
Son of perdition
Sheep and Goats
Islamic
Al Qa im
Beast of the Earth
Dhu al Qarnayn
Dhul Suwayqatayn
Dajjal
Israfil
Mahdi
Sufyani
Jewish
Messiah
War of Gog and Magog
Third Temple
Norse
Zoroastrian
Saoshyant
Others
     end times prediction
     phenomenon
Apocalypse
Apocalyptic literature
Apocalypticism
Armageddon
Blood moon prophecy
Earth Changes
End time
Gog and Magog
List of dates predicted for apocalyptic events
Messianism
Messianic Age
Millenarianism
Millennialism
Premillennialism
Amillennialism
Postmillennialism
Nemesis  hypothetical star 
Nibiru cataclysm
Rapture
Prewrath
Posttribulation rapture
Resurrection of the dead
Vulnerable world hypothesis
World to come
Fictional
Alien invasion
Apocalyptic and post apocalyptic fiction
List of apocalyptic and post apocalyptic fiction
List of apocalyptic films
Climate fiction
Disaster films
List of disaster films
Zombie apocalypse
Zombie
Organizations
Centre for the Study of Existential Risk
Future of Humanity Institute
Future of Life Institute
Nuclear Threat Initiative
General
Disaster
Depression
Financial crisis
Survivalism

 World     portal
 Categories
Apocalypticism
Future problems
Hazards
Risk analysis
Doomsday scenarios






Retrieved from  https   en wikipedia org w index php title AI takeover amp oldid